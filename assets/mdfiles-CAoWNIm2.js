const e=`---
name: "Aditya Kumar Singh"
slug: "aditya-singh"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/128071145?v=4"

---


<!--markdownlint-disable-->

# About Aditya Kumar Singh

Hi! I'm Aditya Kumar Singh, a passionate software developer and open-source enthusiast from India, I'm currently pursuing my Bachelor's in Information Technology. I'm excited to be working with Sugar Labs as a GSoC 2025 contributor, where I'm enhancing the 3D Human Body and Stickman Animation Activities for Sugarizer.

## Experience

- **GSoC 2025 Contributor at Sugar Labs**  
  Working on Sugarizer Human Activity Pack enhancing the 3D Human Body Activity with anatomical layer toggling, Doctor Mode, and multiplayer support, and building a Stickman Animator with AI-based pose estimation.

## Current Projects

- **3D Human Body Activity (Sugarizer)**  
  A fully interactive anatomical learning tool using Three.js, localized UI, and collaborative learning features.

- **Stickman Animation Activity (Sugarizer)**  
  A creative animation tool where users can build motion sequences using a skeletal system, with onion skinning, AI-based pose estimation, and video export.


## Connect with Me

- **GitHub**: [@AdityaKrSingh26](https://github.com/AdityaKrSingh26)
- **Email**: [adityakrsingh2604@gmail.com](mailto:adityakrsingh2604@gmail.com)
- **LinkedIn**: [Aditya Kumar Singh](https://linkedin.com/in/adityakrsingh26)
- **Website**: [aditya-singh.me](https://aditya-singh.me)
- **Discord**: [praise_dark_lord](https://discord.com/users/praise_dark_lord)
`,co=Object.freeze(Object.defineProperty({__proto__:null,default:e},Symbol.toStringTag,{value:"Module"})),n=`---\r
name: "Aman Chadha"\r
slug: "aman-chadha"\r
title: "DMP'25 Contributor"\r
organization: "SugarLabs"\r
description: "DMP'25 Contributor at SugarLabs"\r
avatar: "https://avatars.githubusercontent.com/u/79802170?v=4"\r
---\r
\r
<!--markdownlint-disable-->\r
\r
# About Aman Chadha\r
\r
I am a DMP 2025 contributor working with Sugar Labs on enhancing Music Blocks' internationalization system using AI-supported translation. I'm passionate about building intelligent systems, developer tools, and creative educational platforms that empower users across languages.\r
\r
## Experience\r
\r
- Contributor at Sugar Labs (DMP '25)\r
\r
## Current Projects\r
\r
- **JS Internationalization with AI Translation Support**:  \r
  Integrating a modern i18n workflow in Music Blocks and enhancing it with AI-powered fallback translations, context-aware retrieval, and part-of-speech–informed RAG models.\r
\r
## Connect with Me\r
\r
- **GitHub**: [@ac-mmi](https://github.com/ac-mmi)\r
- **Email**: [aman.chadha.mmi@gmail.com](mailto:aman.chadha.mmi@gmail.com)\r
\r
`,uo=Object.freeze(Object.defineProperty({__proto__:null,default:n},Symbol.toStringTag,{value:"Module"})),t=`---
name: "Aman Naik"
slug: "amannaik247"
title: "DMP'25 Contributor"
organization: "SugarLabs"
description: "DMP'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/168978808?v=4"
---

<!--markdownlint-disable-->

# About Aman Naik

I’m someone who loves building smart tools that make life a little easier—whether it’s a chatbot that talks like Lord Krishna or a system that helps forecast real-time prices. I’ve explored everything from AI and machine learning to satellite data and creative writing prompts. I enjoy blending tech with storytelling, finding joy in both solving real problems and crafting meaningful experiences. For me, coding isn’t just logic, it’s a way to create things that connect with people.

## Experience

- DMP'25 contributor for SugarLabs  
- Active Open Source Contributor

## Current Projects

Adding an AI-assistant to the Write Activity 

## Connect with Me

- **GitHub**: [@amannaik247](https://github.com/amannaik247)
- **Email**: [amancodes247@gmail.com](mailto:your.email@example.com)
- **LinkedIn**: [Aman Naik](https://linkedin.com/in/aman-naik)`,ho=Object.freeze(Object.defineProperty({__proto__:null,default:t},Symbol.toStringTag,{value:"Module"})),a=`---
name: "Anvita Prasad"
slug: "anvita-prasad"
title: "DMP'25 Contributor"
organization: "SugarLabs"
description: "DMP'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/147875261?s=400&u=e784808241accea1d4c664bba0ce7bd6ca000662&v=4"
---

<!--markdownlint-disable-->

# About Anvita Prasad

Anvita is a DMP 2025 contributor at SugarLabs, working on improving synth and sample features in Music Blocks. A second-year Computer Science student at IIIT Kancheepuram and passionate open-source contributor, she strives to create meaningful and impactful experiences that bridge technology and creativity.

## Experience

- **DMP 2025**: Improving synth and sample features in Music Blocks
- **Sugar Labs Member**: Active contributor to Sugar's developer tooling and educational platforms
- **Music Theory**: Completed Grade 4 in Trinity music theory

## Current Projects

- Improving Synth and Sample Features in Music Blocks
- Music Blocks Developer

## Connect with Me

- **GitHub**: [@AnvitaPrasad](https://github.com/AnvitaPrasad)
- **Email**: [anvita.prasad1@gmail.com](mailto:anvita.prasad1@gmail.com)
- **LinkedIn**: [Anvita Prasad](https://www.linkedin.com/in/anvita-prasad)
- **Website**: [anvitaprasad.netlify.app](https://anvitaprasad.netlify.app/) `,go=Object.freeze(Object.defineProperty({__proto__:null,default:a},Symbol.toStringTag,{value:"Module"})),o=`---
name: "Bishoy Wadea"
slug: "bishoy-wadea"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/108888519?s=400&u=084aa7be2ae3aedd1cf38175557820a49b7efa93&v=4"
---

<!--markdownlint-disable-->

# About Bishoy Wadea

I am **Bishoy Wadea**, a Google Summer of Code 2025 contributor with Sugar Labs, developing a suite of math games to make learning more engaging and interactive. With prior experience at Microsoft and currently an R&D engineer at Siemens, I am passionate about building open-source tools that make complex ideas fun and approachable for learners.

## Experience

- **GSoC 2025**: Developing interactive math games for Sugar Labs.
- **R&D Backend Engineer Intern – Siemens**: Contributing to backend systems with a focus on performance, reliability, and scalability.
- **Microsoft Summer Engineering Program**: Built and optimized a 7TB data pipeline.

## Current Projects

- Developing 10 interactive math games for Sugar Labs.


## Connect with Me

- **GitHub**: [@bishoywadea](https://github.com/Bishoywadea)
- **Email**: [bishoyw.fathy@gmail.com](mailto:bishoyw.fathy@gmail.com)
- **LinkedIn**: [Bishoy Wadea](https://www.linkedin.com/in/bishoy-wadea-27b016250/)`,mo=Object.freeze(Object.defineProperty({__proto__:null,default:o},Symbol.toStringTag,{value:"Module"})),i=`---
name: "Diwangshu Kakoty"
slug: "diwangshu-kakoty"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "Member and GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/142284646?s=400&u=81be7e66ba1d554e6928fe267d68af5e2a90e359&v=4"
---

<!--markdownlint-disable-->

# About Diwangshu Kakoty

Hi, I'm Diwangshu - a B.Tech student and lifelong learner in computer science. I'm a dedicated contributor, community member, and a 2025 Google Summer of Code intern with SugarLabs, where I’m working on the project "AI Tools for Reflection." My passion lies in creativity and building meaningful solutions that benefit society, and I see coding as my way to bring those ideas to life.


## Experience

- **GSoC 2025**: AI Tools for Reflection Learning
- **SugarLabs Member**: Active contributor to various projects
- C, JS and Python development

## Current Projects

- AI Tools for Reflection Learning
- Music Blocks 3 development


## Connect with Me

- **GitHub**: [@Commanderk3](https://github.com/Commanderk3)
- **Email**: [diwangshukakoty@gmail.com](mailto:diwangshukakoty@gmail.com)
- **LinkedIn**: [Diwangshu Kakoty](https://www.linkedin.com/in/diwangshu-kakoty/)
- **Twitter**: [@redCoder101](https://twitter.com/redCoder101)
- **Discord**: [commanderk3](https://discord.com/users/commanderk3)`,po=Object.freeze(Object.defineProperty({__proto__:null,default:i},Symbol.toStringTag,{value:"Module"})),s=`---
name: "Elwin Li"
slug: "elwin-li"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "GSoC'25 Contributor at SugarLabs"
avatar: "https://i.ibb.co/rGyw3WZM/Untitled-design-1.webp"
---

<!--markdownlint-disable-->

# About Elwin Li

Elwin is a Google Summer of Code 2025 contributor for Sugarlabs, working on bridging the gap between text-based coding and block coding in MusicBlocks.

## Experience

- **GSoC 2025**: Enhancing the JSeditor through adding code to block conversion, and fully functional debugger

## Current Projects

- [Code to Block conversion](https://github.com/sugarlabs/musicblocks/pull/4707) (Completed)
- Debugger (WIP)
- Syntax highlighting (WIP)

## Connect with Me

- **GitHub**: [@ebeetles](https://github.com/ebeetles)
- **Gmail**: [elwin.s.li@gmail.com](mailto:elwin.s.li@gmail.com)
- **LinkedIn**: [Elwin Li](https://www.linkedin.com/in/elwinsli/)

`,bo=Object.freeze(Object.defineProperty({__proto__:null,default:s},Symbol.toStringTag,{value:"Module"})),r=`---
name: "Harshit Verma"
slug: "harshit-verma"
title: "Member and DMP'25 Contributor"
organization: "Sugar Labs"
description: "Member and DMP'25 Contributor at Sugar Labs"
avatar: "https://avatars.githubusercontent.com/u/169194753?v=4"
---

<!--markdownlint-disable-->

# About Harshit Verma

I'm Harshit Verma, a Computer Science Engineering student with a passion for technology, problem-solving, and building innovative software solutions.  
I'm currently exploring various areas of computer science, including software development, AI/ML, and system design. I enjoy turning ideas into code and continuously learning new tools and technologies to sharpen my skills. Whether it's contributing to open-source, building personal projects, or debugging complex systems, I'm always up for a challenge that helps me grow as a developer.

## Experience

- **DMP 2025**: LLM-Powered Debugger for Pippy
- **SugarLabs Member**: Member and Contributor to various projects
- **Hactoberfest 2024:** Contributed to Open-Source projects

## Current Projects

- LLM-Powered Debugger for Pippy
- Music Blocks Developer
- Sugar Labs website development

## Connect with Me

- **GitHub**: [@therealharshit](https://github.com/therealharshit)
- **Email**: [therealharshit014@gmail.com](mailto:therealharshit014@gmail.com)
- **LinkedIn**: [Harshit Verma](https://linkedin.com/in/therealharshit)
`,fo=Object.freeze(Object.defineProperty({__proto__:null,default:r},Symbol.toStringTag,{value:"Module"})),l=`---
name: "Justin Charles"
slug: "justin-charles"
title: "Member and DMP'25 Contributor"
organization: "Sugar Labs"
description: "Member and DMP'25 Contributor at Sugar Labs"
avatar: https://avatars.githubusercontent.com/u/143245796?s=400&u=56426d9e56b5d8ee545ba6b753e300d90e994eaa&v=4
---

<!--markdownlint-disable-->

# About Justin Charles

I'm Justin Charles, an enthusiastic Computer Science student passionate about open-source, creative coding, and building impactful developer tools.  
As a contributor at Sugar Labs and a participant in DMP 2025, I’m focused on improving the developer experience through intelligent tooling and user-centric design. I thrive on collaborative environments and believe in writing clean, maintainable code that scales.

## Experience

- **DMP 2025**: Enhancing Debugger Capabilities for Pippy using LLMs  
- **Sugar Labs Member**: Active contributor to Sugar's developer tooling and educational platforms  
- **Open Source Contributor**: Regular participant in Hacktoberfest and community-led initiatives

## Current Projects

- MusicBlocks-v4 Masonry Module
- Music Blocks Developer

## Connect with Me

- GitHub: [@justin212407](https://github.com/justin212407)
- Gmail: [charlesjustin2124@gmail.com](mailto:charlesjustin2124@gmail.com)
- LinkedIn: [Justin Charles](https://www.linkedin.com/in/justin-c-663840297/)
`,wo=Object.freeze(Object.defineProperty({__proto__:null,default:l},Symbol.toStringTag,{value:"Module"})),d=`---
name: "Krish Pandya"
slug: "krish-pandya"
title: "Maintainer and GSoC'25 Contributor"
organization: "SugarLabs"
description: "GSoC'25 Contributor at SugarLabs working on GTK4 migration"
avatar: "https://avatars.githubusercontent.com/u/135974627?s=400&u=d8834bf3a691f090819069974b42cf936a93b0e7&v=4"
---

<!--markdownlint-disable-->

# About Krish Pandya

I'm Krish, aka MostlyK, a B.Tech student in Electronics and Communication Engineering at IIITH. While my degree might say ECE, I've completely fallen down the open source rabbit hole. I believe in doing things right the first time, even if it takes longer, and I approach problems by understanding the "why" behind changes, not just the "what."

## Experience

- Systems engineering and graphics programming
- Open source development and contribution
- C/Python development
- Linux and System Adminstration

## Current Projects

- **GSoC 2025**: GTK4 migration for Sugar Labs desktop environment
- Modular architecture and newer build system design for Sugar
- Sugar-AI and it's implementation along with other fun stuff.

## Connect with Me

- **GitHub**: [@mostlykiguess](https://github.com/mostlykiguess)
- **Email**: [krishpandya93@gmail.com](mailto:krishpandya93@gmail.com)
- **LinkedIn**: [Krish Pandya](https://www.linkedin.com/in/krish-pandya-020aaa261/)
- **Mastodon**: [@mostlyk](https://mastodon.social/@mostlyk)
`,yo=Object.freeze(Object.defineProperty({__proto__:null,default:d},Symbol.toStringTag,{value:"Module"})),c=`---
name: "Mebin Thattil"
slug: "mebin-thattil"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "GSoC'25 Contributor at SugarLabs"
avatar: "https://mebin.shop/mebin-380.webp"
---

<!--markdownlint-disable-->

# About Mebin Thattil

Hey, I'm Mebin 👋🏻! I'm a first year student at PES University, Bangalore, India, currently pursuing a BTech in Computer Science. I’ve had a deep passion for tech ever since I was 10, when I first learned in a CS class that you could write a couple of lines of code and build a (barely functional) website. That simple idea sparked something in me, and over the years, my love for computer science has only grown—especially while building a bunch of cool things along the way.

I'm going to spend my summer working on the [Speak Activity](https://github.com/sugarlabs/speak). I will be refactoring the chatbot in the speak activity to use Gen-AI.

About a month ago, I launched my personal portfolio website: [mebin.in](https://mebin.in/). It runs on an 8-year-old Raspberry Pi sitting at home 🤩, so apologies in advance if the site is occasionally slow or down (power cuts are a real pain). I ocassionally write blogs there.

I'm also building a Bluesky client in the Nim programming language. I'm a strong advocate for education in technology. In the past, I built a web application aimed at connecting students in rural areas with those in urban areas to help foster a free and open peer-to-peer learning ecosystem.

## Connect with Me

- **GitHub**: [@mebinthattil](https://github.com/mebinthattil)
- **Website**: [mebin.in](https://mebin.in/)
- **Email**: [mail@mebin.in](mailto:mail@mebin.in)
- **LinkedIn**: [Mebin Thattil](https://www.linkedin.com/in/mebin-thattil/)
`,ko=Object.freeze(Object.defineProperty({__proto__:null,default:c},Symbol.toStringTag,{value:"Module"})),u=`---
name: "Muhammad Haroon"
slug: "muhammad-haroon"
title: "Member & SSoC'25 Contributor"
organization: "Sugar Labs"
description: "Member & SSoC'25 Contributor at Sugar Labs"
avatar: "/assets/Developers/Muhammad_Haroon/muhammadharoon.webp"
---

<!--markdownlint-disable-->

# About Muhammad Haroon

Hi, I’m Muhammad Haroon, a final year student at NED University Karachi, Pakistan, pursuing a degree in Computer Information & Systems Engineering.

I have been actively contributing to Sugar Labs for a long time not just in code, but also in documentation and by assisting new contributors.

This summer, I’ve been selected for Sugar Summer of Code (SSoC) 2025. This is the first time Sugar Labs is running this program, and I’m proud to be a pilot candidate. I’ll be working on Generative AI Instrument Sample Generation for Music Blocks, which will give students endless options for sound samples.

## Experience

- **SSoC 2025**: Generative AI Instrument Sample Generation for Music Blocks
- **Sugar Labs Member**: Active contributor to various projects

## Current Projects

- Generative AI Instrument Sample Generation for Music Blocks
- Sugar Labs website development

## Connect with Me

- **GitHub**: [@haroon10725](https://github.com/haroon10725)
- **Email**: [haroongondal347@gmail.com](mailto:haroongondal347@gmail.com)
- **LinkedIn**: [Muhammad Haroon](https://www.linkedin.com/in/muhammad-haroon-7003b923b/)`,vo=Object.freeze(Object.defineProperty({__proto__:null,default:u},Symbol.toStringTag,{value:"Module"})),h=`---
name: "Nikhil Bhatt"
slug: "nikhil-bhatt"
title: "GSoC'25 Contributor" 
organisation: "Sugarlabs"
description: "GSoc'25 Contributor, learning through code"
avatar: "https://avatars.githubusercontent.com/u/154296996?s=400&u=985121a969ea993a325f2690d74a0712f0599309&v=4"
---

<!--markdownlint-disable-->

# About Nikhil Bhatt
Nikhil Bhatt is a Google Summer of Code 2025 contributor and full stack product developer with a strong focus on building impactful, scalable tools.

## Experience

- **GSoC 2025**: Music Blocks v3 Backend Development

## Current Projects

- Git backend for Musicblocks


## Connect with Me

- **GitHub**: [BeNikk](https://github.com/BeNikk)
- **Email**: [bhattnik442@gmail.com](mailto:bhattnik442@gmail.com)
- **LinkedIn**: [Nikhil bhatt](https://www.linkedin.com/in/nikhil-bhatt-3b37a0255/)
- **Twitter**: [Nikhil](https://twitter.com/Be_Nikkk)
`,So=Object.freeze(Object.defineProperty({__proto__:null,default:h},Symbol.toStringTag,{value:"Module"})),g=`---
name: "Om Santosh Suneri"
slug: "om-santosh-suneri"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "Maintainer and GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/142336291?s=400&u=6f66e785309c44a70de1f634e768c60a47de3c1c&v=4"
---

<!--markdownlint-disable-->

# About Om Santosh Suneri

Suneri is a passionate open-source contributor and a Google Summer of Code 2025 contributor with SugarLabs. He is currently developing the AI-powered Debugger for Music Blocks, a project he originally conceptualized during one of SugarLabs’ biweekly community meetings. This innovative tool aims to assist learners and educators by automatically detecting and explaining errors in Music Blocks projects using LLMs and vector-based retrieval techniques. With a strong interest in the intersection of educational tools and artificial intelligence, Suneri is dedicated to building solutions that make learning to code more accessible and engaging for users of all ages.

## Experience

- **GSoC 2025**: AI-powered Debugger for Music Blocks
- **SugarLabs Maintainer**: Active contributor to various projects

## Current Projects

- AI-powered Debugger for Music Blocks  
- SugarLabs website development  
- Music Blocks Developer  


## Connect with Me

- **GitHub**: [@omsuneri](https://github.com/omsuneri)
- **Gmail**: [omsuneri@gmail.com](mailto:omsuneri@gmail.com)
- **LinkedIn**: [Om Santosh Suneri](https://www.linkedin.com/in/om-santosh-suneri-736767166/)
- **Twitter**: [@suneri_om](https://x.com/suneri_om)
`,Io=Object.freeze(Object.defineProperty({__proto__:null,default:g},Symbol.toStringTag,{value:"Module"})),m=`---
name: "Safwan Sayeed"
slug: "safwan-sayeed"
title: "Maintainer and GSoC'25 Contributor"
organization: "SugarLabs"
description: "Maintainer and GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/111475221?s=400&u=084aa7be2ae3aedd1cf38175557820a49b7efa93&v=4"
---

<!--markdownlint-disable-->

# About Safwan Sayeed

Safwan is a dedicated maintainer and Google Summer of Code 2025 contributor at SugarLabs, working primarily on the Music Blocks 4 Program Engine development. With a passion for educational technology and open-source development, Safwan contributes to making programming more accessible to learners worldwide.

## Experience

- **GSoC 2025**: Music Blocks 4 Program Engine development
- **SugarLabs Maintainer**: Active contributor to various projects

## Current Projects

- Music Blocks 4 Program Engine
- SugarLabs website development


## Connect with Me

- **GitHub**: [@sa-fw-an](https://github.com/sa-fw-an)
- **Email**: [isafwansayeed@gmail.com](mailto:isafwansayeed@gmail.com)
- **LinkedIn**: [Safwan Sayeed](https://linkedin.com/in/safwan-sayeed-6a3a482a9)
- **Twitter**: [@safwan_say](https://x.com/safwan_say)
- **Website**: [www.safwansayeed.in](https://safwansayeed.in)`,Ao=Object.freeze(Object.defineProperty({__proto__:null,default:m},Symbol.toStringTag,{value:"Module"})),p=`---
name: "Saumya Shahi"
slug: "saumya-shahi"
title: "GSoC'25 Contributor"
organization: "SugarLabs"
description: "GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/147405306?v=4"
---

<!--markdownlint-disable-->

# About Saumya Shahi

Saumya is a GSoC 2025 contributor at SugarLabs, currently working on the Masonry Module for Music Blocks. A second-year Computer Science student at IIIT Kottayam with a specialization in Cybersecurity, Saumya is passionate about building intuitive and impactful user experiences.

Beyond open source, Saumya actively explores quantum computing and cryptographic systems, and has contributed to research in quantum cryptanalysis under DRDO CQC.

## Experience

- **GSoC 2025**: Developing the Masonry Module for Music Blocks, a visual programming environment.
- **Quantum Cryptanalysis Research Intern**: DRDO CQC at NITK, working on cipher distinguishers using quantum algorithms

## Current Projects

- Music Blocks Masonry Module
- Quantum Feistel cryptanalysis 

## Connect with Me

- **GitHub**: [@saumyashahi](https://github.com/saumyashahi)
- **Email**: [saumya23bcy18@iiitkottayam.ac.in](mailto:saumya23bcy18@iiitkottayam.ac.in)
- **LinkedIn**: [Saumya Shahi](https://linkedin.com/in/saumya-shahi)
`,To=Object.freeze(Object.defineProperty({__proto__:null,default:p},Symbol.toStringTag,{value:"Module"})),b=`---
name: "Shubham Singh"
slug: "shubham-singh"
title: "Maintainer and GSoC'25 Contributor"
organization: "SugarLabs"
description: "Maintainer and GSoC'25 Contributor at SugarLabs"
avatar: "https://avatars.githubusercontent.com/u/174003514?s=400&u=e43600ba24f563f3799388137119ae119c74ffac&v=4"
---

<!--markdownlint-disable-->

# About Shubham

Shubham Singh is a passionate developer, open-source contributor, and Google Summer of Code 2025 contributor at SugarLabs. As a core contributor, he brings together creativity and functionality, optimizing both the user experience and technical performance of projects. Shubham is currently working on enhancing educational tools, with a focus on accessibility, interactivity, and meaningful design—empowering learners globally through open-source innovation.


## Experience

- **GSoC 2025**: Music Blocks v3 color sensor development
- **SugarLabs Maintainer**: Active contributor to various projects

## Current Projects

- Music Blocks v3 Development of Color Sensor.
- SugarLabs website development


## Connect with Me

- **GitHub**: [@FirePheonix](https://github.com/FirePheonix)
- **Email**: [shubhsoch@gmail.com](mailto:shubhsoch@gmail.com)
- **LinkedIn**: [Shubham Singh](https://www.linkedin.com/in/shubham-singh-8a5643198/)
- **Twitter**: [@shubhamm069](https://x.com/shubhamm069)
- **Website**: 
- **Discord**: [ctrlaltresett](https://discord.com/users/Shubham#0418)`,Po=Object.freeze(Object.defineProperty({__proto__:null,default:b},Symbol.toStringTag,{value:"Module"})),f=`---
title: "New foundation focused on taking the Sugar user interface to the next level of usability and utility"
category: "PRESS RELEASE"
date: "2008-05-15"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

Cambridge, Mass., May 15, 2008 — Sugar Labs Foundation is being established to further extend Sugar, the highly acclaimed open-source “learn learning” software platform originally developed for the One Laptop per Child (OLPC) XO laptop. Sugar is the core of the XO laptop’s human-computer interface; it provides a fun, easy-to-use, social experience that promotes sharing and learning.

Sugar Labs will focus on providing a software ecosystem that enhances learning on the XO laptop as well as other laptops distributed by companies such as the ASUS Eee PC. Consistent with OLPC’s mission to provide opportunities for learning, an independent Sugar Labs Foundation can deliver learning software to other hardware vendors and, consequently, reach more children.

Sugar Labs will take a proven learning concept to the next level of refinement, stability, and cohesiveness, and will be a unifying catalyst for free and open-source learning systems across multiple distribution and hardware platforms. The Labs will support a community of developers focused on learning, as well as support for the learners themselves. The Sugar platform has already been bundled with the most recent releases of the Ubuntu and Fedora GNU/Linux distributions.

Walter Bender, former president of software and content at OLPC, is helping launch Sugar Labs, working closely with developers and community members from around the world who have played lead roles in developing the Sugar user interface (UI). Prior to OLPC, Bender was executive director and a founding member of the Media Lab at MIT. He has participated in much pioneering research in electronic publishing and personalized, interactive multimedia.

In order to provide a rich learning experience to as many of the world’s children as possible, it is critical not just to provide computers to children, but also to ensure that the software maximizes their potential for engaging in learning activities: exploration, expression, and collaboration. By being independent of any specific hardware platform and by remaining dedicated to the principles of free and open-source software, Sugar Labs ensures that others can develop diverse interfaces and applications from which governments and schools can choose. An independent Sugar Labs ensures that the community can continue the development of a highly innovative interface that is already engaging children in learning in more than two dozen countries worldwide.

“This is a very exciting time in the development of software for children’s education,” said Walter Bender. “In the first generation of the Sugar UI, the free and open-source community has demonstrated an exceptional ability to create a platform that enables children to explore the world, share their discoveries, and express themselves. As a separate foundation, we will be able to advance Sugar’s development even further and make it available on multiple distributions and hardware platforms.”

Many of the core Sugar developers are participating in the launch, including Marco Pesenti Gritti, Bert Freudenberg, Simon Schampijer, Bernardo Innocenti, Aaron Kaplan, Christoph Derndorfer, and Tomeu Vizoso.

Bert Freudenberg, one of the developers of the Etoys activity, commented, “Expanding Sugar to more hardware platforms gives a great boost to all developers of educational software. Sugar is the first system specifically aimed at helping children to learn while supporting a rich variety of contributed applications. As third-party developers, my colleagues at Viewpoints Research Institute look forward to a great relationship with Sugar Labs.”

Tomeu Vizoso added, “Sugar has been brought to maturity by OLPC and a relatively small team of community supporters. The time has come to unlock Sugar’s potential as a global education project; the creation of Sugar Labs is the next step — expanding upon a project where people from all around the world can contribute to improving education, with the assurance that their efforts will be of benefit to everyone.”
`,Mo=Object.freeze(Object.defineProperty({__proto__:null,default:f},Symbol.toStringTag,{value:"Module"})),w=`---
title: "Sugar Labs joins the Software Freedom Conservancy"
category: "PRESS RELEASE"
date: "2008-12-09"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

Boston, MA, December 9, 2008 — Sugar Labs today announced its membership in the Software Freedom Conservancy, an organization of free and open-source software projects. Sugar Labs supports the free and open-source desktop environment, Sugar, originally created for the One Laptop per Child Project (OLPC). The Sugar community now has an active global developer base that is focused on engaging young children in learning through computing and the Internet. As a member of the Conservancy, the Sugar community will work to accelerate the adoption of the Sugar learning platform and strengthen the project by attracting new industry members and community contributors.

In May 2008, the Sugar project became independent of OLPC, making Sugar available to a wider community of developers and users. Subsequently, Sugar has been ported to Debian, Ubuntu, and other GNU/Linux distributions. Sugar can now run on almost any computer hardware. In October 2008, Sugar Labs released Sugar Version 0.82, which features enhanced usability and stability. In November, Sugar announced the availability of the pre-alpha version of “Sugar on a Stick,” a LiveUSB image of Sugar that gives children access to Sugar on any computer using just a USB key. Joining the Conservancy is an important milestone in the path toward making Sugar available to children everywhere.

Founded in March 2006, the Conservancy allows developers of its member projects to unite under a common organization that provides much-needed administrative services. This structure spares each software project the burden of starting and maintaining its own independent non-profit organization. Sugar Labs has joined as the Conservancy’s fifteenth member project.
`,Co=Object.freeze(Object.defineProperty({__proto__:null,default:w},Symbol.toStringTag,{value:"Module"})),y=`---
title: "La Asociación sin fines de lucro Sugar Labs Anuncia su Nueva Versión de la Plataforma de Aprendizaje Sugar para Niños que Funciona en Notebooks y PCs"
category: "PRESS RELEASE"
date: "2009-03-16"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR_es_20090316.pdf)

Cambridge, MA, March 16, 2009: Sugar Labs™ anuncia que la versión 0.84 de la Plataforma de Aprendizaje de Sugar para la XO-1 de OLPC, las PCs de aula y los notebooks ya se encuentra disponible. Diseñada desde un principio para los niños, el entorno Sugar es usado aproximadamente por un millón de estudiantes, cuyas edades fluctúan entre los 5 y 12 años, en aproximadamente 40 países durante todos los días del calendario escolar. Esta versión mejorada se caracteriza por poseer nuevas Actividades colaborativas. Asimismo, y en respuesta a la retroalimentación brindada por los docentes, posee la capacidad para detener y reanudar las Actividades con facilidad, lo cual permite ahorrar tiempo en el aula.

Walter Bender, Director Ejecutivo de Sugar Labs, comentó lo siguiente: “Nos encontramos muy emocionados con este lanzamiento que funciona en un mayor número de PCs que antes y posee Actividades nuevas y únicas para que los niños investiguen juntos, tales como la Actividad Mapa Mental, una herramienta de pensamiento crítico que se usa para crear diagramas que representan conceptos e ideas que se encuentran relacionados y dispuestos alrededor de una palabra clave o de una idea central y la Actividad Portafolio, una herramienta de evaluación que brinda mayor facilitad para que tanto los docentes como los padres de familia revisen el progreso que realiza el niño.” 

Igualmente, el Diario Sugar, que proporciona un back up automático y el historial del trabajo de los estudiantes, posee nuevas características a fin de permitirles tomar apuntes o hacer comentarios respecto a su trabajo, así como volver a visitar y revisar proyectos anteriores. Por su parte, la nueva Actividad Infoslicer (Selecciona y Corta Información) permite a los docentes seleccionar el contenido de páginas Web con facilidad y rapidez para editarlo, organizarlo y distribuirlo como material pedagógico. De igual modo, para los estudiantes mayores que tienen curiosidad por saber cómo funcionan las computadoras, la función Vista de Código es actualmente general para todas las Actividades.

La Plataforma de Aprendizaje Sugar es un software libre y de código abierto y se encuentra disponible para ser descargado en www.sugarlabs.org. Sugar, la interfaz originaria de la XO-1 de OLPC de uso diario en todo el mundo, ha sido traducida a 26 idiomas y tiene 50 idiomas más en proceso de traducción. El apoyo comunitario se encuentra disponible en línea las 24 horas al día/7 días a la semana. Sugar se encuentra disponible en las principales distribuciones GNU/Linux, las últimas computadoras con virtualización Apple Macintosh™ y las PCs Windows™ ejecutadas vía un Live CD de GNU/Linux que no modifica el disco duro. Igualmente, en el tercer trimestre del 2009, se ha programado el lanzamiento de Sugar en formato de tarjeta de memoria (memoria flash) extraíble, una versión de Live USB diseñada para simplificar el uso de Sugar en el aula.

La plataforma de aprendizaje de Sugar forma parte de la colección permanente del Museo de Arte Moderno de Nueva York. Asimismo, en los International Design Excellence Awards ’08 (Premios Internacionales a la Excelencia en Diseño 2008) le fue otorgada una medalla de plata. Su innovador enfoque “centrado en el aprendizaje” ha recibido elogios por parte de los docentes a nivel mundial. Las Actividades de Sugar, exclusivas de la plataforma, permiten a los alumnos estudiar y crear juntos. Los estudiantes aprenden tanto del docente como de otros alumnos.

El Sr. Bender comentó lo siguiente: “Sugar 0.84 representa un paso importante a medida que se trabaja para lograr la versión 1.0 de Sugar en formato de tarjeta de memoria extraíble que simplificará, en gran medida, la evaluación y el uso de Sugar en el aula. Asimismo, este formato de tarjeta de memoria extraíble hace posible que Sugar se ejecute a partir de un simple formato de memoria USB en casi cualquier computadora actual desde las notebooks (computadora portátil) hasta las desktops (computadora personal), así como en la mayoría de PCs más antiguas, sin interferir con las instalaciones de software preexistente.”

“A medida que nos aproximamos al millón de niños “aprendiendo a aprender” con Sugar en la XO-1 de OLPC, solicitamos voluntarios que se unan a nosotros — un reto para los programadores, diseñadores, traductores e implementadores”, refirió el Sr. Bender. “Necesitamos especialmente probadores de software que nos ayuden a hacer de Sugar en formato de tarjeta de memoria extraíble una sólida solución que se encuentre disponible dondequiera que exista una computadora.”
`,Lo=Object.freeze(Object.defineProperty({__proto__:null,default:y},Symbol.toStringTag,{value:"Module"})),k=`---
title: "Sugar Labs, organisation à but non lucratif, annonce la sortie de la nouvelle version de la plateforme d’apprentissage pour enfants Sugar pour PC et netbooks"
category: "PRESS RELEASE"
date: "2009-03-16"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->


[PDF](/assets/post-assets/press/SugarLabsPR_fr_20090316.pdf)

Cambridge, MA, le 16 mars 2009: Sugar Labs™ annonce la sortie de la version 0.84 de sa plateforme d’apprentissage Sugar destinée au XO-1 du projet One Laptop Per Child, aux micro-ordinateurs des établissements scolaires, et aux ordinateurs netbook. Conçu pour enfants de A à Z, l’environnement Sugar est utilisé par près d’un million d’élèves de 5 à 12 ans dans plus de 40 pays, tous les jours. Cette nouvelle version contient de nouvelles Activités Sugar à faire à plusieurs en travail collaboratif et, à la demande des professeurs, prévoit la possibilité d’interrompre et de reprendre facilement les Activités, pour gagner du temps en classe.

Walter Bender, Directeur Exécutif de Sugar Labs, a dit: "Cette nouvelle version est compatible avec beaucoup plus de PC qu’auparavant, et contient de nouvelles Activités que les enfants adoreront découvrir ensemble, comme l’Activité Mindmap, un outil qui développe l’esprit critique et permet de créér des diagrammes représentant des mots et des idées à partir d’un mot-clé central, et l’Activité Portfolio, un outil d’évaluation permettant aux professeurs et aux parents d’établir très simplement les progrès réalisés par l’enfant. Le Journal Sugar, qui fournit une sauvegarde automatique et un historique du travail de l’élève, comporte de nouvelles fonctionnalités permettant aux élèves d’annoter plus facilement leurs travaux, et de reprendre ou réviser des projets déjà réalisés. La nouvelle activité Infoslicer permet aux professeurs de sélectionner rapidement et facilement du contenu pris sur internet, de le modifier et de le remettre en forme pour le redistribuer comme documents pédagogiques. Et pour les élèves plus grands qui veulent savoir comment marchent les ordinateurs, la fonction View Source (voir code source) a été généralisée à toutes les Activités.”

La plateforme d’apprentissage Sugar est un logiciel libre. Elle peut être téléchargée sur le site www.sugarlabs.org. Interface d’origine du projet One Laptop Per Child déjà utilisé quotidiennement dans le monde entier, Sugar a déjà été traduite dans 26 langues et 50 autres doivent suivre. Un soutien technique de la communauté est disponible en ligne 24h/24, 7 jours/7. Sugar est disponible sur toutes les grandes distributions GNU/Linux, les ordinateurs Apple Macintosh™ récents avec virtualisation, et pour PC sous Windows™ via un liveCD GNU/Linux, qui ne touche pas au disque dur. Sugar on a Stick, une version liveUSB censée simplifier l’utilisation de Sugar en classe, doit sortir au 3e trimestre 2009.

La plateforme d’apprentissage Sugar fait partie de la collection permanente du Musée d’Art Moderne de New York, et a reçu la médaille d’argent au Palmarès 2008 de l’excellence du design international (International Design Excellence Awards). Son approche innovante, centrée sur l’apprentissage, a été saluée par les enseignants du monde entier. Les Activités Sugar, disponibles exclusivement sur cette plateforme, permettent aux élèves d’étudier et de créér ensemble: les étudiants apprennent du professeur mais aussi les uns des autres.

Selon M. Bender, “Sugar 0.84 est une étape importante vers la version 1.0 de Sugar on a Stick, qui va considérablement simplifier l’évaluation et l’utilisation de Sugar en classe. Avec Sugar on a Stick, on pourra lancer Sugar à partir d’une simple clé USB sur la plupart des ordinateurs récents, des netbooks aux ordinateurs de bureau, et aussi sur la plupart des vieux PC, sans perturber les logiciels déjà installés.”

“Alors que nous nous approchons du millionième enfant “apprenant à apprendre” avec Sugar sur le XO-1 de One Laptop per Child, nous appelons de nouveau bénévoles à venir nous aider à relever ce défi éducatif: développeurs, concepteurs, traducteurs, et déployeurs”, a déclaré M. Bender. “Nous avons notamment besoin de testeurs pour nous aider à faire de Sugar on a Stick une solution robuste qui fonctionnera avec n’importe quel ordinateur.”
`,xo=Object.freeze(Object.defineProperty({__proto__:null,default:k},Symbol.toStringTag,{value:"Module"})),v=`---
title: "Sugar Labs Nonprofit Announces New Version of Sugar Learning Platform for Children, Runs on Netbooks and PCs"
category: "PRESS RELEASE"
date: "2009-03-16"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR_en_20090316.pdf)

Cambridge, MA, March 16, 2009: Sugar Labs™ announces the availability of version 0.84 of the Sugar Learning Platform for the One Laptop Per Child XO-1, classroom PCs, and netbook computers. Designed from the ground up for children, the Sugar computer environment is used by almost one-million students aged 5 to 12 in over 40 countries every school day. This improved version features new collaborative Sugar Activities and, in response to teacher feedback, the ability to easily suspend and resume Activities, saving time in the classroom.

Walter Bender, Executive Director of Sugar Labs, commented: “We’re excited about this release, which runs on more PCs than before and has great new Activities for kids to explore together such as a Mindmap Activity, a critical-thinking tool used to create diagrams representing words and ideas around a central keyword, and a Portfolio Activity, an assessment tool that makes it even simpler for teachers and parents to review a child’s progress. The Sugar Journal, which provides automatic backup and history of students’ work, has new features to make it easier for students to annotate their work and to revisit and revise past projects. The new Infoslicer Activity enables teachers to quickly and easily select web-based content to edit, package, and distribute as teaching materials. And for older students curious about how computers work, the View Source function is now universal to all Activities.”

The Sugar Learning Platform is free open-source software; it is available for download at www.sugarlabs.org. The native interface of the One Laptop Per Child project’s XO-1 in daily use around the globe, Sugar has been translated into 26 languages with 50 more languages underway. 24/7 community support is available online. Sugar is available on major GNU/Linux distributions, recent Apple Macintosh™ computers with virtualization, and Windows™ PCs via a GNU/Linux liveCD, which doesn’t touch the hard disk. Sugar on a Stick, a liveUSB version designed to simplify classroom use of Sugar, is scheduled for release in Q3 2009.

The Sugar Learning Platform is part of the permanent collection of the Museum of Modern Art in New York and was awarded a silver medal in the International Design Excellence Awards ’08. Its innovative “learning-centric” approach has earned praise from educators worldwide. Sugar Activities, unique to the platform, allow students to study and create together; students learn both from the teacher and from each other.

Mr. Bender commented, “Sugar 0.84 is an important step as we work toward version 1.0 of Sugar on a Stick, which will greatly simplify evaluation and use of Sugar in the classroom. Sugar on a Stick will start Sugar from a simple USB memory stick on nearly any recent computer from netbooks to desktops, and most older PCs as well, without interfering with pre-existing software installations.”

“As we approach the one-millionth child ‘learning to learn’ with Sugar on the OLPC XO-1, we call for volunteers to join us—a challenge to educate for developers, designers, translators, and deployers,” Mr. Bender said. “In particular, we need testers to help us make Sugar on a Stick a robust solution available anywhere there is a computer.”
`,Go=Object.freeze(Object.defineProperty({__proto__:null,default:v},Symbol.toStringTag,{value:"Module"})),S=`---
title: "Sugar Labs kündigt neue Version von Sugar an—die Lernplattform für Kinder läuft auf Netbooks und PCs"
category: "PRESS RELEASE"
date: "2009-03-16"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR_de_20090316.pdf)

Cambridge, MA, 16. März, 2009: Sugar Labs™ hat die Version 0.84 der Lernplattform Sugar freigegeben. Die Software ist auf dem XO-1 von One Laptop Per Child, PCs und Netbooks einsetzbar. Die speziell für Kinder entwickelte Plattform wird von fast einer Million Schülern im Alter von 5 bis 12 Jahren in über 40 Ländern täglich im Schulunterricht eingesetzt.

Walter Bender, Geschäftsführer von Sugar Labs, sagt hierzu: “Wir sind gespannt auf die neue Version, die auf mehr PCs läuft als zuvor und neue, interessante Activities zum gemeinsamen Erkunden beinhaltet. Zum Beispiel die Mindmap Activity, ein Werkzeug zum Erstellen von Diagrammen, die Beziehungen zwischen einem Schlüsselwort und diesem zugeordneten Begriffen aufzeigen. Oder die Portfolio Activity, ein Bewertungswerkzeug, das es Lehrern und Eltern einfacher macht, den Fortschritt eines Kindes zu beurteilen. Das Journal, eine Art Tagebuch, das dem Schüler die chronologische Aufzeichnung seiner Aktivitäten bereitstellt, wurde erweitert. Der Schüler hat es nun leichter seine Arbeiten zu kommentieren und seine Projekte zu überarbeiten. Die neue Infoslicer Activity ermöglicht es Lehrern, schnell und einfach web-basierte Inhalte zu editieren, zusammenzustellen und als Lehrmaterial bereitzustellen. Schüler, die an der Funktionsweise eines Computers interessiert sind, können die View Source Funktion nutzen um tiefere Einblicke zu erhalten. Außerdem wurde in der Entwicklung der Software auf Verbesserungsvorschläge von Lehrern eingegangen. So ist es nun einfacher, vorangegangene Activities fortzuführen, wodurch im Unterricht Zeit eingespart werden kann.

Die Lernplattform Sugar ist Open Source Software und kann von www.sugarlabs.org heruntergeladen werden. Sugar wurde in 26 Sprachen übersetzt und 50 weitere Übersetzungen sind in Bearbeitung. Die Sugar-Gemeinschaft ist Online immer für Fragen und Anregungen offen. Die Plattform ist erhältlich in allen größeren Linux-Distributionen. Sugar kann als Live-System unter Windows™ von einem CD-Image gestartet werden und kann auf Apple Macintosh™ Computern virtualisiert ausgeführt werden. Sugar on a Stick, ein Live-System, das von USB-Speichermedien gestartet wird, und den Einsatz in Computerlaboren erleichtern soll, wird voraussichtlich im dritten Quartal von 2009 erscheinen.

Die Lernplattform Sugar ist Teil der ständigen Ausstellung des Museum of Modern Art in New York. 2008 erhielt sie die Silber-Medaille des International Design Excellence Awards in der Kategorie Interactive Product Experiences. Ihr innovativer lernorientierter Ansatz erhielt weltweites Lob von Pädagogen. Sugar Activities, die einmalig für diese Plattform sind, ermöglichen es den Schülern gemeinsam zu lernen und kreativ zu werden, Schüler können sowohl von ihrem Lehrer als auch voneinander lernen.

Bender fügt hinzu: “Sugar 0.84 ist ein wichtiger Schritt im Hinblick auf die Version 1.0 von Sugar on a Stick, die die Evaluation und die Anwendung von Sugar im Unterricht vereinfachen wird. Sugar on a Stick lädt Sugar von einem USB-Speichermedium auf nahezu jedem gängigen Computer, ob Netbook oder Desktop PC, ohne dabei mit der bereits installierten Software in Konflikt zu geraten.”

“Weil bald das millionste Kind mit Sugar auf dem OLPC XO-1 ‘lernt zu lernen’ laden wir alle Freiwilligen dazu ein, mitzumachen—eine Herausforderung für Entwickler, Pädagogen, Designer, Übersetzer und Anwender,” sagt Bender. “Vor allem brauchen wir Software-Tester, die uns helfen aus Sugar on a Stick eine Alternative zu vorhandener Software auf allen verfügbaren Computern zu machen.”
`,Wo=Object.freeze(Object.defineProperty({__proto__:null,default:S},Symbol.toStringTag,{value:"Module"})),I=`---
title: "Sugar Labs Announces Beta‑1 of Sugar on a Stick, LiveUSB Version of Sugar Learning Platform for Children"
category: "PRESS RELEASE"
date: "2009-04-22"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR_en_20090422.pdf)

Cambridge, MA, April 22, 2009: Sugar Labs™ announces the availability for testing of Sugar on a Stick Beta‑1. This version of the free open-source Sugar Learning Platform, available at [www.sugarlabs.org](http://www.sugarlabs.org) for loading on any 1 Gb or greater USB stick, is designed to facilitate exploration of the award-winning Sugar interface beyond its original platform, the One Laptop per Child XO‑1, to such varied hardware as aging PCs and recent Macs to the latest netbooks.

Teachers and parents interested in trying Sugar with children can download the Sugar on a Stick beta‑1 file from the Sugar Labs website and load it onto a USB stick by following the instructions at [wiki.sugarlabs.org/go/Sugar_on_a_Stick](https://wiki.sugarlabs.org/go/Sugar_on_a_Stick).

Walter Bender, Executive Director of Sugar Labs, said: “Sugar is perfectly suited for children in the classroom with its simple, colorful interface, built-in collaboration, and open architecture. Sugar on a Stick lets you start a computer with Sugar and store a child’s data on the stick without touching the host computer’s hard disk. Sugar’s Activities such as Write, a shared word processor, and the recently announced InfoSlicer Activity, which enables teachers to easily collect and package web-based content for the classroom, benefit fully from Sugar’s collaboration features.”

Caroline Meeks of Solution Grove ([www.solutiongrove.com](http://www.solutiongrove.com)), the Sugar on a Stick project manager, commented: “We’re counting on teachers to help us improve Sugar on a Stick as we work towards our Version‑1 release scheduled for Q3 2009. We just presented Sugar on a Stick at the FOSS VT conference (<http://www.ncose.org/node/47>) where it generated great interest, and our real-world tests at local sites with varied aging PCs have been very encouraging.”

Sugar testers are invited to send bug information and constructive criticism to [feedback@sugarlabs.org](mailto:feedback@sugarlabs.org). “We won’t be able to reply to every message,” continued Ms. Meeks, “but we will read every one in order to make Sugar on a Stick a reliable learning tool in budget-stretched classrooms by the fall.”
`,Do=Object.freeze(Object.defineProperty({__proto__:null,default:I},Symbol.toStringTag,{value:"Module"})),A=`---
title: "Sugar Labs annonce la bêta-1 de Sugar on a Stick, version LiveUSB de Sugar, la plate-forme d’apprentissage pour enfants"
category: "PRESS RELEASE"
date: "2009-04-22"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->


[PDF](/assets/post-assets/press/SugarLabsPR_fr_20090422.pdf)

Cambridge, MA, April 22, 2009: Sugar Labs™ annonce la disponibilité pour tests de la version Bêta-1 de Sugar on a Stick. Cette version du logiciel libre Sugar Learning Platform, disponible sur www.sugarlabs.org pour téléchargement dans n’importe quelle clef USB de 1 Go ou plus, a été conçue pour permettre d’explorer la célèbre interface Sugar au-delà de sa plate-forme d’origine, le XO-1 de One Laptop per Child, sur toutes sortes d’ordinateurs, des PCs anciens aux Macintosh récents en passant par les nouveaux netbooks.

Les enseignants et parents qui veulent essayer Sugar avec des enfants peuvent télécharger le fichier bêta-1 de Sugar on a Stick sur le site web de Sugar Labs et le charger sur une clef USB en suivant les instructions sur [wiki.sugarlabs.org/go/Sugar_on_a_Stick](https://wiki.sugarlabs.org/go/Sugar_on_a_Stick).

Walter Bender, le directeur exécutif de Sugar Labs, a dit : “Sugar est parfaitement adapté aux élèves avec son interface simple et vivante, pensée pour le travail en commun, et avec son architecture ouverte. Sugar on a Stick vous permet de démarrer un ordinateur avec Sugar et de stocker les données de l’enfant dans la clef sans toucher au disque dur de l’ordinateur hôte. Les Activités de Sugar telles que Write, un traitement de texte partagé, et l’Activité InfoSlicer annoncé récemment, qui permet aux enseignants de collectionner et réunir facilement des contenus du web pour la classe, bénéficient pleinement des caractéristiques collaboratives de Sugar.”

Caroline Meeks de Solution Grove ([www.solutiongrove.com](http://www.solutiongrove.com)), gestionnaire du projet Sugar on a Stick, a commenté : “Nous comptons sur les enseignants pour nous aider à améliorer Sugar on a Stick tandis que nous continuons à travailler sur la Version-1 prévue pour le troisième trimestre 2009. Nous venons de présenter Sugar on a Stick à la conférence FOSS VT (<http://www.ncose.org/node/47>) où il a suscité beaucoup d’intérêt, et nos tests sur le terrain avec des PCs variés et anciens ont été très encourageants.”

Les testeurs de Sugar sont invités à envoyer des informations sur tout bogue et autres critiques constructives à l’adresse suivante : [feedback@sugarlabs.org](mailto:feedback@sugarlabs.org). “Nous ne pourrons pas répondre à chaque message,” a continué Mme Meeks, “mais nous allons lire chacun afin de rendre Sugar on a Stick un outil fiable dans les classes qui manquent de ressources d’ici la rentrée.”
`,_o=Object.freeze(Object.defineProperty({__proto__:null,default:A},Symbol.toStringTag,{value:"Module"})),T=`---
title: "Sugar Labs Announces Immediate Availability of Sugar on a Stick; Learning Platform Runs on Any PC or Netbook In The Classroom"
category: "PRESS RELEASE"
date: "2009-06-24"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

LinuxTag, Berlin, June 24, 2009: Sugar Labs™, nonprofit provider of the Sugar Learning Platform to over one-million children worldwide, announces the immediate availability of Sugar on a Stick v1 Strawberry. Available free for download at [www.sugarlabs.org](http://www.sugarlabs.org), Sugar on a Stick can be loaded onto an ordinary 1GB USB flash drive and used to reboot any PC or netbook directly into the award-winning Sugar environment. It runs on recent Macs with a helper CD and in Windows using virtualization. Sugar on a Stick is designed to work with a School Server that can provide content distribution, homework collection, backup services, Moodle integration, and filtered access to the Internet. Today’s Strawberry release is meant for classroom testing; [feedback](mailto:feedback@sugarlabs.org) will be incorporated into the next version, available towards the end of 2009.

“One year after its founding, Sugar Labs is delivering on its education promise for its second million learners,” commented Walter Bender, founder and executive director. “Sugar is preferred because it is a superior learning experience for young children: engaging while being affordable. Sugar on a Stick is a great way to try Sugar without touching your computer’s hard disk. It is also well suited to slower, older PCs and low-powered netbooks. There is a version for the OLPC XO-1 and it will ship with the newer XO-1.5 laptops in the fall.”

Sugar on a Stick provides a coherent and consistent computing experience. It reduces costs by providing flexibility in hardware choices, allowing schools to keep their existing investment in hardware. Learners can benefit from the increased household ownership of computers; by bringing Sugar on a Stick home, every student has a consistent, comparable computing environment that parents can share in as well. It also provides off-line access to applications and content as not every learner has Internet access at home.

As part of an ongoing effort to make Sugar on a Stick classroom-ready, Sugar Labs has been awarded a $20,000 grant from the Gould Charitable Foundation to implement Sugar at the Gardner Pilot Academy, a public elementary school located in one of the most culturally and linguistically diverse sections of Boston, Massachusetts.

Learning Activities are at the heart of Sugar. Sugar on a Stick includes 40 Activities to interest young learners such as Read, Write, Paint, and Etoys. Hundreds more Activities are available free for download at the [Sugar Activity Library](http://activities.sugarlabs.org). Most “Sugarized” Activities have student collaboration built-in; students and teachers work, play, and learn on the same Activities together. The Sugar Learning Platform is open, so by leveraging the work of other open source projects, existing software for children can be integrated; for example, the acclaimed GCompris suite of 100 Activities developed over the past five years by Bruno Coudoin was recently added to Sugar, including Activities such as Chess, Geography, and Sudoku. Teachers and parents interested in Sugar’s Activities and its modern interface for children can watch short videos on the recently opened [Sugar Labs Dailymotion channel](http://www.dailymotion.com/sugarlabs).

Visitors to LinuxTag are welcome to speak with Sugar Labs contributors at booth 7.2a 110a.
`,Eo=Object.freeze(Object.defineProperty({__proto__:null,default:T},Symbol.toStringTag,{value:"Module"})),P=`---
title: "Sugar Labs annonce la disponibilité immédiate de « Sugar on a Stick », une plate-forme d’apprentissage qui fonctionne sur n’importe quel PC ou netbook dans la salle de classe"
category: "PRESS RELEASE"
date: "2009-06-24"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->


LinuxTag, Berlin, 24 Juin 2009: Sugar Labs™, fournisseur à but non-lucratif de la plate-forme pédagogique Sugar à plus d’un million d’enfants dans le monde, annonce la disponibilité immédiate de « Sugar on a Stick v1 Strawberry » (« Bâtonnet de Sucre v1 Fraise »). Logiciel libre disponible en téléchargement gratuit sur [www.sugarlabs.org](http://www.sugarlabs.org), Sugar on a Stick peut être chargé sur une clef USB 1Gb ordinaire et utilisée pour rebooter n’importe quel PC ou netbook dans l’environnement Sugar. Celui-ci tourne sur les Macs récents avec un CD de support et dans Windows en utilisant la virtualisation. Sugar on a Stick est conçu pour marcher avec un serveur d’école qui peut dispenser des contenus, des collections de devoirs à la maison, des services de sauvegarde, l’intégration de Moodle, et un filtrage de l’accès à internet. La version « Fraise » d’aujourd’hui est destinée à être testée dans la salle de classe ; les [retours d’expérience](mailto:feedback@sugarlabs.org) seront intégrés dans la prochaine version, disponible vers la fin 2009.

« Un an après sa fondation, Sugar Labs tient ses promesses pédagogiques pour son second million d’apprenants », commente Walter Bender, fondateur et directeur exécutif. « Sugar est choisi parce qu’il permet une expérience d’apprentissage supérieure pour les jeunes enfants qui l’explorent, tout en étant abordable. Sugar on a Stick est une formidable manière de tester Sugar sans toucher au disque dur de votre ordinateur. C’est aussi bien adapté aux ordinateurs plus lents, aux vieux PCs et aux netbooks peu puissants. Il y a une version pour le XO-1 d’OLPC et cela sera expédié avec les nouveaux XO-1.5 à partir de l’automne. »

Sugar on a Stick fournit une expérience informatique cohérente et conforme. Il réduit les coûts en rendant souple les choix des matériels, permettant aux écoles de conserver leur investissement existant en matériel. Les apprenants peuvent bénéficier du taux grandissant des ordinateurs familials ; en rentrant à la maison avec Sugar on a Stick, chaque étudiant possède son environnement habituel que les parents peuvent partager aussi. Il fournit aussi un accès différé aux applications et contenus, utile pour des apprenants dépourvus d’un accès Internet à la maison.

L’effort pour rendre Sugar on a Stick prêt pour la salle de classe continue ; Sugar Labs a décerné une subvention de $20.000 de la Gould Charitable Foundation pour implémenter Sugar au Gardner Pilot Academy, une école primaire publique située dans un quartier populaire et multiculturel de Boston dans l’état de Massachusetts.

Les Activités pour apprendre sont au cœur de Sugar. Sugar on a Stick est fourni avec 40 Activités intéressantes pour des jeunes apprenants tels que Lire, Écrire, Dessiner, et EToys. Des centaines d’autres Activités sont disponibles gratuitement sur la [Bibliothèque d’Activités Sugar](http://activities.sugarlabs.org). La plupart d’activités « sucrées » offrent la collaboration en natif ; les étudiants et enseignants travaillent, jouent, et apprennent ensemble sur les mêmes Activités. La plate-forme d’apprentissage Sugar est ouverte et bénéficie des travaux d’autres projets ; des logiciels existants peuvent être intégrés. Par exemple, plus de 100 activités tels que Échecs, Géographie, et Sudoku de la suite acclamée GCompris développée depuis cinq ans par Bruno Coudoin ont été ajoutés récemment à Sugar. Des enseignants et parents qui s’intéressent aux activités de Sugar et à son interface moderne pour enfants peuvent visionner de courtes vidéos sur le nouveau canal [Dailymotion de Sugar Labs](http://www.dailymotion.com/sugarlabs).

Les visiteurs à LinuxTag sont invités à dialoguer avec des contributeurs de Sugar Labs au stand 7.2a 110a.
`,jo=Object.freeze(Object.defineProperty({__proto__:null,default:P},Symbol.toStringTag,{value:"Module"})),M=`---
title: "Sugar Labs annuncia l’immediata disponibilità di Sugar on a Stick; La Piattaforma di Apprendimento in grado di funzionare su qualsiasi PC o Netbook disponibile in classe"
category: "PRESS RELEASE"
date: "2009-06-24"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

Berlino, 24 Giugno, 2009: Sugar Labs, la realtà no-profit che ha sviluppato la Piattaforma di Apprendimento Sugar (Sugar Learning Platform) utilizzata da più di un milione di bambini nel mondo intero, annuncia l’immediata disponibilità di "Sugar on a Stick" v1 Strawberry. Disponibile in forma libera e gratuita dal sito [www.sugarlabs.org](http://www.sugarlabs.org), Sugar on a Stick può essere caricato su una normale chiavetta USB da almeno 1Gb e utilizzandola per avviare direttamente il sistema Sugar in qualunque PC o netbook. Può essere utilizzato anche sui più recenti sistemi Mac con l’ausilio di un CD di avvio, e all’interno di sistemi Windows attraverso la virtualizzazione. “Sugar on a Stick” è stato progettato per l’utilizzo insieme ad uno School Server che fornisce distribuzione di contenuti, raccolta di elaborati, servizi di backup, integrazione con la piattaforma Moodle, e accesso protetto ad Internet. La versione odierna di “Sugar on a Stick” v1 Strawberry è pensata per la sperimentazione in classe ([feedback](mailto:feedback@sugarlabs.org)); la prossima versione sarà rilasciata entro la fine del 2009.

"Ad un anno dalla fondazione, Sugar Labs sta rilasciando quanto promesso per il suo secondo milione di studenti" commenta Walter Bender, fondatore e direttore esecutivo. "Sugar viene preferito perché offre grandi opportunità educative ai giovani allievi: attraente e di facile approccio. Sugar on a Stick è un modo eccezionalmente semplice per provare Sugar senza dover installare nulla sul proprio computer. Si tratta inoltre di una soluzione ottima per computer vecchi, lenti o per netbook non particolarmente potenti. Esiste una versione specifica per OLPC XO-1 e questa sarà la versione distribuita con i nuovi XO-1.5 laptop a partire dal prossimo autunno."

Sugar on a Stick fornisce un ambiente coerente e consistente per le attività. Permette una riduzione di costi offrendo adattabilità a molteplici soluzioni hardware, permettendo alle scuole di conservare e riutilizzare gli investimenti in hardware effettuati nel passato. Gli studenti potranno beneficiare della accresciuta possibilità di utilizzare anche a casa i propri strumenti didattici; portando a casa “Sugar on a Stick”, ogni studente ritroverà il proprio ambiente di lavoro scolastico abituale, anche utilizzando computer di famigliari. Permetterà inoltre ad ogni utilizzatore di continuare a utilizzare le proprie applicazioni e contenuti anche off-line, posto che non tutti possano disporre di connessioni ad internet a casa.

Come supporto allo sforzo di rendere “Sugar on a Stick” pronto per l’utilizzo in classe, Sugar Labs ha ricevuto un sussidio di $20,000 da parte della Gould Charitable Foundation per rilasciare Sugar presso la Gardner Pilot Academy, una scuola elementare pubblica situata in una delle aree di Boston, Massachusetts, caratterizzata da una grande varietà culturale e linguistica.

Le Attività di Apprendimento sono il cuore di Sugar. “Sugar on a Stick” include 40 attività preinstallate per catturare l’interesse dei giovani studenti, fra queste Leggi, Scrivi, Disegna, e l’ambiente Etoys. Altre centinaia di attività sono disponibili per essere liberamente scaricate dalla [Sugar Activity Library](http://activities.sugarlabs.org). La maggior parte delle attività "Sugarized" possiedono funzionalità di collaborazione native; gli studenti ed i docenti possono lavorare, giocare ed imparare tutti insieme condividendo le stesse attività. La “Sugar Learning Platform” è aperta, quindi approfittando del lavoro di altri progetti OpenSource, software didattico per bambini già esistente può essere integrato; per esempio, la famosa suite GCompris comprendente più di 100 attività didattiche e ludiche sviluppata nel corso degli scorsi cinque anni da Bruno Coudoin è stata recentemente integrata, comprendendo fra le altre Attività come Scacchi, Geografia e Sudoku. Docenti e genitori interessati a valutare le attività di Sugar e la sua innovativa interfaccia utente specificamente progettata per i bambini possono visionare i filmati disponibili sul canale recentemente attivato da [Sugar Labs su Dailymotion](http://www.dailymotion.com/sugarlabs).

I partecipanti a LinuxTag sono caldamente invitati ad incontrare i collaboratori di Sugar Labs presso lo stand 7.2a 110a.
`,Bo=Object.freeze(Object.defineProperty({__proto__:null,default:M},Symbol.toStringTag,{value:"Module"})),C=`---
title: "Sugar Labs anuncia la disponibilidad inmediata de Sugar On A Stick (Sugar en un pendrive). El plataforma de aprendizaje funciona en casi cualquier PC o portátil que hay en el aula."
category: "PRESS RELEASE"
date: "2009-06-24"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

LinuxTag, Berlín, 24 de junio de 2009: Sugar Labs™, proveedor sin fines de lucro de la plataforma de aprendizaje de Sugar a más de un millón de niños en todo el mundo, anuncia la disponibilidad inmediata de Sugar on a Stick (SoaS) v1 Strawberry (Fresa). Disponible para su descarga gratuita en [www.sugarlabs.org](www.sugarlabs.org), SoaS se puede cargar en una pendrive USB de 1 GB y se utiliza para reiniciar casi cualquier PC, o usar directamente en el portátil y entrar a Sugar, el ambiente premiado de aprendizaje. Funciona en los últimos equipos Mac con la ayuda de un CD y en Windows usando la virtualización.

Sugar on a Stick está diseñado para trabajar con un servidor de colegio que puede proporcionar la distribución de contenidos, el recojo de tareas, los servicios de copia de seguridad, la integración de Moodle y la filtración del acceso a Internet. El Strawberry de hoy está listo para probarse en las escuelas. [Comentarios](mailto:feedback@sugarlabs.org) se incorporarán en la próxima versión, disponible a finales de 2009.

"Un año después de su fundación, Sugar Labs está cumpliendo su promesa de educación para su segundo millón de estudiantes", comentó Walter Bender, fundador y director ejecutivo. "Sugar es preferido porque ofrece una excelente experiencia de aprendizaje para los niños pequeños: divertida y económica. Sugar on a Stick es una gran manera de probar Sugar sin tocar el disco duro de la computadora. También es muy adecuado para las computadoras más lentas, más antiguas y para las portátiles pequeñas de baja potencia. Existe una versión para la OLPC XO-1 y se suministrará con las nuevas computadoras portátiles XO-1.5 en el otoño."

Sugar on a Stick ofrece una experiencia coherente y consistente. Reduce costos, proporcionando flexibilidad en opciones de tipos de computadoras, permitiendo que las escuelas mantengan sus inversiones existentes en sus aparatos. Para los que tienen computadora en casa, pueden llevar el Sugar on a Stick consigo. Cada estudiante tiene un ambiente de computación coherente y comparable que los padres pueden compartir también. Además, proporciona acceso fuera de línea a aplicaciones y contenido para los alumnos que no tienen acceso a Internet en casa.

Como parte de un esfuerzo continuo para hacer Sugar on a Stick listo para las aulas, Sugar Labs ha recibido una subvención de 20.000 dólares de la Fundación de Beneficencia Gould para aplicar un proyecto piloto de Sugar en la Academia Gardner, una escuela primaria ubicada en una de las más cultural y lingüísticamente diversas secciones de Boston, Massachusetts.

Actividades dirigidas al aprendizaje están en el corazón de Sugar. Sugar on a Stick incluye 40 actividades de interés para los jóvenes estudiantes tales como Leer, Escribir, Pintura y Etoys. Cientos de actividades están disponibles para su descarga gratuita en la [biblioteca de Actividades de Sugar](http://activities.sugarlabs.org). La mayoría de las actividades "Sugarized" han incorporado la colaboración de estudiantes. Los alumnos y profesores trabajan, juegan y aprenden juntos en las mismas actividades.

La plataforma de aprendizaje de Sugar es abierta. Por lo tanto, Sugar utiliza el trabajo de otros proyectos de código abierto. El software existente para los niños se puede integrar a Sugar. Por ejemplo, el reconocido GCompris, junto con 100 actividades desarrolladas en los últimos cinco años por Bruno Coudoin, fueron añadidos recientemente a Sugar; incluye actividades como Ajedrez, Geografía y Sudoku. Los maestros y padres de familia interesados en las Actividades de Sugar y su interfaz moderna pueden ver videos cortos en el recientemente inaugurado canal de [Sugar Labs Dailymotion](http://www.dailymotion.com/sugarlabs).

Los visitantes a LinuxTag son bienvenidos a hablar con los contribuyentes de Sugar Labs en el mostrador 7.2a 110a.`,Ro=Object.freeze(Object.defineProperty({__proto__:null,default:C},Symbol.toStringTag,{value:"Module"})),L=`---
title: "Sugar Labs gibt die Veröffentlichung von Sugar on a Stick bekannt; die Lernplattform läuft auf jedem PC oder Netbook im Klassenzimmer."
category: "PRESS RELEASE"
date: "2009-06-24"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

LinuxTag, Berlin, 24. Juni 2009: Sugar Labs™, gemeinnütziger Anbieter der Sugar-Lernplattform, die weltweit von über einer Million Kindern benutzt wird, gibt die Veröffentlichung von Sugar on a Stick v1 Strawberry bekannt. Frei zum Download auf [www.sugarlabs.org](www.sugarlabs.org) verfügbar, lässt sich Sugar on a Stick auf einen gewöhnlichen 1GB-USB-Stick laden, von dem aus ein PC oder Netbook direkt in die preisgekrönte Sugar-Umgebung gebootet werden kann. Es läuft auf neuen Macs mit einer Hilfs-CD und unter Windows mittels Virtualisierung. Sugar on a Stick ist für den Betrieb mit einem Schulserver ausgelegt, der die Verteilung von Materialien, das Einsammeln von Hausaufgaben, Datensicherung, Moodle-Anbindung und gefilterten Zugriff auf das Internet bieten kann. Die gegenwärtige Strawberry-Version ist zum Testen im Klassenzimmer gedacht. [Rückmeldungen](mailto:feedback@sugarlabs.org) werden in die nächste Version einfließen, die ende 2009 verfügbar sein wird.

"Ein Jahr nach seiner Gründung arbeitet Sugar Labs an der Auslieferung seiner Bildungszusage an die zweite Million Lernender", so Walter Bender, Gründer und Geschäftsführer. "Sugar wird bevorzugt, weil es kleinen Kindern eine überragende Lernerfahrung bietet: faszinierend und doch erschwinglich. Sugar on a Stick stellt eine wunderbare Möglichkeit dar, Sugar auszuprobieren, ohne die Festplatte des Rechners zu verändern. Es eignet sich auch gut für langsamere, ältere Rechner oder schwachbrüstige Netbooks. Es gibt eine Version für den OLPC XO-1 und es wird auf den neueren XO-1.5-Laptops diesen Herbst zu finden sein."

Sugar on a Stick bietet eine schlüssige und einheitliche Computererfahrung. Es mindert die Kosten durch hohe Flexibilität bei der Hardware-Auswahl, was es Schulen ermöglicht, bereits vorhandene Hardware weiterhin zu nutzen. Die Lernenden können von der zunehmenden Verbreitung von Rechnern in den Haushalten profitieren: Dadurch, dass sich Sugar on a Stick mit nach Hause nehmen lässt, steht jedem Schüler eine einheitliche, vergleichbare Computerumgebung zur Verfügung, die seine Eltern ebenso nutzen können. Auch ermöglicht es Offline-Zugang zu Anwendungen und Materialien, nachdem nicht jeder Lernende zu Hause über einen Internet-Zugang verfügt.

Als Teil der andauernden Bemühungen, Sugar on a Stick für den Einsatz im Klassenzimmer bereit zu machen, wurde Sugar Labs ein 20.000$-Zuschuss der Gould Charitable Foundation zuerkannt, um Sugar an der Gardner Pilot Academy zu implementieren, einer öffentlichen Grundschule in einem der kulturell und sprachlich vielfältigsten Viertel Bostons in Massachusetts, USA.

Lernaktivitäten bilden das Herzstück von Sugar. Sugar on a Stick umfasst 40 Aktivitäten, um das Interesse junger Lernender zu wecken, beispielsweise Lesen, Schreiben, Malen oder Etoys. Hunderte weiterer Aktivitäten stehen in der [Sugar-Aktivitätenbibliothek](http://activities.sugarlabs.org) zum freien Download bereit. Die meisten "ver-Sugar-ten" Aktivitäten ermöglichen die Zusammenarbeit von Schülern: Schüler und Lehrer arbeiten, spielen und lernen gemeinsam in denselben Aktivitäten. Die Sugar-Lernplattform ist offen, sodass durch Einsatz anderer Open-Source-Produkte vorhandene Software für Kinder integriert werden kann. So wurde etwa die gefeierte GCompris-Suite aus 100 Aktivitäten, die die letzten fünf Jahre über von Bruno Coudoin entwickelt wurde, erst kürzlich zu Sugar hinzugefügt, darunter Aktivitäten wie Schach, Geographie oder Sudoku. Lehrer und Eltern, die sich für Sugars Aktivitäten und sein modernes Interface für Kinder interessieren, finden im unlängst eröffneten [Sugar Labs Dailymotion-Kanal](http://www.dailymotion.com/sugarlabs) kurze Videos.

Besucher des LinuxTages sind herzlich eingeladen, mit Beitragenden zu Sugar Labs am Stand 7.2a 110a zu sprechen.
`,Oo=Object.freeze(Object.defineProperty({__proto__:null,default:L},Symbol.toStringTag,{value:"Module"})),x=`---
title: "Sugar Labs kondigt aan dat Sugar on a Stick nu beschikbaar is; dit leerplatform draait op elke pc of netbook."
category: "PRESS RELEASE"
date: "2009-06-24"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

LinuxTag, Berlijn, 24 juni 2009: Sugar Labs™ is de non-profit organisatie die het Sugar Leerplatform levert aan meer dan één miljoen kinderen over de hele wereld. Zij kondigt aan dat nu Sugar on a Stick versie 1 beschikbaar is onder de naam **"Strawberry"**. Het is gratis op te halen bij [www.sugarlabs.org](http://www.sugarlabs.org) en te installeren op een 1 GB flash drive. Daarna kan Sugar direct worden opgestart op een PC of netbook. Het draait ook op recente Macs met een hulp-CD en in Windows met gebruik van virtualisatie.

Sugar on a Stick is ontworpen in combinatie met een School Server, waarmee het volgende kan worden verzorgd: distributie van informatie/leerstof, huiswerk verzamelen, backups maken, integratie met Moodle en gefilterde toegang tot het internet. Deze "Strawberry"-versie is bedoeld om in de klas te testen; feedback zal in de volgende versie worden opgenomen en komt tegen het einde van 2009 beschikbaar.

> "Eén jaar na oprichting maakt Sugar Labs haar beloften waar voor haar tweede miljoen studenten," zegt Walter Bender, oprichter en directeur.  
> "Sugar heeft de voorkeur, want het is een superieure leeromgeving voor jonge kinderen: motiverend en betaalbaar. Sugar on a Stick is een geweldige manier om het uit te proberen zonder de harde schijf te veranderen. Het is ook geschikt voor oudere pc’s en langzamere netbooks. Er is een versie voor de OLPC XO-1 en het zal geleverd worden met de nieuwere XO-1.5 laptops in de herfst."

Sugar on a Stick geeft een samenhangend en consistente werkomgeving. Het vermindert kosten doordat het op veel hardware kan worden geïnstalleerd, zodat scholen hun bestaande apparatuur kunnen blijven gebruiken. Het komt de leerlingen ten goede dat zij hun vertrouwde Sugar on a Stick-omgeving mee naar huis kunnen nemen en het ook kunnen delen met hun ouders. Het geeft ook offline toegang tot hun activiteiten en leerstof, daar niet iedere leerling thuis internet heeft.

Als onderdeel van een voortdurende inspanning om Sugar on a Stick klaar te maken voor de klas, heeft Sugar Labs een donatie van **$20.000** ontvangen van de Gould Charitable Foundation om Sugar te installeren op de Gardner Pilot Academy, een openbare basisschool in een wijk van Boston, Massachusetts met één van de grootste verscheidenheid aan achtergronden qua cultuur en taal.

Leeractiviteiten zijn het hart van Sugar. Sugar on a Stick bevat **veertig activiteiten** voor jonge leerlingen zoals lezen, schrijven, tekenen en eToys. Er zijn nog honderden andere activiteiten gratis op te halen bij de [Sugar Activiteiten Bibliotheek](http://activities.sugarlabs.org). De meeste van deze activiteiten hebben samenwerking ingebouwd: leerlingen en onderwijskrachten werken, spelen en leren samen.

Het Sugar Leerplatform is open, dus andere bestaande open-sourceprojecten voor kinderen kunnen erin geïntegreerd worden. Zo is de bekende **GCompris-suite** van honderd activiteiten onlangs toegevoegd aan Sugar, met activiteiten als schaken, aardrijkskunde en sudoku. Dit project werd de afgelopen vijf jaar door **Bruno Coudoin** ontwikkeld.

Leerkrachten en ouders die geïnteresseerd zijn in Sugar-activiteiten en de moderne interface voor kinderen kunnen korte video’s bekijken op het onlangs geopende [Sugar Labs Dailymotion-kanaal](http://www.dailymotion.com/sugarlabs).

Bezoekers aan LinuxTag zijn welkom bij stand **7.2a 110a** om te komen praten met Sugar Labs-medewerkers.`,zo=Object.freeze(Object.defineProperty({__proto__:null,default:x},Symbol.toStringTag,{value:"Module"})),G=`---
title: "Sugar Labs and Free Software Foundation Celebrate Software Freedom Day, Announce Joint Efforts to Promote the Sugar Learning Platform for Children Worldwide"
category: "PRESS RELEASE"
date: "2009-11-18"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

CAMBRIDGE, MA, September 18, 2009 — Sugar Labs, nonprofit provider of the Sugar Learning Platform for children, and the Free Software Foundation (FSF), which promotes computer users’ right to use, study, copy, modify, and redistribute computer programs, have announced joint efforts to collaborate and promote Sugar on the occasion of **Software Freedom Day**, September 19th.

The FSF will host an event in Boston featuring Sugar Labs Executive Director **Walter Bender**, FSF president **Richard Stallman**, and other speakers. **Peter Brown**, FSF’s executive director, said:

> “The Sugar Learning Platform is fast becoming an essential route to computer user freedom for children around the world. The international free software movement is getting behind Sugar, and we want to use Software Freedom Day as an opportunity to help draw community attention, developer resources, and external funders to the important work going on at Sugar Labs.”

The FSF has upgraded its hosting services support of Sugar Labs to keep pace with its growth. As part of the ongoing relationship, **Bernardo Innocenti**, a member of the Sugar Labs Oversight Board, is working at the FSF offices. Mr. Innocenti stated:

> “The FSF and Sugar Labs are pursuing distinct, but interdependent goals; Free (as in Freedom) Software is a fundamental part of globally accessible education, and good education enables critical thought, a pre-requisite for appreciating the value of Freedom.”

Sugar is a global project. Translated into **25 languages**, it is used in classrooms in **40 countries** by over **1 million children** as part of the **One Laptop per Child (OLPC)** nonprofit program. Sugar’s simple interface, built-in collaboration, and automatic backup through each student’s Journal have been designed to interest young learners.

The recently released **Sugar on a Stick (SoaS)** project brings Sugar to even more children, allowing young learners to keep a working copy of Sugar on a simple USB stick, ready to start up any PC or netbook with the child’s environment and data. Pilot projects in schools with Sugar on a Stick are underway in **Boston**, **Berlin**, and elsewhere.

SoaS is **free software** available under the **General Public License (GPL)** and is available for download without charge at [sugarlabs.org](http://www.sugarlabs.org).

According to Walter Bender:

> “Sugar is running on over 99% of all of the OLPC-XO laptops around the world because governments prefer its quality, openness, built-in collaboration, and easy localization to indigenous languages. Teachers and students are exercising their freedom by modifying and improving Sugar and its Activities. With Sugar on a Stick, access to Sugar is even more widespread.”

For example, **Uruguay** has distributed a Sugar-equipped OLPC laptop to every student in the country. [Alexandre Oliva of FSF’s sister organization Free Software Foundation Latin America](http://www.fsfla.org) said:

> “I was amazed when I first saw Sugar in action in Peru two years ago; shortly thereafter, my daughter tasted Sugar and loved it. She’s going to elementary school next year, and I’m very happy she can now easily carry Sugar with her, and share it with her friends. Myself, I’m going to spread its freedom into as many schools as I can.”

**Karsten Gerloff**, President of [Free Software Foundation Europe](http://fsfe.org), added:

> “Education and Free Software are both all about sharing knowledge. Through projects like Sugar, young people around the world can discover the creativity that freedom makes possible. Together with the political backing that FSFE’s Edu-Team and others are building, Sugar puts Free Software in its rightful place in education.”

Sugar Labs relies on the efforts of **software developers** who donate their skills to the project. Mr. Bender continued:

> “We are looking for developers with experience in GNU/Linux, Python and/or Gtk+ for contributing to the Sugar shell and educational Activities for children. We also need testers, experienced packagers, and educators willing to contribute their ideas for Sugar in the classroom.”`,Fo=Object.freeze(Object.defineProperty({__proto__:null,default:G},Symbol.toStringTag,{value:"Module"})),W=`---
title: "L’association à but non lucratif Sugar Labs annonce la version 2 de “Sugar on a Stick” qui améliore la lecture de livres électroniques et transforme n’importe quelle clé USB en une plate-forme éducative pour les enfants ; partenariat avec Nexcopy, Inc."
category: "PRESS RELEASE"
date: "2009-12-08"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->
PARIS, le 8 décembre 2009 - **Netbook World Summit** - Sugar Labs® la communauté de volontaires développant la plate-forme éducative Sugar déjà diffusée à plus d’un million d’enfants dans le monde, annonce la sortie de **Sugar on a Stick v2 “Blueberry” (Myrtille)**.

Disponible en téléchargement sur [http://www.sugarlabs.org][0], Sugar on a Stick peut s’installer sur toute clé USB de 1Go ou plus et permet, sans modifier l’installation, de faire fonctionner n’importe quel PC, netbook ou un Mac récent, dans l’environnement pour enfant Sugar. Sugar est également disponible pour la plupart des distributions GNU/Linux, peut fonctionner de manière virtualisée sur Windows et Apple OS X et intègre nativement des fonctionnalités de collaboration et de sauvegarde dans le Journal des activités.

La dernière version de Sugar propose :
- une navigation web simplifiée,
- une meilleure gestion des réseaux sans fil,
- un portail d’installation de nouvelles Activités pour enfants,
- une configuration clavier facilitée,
- et l’intégration de **Gnash** pour le support des contenus Adobe Flash.

De nouvelles Activités comme **Physiques** et **OOo4Kids** complètent les applications favorites telles que **Naviguer** et **Lire**, adaptées à la lecture de livres électroniques.

> “Sugar on a Stick est une merveilleuse manière d’expérimenter Sugar,” commente Walter Bender, le président exécutif du Sugar Labs. “En cette période de fêtes de fin d’année, nous souhaitons rappeler aux parents et aux enseignants que les livres électroniques ne sont pas réservés à des coûteux lecteur dédiés, mais font partie du mouvement libre d’accès à la connaissance pour aider les enfants partout dans le monde à développer un accès critique à la connaissance et combler le fossé numérique partout où il existe.”

Sugar on a Stick intègre plusieurs activités de lecture de livres électroniques pour télécharger et visualiser des livres aux formats PDF, EPUB et DejaVu. De plus, l’Activité **Read Etexts** peut lire des livres électroniques à haute voix, permettant de convertir n’importe quel vieux PC ou un netbook à bas coût en un outil de lecture audio pour les personnes à vision réduite. Avec Sugar, les enfants peuvent même construire leurs propres livres électroniques.

Des centaines de livres électroniques pour enfants sont disponibles sur :
- [Projet Gutenberg](https://www.gutenberg.org),
- [Internet Archive Children’s Library](https://archive.org/details/iacl),
- [epubBooks.com](https://www.epubbooks.com),
- [Feedbooks.com](https://www.feedbooks.com),
- [ManyBooks.net](https://manybooks.net),
- et d’autres comme [International Children’s Digital Library](http://en.childrenslibrary.org).

Des projets pilotes sont en cours dans des écoles aux États-Unis et en Europe. Les responsables d’écoles intéressés par Sugar seront ravis de découvrir la mise à jour du **Serveur d’école XS**, qui permet :
- un accès protégé à Internet,
- la distribution de contenu,
- une intégration Moodle,
- et des sauvegardes centralisées.

Pour soutenir ce déploiement, Sugar Labs a établi un partenariat avec **Nexcopy, Inc.**, basée à Rancho Santa Margarita, Californie. Nexcopy, spécialiste des solutions de duplication USB, a lancé le site [http://recycleusb.com](http://recycleusb.com). Ils récupèrent des clés USB, les chargent avec Sugar on a Stick, puis les renvoient au Sugar Labs pour distribution dans les écoles. Nexcopy a également offert une unité de réplication de 20 clés au projet.

> Greg Morris, Président de Nexcopy, commente :  
> “Nexcopy est fier d’être partenaire avec une organisation à but non lucratif comme le Sugar Labs. Nous sommes convaincus que la plate-forme éducative Sugar est un pas dans la bonne direction pour permettre aux enfants d’être efficaces avec les ordinateurs. Notre objectif est de donner au Sugar Labs le support et l’équipement nécessaire pour permettre le succès de cette opération philanthropique et permettre la production de masse d’un grand nombre de clés Sugar pour un déploiement global. Je suis très honoré que Nexcopy fasse partie de ce processus.”

### À propos du Sugar Labs
Sugar Labs est une organisation non lucrative de volontaires, membre du projet **Software Freedom Conservancy**. À l’origine intégré au projet One Laptop Per Child, Sugar Labs coordonne les efforts mondiaux pour fournir des opportunités éducatives à travers la plate-forme Sugar. Soutenu par des dons, Sugar Labs cherche activement des fonds pour accélérer son développement.  
🔗 [http://www.sugarlabs.org](http://www.sugarlabs.org )

### À propos de Nexcopy Incorporated
Nexcopy Incorporated est spécialisée dans le développement d’outils de duplication de mémoire flash de haute performance. Présente sur les marchés d’Amérique Centrale et du Sud, d’Europe, d’Inde, d’Asie, ainsi que sur le marché américain, la société est basée en Californie.

---

Sugar Labs est une marque déposée de la Software Freedom Conservancy. Les autres marques déposées sont la propriété respective de leurs auteurs.
`,Uo=Object.freeze(Object.defineProperty({__proto__:null,default:W},Symbol.toStringTag,{value:"Module"})),D=`---
title: "Sugar Labs Nonprofit Announces v2 of Sugar on a Stick with Improved E-Book Readers, Recycles Any USB Stick Into Learning Environment for Children; Partners with Nexcopy, Inc."
category: "PRESS RELEASE"
date: "2009-12-08"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

PARIS, December 8, 2009 — Netbook World Summit — Sugar Labs® (R), volunteer-driven nonprofit provider of the Sugar Learning Platform for over one million children around the world, announces the release of Sugar on a Stick v2 “Blueberry.” Available for download at [http://www.sugarlabs.org](http://www.sugarlabs.org), Sugar on a Stick can be loaded onto any ordinary 1GB or greater flash drive to reboot any PC, netbook or recent Mac directly into the child-friendly Sugar environment without touching the existing installation. 

Sugar is also available for GNU/Linux distributions, runs under virtualization on Windows and Apple OS X, and features built-in classroom collaboration and automatic backup to a Journal. The latest version of Sugar offers simpler navigation, improved wireless networking, streamlined updating of Activities for children, easier keyboard configuration, better Gnash support for Adobe Flash content, and more. New Activities such as Physics and OOo4Kids join updated favorites such as Browse and Read, suitable for reading e-books.

“Sugar on a Stick is a great way to experience Sugar,” commented Walter Bender, Sugar Labs executive director. “In this holiday season, we wish to remind parents and teachers that e-books are not only for costly reader units for the well-to-do, but freely available as part of the open-access to knowledge movement to help children everywhere develop critical learning skills and to bridge the digital divide wherever it exists.”

Sugar on a Stick includes several e-book reader Activities to find and display e-books in PDF, EPUB, and DejaVu formats. The Read Etexts Activity can read e-books out loud, converting any old PC or inexpensive netbook into a text-to-speech aid for disabled readers. With Sugar, children can even make their own e-books. Thousands of e-books for children are available on websites such as Project Gutenberg, the Internet Archive Children’s Library, epubBooks.com, Feedbooks.com, and ManyBooks.net. Other sites offer online reading, such as the International Children’s Digital Library.

Pilot Sugar projects are underway in American and European schools. School administrators wishing to deploy Sugar will be interested in OLPC’s recently updated XS school server software, which provides “safety net” and connectivity services at the school level: backup, content distribution, filtered access to the Internet, and Moodle integration. 

To assist schools interested in testing this technology, Sugar Labs has partnered with Nexcopy, Inc. of Rancho Santa Margarita, California, an industry leader in USB duplicator solutions, to open [http://recycleusb.com](http://recycleusb.com). Nexcopy will collect used USB sticks, reload them with Sugar on a Stick, and forward them to Sugar Labs for distribution to schools. Nexcopy has also donated a 20-stick USB duplication unit to Sugar Labs.

Greg Morris, President of Nexcopy, commented, “Nexcopy is proud to partner with a nonprofit organization such as Sugar Labs. We believe the Sugar Learning Platform is clearly a step in the right direction for getting children involved with personal computers. Our objective is to give Sugar Labs the back-end equipment support needed to make this philanthropy successful and help with producing the large number of Sugar Sticks needed for global deployment. I am very honored Nexcopy is a part of this process.”

**About Sugar Labs**: Sugar Labs, a volunteer-driven, nonprofit organization, is a member project of the Software Freedom Conservancy. Originally part of the One Laptop Per Child project, Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities to children through the Sugar Learning Platform. Sugar Labs is supported by donations and is seeking funding to accelerate development. For more information, please visit [http://www.sugarlabs.org](http://www.sugarlabs.org).

**About Nexcopy Incorporated**: Nexcopy Incorporated specializes in developing and manufacturing the finest and most feature-rich flash memory duplicators in the market. Pioneering the solid-state memory duplication market, Nexcopy supplies Central and South America, Europe, India, Asia, Pacific Rim and serves the U.S. market through its headquarters in California.

Sugar Labs is a registered trademark of the Software Freedom Conservancy. Other names are trademarks of their respective owners.`,No=Object.freeze(Object.defineProperty({__proto__:null,default:D},Symbol.toStringTag,{value:"Module"})),_=`---
title: "L'Office de secours et de travaux des Nations unies choisi les ordinateurs du projet One Laptop per Child et la plate-forme Sugar pour un projet majeur d'éducation au proche orient"
category: "PRESS RELEASE"
date: "2010-04-29"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

CAMBRIDGE, Mass, 29 avril 2010 - L'Office de secours et travaux des Nations unies pour les réfugiés de Palestine au proche orient ([UNRWA](http://www.unrwa.org)) a annoncé un programme ambitieux de 3 ans pour fournir à un demi-million d'enfants réfugiés Palestinien, dans la bande de Gaza, au Liban, en Syrie et en Jordanie, un ordinateur équipé de la plateforme éducative Sugar, plusieurs fois primée.

"Motiver la prochaine génération en lui donnant l'accès à la connaissance et à l'apprentissage est capital pour les projets éducatifs de l'UNRWA. Nous enseignons à 500 000 enfants au Proche Orient chaque jour et donner à chacun d'entre eux un ordinateur sera une énorme contribution pour combler le fossé technologique et d'accès au savoir dans l'une des régions les plus troublée du monde", a indiqué Chris Gunness, le porte-parole de l'UNWRA.

Selon Walter Bender, fondateur et directeur exécutif du Sugar Labs: "Aujourd'hui, de la forêt vierge du Pérou aux steppes de Mongolie, des collines du Rwanda aux montages d'Afghanistan, un million et demi d'enfants apprennent chacun dans leur langue maternelle, sur les ordinateurs XO du projet OLPC grâce à Sugar et sa suite d'Activités d'apprentissage. Le projet de l'UNRWA ajoutera un demi-million d'apprenants supplémentaires en provenance de la vallée de Jordanie et du Moyen Orient, et d'autres projets vont voir le jour prochainement. C'est une génération entière qui apprend avec Sugar."

Le cœur de Sugar, ce sont ses Activités pour les enfants ([http://activities.sugarlabs.org](http://activities.sugarlabs.org)). Amusant et motivant, ce sont des programmes qui permettent de lire des livres électroniques, d'écrire, de dessiner, de naviguer sur Internet, de programmer et plein d'autres choses. Sugar intègre de plus le travail collaboratif et l'enregistrement des activités réalisées dans le journal ce qui le rend particulièrement adapté à l'utilisation en classe mais aussi en dehors de l'école pour continuer les apprentissages. Complété par un serveur d'école XS, un logiciel libre et ouvert proposé par le projet One Laptop Per Child, il permet de fournir aux jeunes apprenants un environnement connecté sûr et sécurisé.

Les contenus existant de l'UNRWA seront adaptés à Sugar et la formation des enseignants va démarrer prochainement. Le projet de l'UNRWA fait suite au déploiement l'année dernière de 1000 ordinateurs XO dans les écoles Palestinienne par le PEI (Palestine Education Initiative [http://www.pei.gov.ps](http://www.pei.gov.ps), [http://en.palexo.com](http://en.palexo.com)). Sugar Labs est à la recherche de développeurs et de volontaires pour faire de ce projet un vrai succès.

A propos du Sugar Labs: Sugar Labs est un organisation non lucrative de volontaires, membre du projet Software Freedom Conservancy. A l’origine intégré au projet One Laptop Per Child, Sugar Labs coordonne les volontaires dans le monde qui sont passionés par l’idée de fournir des opportunités d’éducation à travers la plate-forme éducative Sugar. Sugar Labs est soutenu par des donations et cherche des fonds pour accélérer son développement. Pour plus d’information, voir [http://www.sugarlabs.org](http://www.sugarlabs.org)

Sugar Labs est une marque déposée de la Software Freedom Conservancy. Les autres marques déposées sont la propriété respective de leur auteurs.`,Ho=Object.freeze(Object.defineProperty({__proto__:null,default:_},Symbol.toStringTag,{value:"Module"})),E=`---
title: "United Nations Relief and Works Agency Sceglie i Laptop di One Laptop per Child con  Sugar per un Importante Progetto Educativo in Medio Oriente"
category: "PRESS RELEASE"
date: "2010-04-29"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

CAMBRIDGE, Mass., 29 Aprile, 2010 — L'Agenzia delle Nazioni Unite per i rifugiati della Palestina nel Medio Oriente ([UNRWA](http://www.unrwa.org)) ha annunciato un ambizioso programma triennale per fornire un computer portatile dotato del premiato ambiente software Sugar Learning Platform a mezzo milione di bambini palestinesi rifugiati nella Striscia di Gaza, Libano, Siria, e Giordania.

“Rafforzare la prossima generazione grazie a conoscenza e capacità di apprendimento è l'aspetto centrale per progetti educativi dell'UNRWA. Ogni giorno forniamo istruzione a 500.000 bambini nel Medio Oriente e fornire ad ognuno di loro un laptop sarà un grande aiuto a chiudere il gap di conoscenza e tecnologie in una delle regioni del mondo con maggiori problemi,” dice Chris Gunness, portavoce dell'UNRWA.

Walter Bender, fondatore e Direttore Esecutivo di Sugar Labs, dichiara: “Ad oggi, un milione e mezzo di bambini, dalle foreste equatoriali del Perù alle steppe della Mongolia, dalle colline del Rwanda alle montagne dell'Afganistan, stanno imparando, utilizzando la loro lingua madre grazie a Sugar e alla collezione di Attività didattiche con i laptop XO di OLPC. Il progetto di UNRWA accrescerà di un altro mezzo milione di studenti nella valle del Giordano e nel Medio Oriente, altri progetti sono in sviluppo. Una intera nuova generazione sta apprendendo con Sugar.”

Al cuore di Sugar sono le Attività: [http://activities.sugarlabs.org](http://activities.sugarlabs.org) – programmi divertenti e appassionanti, nati per leggere libri elettronici, scrivere, disegnare, navigare la rete Internet, programmare, e molto altro ancora. Sugar integra capacità di collaborazione fra utenti e di memorizzazione dei dati in una struttura organizzata in base temporale (Diario), funzionalità estremamente adatte sia ad un utilizzo in classe che per continuare ad apprendere e studiare anche al di fuori della scuola. Il sistema XS School Server, basato su software libero, reso disponibile da One Laptop per Child, permette un accesso sicuro e filtrato alla rete Internet per i giovani studenti.

I materiali didattici di UNRWA esistenti saranno adattati a Sugar e si sta già provvedendo anche alla formazione dei docenti. Il progetto di UNRWA segue le orme della distribuzione avvenuta lo scorso anno di 1000 laptops XO nelle scuole della Palestina a cura della Palestine Education Initiative ([http://www.pei.gov.ps](http://www.pei.gov.ps), [http://en.palexo.com](http://en.palexo.com)). Sugar Labs è lieta di accogliere sviluppatori e volontari che vogliano collaborare alla riuscita di questa iniziativa.`,qo=Object.freeze(Object.defineProperty({__proto__:null,default:E},Symbol.toStringTag,{value:"Module"})),j=`---
title: "United Nations Relief and Works Agency chooses One Laptop per Child Laptops with Sugar for Major Education Project in Mideast"
category: "PRESS RELEASE"
date: "2010-04-29"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

CAMBRIDGE, Mass, April 29, 2010 - The United Nations Relief and Works Agency for Palestine Refugees in the Near East (UNRWA, [http://www.unrwa.org](http://www.unrwa.org)) has announced an ambitious three-year program to provide a laptop loaded with the award-winning Sugar Learning Platform to one-half million Palestine refugee children in the West Bank and Gaza, Lebanon, Syria, and Jordan.

“Empowering the next generation through knowledge and learning is central to UNRWA’s education projects. We are teaching 500,000 children in the Middle East every day and having all of them with a laptop will be a huge contribution to bridging the technology and knowledge gap in one of the most troubled regions of the world,” said Chris Gunness, UNWRA Spokesman.

Walter Bender, founder and Executive Director of Sugar Labs, said: “Today, one-and-one-half-million children, from the rain forests of Peru to the steppes of Mongolia, from the hills of Rwanda to the mountains of Afghanistan, are learning in their native tongues with Sugar and its suite of learning Activities on OLPC’s XO laptops. The UNRWA project will add one-half million more learners in the Jordan valley and throughout the Middle East, and more projects are on the way. An entire generation is learning with Sugar.”

The heart of Sugar is its Activities for children ([http://activities.sugarlabs.org](http://activities.sugarlabs.org)), fun and engaging programs for reading e-books, writing, drawing, browsing the Internet, programming, and so on. Sugar has collaboration and backup to a Journal built-in, making it particularly well-suited both for the classroom and outside school where learning continues. The free open source XS School Server, available from One Laptop per Child, provides a safely filtered online environment for young learners.

Existing UNRWA learning content will be adapted to Sugar and teacher training is underway. The UNRWA project follows last year’s deployment of 1000 XO laptops in Palestinian schools by the Palestine Education Initiative ([http://www.pei.gov.ps](http://www.pei.gov.ps), [http://en.palexo.com](http://en.palexo.com)). Sugar Labs welcomes developers and volunteers to make this important endeavor successful.

About Sugar Labs: Sugar Labs, a volunteer-driven, nonprofit organization, is a member project of the Software Freedom Conservancy. Originally part of the One Laptop Per Child project, Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities to children through the Sugar Learning Platform. Sugar Labs is supported by donations and is seeking funding to accelerate development. For more information, please visit [http://www.sugarlabs.org](http://www.sugarlabs.org).`,Ko=Object.freeze(Object.defineProperty({__proto__:null,default:j},Symbol.toStringTag,{value:"Module"})),B=`---
title: "La Plataforma de Aprendizaje Sugar y el Escritorio GNOME se distribuirán hoy en la One Laptop per Child modelo XO-1.5; también se ejecutará en el nuevo XO-HS High School Edition"
category: "PRESS RELEASE"
date: "2010-06-04"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

ASUNCIÓN, 14 de junio de 2010 — Sugar Labs, el Proyecto de Escritorio Libre GNOME, y One Laptop per Child (OLPC) han anunciado una actualización del software que se ofrece en el OLPC XO-1.5. Los 1,5 millones de niños que ya usan Sugar en el XO-1 original también podrán beneficiarse de la actualización ya que Paraguay Educa ha portado el software.

La plataforma de aprendizaje Sugar promueve el aprendizaje colaborativo a través de Actividades amigables para los niños que fomentan el pensamiento crítico. El escritorio libre GNOME es un componente distinguido de todas las principales distribuciones de GNU/Linux, adecuado para niños mayores y adultos. El cambio entre los dos entornos se realiza con un único click. Con GNOME en el portátil XO, se abre la puerta a miles de aplicaciones de formación y de productividad adicionales.

El XO-1.5 tiene el mismo diseño industrial que el XO-1 original. Está basado en un procesador VIA, que proporciona el doble de velocidad que el XO-1, y tiene 4 veces más de memoria DRAM y memoria FLASH. OLPC ha anunciado la disponibilidad de una edición para secundaria del XO-1.5, el XO-HS High School Edition, con un diseño de teclado nuevo, más cómodo para los estudiantes mayores. El primer despliegue del XO-HS está programado para empezar en Uruguay en el marco del exitoso Plan Ceibal a partir de septiembre.

Los niños familiarizados con el XO-1 evolucionarán naturalmente a las funcionalidades ampliadas del XO-1.5. "One Laptop per Child promueve software libre y de código abierto para que pueda evolucionar y adaptarse a las necesidades de los niños. La plataforma Sugar en el XO es clave para nuestra misión educativa porque proporciona a los estudiantes un entorno de software de aprendizaje único e intuitivo", dijo el director ejecutivo de la asociación OLPC Rodrigo Arboleda.

Stormy Peters, Directora Ejecutiva de la GNOME Foundation, dice: “Estamos muy entusiasmados de estar trabajando con Sugar y OLPC para proveer software de escritorio para niños de todas las edades. La misión de GNOME es proporcionar un escritorio libre y accesible para todos. Los niños, desde Uruguay hasta Ghana, serán capaces de utilizar sus XO para aprender y mostrar a sus amigos y familias cómo usar Sugar y GNOME."

Walter Bender, director ejecutivo de Sugar Labs, dijo que "la fluidez de cambio entre los dos escritorios ofrece al alumno la capacidad de transición de un entorno de aprendizaje —Sugar— a un entorno de producción —GNOME—. Así disponen de los medios para perfeccionar las habilidades creativas adquiridas en educación primaria, con las capacidades emprendedoras de la educación secundaria".

“Sugar on a Stick” permite a los niños que no tienen un ordenador portátil XO beneficiarse de este nuevo software. Disponible para descarga desde Sugar Labs, en la nueva distribución v3 Mirabelle, puede ser cargada en un pendrive USB común y usarse para iniciar Sugar en una PC sin tocar el disco duro. Las laptops XO y Sugar on a Stick ejecutan Fedora GNU/Linux.

**Acerca de Sugar Labs®:** Sugar Labs es una organización dirigida por voluntarios, sin ánimo de lucro y es un proyecto miembro de Software Freedom Conservancy. Originalmente parte del proyecto One Laptop Per Child, Sugar Labs coordina voluntarios en todo el mundo apasionados por la posibilidad de proveer oportunidades educacionales a niños a través de la Sugar Learning Platform. Sugar Labs es soportada por donaciones y está en busca de apoyo económico y voluntarios para acelerar el desarrollo. Para más información, por favor visita: [http://www.sugarlabs.org](http://www.sugarlabs.org).

**Acerca de GNOME:** GNOME es un proyecto de software libre que desarrolla un estándar de escritorio completo, accesible y fácil de utilizar en todas las distribuciones principales de GNU/Linux y Unix. Popular en instalaciones corporativas grandes y entre millones de pequeñas y medianas empresas y usuarios domésticos a lo largo del mundo, incluye un entorno de desarrollo para crear nuevas aplicaciones. La Fundación GNOME se compone de cientos de desarrolladores voluntarios y compañías líderes de la industria. Se puede obtener mayor información en [http://www.gnome.org](http://www.gnome.org) y [http://foundation.gnome.org](http://foundation.gnome.org).

**Acerca de One Laptop per Child:** ([http://www.laptop.org](http://www.laptop.org)) OLPC es una organización sin ánimo de lucro creada por Nicholas Negroponte y otros del Media Lab del MIT para diseñar, fabricar y distribuir portátiles lo suficientemente baratos como para proporcionar a cada niño en el mundo acceso al conocimiento y a las formas modernas de educación.`,Vo=Object.freeze(Object.defineProperty({__proto__:null,default:B},Symbol.toStringTag,{value:"Module"})),R=`---
title: "Sugar Labs Announces New Version of Sugar on a Stick, Educational Software for Children"
category: "PRESS RELEASE"
date: "2010-06-10"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

BERLIN, June 10, 2010 — LinuxTag — Sugar Labs®, nonprofit provider of the Sugar Learning Platform to over one and a half million children worldwide, has released Mirabelle, the third version of Sugar on a Stick, a collaborative learning environment that can be loaded onto any ordinary USB thumbdrive and used with a PC, netbook or Mac without touching the hard disk. It is available free for download at [https://wiki.sugarlabs.org/go/Sugar_on_a_Stick](https://wiki.sugarlabs.org/go/Sugar_on_a_Stick). Sugar runs natively on major GNU/Linux distributions and can also run in virtualization under Microsoft Windows and Apple OS X.

One year after the premiere of v1 Strawberry at LinuxTag 2009 and following v2 Blueberry last December, v3 Mirabelle brings improved stability and simplified customization to curious teachers interested in testing Sugar on new netbooks or PCs already in the classroom. We suggest teachers reach out to university-level computer science and education schools to build local support structures, important with an ICT project.

Sebastian Dziallas, Project Lead for Sugar on a Stick and a recent high school graduate based in Germany, said, "Teachers have told us how important reliability is in the classroom while engaging students, so we decided to create a release that has a stable core and can be customized to fit every deployment's needs. Mirabelle is a solid baseline which teachers can customize with Activities interesting to young learners. Part of our strategy is to achieve sustainable development while inviting new contributors. We achieved this by integrating Sugar on a Stick more closely with Fedora, the underlying GNU/Linux distribution; Mirabelle is now an official Fedora Spin."

Sugar Labs is also making available a Sugar Creation Kit, a downloadable DVD which includes Mirabelle, documentation, and a library of Sugar Activities, fun and engaging programs for children taken from the [Sugar Activity Library](http://activities.sugarlabs.org).

Thomas Gilliard, a Sugar Labs contributor, said, "The Sugar Creation Kit turns any PC into a Sugar on a Stick generating station. Tools and documentation are gathered on one disk; busy teachers don't have to hunt down anything. This makes it possible to work via 'sneaker net' and in a classroom behind a firewall."

Visitors to LinuxTag are invited to meet Sugar Labs contributors at Hall 7.2a, Booth 115.

**About Sugar Labs**: Sugar Labs, a volunteer-driven, nonprofit organization, is a member project of the Software Freedom Conservancy. Originally part of the One Laptop Per Child project, Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities to children through the Sugar Learning Platform. Sugar Labs is supported by donations and is seeking funding to accelerate development. For more information, please visit [http://www.sugarlabs.org](http://www.sugarlabs.org).`,Jo=Object.freeze(Object.defineProperty({__proto__:null,default:R},Symbol.toStringTag,{value:"Module"})),O=`---
title: "Sugar Labs Annuncia una Nuova Versione di Sugar on a Stick, piattaforma software educativa per bambini"
category: "PRESS RELEASE"
date: "2010-06-10"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

**BERLINO, 10 Giugno, 2010 — LinuxTag** — Sugar Labs®, il produttore nonprofit della Sugar Learning Platform utilizzata da più di un milione e mezzo di bambini nel mondo, ha rilasciato *Mirabelle*, la terza versione di Sugar on a Stick, una piattaforma collaborativa di apprendimento che può essere caricata su un normale disco rimovibile USB e utilizzata su un PC, netbook o Mac senza alcuna modifica al disco rigido del sistema ospite. È liberamente disponibile per il download all'indirizzo [https://wiki.sugarlabs.org/go/Sugar_on_a_Stick](https://wiki.sugarlabs.org/go/Sugar_on_a_Stick).  
Sugar funziona in modo nativo sulle principali distribuzioni GNU/Linux e attraverso la virtualizzazione su Microsoft Windows e Apple OS X.

Esattamente un anno dopo la premiere della v1 Strawberry al LinuxTag 2009 e dopo la v2 Blueberry resa disponibile lo scorso dicembre, la v3 Mirabelle presenta maggior stabilità e una più facile personalizzazione per gli insegnanti interessati a sperimentare Sugar sui nuovi netbook o PC eventualmente già presenti in classe. Suggeriamo agli insegnanti di contattare facoltà universitarie di informatica ed educazione per costruire strutture di supporto locali, fondamentali per un progetto ICT.

Sebastian Dziallas, Project Leader di Sugar on a Stick e neodiplomato residente in Germania, dichiara:  
> “Gli insegnanti ci hanno detto quanto l'affidabilità sia fondamentale lavorando in classe con gli studenti, quindi abbiamo deciso di creare una versione caratterizzata da un core affidabile e che potesse poi essere personalizzata per soddisfare qualsiasi esigenza di rilascio.  
> Mirabelle è una base solida che gli insegnanti possono personalizzare con le Attività maggiormente interessanti per i loro giovani studenti.  
> La nostra strategia è mirata anche a sviluppare la piattaforma grazie alla collaborazione di nuovi contributori. Abbiamo ottenuto questo grazie anche alla integrazione più stretta di Sugar on a Stick con Fedora, la distribuzione GNU/Linux su cui è basato; Mirabelle ora è un Fedora Spin ufficiale.”

Sugar Labs rende inoltre disponibile un **Sugar Creation Kit**, un DVD scaricabile che include Mirabelle, documentazione e una completa libreria di Attività Sugar, programmi divertenti ed interessanti estratti dalla Sugar Activity Library disponibile online ([http://activities.sugarlabs.org](http://activities.sugarlabs.org)).

Thomas Gilliard, un contributore di Sugar Labs, commenta:  
> “Il *Sugar Creation Kit* trasforma ogni PC in una stazione in grado di produrre istanze di Sugar on a Stick. Strumenti e documentazione sono tutti raccolti in un unico disco; gli insegnanti non perderanno tempo nella ricerca di quanto possa essere utile alla loro attività didattica.  
> Questo strumento permette inoltre di lavorare via 'sneaker net' (non connessi a Internet) e in aule protette da firewall.”

I visitatori del LinuxTag sono invitati ad incontrare gli sviluppatori di Sugar Labs presso il **Booth 115, Hall 7.2a**.`,Xo=Object.freeze(Object.defineProperty({__proto__:null,default:O},Symbol.toStringTag,{value:"Module"})),z=`---
title: "Sugar Labs annonce la nouvelle version de «Sugar-On-A-Stick», son système éducatif à destination des enfants"
category: "PRESS RELEASE"
date: "2010-06-10"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->


Berlin, le 10 juin 2010 - LinuxTag - Sugar Labs, organisation à but non lucratif à l’origine du développement de la plateforme éducative Sugar (déjà utilisée par plus de 1,5 millions d’enfants dans le monde), a dévoilé la troisième version de Sugar on a Stick, «Mirabelle», qui offre un environnement d’apprentissage collaboratif, utilisable depuis un PC, un netbook ou un Mac, sans aucune manipulation sur le système d’exploitation d’origine installé sur son disque, en utilisant une simple clé USB préchargée. Sugar on a Stick est téléchargeable à l’adresse suivante : [https://wiki.sugarlabs.org/go/Sugar_on_a_Stick](https://wiki.sugarlabs.org/go/Sugar_on_a_Stick). Le programme Sugar fonctionne nativement avec la majorité des distributions GNU/Linux et peut être également utilisé depuis une machine virtuelle sur environnement Microsoft Windows ou Apple OS X.

Un an après la première version de Sugar on a Stick («Strawberry») présentée lors de la conférence LinuxTag 2009 et suivi par «Blueberry» en décembre dernier, la nouvelle version «Mirabelle» apporte une meilleure stabilité et améliore les possibilités de personnalisation du système qui est offerte aux enseignants curieux et désireux d’utiliser Sugar sur les ordinateurs déjà présents en classe. D’ailleurs, nous recommandons vivement aux enseignants de développer autour de leur projet les différentes interactions et les échanges, en particulier avec le milieu universitaire autour de l’information ou des sciences de l’éducation. C’est un élément essentiel pour mener à bien un projet TICE.

Sebastian Dziallas, chef de projet Sugar on a Stick, et étudiant allemand récemment diplômé rapporte que «les enseignants nous ont dit à quel point la fiabilité du programme est importante lorsqu’il est utilisé par les élèves en classe. C’est pour cela que nous avons décidé de rendre disponible une version avec un noyau stable et qui soit adaptable facilement à son environnement. Mirabelle est une version avec laquelle les enseignants pourront adapter les Activités en fonction des intérêts des enfants. De plus, une partie de notre stratégie consiste à faire naître un schéma de développement durable en invitant de nouvelles personnes à contribuer au projet. Nous avons aussi pu proposer les nouveautés de Mirabelle en optimisant la base de Sugar, la distribution GNU/Linux Fedora. Mirabelle est donc officiellement dérivée de Fedora, un Fedora Spin.»

Sugar Labs a également rendu disponible le «Sugar Creation Kit», un DVD qui comprend Mirabelle, la documentation associée ainsi qu’un ensemble d’Activités pour Sugar, parmi les plus amusantes et attrayantes, aussi disponibles également en téléchargement sur le Sugar Activity Library ([http://activities.sugarlabs.org](http://activities.sugarlabs.org)).

Thomas Gilliard, un des contributeurs à Sugar Labs explique que «Le Sugar Creation Kit permet de transformer n’importe quel PC en un poste capable de configurer des clés Sugar On A Stick. Les outils et la documentation nécessaire sont déjà présents sur le DVD si bien que les enseignants ne perdront pas de temps à rechercher une information, même derrière un pare-feu, sans avoir à se connecter au réseau».

Sugar Labs sera présent pour toute la durée du salon LinuxTag 2010 au stand 115, Hall 7.2a.

**À propos du Sugar Labs** : Sugar Labs est une organisation non lucrative de volontaires, membre du projet Software Freedom Conservancy. À l’origine intégré au projet One Laptop Per Child, Sugar Labs coordonne les volontaires dans le monde qui sont passionnés par l’idée de fournir des opportunités d’éducation à travers la plate-forme éducative Sugar. Sugar Labs est soutenu par des donations et cherche des fonds pour accélérer son développement. Pour plus d’informations, voir [http://www.sugarlabs.org](http://www.sugarlabs.org)

Sugar Labs est une marque déposée de la Software Freedom Conservancy. Les autres marques déposées sont la propriété respective de leurs auteurs.`,$o=Object.freeze(Object.defineProperty({__proto__:null,default:z},Symbol.toStringTag,{value:"Module"})),F=`---
title: "La plateforme éducative Sugar et l'interface bureautique GNOME désormais présents sur le nouvel XO 1.5 de la fondation OLPC, ainsi que le nouveau modèle XO-HS High School Edition"
category: "PRESS RELEASE"
date: "2010-01-14"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

ASUNCIÓN, le 14 juin 2010 – Sugar Labs, le projet d'interface bureautique libre GNOME, et la fondation One Laptop per Child (OLPC) ont annoncé conjointement une mise à jour du logiciel de l'ordinateur XO-1.5. Les 1,5 millions d'enfants qui utilisent déjà Sugar sur le XO-1 d'origine pourront également bénéficier de cette mise à jour, grâce au concours du Paraguay Educa qui a adapté cette mise à jour pour le XO-1.

La plateforme éducative Sugar fait la promotion de l'apprentissage collaboratif à travers des Activités adaptées aux enfants, qui encouragent une pensée critique. L'interface bureautique GNOME, installé sur toutes les distributions majeures GNU/Linux, est destinée aux enfants plus âgés et aux adultes. Changer d'environnement se fait en un clic. Avec l'environnement GNOME présent sur l'ordinateur XO, la porte est ouverte à des millers d'applications éducatives et créatives supplémentaires.

Le XO-1.5 est basé sur le même design que le premier XO. Equipé d'un processeur VIA, il est deux fois plus rapide que la première génération et dispose de quatre fois plus de mémoire RAM et d'espace de stockage. La fondation OLPC a annoncé la disponibilité d'une version destinée aux collégiens du dernier XO-1.5, nommé XO-HS (High School Edition), avec un clavier entièrement revu, plus confortable pour les élèves plus âgés. Le premier déploiement du XO-HS se déroulera en septembre en Uruguay dans le cadre du très réussi Plan Ceibal.

Les enfants habitués au XO-1 pourront évoluer vers un XO-1.5 avec ses fonctionnalités supérieures. "Le projet One Laptop per Child promeut le logiciel libre si bien que l'enfant pourra grandir et adapter son XO à ses besoins. La plateforme Sugar sur le XO est l'élément clé de notre mission éducative car il offre à l'élève un environnement d'apprentissage unique et intuitif", explique Rodrigo Arboleda, président de l'association OLPC.

Stormy Peters, Directeur Exécutif de la fondation GNOME, indique que "Nous sommes vraiment enthousiasmés de travailler avec Sugar et le projet OLPC pour fournir une interface bureautique aux enfants de tous les âges. La mission de GNOME est de fournir une interface bureautique libre et accessible à tous. De l'Uruguay au Ghana, les enfants pourront utiliser leurs nouveaux XO pour apprendre et pour montrer à leurs amis et famille comment utiliser Sugar et GNOME."

Walter Bender, Directeur Exécutif du Sugar Labs, précise que "La fluidité du passage d'un bureau à l'autre offre aux élèves la capacité de passer d'un environnement d'apprentissage - Sugar - à un environnement de production et de productivité - GNOME. Ils ont ainsi les moyens de transformer les compétences créatives qu'ils ont acquis à l'école primaire en des compétences entrepreneuriales dans le cadre de l'enseignement secondaire."

De plus, Sugar on a Stick permet aux enfants qui n'ont pas l'ordinateur XO de bénéficier de ce nouveau logiciel. Il est téléchargeable sur le site web du Sugar Labs dans sa nouvelle version, v3 "Mirabelle". Il peut être chargé sur n'importe quelle clé USB et utilisé pour démarrer un PC sous Sugar, sans modifier le contenu du disque dur. L'ordinateur XO et Sugar on a Stick fonctionnent avec Fedora GNU/Linux.

**À propos du Sugar Labs :**  
Sugar Labs est une organisation non lucrative de volontaires, membre du projet Software Freedom Conservancy. À l’origine intégré au projet One Laptop Per Child, Sugar Labs coordonne les volontaires dans le monde qui sont passionnés par l’idée de fournir des opportunités d’éducation à travers la plate-forme éducative Sugar. Sugar Labs est soutenu par des donations et cherche des fonds pour accélérer son développement. Pour plus d’information, voir <http://www.sugarlabs.org>

**À propos de GNOME :**  
GNOME est un projet de logiciel libre qui développe, pour toutes les distributions majeures de GNU/Linux et d'Unix, une interface bureautique complète, accessible et facile d'utilisation. Fort d'un succès mondial, grâce à de larges déploiements dans les grandes entreprises et avec des millions d'utilisateurs dans les PME et chez les particuliers, GNOME intègre un environnement de développement permettant de créer de nouvelles applications. La fondation à but non lucratif GNOME est constituée de centaines de volontaires développeurs et entreprises leader sur leur marché. Plus d'informations sont disponibles sur [http://www.gnome.org](http://www.gnome.org) et [http://foundation.gnome.org](http://foundation.gnome.org).

**À propos de One Laptop per Child**  
([http://www.laptop.org](http://www.laptop.org)) : OLPC est une organisation à but non-lucratif créée par Nicholas Negroponte et d'autres membres du Media Lab du MIT afin de concevoir, produire et distribuer des ordinateurs portables suffisamment abordables pour permettre à chaque enfant du monde d'avoir un accès au savoir et aux formes modernes d'éducation.

*Sugar Labs est une marque déposée de la Software Freedom Conservancy. Les autres marques déposées sont la propriété respective de leurs auteurs.*`,Yo=Object.freeze(Object.defineProperty({__proto__:null,default:F},Symbol.toStringTag,{value:"Module"})),U=`---
title: "Sugar Learning Platform and GNOME Desktop Now Shipping on the One Laptop per Child XO-1.5; Will Run On New XO-HS"
category: "PRESS RELEASE"
date: "2010-06-14"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

ASUNCIÓN, June 14, 2010 – Sugar Labs, the GNOME Free Desktop Project, and One Laptop per Child (OLPC) have announced an update to the software offered on the OLPC XO-1.5. The 1.5 million children already using Sugar on the original XO-1 can also benefit from the update, since Paraguay Educa has backported the software.

The Sugar Learning Platform promotes collaborative learning through child-friendly Activities that encourage critical thinking. The GNOME free desktop is a hallmark of all major GNU/Linux distributions, suitable for older children and grownups. Switching between the two environments takes only a single click. With GNOME on the XO laptop, the door is opened to thousands of additional educational and productivity applications.

The XO-1.5 has the same industrial design as the original XO-1. Based on a VIA processor, it provides 2× the speed of the XO-1, 4× DRAM memory, and 4× FLASH memory. OLPC has announced the availability of a high-school edition of the XO-1.5, the XO-HS, with a newly designed keyboard, more comfortable for older students. The first deployment of the XO-HS is set to begin in Uruguay under the highly successful Plan Ceibal in September.

Children familiar with the XO-1 will naturally grow into the XO-1.5 with its expanded functionality. “One Laptop per Child promotes open-source software so that it can grow and adapt to the needs of the child. The Sugar platform on the XO is key to our educational mission because it gives students a unique and intuitive learning software environment,” said OLPC Association CEO Rodrigo Arboleda.

Stormy Peters, Executive Director of the GNOME Foundation, said, “We're really excited to be working with Sugar and OLPC to provide desktop software to children of all ages. GNOME's mission is to provide a free desktop accessible to everyone. Children from Uruguay to Ghana will be able to use their XOs to learn and to show their friends and families how to use Sugar and GNOME.”

Walter Bender, Executive Director of Sugar Labs, said “the fluidity of movement between the two desktops gives learners the ability to transition from a learning environment – Sugar – to a production and productivity environment – GNOME. They have the means of honing the creative skills acquired in an elementary education setting into entrepreneurial skills in a secondary education setting.”

“Sugar on a Stick” allows children who don't have an XO laptop to benefit from this new software. Available for download from Sugar Labs in the new, v3 Mirabelle flavor, it can be loaded onto an ordinary USB thumbdrive and used to start a PC in Sugar without touching the hard disk. The XO laptops and Sugar on a Stick run Fedora GNU/Linux.

### About Sugar Labs

Sugar Labs, a volunteer-driven, nonprofit organization, is a member project of the Software Freedom Conservancy. Originally part of the One Laptop Per Child project, Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities to children through the Sugar Learning Platform. Sugar Labs is supported by donations and is seeking funding to accelerate development. For more information, please visit [http://www.sugarlabs.org](http://www.sugarlabs.org).

### About GNOME

GNOME is a free-software project which develops a complete, accessible and easy-to-use desktop standard on all leading GNU/Linux and Unix distributions. Popular with large corporate deployments and millions of small-business and home users worldwide, it includes a development environment to create new applications. The nonprofit GNOME Foundation is composed of hundreds of volunteer developers and industry-leading companies. More information can be found at [http://www.gnome.org](http://www.gnome.org) and [http://foundation.gnome.org](http://foundation.gnome.org).

### About One Laptop per Child

[http://www.laptop.org](http://www.laptop.org): OLPC is a non-profit organization created by Nicholas Negroponte and others from the MIT Media Lab to design, manufacture and distribute laptop computers that are inexpensive enough to provide every child in the world access to knowledge and modern forms of education.`,Qo=Object.freeze(Object.defineProperty({__proto__:null,default:U},Symbol.toStringTag,{value:"Module"})),N=`---
title: "Sugar Learning Platform e GNOME Desktop sono disponibili per gli XO-1.5 di One Laptop per Child; Compatibili anche per i nuovi XO-HS High School Edition"
category: "PRESS RELEASE"
date: "2010-06-14"
author: "Sugar Labs"

---
<!-- markdownlint-disable -->

ASUNCIÓN, 14 Giugno, 2010 – Sugar Labs, GNOME Free Desktop Project, e One Laptop per Child (OLPC) annunciano un aggiornamento al software fornito insieme sui OLPC XO-1.5. Anche il milione e mezzo di bambini che già utilizzano Sugar con gli XO-1 originali potranno beneficiare dell'aggiornamento grazie al backporting realizzato da Paraguay Educa.

Sugar Learning Platform promuove l'apprendimento collaborativo attraverso molteplici Attività orientate all'infanzia, studiate anche per stimolare il pensiero critico. Lo GNOME free desktop è il marchio di fabbrica di tutte le principali distribuzioni GNU/Linux ed è ottimo per i bimbi più grandi e gli adolescenti. Per alternare i due ambienti operativi è sufficiente un singolo click. Con GNOME sui laptop XO si apre la porta a migliaia di altri applicativi per la didattica e per la produttività.

Il laptop XO-1.5 ha design identico all'XO-1 originale. Essendo basato su processore VIA, ha il doppio della velocità, il quadruplo della memoria RAM ed il quadruplo della memoria FLASH rispetto a un XO-1. OLPC ha annunciato la disponibilità di una versione specifica per le scuole superiori dell'XO-1.5, che sarà chiamata XO-HS, dotata di una tastiera riprogettata per essere più funzionale per gli studenti più grandi. La prima consegna di XO-HS è prevista in settembre in Uruguay nel contesto del progetto di successo Plan Ceibal.

I bambini che hanno già familiarità con XO-1 potranno crescere con le maggiori funzionalità di XO-1.5. “One Laptop per Child" promuove il software libero così che possa crescere, migliorare ed adattarsi alle esigenze dei bambini. La Piattaforma Sugar su XO è un componente chiave per la nostra missione educativa, in quanto offre agli studenti un ambiente software di lavoro uniforme e intuitivo", dichiara Rodrigo Arboleda, CEO della OLPC Association.

Stormy Peters, Direttore Esecutivo della GNOME Foundation, dichiara, “Siamo entusiasti di avere l'opportunità per lavorare con Sugar e OLPC per fornire un software di desktop ai giovani di tutte le età. La missione di GNOME è quella di realizzare un desktop libero utilizzabile da tutti. Bambini dall'Uruguay al Ghana potranno utilizzare i loro laptop XO per apprendere e insegnare ai loro amici e genitori come utilizzare insieme Sugar e GNOME.”

Walter Bender, Direttore Esecutivo di Sugar Labs, dichiara “la fluidità di movimento fra i due ambienti desktop offre agli studenti la possibilità di passare da una piattaforma di apprendimento – Sugar – ad un ambiente di produttività e lavoro – GNOME. Avranno quindi gli strumenti per utilizzare le conoscenze creative acquisite nella loro educazione di base per sviluppare capacità imprenditoriali nella educazione secondaria.”

“Sugar on a Stick” permette ai bambini che non possiedono un laptop XO di beneficiare di questo nuovo software. Disponibile per il download dal sito internet di Sugar Labs nella nuova versione, v3 Mirabelle, può essere caricato su una normale chiavetta USB di memoria ed utilizzata per avviare un PC con Sugar senza modificare in alcun modo il computer ospite. I laptop XO e Sugar on a Stick utilizzano Fedora GNU/Linux.

**In merito a Sugar Labs**: Sugar Labs, a volunteer-driven, nonprofit organization, è un progetto membro della Software Freedom Conservancy. Originariamente parte del progetto One Laptop Per Child, Sugar Labs coordina volontari di tutto il mondo motivati ad offrire opportunità ai bambini di apprendere attraverso la Sugar Learning Platform. Sugar Labs è sorretta solo da donazioni e sta cercando aiuto e collaborazione da volontari per accelerare lo sviluppo. Per maggiori informazioni visitate: [http://www.sugarlabs.org](http://www.sugarlabs.org).

**In merito a GNOME**: GNOME è un progetto di free-software che sviluppa un desktop standard completo, accessibile e di facile utilizzo, per tutte le principali distribuzioni GNU/Linux e Unix. Ampiamente conosciuto e utilizzato nelle grandi imprese e in milioni di piccole aziende e utenti privati nel mondo, include anche un ambiente completo di sviluppo per creare nuovi programmi. La nonprofit GNOME Foundation è costituita da centinaia di sviluppatori volontari e da industrie-leader. Ulteriori informazioni possono essere reperite presso: [http://www.gnome.org](http://www.gnome.org) e [http://foundation.gnome.org](http://foundation.gnome.org).

**In merito a One Laptop per Child** ([http://www.laptop.org](http://www.laptop.org)): OLPC è una organizzazione non-profit creata da Nicholas Negroponte ed altri del MIT Media Lab per progettare, produrre e distribuire laptop computers che siano così economici da poter fornire ad ogni bambino del mondo accesso alla conoscenza e alle più moderne forme di apprendimento.`,Zo=Object.freeze(Object.defineProperty({__proto__:null,default:N},Symbol.toStringTag,{value:"Module"})),H=`---
title: "La organización sin fines de lucro Sugar Labs patrocina el equipo de ciclistas Team Chipotle para dar a conocer su misión educativa."
excerpt: "Sugar Labs se asocia con el equipo de ciclismo Team Chipotle en un acuerdo innovador de patrocinio para recaudar fondos y dar a conocer su misión educativa, involucrando a niños en Uruguay para documentar la carrera usando sus laptops XO."
category: "PRESS RELEASE"
date: "2011-04-15"
slug: "sugar-labs-patrocina-team-chipotle-mision-educativa"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "ciclismo,educacion,olpc,uruguay,team-chipotle,stem,plan-ceibal,laptops-xo"
---
<!-- markdownlint-disable -->

MONTEVIDEO, Uruguay, Abril 15, 2011 — Sugar Labs (R), el fabricante de software para el proyecto One Laptop Per Child (OLPC), va a patrocinar a Team Chipotle, el equipo de ciclistas de Slipstream Sports LLC en un acuerdo sin precedentes que permitirá recabar fondos para la organización sin fines de lucro. La participación del equipo Chipotle permitirá que se conozca la labor de Sugar Labs a lo largo de todo el mundo: la camiseta del equipo Chipotle Development llevará el logo de Sugar Labs.

"El joven equipo de ciclistas Slipstream Sports ha surgido del objetivo fundacional de la compañía de apoyar los jóvenes talentos y desarrollar la próxima generación de campeones de ciclismo. A los niños les encantan las carreras de bicicletas, y los jóvenes ciclistas son excelentes referentes para los ellos", dijo Jonathan Vaughters, CEO de Slipstream Sports. "Queremos generar un cambio en las vidas de los jóvenes estudiantes y atletas y nuestro innovador acuerdo de patrocinio con Sugar Labas es parte de ello."

El equipo participará durante los próximos 10 días en la 68a. Vuelta Ciclista del Uruguay 2011. Los escolares uruguayos se incorporarán al evento tomando fotos y escribiendo artículos con sus laptops verdes XO cuando la carrera llegue a sus ciudades. Enviarán su trabajo a [concurso@rapceibal.info](mailto:concurso@rapceibal.info) para que se publique en el blog [http://www.sugarlabs.org/vueltaciclista](http://www.sugarlabs.org/vueltaciclista). Los mejores artículos recibirán premios que serán entregados en el próximo evento de desarrolladores de software eduJAM! que tendrá lugar en Montevideo del 5 al 7 de mayo ([http://ceibaljam.org](http://ceibaljam.org)).

"Los deportes y STEM (por ciencia, tecnología, ingeniería y matemáticas en inglés) tienen una gran sinergia. Estamos entusiasmados con las oportunidad de despertar el interés de los niños en matemáticas y ciencia a través de su interés por la carrera", dijo Walter Bender, fundador y director ejecutivo de Sugar Labs.

Uruguay es el primer país en el mundo de equipar al 100% de estudiantes y maestros de escuela primaria, más de medio millón de personas, con una laptop OLPC XO ejecuando Sugar a través del Plan Ceibal ([http://ceibaljam.org](http://ceibaljam.org)).

Según Gabriel Eirea del CeibalJAM!, "Esta carrera, luego del fútbol, es el evento deportivo más popular en nuestro país y es una parte integral de la cultura local. Cada año durante Semana Santa esta carrera recorre muchas localidades remotas del país y es seguida por cientos de miles de entusiastas espectadores. La comunidad de voluntarios que apoya la implementación del Plan Ceibal, representada por RAP Ceibal y ceibalJAM!, desea promover el uso de las laptops XO en las escuelas, en las comunidades y promueve la apropiación de la tecnología. Con la plataforma Sugar y la laptop XO, nuestros niños no solamente consumen contenido, sino que lo generan. Durante la carrera, niños de todo el país bloguearán sobre el equipo. En el evento eduJAM!, desarrolladores de la plataforma Sugar se encontrarán con niños que se beneficiarán de su trabajo y son el centro de su misión."

Image: ![ChipotleDevelopmentTeam_RedlandsCyclingClassic.webp](/assets/post-assets/press/ChipotleDevelopmentTeam_RedlandsCyclingClassic.webp)

**Sobre Sugar Labs®**: Sugar Labs, una organización sin fines de lucro, conducida por voluntarios, es un proyecto miembro de Software Freedom Conservancy. Originalmente parte del proyecto One Laptop Per Child, Sugar Labs coordina voluntarios en todo el mundo que tienen pasión por dar a los niños oportunidades de educarse a través de la Plataforma de Aprendizaje Sugar. Sugar Labs se mantiene en base a donaciones y está buscando financiación y voluntarios para acelerar su desarrollo. Por más información, visite por favor [http://www.sugarlabs.org](http://www.sugarlabs.org).

**Sobre Slipstream Sports LLC**: fundada en 2005, Slipstream Sports, LLC es una empresa de avanzada en el rubro de gestión deportiva dedicada a promover el crecimiento ético del ciclismo y desarrollar la próxima generación de campeones de ciclismo. Por más información, por favor visite [http://www.slipstreamsports.com](http://www.slipstreamsports.com).

*Sugar Labs es una marca registrada de Software Freedom Conservancy. Otros nombres son marcas registradas de sus respectivos dueños.*

**NOTA:** El equipo Chipotle Development desafortunadamente no va a participar de la 68a. Vuelta Ciclista del Uruguay este año.`,ei=Object.freeze(Object.defineProperty({__proto__:null,default:H},Symbol.toStringTag,{value:"Module"})),q=`---
title: "Sugar Labs Nonprofit Sponsoring Team Chipotle to Raise Awareness of Educational Mission"
excerpt: "Sugar Labs partners with Team Chipotle cycling team in an innovative sponsorship arrangement to raise awareness and funds for its educational mission while engaging children in Uruguay to document the race using their XO laptops."
category: "PRESS RELEASE"
date: "2011-04-15"
slug: "sugar-labs-sponsoring-team-chipotle-awareness-educational-mission"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "cycling,education,olpc,uruguay,team-chipotle,stem,plan-ceibal,xo-laptops"
---
<!-- markdownlint-disable -->


MONTEVIDEO, Uruguay, April 15, 2011 — Sugar Labs®, software provider to the
One Laptop Per Child (OLPC) project, will sponsor Team Chipotle, the
Continental cycling team owned and operated by Slipstream Sports LLC, in a
groundbreaking arrangement which will raise funds to support the nonprofit's
educational mission. Team Chipotle will raise awareness for Sugar Labs at
races around the world with team jerseys carrying the Sugar Labs logo.

"Team Chipotle has grown out of our founding goal of developing the next
generation of cycling champions. Every kid loves a bike race and young
cyclists provide great role models for children," said Jonathan Vaughters, CEO
of Slipstream Sports. "We want to make a difference in the lives of young
athletes and children and our innovative sponsorship arrangement with Sugar
Labs is part of that."

The team will race over the next ten days in the 68th Vuelta Ciclista del
Uruguay 2011 and pupils there will participate, taking photos and writing
articles with their green XO laptops as the race passes through their towns,
and e-mailing them to
[concurso@rapceibal.info](mailto:concurso@rapceibal.info) for posting to a
blog ([http://www.sugarlabs.org/vueltaciclista](http://www.sugarlabs.org/vueltaciclista)). The best articles will win
prizes to be awarded at the eduJAM! Developers Summit which will take place in
Montevideo May 5–7 ([http://ceibaljam.org](http://ceibaljam.org)).

"Sports and STEM (Science, Technology, Engineering, and Mathematics) have a
great synergy. We are excited by the prospect of engaging children in learning
math and science through their excitement about the race", said Walter Bender,
founder and Executive Director of Sugar Labs.

Uruguay is the first country in the world to provide 100% of its elementary
school pupils and teachers - over half a million - with an OLPC XO laptop
running Sugar through its Plan Ceibal ([http://ceibaljam.org](http://ceibaljam.org)).

According to Gabriel Eirea of CeibalJAM!, "This race is, after football, the
most popular sports event in the country and is an integral part of our local
culture. Every year during Holy Week this race passes through the remotest
towns of the country and is followed by hundreds of thousands of enthusiastic
viewers. The volunteer community supporting Plan Ceibal, represented by RAP
Ceibal and ceibalJAM!, wants to promote the use of XO laptops beyond the
schools, inside the communities, advocating technology appropriation. With
Sugar and the XO, our children don't just consume content, they create it.
During the race, children throughout the country will be blogging about the
team. At eduJAM!, Sugar Labs developers will meet children who are at the
center of their mission and benefit from their work."

Image: ![ChipotleDevelopmentTeam_RedlandsCyclingClassic.webp](/assets/post-assets/press/ChipotleDevelopmentTeam_RedlandsCyclingClassic.webp)

About Sugar Labs: Sugar Labs, a volunteer-driven, nonprofit organization, is a
member project of the Software Freedom Conservancy. Originally part of the One
Laptop Per Child project, Sugar Labs coordinates volunteers around the world
who are passionate about providing educational opportunities to children
through the Sugar Learning Platform. Sugar Labs is supported by donations and
is seeking funding to accelerate development. For more information, please
visit [http://www.sugarlabs.org](http://www.sugarlabs.org).

About Slipstream Sports LLC: Founded in 2005, Slipstream Sports, LLC is a
highly progressive sports management company dedicated solely to promoting the
ethical growth of cycling and developing the next generation of cycling
champions. For more information, please visit
[http://www.slipstreamsports.com](http://www.slipstreamsports.com).

Sugar Labs is a registered trademark of the Software Freedom Conservancy.
Other names are trademarks of their respective owners.

NOTE: The Chipotle Development Team will unfortunately not race in the Vuelta
Ciclista del Uruguay this year.`,ni=Object.freeze(Object.defineProperty({__proto__:null,default:q},Symbol.toStringTag,{value:"Module"})),K=`---
title: "La organización educacional sin fines de lucro Sugar Labs(R) celebra el Día del Aprendizaje Digital con dos ganadores del premio Google Code-In"
excerpt: "Sugar Labs anuncia que dos estudiantes, Agustín Zubiaga Sánchez y Aneesh Dogra, han sido ganadores del premio principal de Google Code-In por sus significativas contribuciones a la plataforma de aprendizaje Sugar."
category: "PRESS RELEASE"
date: "2013-02-05"
slug: "sugar-labs-celebra-dia-aprendizaje-digital-ganadores-code-in"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "google-code-in,dia-aprendizaje-digital,educacion,programacion,estudiantes,codigo-abierto,python"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-es.20130205.pdf)

CAMBRIDGE, Mass, 5 de Febrero del 2013 – Sugar Labs(R), una organización educativa sin fines de lucro, proveedora de software libre para el aprendizaje para niños, se enorgullece de celebrar el 6 de febrero como el Día del Aprendizaje Digital.  
**Enlace:** [Digital Learning Day](http://www.digitallearningday.org)

...con dos ganadores del principal premio del Google Code-In, Agustin Zubiaga Sanchez y Aneesh Dogra, quienes tuvieron una brillante participación en el programa anual de Google, para estudiantes de entre 13 y 17 años de edad. Más de 50 participantes de 14 países participaron para mejorar Sugar, guiados por 22 voluntarios de Sugar Labs(R). Los ganadores visitarán las instalaciones de Google en Mountain View, CA, esta primavera.  
**Más info:** [Google Code-In 2012](http://developers.google.com/open-source/gci/2012)

Agustin (Aguz para sus amigos) tiene 15 años, vive en un pueblo de Uruguay y es un reciente graduado de la escuela técnica Rafael Perazza dependiente de la Universidad del Trabajo del Uruguay. Luego de usar Sugar por varios años, su maestro del club de computadoras lo animó a aprender el lenguaje de programación Python usado en Sugar. Uno de sus proyectos involucra código para agregar una imagen de fondo a la Vista de Hogar de Sugar. Él dice: "Comencé a programar gracias a Sugar y ahora estoy muy contento de ser uno de sus desarrolladores."

Aneesh, quien ya ganó el Google Code-In del año anterior, tiene 17 años y vive en Punjab, India. Él trabajó actualizando un gran número de Actividades Sugar para niños y contribuyó con el libro electrónico "Cómo hacer una Actividad Sugar".  
**Libro (EN):** [Make Your Own Sugar Activities](http://www.flossmanuals.net/make-your-own-su%20gar-activities)  
**Libro (ES):** [Cómo Hacer una Actividad Sugar](http://en.flossmanuals.net/como-hacer-una-actividad-sugar)

Habiendo ganado premios previamente, incluyendo el Concurso Raspberry Pi Summer Coding del último año, está interesado en aplicaciones audiovisuales y seguridad informática.  
**Premio anterior:** [Raspberry Pi Summer Coding](http://www.raspberrypi.org/archives/2544)  
**Blog personal de Aneesh:** [anee.me](http://anee.me)

"Fue muy difícil elegir los ganadores," comentó Chris Leonard, enlace por Sugar Labs(R) para el Google Code-In. "Un tercio de nuestros participantes completó múltiples tareas. Aneesh fue muy prolífico, completando más de 40 tareas y Aguz hizo mejoras fundamentales en la plataforma Sugar. Todos nuestros participantes aprendieron cosas en estos tres meses. Notablemente, un participante, Daniel Francis, de Uruguay, tuvo que retirarse del concurso porque fue elegido para la Comisión de Supervisión de Sugar Labs, durante el concurso, a la madura edad de 14 años."

"Seis años después de que Sugar apareció en las aulas, su primera generación de estudiantes está convirtiéndose en los ingenieros, escritores y maestros del mañana," dice Walter Bender, fundador de Sugar Labs. "Aguz y Daniel crecieron con Sugar en Uruguay donde es usado en cada escuela, y Google Code-In tuvo su primer participante desde Perú, donde Sugar es parte de un programa nacional también. Sugar fue diseñado para tener un piso bajo, sin techo, y su Diario, Actividades, colaboración integrada y Visualización de código lo hacen ideal para el aula."

Aunque Sugar es usado principalmente en países en desarrollo mundialmente a través del programa One Laptop Per Child, apela a que todos los niños descubran la era digital del siglo 21.  
**Conoce más:** [One Laptop Per Child](http://laptop.org)

El Dr. Gerald Ardito, un miembro del comité para Sugar Labs(R), maestro de escuela media y profesor de Ciencias de la Computación en Westchester, NY, ha usado las Laptops XO y Sugar en una variedad de contextos educacionales. "Lo que ha sido tan poderoso es ver a los estudiantes ser capaces de tomar posesión real de su aprendizaje cuando usan Sugar", él dice. "Los he visto una y otra vez, pasar de ser consumidores a ser productores de medios digitales."

Sugar Labs(R) desea agradecer a Google y a Bradley Kuhn de la organización Software Freedom Conservancy, madre de Sugar Labs y otros proyectos de software libre/código abierto.

**Imagen del anuncio:**  
![SugarLabs GCI 2012 Winners](/assets/post-assets/press/SugarLabs_GCI_2012_Winners.webp)

---

**Sobre Sugar Labs(R):**  
Sugar Labs, una organización sin fines de lucro, conducida por voluntarios, es un proyecto miembro de Software Freedom Conservancy. Originalmente parte del proyecto One Laptop Per Child, Sugar Labs coordina voluntarios en todo el mundo que tienen pasión por dar a los niños oportunidades de educarse a través de la Plataforma de Aprendizaje Sugar.  
Sugar Labs se mantiene en base a donaciones y está buscando financiación y voluntarios para acelerar su desarrollo.  
**Sitio oficial:** [www.sugarlabs.org](http://www.sugarlabs.org)

*Sugar Labs es una marca registrada de la Software Freedom Conservancy. Otros nombres y marcas corresponden a sus respectivos dueños.*`,ti=Object.freeze(Object.defineProperty({__proto__:null,default:K},Symbol.toStringTag,{value:"Module"})),V=`---
title: "Le Sugar Labs(R), organisme non lucratif à but éducatif, célèbre le 'Digital Learning Day' avec deux lauréats au grand prix du 'Google Code-In'"
excerpt: "Sugar Labs annonce deux étudiants, Agustin Zubiaga Sanchez et Aneesh Dogra, comme lauréats du grand prix Google Code-In qui ont apporté des contributions significatives à la plateforme d'apprentissage Sugar."
category: "PRESS RELEASE"
date: "2013-02-05"
slug: "sugar-labs-celebre-digital-learning-day-lauréats-google-code-in"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "google-code-in,digital-learning-day,education,programming,students,open-source,python"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-fr.20130205.pdf)

Cambridge (Massachusetts), 5 février 2013 — Le Sugar Labs(R), l'éditeur éducatif à but non lucratif de logiciels libres et ouverts à destination des enfants, a le plaisir de célébrer la Journée d'Apprentissage Numérique (Digital Learning Day) du 6 février.  
**Lien :** [Digital Learning Day](http://www.digitallearningday.org)

Avec les lauréats au grand prix Google Code-In :  
**Lien :** [Google Code-In 2012](http://developers.google.com/open-source/gci/2012)  
Agustin Zubiaga Sanchez et Aneesh Dogra, deux participants brillants au programme annuel de Google destiné aux élèves de l'enseignement secondaire, âgés de 13 à 17 ans. Plus de 50 participants représentant 14 pays, accompagnés par 22 tuteurs volontaires pour le Sugar Labs, ont contribué à améliorer Sugar. Les lauréats visiteront le siège de Google à Mountain View, en Californie, au cours du printemps prochain. Google Code-In et son programme associé destiné aux étudiants de niveau universitaire, le Google Summer of Code, invitent les organismes open source à encadrer des étudiants travaillant sur des tâches de programmation et de documentation réelles.

Agustin (Aguz pour ses amis) est âgé de 15 ans. Il vit dans un village en Uruguay et vient d'obtenir son diplôme universitaire du centre Rafael Perazza de l'Universidad del Trabajo del Uruguay (UTU). Utilisateur de Sugar depuis plusieurs années, son enseignant du club informatique l'a encouragé à apprendre le langage de programmation Python utilisé par Sugar. L'un de ses projets consistait à ajouter des images d'arrière-plan à la page d'accueil de Sugar. Il déclare : "C'est grâce à Sugar que j'ai commencé à programmer. Aujourd'hui, je suis très heureux d'être l'un de ses développeurs."

Aneesh, lui aussi lauréat du Google Code-In de l'an passé, a 17 ans et vit au Punjab, en Inde. Il a participé à la mise à jour de plusieurs "apps" Sugar destinées aux enfants et a contribué à la rédaction du livre électronique :  
**Lien :** [Réalisez votre propre activité Sugar](http://www.flossmanuals.net/make-your-own-sugar-activities)

Après avoir gagné différents prix, parmi lesquels :  
**Lien :** [Raspberry Pi Summer Coding Contest](http://www.raspberrypi.org/archives/2544),  
il s'intéresse aux applications audiovisuelles et à la sécurité informatique. Aneesh publie son blog :  
**Lien :** [anee.me](http://anee.me)

"Choisir les lauréats n'était pas une tâche facile", explique Chris Leonard, le correspondant du Sugar Labs auprès du Google Code-In. "Un bon tiers de nos participants ont réalisé différentes tâches. Aneesh a eu une activité prolifique, avec plus de 40 tâches à son actif, et Aguz a apporté des améliorations capitales à la plateforme Sugar. Tous nos participants ont beaucoup appris au cours de ces trois derniers mois. Fait remarquable, l'un des participants, Daniel Francis, d'Uruguay, a dû se retirer du concours après avoir été désigné au Sugar Labs Oversight Board pendant le déroulement du concours. Détail important : il vient tout juste d'avoir 14 ans."

"Six ans après la première utilisation de Sugar dans des salles de classe, cette première génération d'étudiants préfigure les ingénieurs, les auteurs et les enseignants de demain," a déclaré Walter Bender, le fondateur du Sugar Labs. "Aguz et Daniel ont grandi avec Sugar, en Uruguay, alors que Sugar est utilisé dans toutes les écoles et que le Google Code-In compte son tout premier participant originaire du Pérou, pays dans lequel Sugar intègre également le cursus scolaire national. Sugar a été conçu pour sa facilité d'accès et son potentiel illimité. Le 'Journal', les 'Activités', les fonctions de collaboration et de visualisation du code source, qui intègrent la plateforme Sugar, en font un instrument idéal pour la classe."

Sugar est utilisé dans de nombreux pays émergents dans le monde entier, participant au programme :  
**Lien :** [One Laptop Per Child](http://laptop.org)  
Il s'adresse, plus largement, à tous les enfants qui découvrent le 21ème siècle numérique.

Gerald Ardito, membre du bureau du Sugar Labs, enseignant de collège et professeur d'informatique à Westchester (New-York), utilise Sugar dans différents contextes éducatifs. De son propre aveu, "Observer les étudiants prendre littéralement en mains leur propre apprentissage grâce à Sugar est une expérience unique". "J'ai observé à de nombreuses reprises, au cours de ces dernières années, comment ils passaient du stade de consommateurs de médias numériques à celui de producteurs."

Le Sugar Labs tient à exprimer sa gratitude à Google et tout particulièrement à Bradley Kuhn, le directeur exécutif du Software Freedom Conservancy, organisme fédérant le Sugar Labs et 27 autres projets de logiciels libres et ouverts.

**Image :**  
![SugarLabs GCI 2012 Winners](/assets/post-assets/press/SugarLabs_GCI_2012_Winners.webp)

---

**À propos de Sugar Labs(R)**  
Sugar Labs(R) est une organisation non lucrative de volontaires, membre du projet Software Freedom Conservancy. À l’origine intégré au projet One Laptop Per Child, Sugar Labs coordonne les volontaires dans le monde qui sont passionnés par l’idée de fournir des opportunités d’éducation à travers la plate-forme éducative Sugar. Sugar Labs(R) est soutenu par des donations et cherche des fonds pour accélérer son développement. Pour plus d’information, voir [www.sugarlabs.org/press](http://www.sugarlabs.org/press) ou contacter **pr@sugarlabs.org**.

*Sugar Labs(R) est une marque déposée de la Software Freedom Conservancy. Les autres marques déposées sont la propriété respective de leur auteurs.*`,ai=Object.freeze(Object.defineProperty({__proto__:null,default:V},Symbol.toStringTag,{value:"Module"})),J=`---
title: "Sugar Labs(R) Educational Nonprofit Celebrates Digital Learning Day With Two Google Code-In Grand Prize Winners"
excerpt: "Sugar Labs announces two students, Agustin Zubiaga Sanchez and Aneesh Dogra, as Google Code-In grand prize winners who made significant contributions to the Sugar Learning Platform."
category: "PRESS RELEASE"
date: "2013-02-05"
slug: "sugar-labs-celebrates-digital-learning-day-code-in-winners"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "google-code-in,digital-learning-day,education,programming,students,open-source,python"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-en.20130205.pdf)

CAMBRIDGE, Mass, February 5, 2013 — Sugar Labs(R), educational nonprofit provider of free and open-source learning software for children, is proud to celebrate **[Digital Learning Day](http://www.digitallearningday.org)** on February 6th with **[Google Code-In](http://developers.google.com/open-source/gci/2012)** grand prize winners Agustin Zubiaga Sanchez and Aneesh Dogra, who participated brilliantly in Google's annual program for middle and high school students aged 13 to 17. Over 50 participants from 14 countries, mentored by 22 Sugar Labs volunteers, helped to improve Sugar. The winners will visit Google headquarters in Mountain View, CA this spring. Google Code-In and its sister program for university students, Google Summer of Code, invite open source organizations to mentor students who work on real programming and documentation tasks.

Agustin (Aguz to his friends) is 15, lives in a village in Uruguay and is a recent graduate of Rafael Perazza Technical High School at Universidad del Trabajo del Uruguay. After using Sugar for several years, his computer club teacher encouraged him to learn the Python programming language used in Sugar. One of his projects involved code to add background images to Sugar's Home View. He says, "I started programming thanks to Sugar and now I am very happy to be one of its developers."

Aneesh, also a winner at last year's Google Code-In, is 17 and lives in Punjab, India. He worked on updating a large number of Sugar "Apps" for children and contributed to the "**[Make Your Own Sugar Activities!](http://www.flossmanuals.net/make-your-own-sugar-activities)**" ebook. Having won previous honors, including runner-up in last year's **[Raspberry Pi Summer Coding Contest](http://www.raspberrypi.org/archives/2544)**, he is interested in audiovisual applications and computer security. More information about Aneesh is available on his **[blog](http://anee.me)**.

"We had a hard time choosing our winners," commented Chris Leonard, Sugar Labs liaison for Google Code-In. "Fully a third of our participants completed multiple tasks. Aneesh was prolific, completing over 40 tasks, and Aguz made fundamental improvements to the Sugar platform itself. All of our participants learned over these past three months. Notably, one participant, Daniel Francis of Uruguay, had to take his name out the running because he was elected to the Sugar Labs Oversight Board during the contest at the ripe old age of 14."

"Six years after Sugar first appeared in classrooms, its first generation of learners are becoming tomorrow's engineers, writers, and teachers," said Walter Bender, founder of Sugar Labs. "Aguz and Daniel grew up with Sugar in Uruguay where Sugar is used in every school and Google Code-In had its first ever participant from Peru, where Sugar is part of the nationwide curriculum as well. Sugar was designed to be low floor, no ceiling and its Journal, Activities, built-in collaboration and View Source features make Sugar ideal for the classroom."

Sugar is used in developing countries worldwide through the **[One Laptop Per Child program](http://laptop.org)**, but it also appeals to all children discovering the digital 21st century. Dr. Gerald Ardito, a Sugar Labs board member, as well as a middle school teacher and professor of Computer Science in Westchester, NY, has used Sugar in a variety of educational settings. "It is so powerful to watch students be able to take real ownership of their learning when they are using Sugar", he said. "I have seen them time and time again move from being consumers of computer centered media to producers."

Sugar Labs wishes to thank Google and in particular Bradley Kuhn, executive director of the Software Freedom Conservancy, parent organization of Sugar Labs and 27 other free/libre software projects.

**Image:**  
![SugarLabs_GCI_2012_Winners.webp](/assets/post-assets/press/SugarLabs_GCI_2012_Winners.webp)

---

**About Sugar Labs(R):**  
Sugar Labs(R), a volunteer-driven, educational nonprofit organization, is a member project of the Software Freedom Conservancy. Originally part of the One Laptop Per Child project, Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities to children through the Sugar Learning Platform. Sugar Labs(R) is supported by donations and is seeking funding to accelerate development. For more information, please visit [sugarlabs.org/press](http://www.sugarlabs.org/press) or contact pr@sugarlabs.org.

Sugar Labs(R) is a registered trademark of the Software Freedom Conservancy. Other names are trademarks of their respective owners.`,oi=Object.freeze(Object.defineProperty({__proto__:null,default:J},Symbol.toStringTag,{value:"Module"})),X=`---
title: "Children Programmers Abound at First International TurtleArt Day"
excerpt: "Sugar Labs celebrates the first TurtleArt Day in Caacupé, Paraguay, with 275 students and 77 teachers exploring creative programming through the TurtleArt environment."
category: "PRESS RELEASE"
date: "2013-10-12"
slug: "children-programmers-first-international-turtleart-day"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "turtleart,programming,education,art,logo,children,paraguay,international-day"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-en.20131015.pdf)

CAACUPÉ, Paraguay, October 12, 2013 — Sugar Labs®, educational nonprofit provider of free and open-source learning software for children, is proud to celebrate **TurtleArt Day**  
- **Event Info:** [TurtleArt Day](http://turtleartday.org)  
in Caacupé, Paraguay, with 275 students, their parents, and 77 teachers. They were joined by educators and Sugar developers from 8 countries throughout the Americas and as far away as Australia. Additional TurtleArt Days are planned for Peru, Costa Rica, Argentina, and Malaysia; the next will be October 15th in Montevideo, Uruguay.

Caacupé has been the focus of a one-to-one learning program run by  
- **Organization:** [Paraguay Educa](http://www.paraguayeduca.org)  
since 2008. The foundation is active in 35 schools, working with 365 teachers and 9,700 children. The children of Caacupé live in areas with high poverty levels: 60% of them are street workers and most have at least one parent living abroad. Much of the coordination was done by "Evolution" children, youth leaders in Caacupé who attend school in the morning, teach in the afternoon, and on weekends supply technical support to school programs.

TurtleArt is a programming environment with a graphical "turtle" that draws colorful art based on snap-together elements. Its "low floor" provides an easy entry point for beginners. It also has "high ceiling" programming features that challenge the more adventurous student. TurtleArt's roots are in Logo, the first programming language for children, created by Seymour Papert, Wally Feurzeig, Daniel Bobrow, and Cynthia Solomon in 1967. Logo's friendly turtle, which relies on instructions from children to move, has inspired adaptations from Logo for the Apple® II to Lego® Mindstorms®, TurtleArt, and Scratch.

An international group of TurtleArtists travelled to Caacupé with the generous support of BBVA Bank to launch the first TurtleArt Day. Also participating was  
- **EduJam Group:** [EduJam!](http://ceibaljam.org)  
attendants, a group of developers who work on open-source educational software. Caacupé's participants enjoyed workshops to create TurtleArt projects; interactive programming that involved robots and sensors; and discussions where educators and children shared their experiences.

> "Logo was designed to be 'mathland'; TurtleArt is 'artland'," says Artemis Papert, co-creator of TurtleArt.  
> "It allows us to bring together art and programming. While you do art, you also do programming, math, and geometry — the tools you need while focusing on doing art. We have observed that artists become more comfortable with programming and programmers become more comfortable with art when they use TurtleArt."

Cecilia Rodríguez Alcalá, Executive Director of Paraguay Educa, said,  
> "The aspects of TurtleArt Day highlighted by the Evolution team included cultural exchange between the children and the international community, and children teaching each other, pursuing their personal interests, including projects involving physical-world interaction."

Claudia Urrea, an educator and member of the Sugar Labs Oversight Board, said,  
> "With TurtleArt, the children enjoyed programming the robots and using sensors, creating artistic images, engaging in the concrete use of mathematical concepts such as variables and random numbers, realizing how quickly the pace of their learning evolved, and discovering the multiple applicabilities of computation."

Andres Aguirre of the Butia project, a robot programmed with TurtleArt, said,  
> "Even though the children had limited time to use the robots, they were able to experiment with some high-level programming concepts such as conditionals and control structures."

**Images:**  
- ![caacupe-turtleartday-captura-pantalla.webp](/assets/post-assets/press/caacupe-turtleartday-captura-pantalla.webp)  
- ![caacupe-turtleartday.webp](/assets/post-assets/press/caacupe-turtleartday.webp)

---

### About Sugar Labs®  
Sugar Labs, a volunteer-driven, nonprofit organization, is a member project of the Software Freedom Conservancy. Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities through the Sugar Learning Platform. Sugar is installed on more than three million computers. Sugar Labs is supported by donations and is seeking funding to accelerate development.

For more information, please visit [sugarlabs.org/press](http://www.sugarlabs.org/press) or contact **pr@sugarlabs.org**.

*Sugar Labs® is a registered trademark of the Software Freedom Conservancy. Other names are trademarks of their respective owners.*`,ii=Object.freeze(Object.defineProperty({__proto__:null,default:X},Symbol.toStringTag,{value:"Module"})),$=`---
title: "Programadores niños abundan en el primer Día Internacional de TurtleArt"
excerpt: "Sugar Labs celebra el primer Día de Tortugarte en Caacupé, Paraguay, con 275 estudiantes y 77 profesores explorando programación creativa a través del entorno TurtleArt."
category: "PRESS RELEASE"
date: "2013-10-12"
slug: "primer-dia-internacional-turtleart"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "tortugarte,programming,education,art,logo,children,paraguay,international-day"
---
<!-- markdownlint-disable -->


[PDF](/assets/post-assets/press/SugarLabsPR-es.20131015.pdf)

Caacupé, Paraguay, 12 de octubre de 2013 — Sugar Labs®, el proveedor educativo de aprendizaje sin fines de lucro de software libre y de código abierto para los niños, se enorgullece de celebrar el Día de Tortugarte en Caacupé, Paraguay, con 275 estudiantes, sus padres y 77 profesores. A ellos se sumaron educadores y desarrolladores de Sugar procedentes de 8 países de América y de otros lugares lejanos como Australia. Están previstos Días de Tortugarte adicionales para Perú, Costa Rica, Argentina y Malasia; el próximo será el 15 de octubre en Montevideo, Uruguay.

Caacupé ha sido objeto del programa Una Computadora Por Niño —modelo de aprendizaje uno a uno— a cargo de Paraguay Educa desde 2008. La fundación opera en 35 escuelas, en colaboración con 365 profesores y 9.700 niños. Los niños y niñas de Caacupé viven en áreas con altos niveles de pobreza: el 60 % de ellos trabaja en la calle y la mayoría tiene al menos un padre que vive en el extranjero. Gran parte de la coordinación fue hecha por los chicos "Evolution", líderes juveniles de Caacupé que asisten a la escuela por la mañana, enseñan por la tarde y los fines de semana ofrecen asistencia técnica a los programas escolares.

Tortugarte es un entorno de programación con una "tortuga" gráfica que dibuja arte colorido a base de elementos de cierre conjunto. Su "piso bajo" proporciona un punto de entrada fácil para los principiantes. También cuenta con funciones de programación de "alto techo" que retan al estudiante más aventurero. Las raíces de Tortugarte están en Logo, el primer lenguaje de programación para niños, creado por Seymour Papert, Wally Feurzeig, Daniel Bobrow y Cynthia Salomón en 1967. La tortuga amistosa del logotipo, que se basa en las instrucciones de los niños para moverse, ha inspirado adaptaciones de Logo para Apple® II, Lego® Mindstorms®, Tortugarte y Scratch.

Un grupo internacional de Tortu-artistas viajó a Caacupé con el generoso apoyo del banco BBVA para lanzar el primer Día de Tortugarte. También participaron del eduJAM!, un evento de desarrolladores que trabajan en software educativo de código abierto. Los participantes disfrutaron de talleres para crear proyectos de Tortugarte en Caacupé, programación interactiva con robots y sensores, y discusiones donde educadores y niños compartieron sus experiencias.

"El logotipo fue diseñado para ser 'La Tierra de las Matemáticas'; Tortugarte es 'La Tierra del Arte'", dice Artemis Papert, co-creadora de Tortugarte. "Nos permite reunir el arte y la programación. Mientras uno hace arte, también hace programación, matemáticas y geometría —las herramientas que se necesitan mientras se centra en hacer arte. Hemos observado que los artistas se sienten más cómodos con la programación y los programadores se sienten más cómodos con el arte cuando utilizan Tortugarte."

Brian Silverman, co-creador de Tortugarte, observó: "Me quedé sorprendido por la pasión de los niños que vinieron al Día de Tortugarte: fueron salvajemente entusiastas y mantuvieron su atención durante seis horas. Llegaron al evento con solo una experiencia rudimentaria en Tortugarte y se fueron con más conocimiento acerca de su potencial artístico".

Cecilia Rodríguez Alcalá, directora ejecutiva de Paraguay Educa, dijo: "Entre los aspectos destacados del Día de Tortugarte sobresale el desempeño en equipo de los jóvenes Evolution, ya que incluye el intercambio cultural entre los niños y la comunidad internacional, así como la enseñanza entre pares y proyectos de interacción física en el mundo".

Claudia Urrea, educadora y miembro de la Junta de Supervisión de Sugar Labs, dijo: "Con Tortugarte, los niños disfrutaron de la programación de robots y el uso de sensores, la creación de imágenes artísticas, y la participación concreta en el uso de conceptos matemáticos como variables y números aleatorios. Fue notable la rapidez con que evolucionó su aprendizaje y el descubrimiento de las múltiples aplicaciones de la informática".

Andrés Aguirre, del proyecto Butiá —un robot programado con Tortugarte—, dijo: "A pesar de que había tiempo limitado para usar los robots, los niños fueron capaces de experimentar con algunos conceptos de programación de alto nivel, tales como condicionales y estructuras de control".

**Más información:**  
- [Día de Tortugarte](http://turtleartday.org)  
- [Paraguay Educa](http://www.paraguayeduca.org)  
- [Ceibal Jam](http://ceibaljam.org)

**Imágenes del evento:**  
- ![Captura de pantalla](/assets/post-assets/press/caacupe-turtleartday-captura-pantalla.webp)  
- ![Evento en Caacupé](/assets/post-assets/press/caacupe-turtleartday.webp)

**Sobre Sugar Labs®:**  
Es una organización sin fines de lucro dirigida por voluntarios, miembro de la Software Freedom Conservancy. Sugar Labs coordina alrededor del mundo a voluntarios apasionados por proveer oportunidades educativas a través de la plataforma de aprendizaje Sugar. Sugar se encuentra instalada en más de tres millones de computadoras. Sugar Labs se mantiene a base de donaciones y busca fondos para acelerar su desarrollo. Para más información visita [sugarlabs.org/press](http://www.sugarlabs.org/press) o escribe a [pr@sugarlabs.org](mailto:pr@sugarlabs.org).

Sugar Labs es una marca registrada de la Software Freedom Conservancy. Otros nombres y marcas mencionados corresponden a sus respectivos dueños.`,si=Object.freeze(Object.defineProperty({__proto__:null,default:$},Symbol.toStringTag,{value:"Module"})),Y=`---
title: "Une foule d'enfants programmeurs participe à la 1ère Journée Internationale TurtleArt"
excerpt: "Sugar Labs célèbre la première Journée TurtleArt à Caacupé, Paraguay, avec 275 élèves, 77 professeurs et des participants internationaux explorant la programmation créative à travers l'environnement TurtleArt."
category: "PRESS RELEASE"
date: "2013-10-12"
slug: "premiere-journee-internationale-turtleart"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "turtleart,programming,education,art,logo,children,paraguay,international-day"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-fr.20131015.pdf)

CAACUPÉ, Paraguay, le 12 Octobre 2013. Sugar Labs(R), fournisseur à but non lucratif de programmes éducatifs gratuits et sous licence libre, célèbre avec une grande fierté la journée TurtleArt à Caacupé, au Paraguay. 275 élèves y participent avec leurs parents ainsi que 77 professeurs. Des éducateurs et des développeurs Sugar se sont joints à eux, venant de 8 pays des Amériques mais aussi d'aussi loin que l'Australie. De nouvelles journées TurtleArt sont prévues au Pérou, au Costa Rica, en Argentine et en Malaysie; la prochaine aura lieu le 15 octobre à Montevideo, Uruguay.

Caacupé héberge depuis 2008 un programme d'"apprentissage un-à-un" mené par [Paraguay Educa](http://www.paraguayeduca.org). Cette fondation est présente dans 35 écoles, collabore avec 365 professeurs et 9.700 enfants. Les enfants de Caacupé vivent dans des zones de grande pauvreté: 60% d'entre eux sont des travailleurs des rues et la plupart ont au moins un de leur parents qui vit à l'étranger. Une bonne part de la coordination a été assurée par des jeunes de Caacupé, engagés dans le programme "Evolution". Ils suivent les cours à l'école le matin, enseignent l'après-midi et fournissent une assistance technique aux programmes de l'école le week-end.

TurtleArt est un environnement de programmation au sein duquel une "tortue" graphique trace des dessins colorés à partir d'éléments de base pouvant s'emboîter. Son caractère accessible fait d'elle l'activité idéale pour une initiation à la programmation. TurtleArt trouve ses origines dans le langage Logo, le premier langage de programmation pour enfants créé par Seymour Papert, Wally Feurzeig, Daniel Bobrow et Cynthia Solomon en 1967. La sympathique tortue de Logo, qui se déplace suivant les instructions données par les enfants, a inspiré des adaptations allant de l'Apple(R) II à Lego(R) Mindstorms(R), TurtleArt et Scratch.

Un groupe international d'artistes TurtleArt a fait le voyage jusqu'à Caacupé pour ce lancement de la première journée TurtleArt, grâce au généreux soutien financier de la banque BBVA. Parmi les participants à cette première journée on trouve aussi des développeurs de [EduJam!](http://ceibaljam.org), groupe qui développe des logiciels éducatifs en licence libre.

Les participants de Caacupé ont pris part avec enthousiasme à des ateliers autour de projets TurtleArt; de la programmation interactive utilisant des robots et des capteurs et enfin de discussions où éducateurs et enfants ont pu partager leurs expériences.

"Le langage Logo a été conçu comme le 'royaume des maths'; TurtleArt est plutôt le 'royaume du dessin d'art'" nous confie Artemis Papert, co-créateur de TurtleArt. "Il nous offre la possibilité de réunir dessin et programmation. Quand vous pratiquez le dessin, vous faites aussi de la programmation, des maths et de la géométrie – vous vous en servez comme outil pour dessiner. Nous avons remarqué que les artistes se sentent ensuite plus à l'aise en programmation et les programmeurs plus à l'aise dans les activités artistiques quand ils utilisent TurtleArt."

Brian Silverman, co-créateur de TurtleArt fait la remarque suivante: "J'ai été fasciné par la passion éveillée chez les enfants venant participer à la journée TurtleArt. Ils étaient enthousiastes en diable et sont restés concentrés pendant six heures. Ils sont venus ici avec une expérience de TurtleArt vraiment rudimentaire et sont repartis avec une meilleure compréhension de son potentiel artistique."

Cecilia Rodríguez Alcalá, directrice de Paraguay Educa, déclare: "Ce que l'équipe Evolution a mis en lumière lors de cette journée TurtleArt, ce sont les aspects d'échange culturel entre les enfants et la communauté internationale et le fait que les enfants enseignent les uns aux autres, tout en suivant leurs goûts personnels, notamment sur des projets qui comportent une interaction avec le monde physique."

Claudia Urrea, éducatrice et membre du bureau de supervision de Sugar Labs s'entousiasme : "Avec TurtleArt, les enfants adorent programmer les robots et utiliser les capteurs pour créer des images artistiques, s'adonner à des activités concrètes utilisant des concepts mathématiques tels que les variables et les nombres aléatoires. Ils se rendent compte de la vitesse à laquelle ils apprennent et découvrent les applications multiples de l'informatique."

Andres Aguirre du projet Butia, un robot programmé avec TurtleArt, déclare: "Bien que les enfants aient disposé d'un temps limité pour utiliser les robots, ils ont pu faire l'expérience de concepts de programmation haut-niveau tels que les tests conditionnels et structures de contrôle."

- **Lien:** [Día de Tortugarte](http://turtleartday.org)  
- **Lien:** [Paraguay Educa](http://www.paraguayeduca.org)  
- **Lien:** [CeibalJam!](http://ceibaljam.org)

Image: ![Capture d'écran TurtleArt Caacupé](/assets/post-assets/press/caacupe-turtleartday-captura-pantalla.webp)  
Image: ![Journée TurtleArt Caacupé](/assets/post-assets/press/caacupe-turtleartday.webp)

---

**À propos de Sugar Labs(R)**  
Sugar Labs(R) est une organisation non lucrative de volontaires, membre du projet Software Freedom Conservancy. Sugar Labs coordonne les volontaires dans le monde qui sont passionnés par l'idée de fournir des opportunités d'éducation à travers la plate-forme éducative Sugar; installée sur plus de 3 millions d'ordinateurs. Sugar Labs(R) est soutenu par des donations et cherche des fonds pour accélérer son développement. Pour plus d'information, voir [http://www.sugarlabs.org/press](http://www.sugarlabs.org/press) ou contacter **pr@sugarlabs.org**.

Sugar Labs(R) est une marque déposée de la Software Freedom Conservancy. Les autres marques déposées sont la propriété respective de leurs auteurs.`,ri=Object.freeze(Object.defineProperty({__proto__:null,default:Y},Symbol.toStringTag,{value:"Module"})),Q=`---
title: "Sugar Labs(R), organización sin fines de lucro para la Educación celebra dos Ganadores del Gran Premio de Google Code-In"
excerpt: "Sugar Labs reconoce a los estudiantes Ignacio Rodríguez y Jorge Alberto Gómez López como ganadores del gran premio de Google Code-In, quienes contribuyeron significativamente a mejorar la plataforma de aprendizaje Sugar."
category: "PRESS RELEASE"
date: "2014-01-22"
slug: "sugar-labs-celebra-ganadores-google-code-in"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "google-code-in,open-source,education,students,programming,development,uruguay,el-salvador"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-es.20140122.pdf)

CAMBRIDGE, Mass, Enero 22, 2014 — Sugar Labs(R), organización educativa sin fines de lucro que provee software de aprendizaje libre y de código abierto para niños, se enorgullece en reconocer a los ganadores del gran premio de Google Code-In (GCI) Ignacio Rodríguez y Jorge Alberto Gómez López, quienes participaron de forma brillante en el programa anual de Google para estudiantes de secundaria y bachillerato entre 13 a 17 años de edad.

A través de GCI, Google invita a las organizaciones de código abierto a asesorar estudiantes que trabajan en tareas reales de programación y documentación. Poco más de 30 participantes de más de una docena de países —desde Australia a Zimbabwe—, asesorados por voluntarios de Sugar Labs, ayudaron a mejorar la plataforma de aprendizaje Sugar que utilizan más de tres millones de niños en todo el mundo. Los ganadores visitarán la sede de Google en Mountain View, California esta primavera.

Ignácio, quien tiene 14 años y vive en Canelones, Uruguay, creció con Sugar y comenzó a participar en el desarrollo de Sugar desde hace tres años. "¡La competencia fue un lugar para socializar y hacer amigos!", dice él. "Aunque sentí presión, la comunidad estaba allí para ayudar."

Jorge, de 17 años, vive en Santa Tecla, El Salvador. "Nunca en mi vida soñé empezar a trabajar en un proyecto de código abierto; fue muy divertido explorar un mundo totalmente nuevo, aprender nuevas herramientas, y lo más importante, hacer nuevos amigos de diferentes partes del mundo —personas que comparten el mismo objetivo y trabajan como una comunidad. Siento que soy parte de Sugar Labs, que formó parte de un gran proyecto, con los amigos y mentores".

Completan la lista de finalistas de Sugar Labs: Sai Vineet de Jamshedpur, India; Emil Dudev desde Sofía, Bulgaria; y Sam Parkinson desde Canberra, Australia (la plataforma Sugar se utiliza ampliamente en las escuelas australianas). Sam comentó: "Contribuir a Sugar, además de darme experiencia en programación, me ha mostrado cómo la programación colaborativa puede ser divertida. ¡Y también ha sido divertido trabajar hacia una meta significativa común!"

"GCI ha hecho evidente que los usuarios de Sugar se están convirtiendo en los desarrolladores de Sugar: Sugar no sólo les da la licencia, sino también los medios para desarrollar sus propias herramientas de aprendizaje. Al tomar posesión, se convierten en responsables," dijo Walter Bender, fundador de Sugar Labs. "Ha sido difícil elegir a los ganadores. Muchos participantes completaron múltiples tareas. Ignacio fue prolífico, completando más de 60 tareas, pero nuestros cinco finalistas realizaron mejoras fundamentales a la plataforma misma de Sugar."

José Miguel García, un pedagogo del Departamento de Tecnología Educativa de CODICEN-ANEP en Montevideo, observó: "Por segundo año consecutivo, un joven de Uruguay ha ganado la competencia. La implementación del Plan Ceibal, que entrega en propiedad una computadora portátil por niño y adolescente en Uruguay permite alcanzar niveles de equidad en cuanto al acceso a las tecnologías. Estas computadoras portátiles, además de ser utilizadas en la educación formal, permiten a los jóvenes investigar y desarrollarse en diversas actividades, ya sean lúdicas, artísticas, comunicativas, de programación, etc. Estos jóvenes, orientados e incentivados por su familia, profesores y/o por la propia comunidad de Sugar, alcanzan niveles importantes en el desarrollo del conocimiento, habilidad fundamental para la sociedad del siglo XXI."

Sugar Labs desea agradecer a Google y, en particular, a Bradley Kuhn, director ejecutivo de la Software Freedom Conservancy.

---

**Sobre Google Code-In**  
**Sitio Oficial:** [developers.google.com/open-source/gci](http://developers.google.com/open-source/gci)  
**Blog Oficial:** [google-opensource.blogspot.fr](http://google-opensource.blogspot.fr/2014/01/google-code-in-2013-drumroll-please.html) 

---

**Imágenes**  
![Ignacio Rodríguez - Ganador GCI 2013](/assets/post-assets/press/SugarLabs_GCI_2013_Winner_Ignacio.webp)  
![Jorge Alberto Gómez López - Ganador GCI 2013](/assets/post-assets/press/SugarLabs_GCI_2013_Winner_Jorge.webp)

---

**Sobre Sugar Labs(R)**  
Sugar Labs, una organización sin fines de lucro conducida por voluntarios, es un proyecto miembro de Software Freedom Conservancy. Originalmente parte del proyecto One Laptop Per Child, Sugar Labs coordina voluntarios en todo el mundo que tienen pasión por dar a los niños oportunidades de educarse a través de la Plataforma de Aprendizaje Sugar.  

Sugar Labs se mantiene en base a donaciones y está buscando financiación y voluntarios para acelerar su desarrollo. Por más información, por favor visite [sugarlabs.org](http://www.sugarlabs.org) o contacte a [pr@sugarlabs.org](mailto:pr@sugarlabs.org).

Sugar Labs es una marca registrada de la Software Freedom Conservancy. Otros nombres y marcas corresponden a sus respectivos dueños.

---`,li=Object.freeze(Object.defineProperty({__proto__:null,default:Q},Symbol.toStringTag,{value:"Module"})),Z=`---
title: "Sugar Labs(R) Educational Nonprofit Celebrates Two Google Code-In Grand Prize Winners"
excerpt: "Sugar Labs recognizes students Ignacio Rodríguez and Jorge Alberto Gómez López as winners of the Google Code-In Contest, who contributed significantly to improving the Sugar Learning Platform used by over three million children worldwide."
category: "PRESS RELEASE"
date: "2014-01-22"
slug: "sugar-labs-celebrates-google-code-in-winners"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "google-code-in,education,open-source,students,programming,development,uruguay,el-salvador"
---
<!-- markdownlint-disable -->

[PDF](/assets/post-assets/press/SugarLabsPR-en.20140122.pdf)

CAMBRIDGE, Mass, January 22, 2014 — Sugar Labs®️, educational nonprofit provider of free and open-source learning software for children, is proud to recognize the **Google Code-In Contest**.

**Watch Live:** [Google Code-In Overview](http://developers.google.com/open-source/gci/)  
**Platform:** [Google Open Source Blog](http://google-opensource.blogspot.fr/2014/01/google-code-in-2013-drumroll-please.html)

Grand-prize winners **Ignacio Rodríguez** and **Jorge Alberto Gómez López**, who participated brilliantly in Google's annual program for middle- and high-school students aged 13 to 17. Through GCI, Google invites open source organizations to mentor students who work on real programming and documentation tasks. Over 30 participants from more than a dozen countries — from Australia to Zimbabwe — mentored by Sugar Labs volunteers, helped to improve the Sugar Learning Platform used by over three million children worldwide. The winners will visit Google headquarters in Mountain View, California this spring.

Ignacio, who is 14 and lives in Canelones, Uruguay, grew up with Sugar and began participating in Sugar development three years ago. "The competition was a place to socialize and make friends!", he says. "While I felt pressure, the community was there to help."

Jorge, age 17, lives in Santa Tecla, El Salvador. "I never dreamed I would be working on an open source project; it was really fun to explore a whole new world, learn new tools, and most importantly, make new friends from different parts of the world — people that share the same objective and work as a community. I feel that I'm part of Sugar Labs, part of a big project, with friends and mentors."

Rounding out the Sugar Labs list of finalists are **Sai Vineet** from Jamshedpur, India, **Emil Dudev** from Sofia, Bulgaria, and **Sam Parkinson** from Canberra, Australia (Sugar is widely deployed in Australian schools). Sam remarked, "Contributing to Sugar has, besides giving me experience in programming, shown me how fun programming collaboratively can be! And it's also been fun working towards a common, meaningful goal."

> "GCI has made it evident that Sugar users are becoming the Sugar developers: Sugar not only gives them the license but also the means for developing their own tools for learning. In taking ownership, they become responsible,"  
> — *Walter Bender, founder of Sugar Labs*

"We had a difficult time choosing our winners. Many participants completed multiple tasks. Ignacio was prolific, completing over 60 tasks, but all five of our finalists made fundamental improvements to the Sugar platform itself."

**José Miguel García**, an education researcher from the Department of Educational Technology at Uruguay's CODICEN-ANEP in Montevideo, observed:

> "For the second consecutive year a youth from Uruguay has won the competition. The nationwide Plan Ceibal, which delivers a laptop running Sugar to every child, achieves levels of equity in access to technology. These laptops, besides being used in formal education, enable young people to explore and develop activities, whether recreational, artistic, communication, programming, etc. These young people, guided and encouraged by their families, teachers, and the Sugar community are reaching significant levels in the development of 21st century skills."

Sugar Labs wishes to thank Google and in particular **Bradley Kuhn**, executive director of the Software Freedom Conservancy.

<img src="/assets/post-assets/press/SugarLabs_GCI_2013_Winner_Ignacio.webp" alt="SugarLabs_GCI_2013_Winner_Ignacio.webp" style="width:100%">

<img src="/assets/post-assets/press/SugarLabs_GCI_2013_Winner_Jorge.webp" alt="SugarLabs_GCI_2013_Winner_Jorge.webp" style="width:100%">

---

### About Sugar Labs®️

Sugar Labs®️ is a volunteer-driven member project of [Software Freedom Conservancy](https://sfconservancy.org/), a nonprofit corporation. Originally part of the One Laptop Per Child project, Sugar Labs coordinates volunteers around the world who are passionate about providing educational opportunities to children through the Sugar Learning Platform.

Sugar Labs®️ is supported by donations and is seeking funding to accelerate development. For more information, please visit [www.sugarlabs.org/press](http://www.sugarlabs.org/press) or contact \`pr@sugarlabs.org\`.

Sugar Labs®️ is a registered trademark of the Software Freedom Conservancy. Other names are trademarks of their respective owners.`,di=Object.freeze(Object.defineProperty({__proto__:null,default:Z},Symbol.toStringTag,{value:"Module"})),ee=`---
title: "The connection between Sugar - Students - Teachers"
excerpt: "This Sugar Story explores how the Sugar learning platform connects students and teachers, highlighting user contributions, educational impact, and how the platform's open design encourages innovation from its community."
category: "SUGAR STORIES"
date: "2016-05-15"
slug: "connection-between-sugar-students-teachers"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "education,open-source,teachers,students,uruguay,programming,contribution,learning"
---
<!-- markdownlint-disable -->

Story1: The connection between Sugar - Students - Teachers
---------------------------------------------------------
* * *

One of the first formal studies of Sugar took place in Uruguay in 2009–10. Uruguay was the first country to provide every child a free internet-connected laptop computer. They began distributing OLPC XO laptops running Sugar in 2007. Even though Uruguay is a relatively small country, with less than 500,000 children, it took several years before they could achieve full coverage. The last region to receive laptops was Montevideo. Montevideo was last because there was less need there than in the more rural regions, since many urban children already had access to computers. The delay in deploying in Montevideo presented an opportunity to study the impact of Sugar. Children were asked in 2009—before they has Sugar—what they did with their computers. It should come as no surprise that they used their computers to play games (See Figure). The same children were asked in 2010—after almost one year of using Sugar—what they did with their computers. Again they responded that they used their computers to play games. They were still children after all. But they also used their computers to write, chat, paint, make and watch videos, search for information, etc. In other words, with Sugar, they used the computer as a tool. Children play games. But given the opportunity and the correct affordances, they can leverage computation to do much much more.

<img src="/assets/post-assets/data.webp" alt="Image of data from a DSPE-ANEP survey" class="img-fluid" width="100%"/>

**Figure: Data from a DSPE-ANEP survey of students in Montevideo before and after the deployment of Sugar**

Sugar was designed so that new uses emerging from the community could easily be incorporated, thus Sugar could be augmented and amplified by its community and the end users. We encouraged our end users to make contributions to the software itself. This was in part out of necessity: we were a small team with limited resources and we had no direct access to local curricula, needs, or problems. But our ulterior motive was to engage our users in development as a vehicle for their own learning.

One of the first examples of end-user contributions took place in Abuja, Nigeria, site of the first OLPC pilot project. While teachers and students took to Sugar quickly, they did confront some problems. The most notable of these was that the word-processor application, Write, did not have a spelling dictionary in Igbo, the dialect used in this particular classroom (and one of the more than three-hundred languages currently spoken in Nigeria). From a conventional software-development standpoint, solving this problem (300 times) would be prohibitively expensive. But for children in Abuja, equipped with Sugar, the solution was simple: confronted with the problem of lacking a dictionary, they made their own Igbo dictionary. The did not look for others to do the work for them. The took on the responsibility themselves. The Free/Libre Software ethic built into Sugar enabled local control and innovation.

John Gilmore heard the about our aspiration to reach out to our end users—children—at the 2008 Libreplanet conference. He asked, "how many patches have you received from kids?" At the time, the answer to his question was zero. But over the past nine years, the situation has changed dramatically. By 2015, 50% of the patches in our new releases were coming from children (See Table); our release manager in 2015–16 (Sugar v0.108) was Sam Parkinson, a fifteen-year-old from Australia; our current release manager (Sugar v0.110) is Ignacio Rodríguez, an eighteen-year-old from Uruguay who began hanging out on our IRC channel at age ten and contributing code at age twelve.

| Release number (date)   | Total Commits | Youth Commits | Release note URL                                                       |
|-------------------------|---------------|---------------|------------------------------------------------------------------------|
| 0.102 (July 2014)       | 424           | 108           | [View Notes](https://wiki.sugarlabs.org/go/0.102/Notes)                |
| 0.104 (February 2015)   | 249           | 127           | [View Notes](https://wiki.sugarlabs.org/go/0.104/Notes)                |

**Table 1: Sugar commits by youth contributors**

When the now former president of Uruguay, José Mujica, learned that a twelve-year-old from a small town east of Montevideo had programmed six entirely new Sugar activities for the XO, he smiled and said triumphantly: "Now we have hackers." In his eyes, this one child's ability to contribute to the global Sugar development community was a leading indicator of change and development in his country.

None of this happened on its own. End-user contributions are not simply an artifact of Sugar been Free/Libre Software. Open-source Software gives you access to the code and that Free/Libre Software gives you a license to make changes. But without some level of support, very few people will have the means to exercise the rights granted to them under the license. For this reason, we built scaffolding into Sugar to directly support making changes and extensions to Sugar applications and Sugar itself.

Sugar has no black boxes: the learner sees what the software does and how it does it. Sugar is written in Python and comes with all of the tools necessary to modify Sugar applications and Sugar itself. We chose Python as our development language because of its transparency and clarity. It is a very approachable language for inexperienced programmers. With just one keystroke or mouse click, the Sugar "view source" feature allows the user to look at any program they are running. A second mouse click results in a copy of the application being saved to the Sugar Applications directory, where it is immediately available for modification. (We use a "copy on write" scheme in order to reduce the risk of breaking critical tools. If there is no penalty for breaking code, there is better risk-reward ratio for exploring and modifying code.) The premise is that taking something apart and reassembling it in different ways is a key to understanding it.

Not every creative use of Sugar involves programming. Rosamel Norma Ramírez Méndez is a teacher from a school in Durazno, a farming region about two-hours drive north from Montevideo, Uruguay. Ramírez had her lessons for the week prepared when, first thing Monday morning, one of her students walked into her classroom holding a loofa. The child asked Ramírez, "teacher, what is this?" Rather than answering the question, Ramírez seized the opportunity to engage her class in an authentic learning experience. She discarded her lesson plans for the week. Instead, on Monday the children figured out what they had found; on Tuesday they determined that they could grow it in their community; on Wednesday they investigated whether or not they should grow it in their community; on Thursday they prepared a presentation to give to their farmer parents on Friday about why they should grow this potential cash crop. Not every teacher has the insight into learning demonstrated by Ramírez. And not every teacher has the courage to discard their lesson plans in order to capture a learning opportunity, But given an extraordinary teacher, she was able to mentor her students as they used Sugar as a tool for problem-solving. Ramírez encouraged her students to become active in their learning, which means that they engaged in doing, making, problem-solving, and reflection.

_**"Teachers can learn (and contribute) too." – Walter Bender**_

Sometimes teachers have been directly involved in Sugar software development. Sugar has an abacus application to help children explore whole-number arithmetic and the concept base (the activity allows the user to switch between various base representations of whole numbers). It also lets children design their own abacus. Teachers in Caacupé, Paraguay, were searching for a way to help their students with the concept of fractions. After playing with the Sugar abacus activity, they conceived and created—with the help of the Sugar developer community—a new abacus that lets children add and subtract fractions (See Figure). Sugar didn't just enable the teachers to invent, it encouraged them to invent.

<img src="/assets/post-assets/abacus.webp" alt="Image of the Caacupé Abacus" width="100%" class="img-fluid" />

**Figure: The Caacupé Abacus. The white beads represent whole numbers. The black beads represent fractions.**

Guzmán Trinidad, a high-school physics teacher from Montevideo, Uruguay and Tony Forster, a retired mechanical engineer from Melbourne, Australia collaborated on a collection of physics experiments that could be conducted with a pair of alligator clips and a small collection of Sugar applications. In the process of developing their experiments, they maintained regular communication with the developers, submitting bug reports, documentation, feature requests, and the occasional patch. Other examples of teacher and community-based contributions include Proyecto Butiá, a robotics and sensor platform build on top of Sugar (and GNOME) at Facultad de Ingeniería, Universidad de la República, Uruguay. Butiá inspired numerous other robotics platforms, e.g., RoDI (Robot Didáctico Inalámbrico) developed in Paraguay, as well as a wealth of projects aligned with the pedagogy of Constructionism. In the spirit of Sugar, these hardware projects were all designed to be "open": schematics and firmware were made available under Free/Libre licenses.

In 2012, we were part of a team running a week-long Sugar workshop for more than 60 teachers who had traveled to Chachapoyas, the regional capital of the Amazonas region of Peru. During the day we spend time reviewing the various Sugar activities and discussing strategies for using Sugar in the classroom. In the evenings, we gave a series of optional workshops on specialized topics. One evening, mid-week, the topic was fixing bugs in Sugar. It was not expected that many teachers would attend—in part because we were competing with an annual festival and in part because their background in programming was minimal. But almost everyone showed up. In the workshop, we walked through the process of fixing a bug in the Sugar Mind Map activity and used git to push a patch upstream. Teachers, especially rural teachers, have a hunger for knowledge about the tools that they use. This is in part due to intellectual curiosity and in part due to necessity: no one is going to make a service call to Amazonas. As purveyors of educational technology we have both a pedagogical and moral obligation to provide the means by which our users can maintain (and modify) our products. Enabling those closest to the learners is in the interest of everyone invested in educational technology as it both ensures viability of the product and it is a valuable source of new ideas and initiatives.

References
----------

**Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=vLiCumKjofc)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

- Ceibal Jam (2009). Convenio marco entre la Asociación Civil Ceibal Jam y la Universidad de la República.
- DSPE-ANEP (2011). Informe de evaluación del Plan Ceibal 2010. Administración Nacional de Educación Pública Dirección Sectorial de Planificación Educativa Área de Evaluación del Plan Ceibal.`,ci=Object.freeze(Object.defineProperty({__proto__:null,default:ee},Symbol.toStringTag,{value:"Module"})),ne=`---
title: "Sugar Labs receives eleven contributor projects for GSoC 2024"
excerpt: "Sugar Labs announces acceptance of eleven programming projects for Google Summer of Code 2024, including work on Music Blocks, Sugarizer, AI tools, and more."
category: "PRESS RELEASE"
date: "2024-05-01"
slug: "sugar-labs-gsoc-2024-projects"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "gsoc,google-summer-of-code,programming,education,ai,music-blocks,sugarizer,open-source,mentorship"
---

<!-- markdownlint-disable -->

**CAMBRIDGE, MA, USA -- May 1, 2024 -- Sugar Labs today announced it received eleven projects for participation in this year's Google Summer of Code (GSoC).**

## Sugar Labs receives eleven projects for GSoC

Sugar Labs will receive eleven projects for this year's Google Summer of Code (GSoC), a [12+ week programming project under the guidance of mentors](https://summerofcode.withgoogle.com/). This marks the fourteenth year that Sugar Labs has participated in GSoC since 2009.

## Sugar Labs projects for GSoC 2024

As part of GSoC 2024, Sugar Labs will be working on Music Blocks, Sugarizer, Flatpak, Raspberry Pi, and Sugar Activities. Plus, this summer, we will be working on several AI projects to create new tools for teaching and learning. These include an addition to the Chat and Pippy Activities in Sugar, as well as several Music Blocks projects.

Here is a detailed list of all eleven projects:

| Project Title                                          | Contributor              | Assigned Mentor(s)      |
|--------------------------------------------------------|--------------------------|--------------------------|
| Musical ideation through Generative AI                 | AbhijeetGSOC             | Devin Ulibarri           |
| Sugar on Raspberry Pi                                  | Anurag Singh (Oval-Elephant) | Walter Bender      |
| Music Blocks v4 Project Builder Integration            | Karan Palan              | Anindya Kundu            |
| Make your own Lesson Plan for Music Blocks             | khadar                   | Devin Ulibarri           |
| Add an AI-assistant to the Pippy Activity              | Kshitij_Shah             | Walter Bender            |
| Develop 8 new mathematical activities                  | Marsian                  | Chihurumnaya Ibiam       |
| Musical creation and transcription assistance via generative AI | Mubashir Shariq     | Devin Ulibarri           |
| Add an AI chatbot to the Chat Activity                 | Qixiang                  | Walter Bender            |
| Sugarizer 3D Volume Activity                           | Samarth Bagga            | Lionel Laské             |
| Maintain and Port 12 Sugar Activities to Flatpak       | SudoSu-bham              | tchx84                   |
| Sugarizer VueJS App                                    | UtkarshSiddhpura         | Lionel Laské             |

## Where to find more information about Sugar Labs and GSoC

**Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=vLiCumKjofc)  
**Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

GSoC publishes full details about each organization and their projects. You can find information about Sugar Labs's projects this year at [Google Summer of Code - Sugar Labs](https://summerofcode.withgoogle.com/programs/2024/organizations/sugar-labs).

Since 2019, Sugar Labs has published projects it is considering for Google Summer of Code in a [public repository published on GitHub](https://github.com/sugarlabs/GSoC). People interested in participating as contributors are encouraged to follow this repository.

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology to youth around the world. Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating the need for source code to be published publicly for study, licensed under a Free/Libre license for explicit permission to share and remix, and openly worked upon within a community where students are invited to make contributions, under guidance of experienced mentors.

Donations to support the work of Sugar Labs can be made at [https://wiki.sugarlabs.org/go/Sugar_Labs/Donate](https://wiki.sugarlabs.org/go/Sugar_Labs/Donate).`,ui=Object.freeze(Object.defineProperty({__proto__:null,default:ne},Symbol.toStringTag,{value:"Module"})),te=`---
title: "Sugar Labs: Past, present, and future"
excerpt: "Join Sugar Labs for the kickoff of our new event series exploring our history, current projects, and vision for the future of educational technology for youth around the world."
category: "EVENTS"
date: "2024-05-03"
slug: "sugar-labs-past-present-future"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "events, education, open source, community, sugar labs"
---

<!-- markdownlint-disable -->

**Sugar Labs kicks off a series of events with a live online event titled _"Sugar Labs: Past, present, and future"_ on Friday, May 3, 2024 at 15:00 ET (19:00 UTC).** We invite you to join us as we reflect on our story, explore our vision, and share how you can contribute.

**Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=jZs-QJNfglc)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

---

## Event Information

- **Event:** Sugar Labs: Past, present, and future  
- **Date:** May 3, 2024  
- **Time:** 15:00 ET (19:00 UTC)  
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=jZs-QJNfglc)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

---

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology for youth around the world.

Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating:

- Public access to source code for study  
- Free/Libre licensing for sharing and remixing  
- Open collaboration within a welcoming community  
- Contributions from students under experienced guidance

Support our work: [Donate here](https://www.sugarlabs.org/donate/)

---
`,hi=Object.freeze(Object.defineProperty({__proto__:null,default:te},Symbol.toStringTag,{value:"Module"})),ae=`---
title: "Sugar Labs announces nonprofit status, new executive director"
excerpt: "Sugar Labs officially announces its 501(c)(3) nonprofit status and the appointment of long-time contributor Devin Ulibarri as its first full-time executive director."
category: "PRESS RELEASE"
date: "2024-05-08"
slug: "sugar-labs-announces-nonprofit-status-new-executive-director"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "nonprofit,501c3,leadership,executive-director,free-software,education,announcement,organization"
---
<!-- markdownlint-disable -->

**CAMBRIDGE, MA, USA -- May 8, 2024 -- Sugar Labs today announced its 501(c)(3) nonprofit status as well as its pick for executive director, long-time contributor Devin Ulibarri.**

## Sugar Labs is a 501(c)(3) nonprofit

In 2019, the Sugar Labs oversight board voted to incorporate as its own entity and apply for nonprofit status. After that vote, the members of the board began efforts to leave the Software Freedom Conservancy, incorporate as Sugar Labs Inc., and applied for 501(c)(3) nonprofit status. In the spring of 2021, Sugar Labs Inc. was granted nonprofit status from the IRS.

**More Info:**  
- [Meeting Minutes – May 3, 2019](https://wiki.sugarlabs.org/go/Oversight_Board/Meeting_Minutes-2019-05-03)  
- [Software Freedom Conservancy](https://sfconservancy.org/)

## Devin Ulibarri hired as executive director

In January 2024, the board agreed to hire long-time Sugar Labs contributor Devin Ulibarri as their first full-time executive director. Prior to stepping into this role, he worked as the outreach & communications coordinator for the [Free Software Foundation](https://fsf.org).

**More Info:**  
- [Free Software Foundation](https://fsf.org)  
- [Music Blocks](https://www.sugarlabs.org/music-blocks)

Ulibarri has been a part of the Sugar Labs community for ten years, primarily working together with Walter Bender on [Music Blocks](https://www.sugarlabs.org/music-blocks) development. Devin has been an advocate of the work and philosophy of Sugar Labs, giving talks and leading workshops internationally. As a former board member, he also played a major role in helping the organization achieve its current nonprofit status.

Of the hiring, Sugar Labs board member and founder Walter Bender said, "Devin is a dedicated colleague, with deep roots in both Free/Libre Software and the pedagogy of Constructionism. We're thrilled to have Devin in this new role." Ulibarri responded: "I'm excited to serve within this capacity, to help Sugar Labs grow to bring all of its good work to more teachers, parents, and students across the US and, ultimately, around the globe."

## Current leadership

The officers of Sugar Labs Inc. are currently: Devin Ulibarri, executive director; Claudia Urrea, treasurer; and Walter Bender, secretary. The current board is Samson Goddy, Lionel Laské, Claudia Urrea, Walter Bender, and Alex Perez.

**More Info:**  
- [Sugar Labs Oversight Board](https://wiki.sugarlabs.org/go/Oversight_Board)`,gi=Object.freeze(Object.defineProperty({__proto__:null,default:ae},Symbol.toStringTag,{value:"Module"})),oe=`---
title: "Musical Squares: From Turtle Blocks to Music Blocks and Beyond"
excerpt: "Learn about Music Blocks, a visual programming language that combines music and coding, with a hands-on demonstration during this educational Sugar Labs livestream event."
category: "EVENTS"
date: "2024-05-10"
slug: "musical-squares-turtle-blocks-music-blocks-beyond"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "music,programming,education,turtle-blocks,visual-programming,livestream,coding,music-education"
---
<!-- markdownlint-disable -->

**Sugar Labs is hosting an event _"Learn about Music Blocks, visual programming language with a hands-on activity"_ on Friday, May 10, 2024 at 15:00 ET (19:00 UTC).** Join us for a fun and educational introduction to Music Blocks.

## Event Information

- **Title:** Musical Squares: From Turtle Blocks to Music Blocks and Beyond  
- **Date:** May 10, 2024  
- **Time:** 15:00 ET (19:00 UTC)  
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=jZs-QJNfglc)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

---

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities`,mi=Object.freeze(Object.defineProperty({__proto__:null,default:oe},Symbol.toStringTag,{value:"Module"})),ie=`---
title: "Learn to make games with Gameeky!"
excerpt: "Join developer Martin Abente Lahaye for a hands-on tutorial on creating games with Gameeky, a platform that empowers young learners and educators to build cooperative games and learning experiences."
category: "EVENTS"
date: "2024-05-17"
slug: "learn-make-games-with-gameeky"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "game-development,education,tutorial,livestream,programming,youth,coding,gameeky"
---
<!-- markdownlint-disable -->

**"Learn to make games with Gameeky" will be presented live by developer Martin Abente Lahaye. Get a hands-on tutorial for how to make games with Gameeky. Play, create, and learn: Gameeky lets young learners and educators create and explore cooperative games and learning experiences. Watch live on Friday, May 17, 2024 at 15:00 ET (19:00 UTC).**

## Event Information

- **Title:** Learn to make games with Gameeky  
- **Date:** May 17, 2024  
- **Time:** 15:00 ET (19:00 UTC)  
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=vLiCumKjofc)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

---

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology for youth around the world.

Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating:

- Public access to source code for study  
- Free/Libre licensing for sharing and remixing  
- Open collaboration within a welcoming community  
- Contributions from students under experienced guidance

Support our work: [Donate here](https://www.sugarlabs.org/donate/)
`,pi=Object.freeze(Object.defineProperty({__proto__:null,default:ie},Symbol.toStringTag,{value:"Module"})),se=`---
title: "An OLPC update with Lylian Peraza"
excerpt: "Sugar Labs hosts Lylian Peraza, Vice President of Project Development at OLPC, for a livestream discussion about the latest developments and projects from One Laptop Per Child."
category: "EVENTS"
date: "2024-05-24"
slug: "olpc-update-lylian-peraza"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "olpc,education,technology,livestream,interview,nonprofit,laptops,global-education"
---
<!-- markdownlint-disable -->

**Join Sugar Labs for a discussion with Lylian Peraza, Vice President of Project Development at OLPC. Watch live on Friday, May 24, 2024 at 15:00 ET (19:00 UTC).**

## Event Information

- **Title:** An OLPC update with Lylian Peraza  
- **Date:** May 24, 2024  
- **Time:** 15:00 ET (19:00 UTC)  
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=SuOta9MLLnw)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

---

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology for youth around the world.

Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating:

- Public access to source code for study  
- Free/Libre licensing for sharing and remixing  
- Open collaboration within a welcoming community  
- Contributions from students under experienced guidance

Support our work: [Donate here](https://www.sugarlabs.org/donate/)
`,bi=Object.freeze(Object.defineProperty({__proto__:null,default:se},Symbol.toStringTag,{value:"Module"})),re=`---
title: "Learn: How to git involved with Sugar Labs this summer"
excerpt: "Join Sugar Labs Executive Director Devin Ulibarri for a live session on how to get involved with Sugar Labs this summer while learning valuable programming skills and contributing to educational software."
category: "EVENTS"
date: "2024-05-31"
slug: "how-to-git-involved-sugar-labs-summer"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "volunteer,git,programming,education,summer-programs,open-source,mentorship,coding"
---
<!-- markdownlint-disable -->

**Sugar Labs executive director Devin Ulibarri gives a short intro on ways to "git" involved with Sugar Labs this summer, while learning valuable skills. Watch live on Friday, May 31, 2024 at 15:00 ET (19:00 UTC).**

## Event information

- **Title:** Learn: How to git involved with Sugar Labs this summer  
- **Date:** May 31, 2024  
- **Time:** 15:00 ET (19:00 UTC)  
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=W5ZLFBZkE34)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology to youth around the world. Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating the need for source code to be published publicly for study, licensed under a free/libre license for explicit permission to share and remix, and openly worked upon within a community where students are invited to make contributions, under guidance of experienced mentors.

Support our work: [Donate here](https://www.sugarlabs.org/donate/)
`,fi=Object.freeze(Object.defineProperty({__proto__:null,default:re},Symbol.toStringTag,{value:"Module"})),le=`---
title: "GSoC+DMP contributors initial check-in 1 of 2: Music Blocks projects"
excerpt: "Join Sugar Labs for an introduction to Google Summer of Code (GSoC) and DMP projects this summer, presented by GSoC and DMP interns andfacilitated by their mentors, Devin Ulibarri, Walter Bender, and Anindya Kundu. Watch live on Friday, June 7, 2024 at 13:00 ET (17:00UTC)."
category: "EVENTS"
date: "2024-06-07"
slug: "gsoc-dmp-contributors"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "volunteer,git,programming,education,summer-programs,open-source,mentorship,coding"
---
<!-- markdownlint-disable -->

**Join Sugar Labs for an introduction to Google Summer of Code (GSoC) and DMP projects this summer, presented by GSoC and DMP interns andfacilitated by their mentors, Devin Ulibarri, Walter Bender, and Anindya Kundu. Watch live on Friday, June 7, 2024 at 13:00 ET (17:00UTC).**

## Event information

- **Title:** GSoC+DMP contributors initial check-in 1 of 2: Music Blocks projects
- **Date:** June 7, 2024
- **Time:** 13:00 ET (17:00 UTC)
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=PeIS3gXPFj0)
- **Platform:**  [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)
---

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology for youth around the world.

Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating the need for source code to be published publicly for study, licensed under a free/libre license for explicit permission to share and remix, and openly worked upon within a community where students are invited to make contributions, under guidance of experienced mentors.

Support our work: [Donate here](https://www.sugarlabs.org/donate/)
`,wi=Object.freeze(Object.defineProperty({__proto__:null,default:le},Symbol.toStringTag,{value:"Module"})),de=`---
title: "Writing new Activities and sharing sugar with Youth"
excerpt: "James Simmons shares his journey of contributing to Sugar Labs since 2007, including developing Activities for reading e-texts and creating resources to help others build their own Sugar Activities."
category: "SUGAR STORIES"
date: "2024-9-13"
slug: "writing-new-activities-sharing-sugar-with-youth"
author: "James Simmons"
description: "Sugar Labs Contributor"
tags: "community,activities,development,python,education,programming,ebooks,manuals"
---
<!-- markdownlint-disable -->

_Editorial note: This article was given to us by Sugar Labs community member James Simmons as part of a series called Sugar Stories, which aims to highlight stories from members our community. If you would like to share your Sugar Story with us as an article for possible publication, please send a draft to_ [_info@sugarlabs.org_](mailto:info@sugarlabs.org)_. Please be aware that there is an editorial process that will require some additional effort and collaboration, even after submission._

I started working with OLPC with the Give One Get One program back in 2007. Honestly speaking, at the time, I was more interested in getting an XO laptop for myself than in working for the project. I thought I could use the laptop to read plain textbooks from [Project Gutenberg](https://www.gutenberg.org/). Kindles were very expensive back then, and this looked like a good alternative. And it was. But, at the time, the Read Activity only worked with PDFs. In an effort to expand this functionality, I taught myself to program in Python, studied the code for the [Read Activity](https://activities.sugarlabs.org/en-US/sugar/addon/4028), and created the [Read Etexts Activity](https://activities.sugarlabs.org/en-US/sugar/addon/4035), which supported reading plain text files. Next, I decided that I wanted to have an Activity for reading comic books in CBZ format and created two of them: [View Slides](https://activities.sugarlabs.org/en-US/sugar/addon/4039) and [Read SD Comics](https://activities.sugarlabs.org/en-US/sugar/addon/4340).

![Photo of James Simmons holding a copy of "Make your own Sugar Activities", sitting in front of a computer screen and a small OLPC laptop.](/assets/post-assets/stories/james.webp)

Photo of James Simmons with a copy of "Make your own Sugar Activities". Simmons has been contributing to Sugar since 2007.

At the time, the best, and maybe only, way to learn how to create Activities was to study the code of existing ones. I'm a systems analyst, so that wasn't too difficult for me, since I already had some of the important skills needed to do this. But this situation wasn't great for teachers and their students who may want to create Activities but didn't yet have the skills needed. In 2009 or so, I convinced myself to write a proper manual, which we called [_Make Your Own Sugar Activities!_](https://archive.org/details/MakeYourOwnSugarActivities) I did this using the Floss Manuals website. I was fortunate enough to have a very nice cover illustration done for me by [Oceana Rain Fields](https://archive.flossmanuals.net/make-your-own-sugar-activities/about-the-authors.html), a student participating in the Rural Design Collective's summer mentorship program. The printed book was given out as a door prize at one of the first OLPC conferences. The book was later translated into Spanish by a team of Sugar Labs volunteers as [_Como Hacer Una Actividad Sugar_](https://archive.org/details/ComoHacerUnaActividadSugar).

My personal involvement in Sugar Labs did not require any direct work with children, but, recently, I had the opportunity to introduce a young boy to Sugar. I had an old computer that I was going to give to a family friend, who was studying computer programming in college. His nine-year-old brother found out about it and wanted it for himself, so I installed the latest [Sugar Learning Platform](https://wiki.sugarlabs.org/go/What_is_Sugar#About_the_Sugar_Learning_Platform) and updated my old Activities to run on Python 3. He is pleased to have [the same operating system (OS) used by astronauts on the International Space Station (ISS)](https://www.fsf.org/blogs/community/gnu-linux-chosen-as-operating-system-of-the-international-space-station) and enjoys playing [Tux Kart](https://supertuxkart.net/Main_Page). I look forward to introducing him to even more that Sugar has to offer in the coming months.

It's nice to have the [Sugar environment](https://wiki.sugarlabs.org/go/What_is_Sugar) as an option for kids, as well as ways for the community to participate in the creation of new Activities.`,yi=Object.freeze(Object.defineProperty({__proto__:null,default:de},Symbol.toStringTag,{value:"Module"})),ce=`---
title: "The Sweet Spot – Issue 001"
excerpt: "The inaugural issue of Sugar Labs' newsletter covering recent updates, GSoC projects, ways to get involved, and community news."
category: "COMMUNITY NEWS"
date: "2024-09-20"
slug: "the-sweet-spot-issue-001"
author: "Sugar Labs"
description: "Community Newsletter"
tags: "newsletter,community,gsoc,dmp,updates,volunteer,outreach,education"
---
<!-- markdownlint-disable -->
# Recent news for September 20, 2024

Welcome to the very first issue of the **"Sweet Spot"**, a newsletter for Sugar Labs-related news in development, student and teacher work, events, how to get involved, and other news and information. This newsletter will be published semi-regularly for now, but the plan is to publish it on a bi-monthly, perhaps even monthly, basis in the future. Our aim with this newsletter is to help keep the growing body of Sugar Labs contributors on the same page, all while documenting our growth for our own and others' reference.

This first issue is meant to set a precedent of communication and documentation, as well as to help inform the community of our current status, recent progress, and future plans. Its predecessor is the ["Sugar Digest"](https://lists.sugarlabs.org/archive/community-news/), which still serves as an important catalog of our activities. Like Sugar Digest, this newsletter is intended to keep community members in the loop about everything going on within Sugar Labs. It will highlight any recent publications from us. It will occasionally include links to third-party news and updates that our community finds relevant.

This first issue has links and "news" from a few months back. Future installments will focus on a more acute timeframe than this inaugural issue, which aims to cover our news since the beginning of this year.

We hope that you enjoy this first issue. And, if you have something you'd like to share, please feel free to email [info@sugarlabs.org](mailto:info@sugarlabs.org). And for those who would like to volunteer in other ways, this edition has a list of volunteer help that we need with Sugar Labs overall.

## Updates

### GSoC and DMP students complete their projects

This year's GSoC and DMP students have completed their work for Sugar Labs. Students were asked to document their progress through blogs and participate in online events showcasing their work at regular intervals throughout the summer. You can find links to their blog posts on our bi-weekly summary posts on Medium and watch videos of their presentations on YouTube.

#### Bi-weekly GSoC and DMP summaries:

- [Please help us welcome this summer's Google Summer of Code team for Music Blocks development](https://medium.com/@sugarlabs/please-help-us-welcome-this-summers-google-summer-of-code-team-for-music-blocks-development-6c2524244605)
- [GSoC 2024 Students Weekly Report 1](https://medium.com/@sugarlabs/gsoc-2024-students-weekly-report-1-1af7c29ede0a)
- [GSoC 2024 Students Weekly Reports 2 and 3](https://medium.com/@sugarlabs/gsoc-2024-students-weekly-reports-2-and-3-af03ec159b49)
- [GSoC 2024 Students Weekly Reports 4 and 5](https://medium.com/@sugarlabs/gsoc-2024-students-weekly-reports-4-and-5-987825617340)
- [GSoC 2024 Students Weekly Reports 6 and 7](https://medium.com/@sugarlabs/gsoc-2024-students-weekly-reports-6-and-7-9eacb78e4093)
- [GSoC 2024 Students Weekly Reports 8 and 9](https://medium.com/@sugarlabs/gsoc-2024-students-weekly-reports-8-and-9-fb7d86cfabb1)
- [GSoC 2024 Students Weekly Reports 10 and 11](https://medium.com/@sugarlabs/gsoc-2024-students-weekly-reports-10-and-11-670e9f3bb6b0)

#### YouTube updates:

- [GSoC+DMP contributors initial check-in 1 of 2: Music Blocks projects](https://www.youtube.com/watch?v=PeIS3gXPFj0)
- [GSoC+DMP contributors initial check-in 2 of 2: Sugarizer, Raspberry Pi, Math games, and more](https://www.youtube.com/watch?v=k7eY-tkl2zw)
- [Summer Interlude by GSoC+DMP Interns, Presentation 1 of 2: Music Blocks and Sugarizer](https://www.youtube.com/watch?v=qWLWCdp4_D4)
- [Summer Interlude by GSoC+DMP Interns, Presentation 2 of 2: RPi, AI Assists, Math games, and more](https://www.youtube.com/watch?v=TARoJDitQVg)
- [Summer Finale by GSoC Interns, Presentation 1 of 3: Music Blocks and Sugarizer](https://www.youtube.com/watch?v=dVYpK5fTHsQ)
- [Summer Finale by GSoC Interns, Presentation 2 of 3: RPi, AI Assists, Math games, and more](https://www.youtube.com/watch?v=d0nTfKmOWl8)
- [Summer Finale by DMP Interns, Presentation 3 of 3: Music Blocks, Raspberry Pi and Math games](https://www.youtube.com/watch?v=0yMqz3GW3rY)

### Ways to get involved

Sugar Labs is seeking volunteer assistance in the following ways. Sustained, committed help in any of the following areas will help us grow as an organization. If you are passionate or curious to learn more about any of these roles, and are able to commit the time necessary, then we encourage you to apply. Send a notification of your interest to [info@sugarlabs.org](mailto:info@sugarlabs.org), including some information about yourself, what interests you about the volunteer role, and what experience/qualities make you a good candidate for the position.

- [Help Wanted](https://wiki.sugarlabs.org/go/Help_Wanted)
- [Introduction Video](https://www.youtube.com/watch?v=W5ZLFBZkE34)

## Social Links

- **Wiki** – [https://wiki.sugarlabs.org](https://wiki.sugarlabs.org)
- **Mastodon** – [https://mastodon.social/@sugar_labs](https://mastodon.social/@sugar_labs)
`,ki=Object.freeze(Object.defineProperty({__proto__:null,default:ce},Symbol.toStringTag,{value:"Module"})),ue=`---
title: "Board election results announcement: Three new members for the 2025-26 cycle"
excerpt: "The election results for the Sugar Labs Board of Directors have been announced. Devin Ulibarri, Sumit Srivastava, and Sebastian Silva will serve on the board for the 2025-26 cycle."
category: "COMMUNITY NEWS"
date: "2024-11-08"
slug: "board-election-results-2025-26"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "markdown,parser,test,education,post,aigenerated"
---
<!-- markdownlint-disable -->

# The results for the 2025-26 Sugar Labs board cycle have been determined.

The votes have been counted, and the [results](https://bettervoting.com/dp3xc7/) for the [2025-26 Sugar Labs board cycle](https://www.sugarlabs.org/community/2024/11/22/elections-extension/) have been determined.

The winners are **Devin Ulibarri, Sumit Srivastava, and Sebastian Silva**. They have all been notified and have agreed to serve on the Board of Directors for the 2025-26 cycle. For this election, we used [bettervoting.com](https://bettervoting.com) after doing research on various voting systems. Please read our [original election announcement](https://www.sugarlabs.org/community/2024/11/22/elections-extension/) for more information on how we decided upon this voting system.

The new members of the board will be filling the seats of two outgoing board members, **Lionel Laské and Alex Perez**, and one vacant seat.

The next election for three seats to the **2026-27 cycle** is planned for **August of next year**. All Sugar Labs members may vote, and members can:
- Run for election to the Board of Directors  
- Vote in the elections for the Board of Directors  
- Suggest referenda

As indicated in the [Sugar Labs Inc. bylaws](https://wiki.sugarlabs.org/go/Sugar_Labs/Governance), anyone with "significant and sustained" contributions to Sugar Labs is eligible for membership. If you believe you qualify for membership based on this criteria and are interested in [becoming an official member of Sugar Labs](https://wiki.sugarlabs.org/go/Sugar_Labs/Members), you are encouraged to send an email to <members@sugarlabs.org>.

If you were a member in the past but [did not vote in this election](https://www.sugarlabs.org/community/2024/11/22/elections-extension/), you will need to reapply for membership in order for your membership status to be reinstated. *(If you voted in this election, no further action is required.)* Registering for membership early will help ensure that you will be ready for the next election.

If you are interested in volunteering to assist with the next election in 2025, please contact <volunteering@sugarlabs.org> with your interest.

On behalf of the [Sugar Labs Board of Directors](https://www.sugarlabs.org/leadership/), we offer a big **Thank you!** to all who participated in this year's election.
`,vi=Object.freeze(Object.defineProperty({__proto__:null,default:ue},Symbol.toStringTag,{value:"Module"})),he=`---
title: "Deadline extended to November 24 to apply for a ballot and apply for candidacy"
excerpt: "Sugar Labs has extended the deadline for board of directors election participation to November 24, including both ballot applications and candidacy submissions for the upcoming election cycle."
category: "COMMUNITY NEWS"
date: "2024-11-22"
slug: "elections-extension-november-2024"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "elections,governance,board,voting,deadline,community,membership"
---
<!-- markdownlint-disable -->

**Sugar Labs is running an election this fall for three seats to its board of directors. The deadline to apply for a ballot, as well as submit candidacy for the board, is November 24. Sugar Labs community members are encouraged to participate. By submitting an application for a ballot you will also be considered for membership. Current members who do not apply for a ballot will have their membership rescinded.**

The deadline to apply for a ballot and apply for candidacy is fast approaching. Extended to Sunday, the deadline to [apply for a ballot](https://forms.gle/48F6h5wdV6BpSro66) is now November 24, 2024, End of Day (EoD), Anywhere on Earth (AoE). It is also the deadline to [submit for candidacy](https://wiki.sugarlabs.org/go/Oversight_Board/2025-2026-candidates#Candidates) for the [board of directors](https://www.sugarlabs.org/leadership/).

### Eligibility to vote

Since we made [our initial announcement](https://www.sugarlabs.org/community/2024/11/08/fall-board-elections-how-to-participate/), one of the most frequently asked questions has been *what determines eligibility for participating in the election?* Participation in the election is open to any member of Sugar Labs, and the eligibility requirements for membership are published on [Sugar Labs Members page](https://wiki.sugarlabs.org/go/Sugar_Labs/Members). 

The main gist, however, is that you've made a contribution to Sugar Labs. According to our definition, such a contribution "may be code, documentation, translations, maintenance of project-wide resources, *running a Sugar deployment*, or other non-trivial activities which benefit Sugar Labs."

If you've made such a contribution to Sugar Labs, you are eligible as a member, and, as a member, you may vote. ***Also, if you're not a member or unsure about your status, we still encourage you to submit an application for a ballot.*** We will automatically begin to determine your membership eligibility based on your publicly visible contributions, so no other steps are necessary on your part.

### Current members must vote in this election in order to maintain their membership status

Our most recent membership list may be found [here](https://wiki.sugarlabs.org/go/Sugar_Labs/Members/List). If you are currently a member but you do not apply for a ballot to vote in this election, then we will consider your membership to be rescinded and your membership will be made inactive. Because [our bylaws require a majority vote from members to pass certain amendments](https://wiki.sugarlabs.org/go/Sugar_Labs/Governance#ARTICLE_XI), we need to ensure that our current membership list is up-to-date with active members.

If you've made a contribution to Sugar Labs in the past, ***we strongly encourage you to vote in this election to maintain your membership status.*** We thank you for your contribution, and we encourage you to continue to participate in Sugar Labs, which is now investing in its growth and expansion like never before.

If it's been a while since you've made a contribution, we encourage you to join us on our main [Matrix channel](https://matrix.to/#/#sugar:matrix.org) and follow us on [GitHub](https://github.com/sugarlabs/). These two channels are currently the most active for coordinating contributions.

### Receive your ballot

We encourage you to vote. The application to receive your ballot, due by the End of Day (EoD), Anywhere on Earth (AoE), November 24, 2024, is [here](https://forms.gle/48F6h5wdV6BpSro66).

### Running for a board position

For those of you who would like to run for a board position, you will need to add your name and statement to the list on the [candidate page](https://wiki.sugarlabs.org/go/Oversight_Board/2025-2026-candidates). If you need any technical assistance with the wiki, please contact <elections@sugarlabs.org>.

Candidates should read and understand the terms of the [Sugar Labs Inc.'s Bylaws](https://wiki.sugarlabs.org/go/Sugar_Labs/Governance), as well as any domestic and international laws governing participation in a US-based 501(c)(3) nonprofit board.

### Election timeline

The updated timeline of the election is planned as follows, with a deadline to receive ballot applications for the End of Day (EoD), Anywhere on Earth (AoE), November 24, 2024, and a deadline to vote for the end of day on December 13, 2024.

| Stage      | Date         | Event                                                                                                                                                        |
|------------|--------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Stage I    | November 8   | Announcement of election date and first call for candidates.                                                                                                 |
| Stage II   | ~~Nov 22~~ Nov 24 | Deadline to receive [candidacy applications](https://wiki.sugarlabs.org/go/Oversight_Board/2025-2026-candidates#Candidates) and [ballot applications](https://forms.gle/48F6h5wdV6BpSro66). |
| Stage III  | November 27  | Ballots to be sent by email. If you do not receive your ballot by the following day, please email <elections@sugarlabs.org>.                                 |
| Stage IV   | December 13  | Deadline to vote.                                                                                                                                             |
| Stage V    | December 19  | Election results announced.                                                                                                                                  |

### Election method

After doing research on various [election software recommended by the FLOSS community](https://github.com/sugarlabs/elections-research), we have decided to use [bettervoting.com](http://bettervoting.com). The software is licensed under the AGPLv3, and the system supports automatic runoff vote tallying. Our internal research on the system can be found in [this document](https://docs.google.com/document/d/1kuXXL-tVgB1Ptu50cTonWtRnAuKmWn1jyKd1qPgqFJY/edit?tab=t.0).

Again, we encourage you to take the first step and apply for a ballot via our [application form](https://forms.gle/48F6h5wdV6BpSro66), and we look forward to your involvement.
`,Si=Object.freeze(Object.defineProperty({__proto__:null,default:he},Symbol.toStringTag,{value:"Module"})),ge=`---
title: "Today, help Sugar Labs continue to transform education"
excerpt: "Sugar Labs Executive Director Devin Ulibarri shares the organization's vision and growth plans, highlighting achievements and requesting community support through donations to expand their educational initiatives."
category: "COMMUNITY NEWS"
date: "2024-12-03"
slug: "help-sugar-labs-continue-transform-education"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "fundraising,donations,education,nonprofit,growth,community,technology,open-source"
---
<!-- markdownlint-disable -->

**Shared recently on our [mailing list](https://buttondown.com/sugarlabs), Sugar Labs executive director Devin Ulibarri shares his dreams for the organization and how you can help us at this critical moment in our growth.**

Hello,

Sugar Labs is at a critical inflection point. We need your support to leverage some important opportunities to grow.

Consider [donating to Sugar Labs](https://www.paypal.com/donate?campaign_id=NEAV3YL4H6B5S) as we move into our next phase.

![Image that has a picture of volunteers at a desk with computers, a teacher in a class with everyone hands raised, and a teacher overlooking two kids at their computers.](/assets/post-assets/donation-banner.webp)
*The Sugar Labs community is a global network of students, teachers, and developers.*

I stepped into the executive director position in January of this year. I did so because I believe in Sugar Labs's mission to create educational software and experiences for children.

I also believe in its approach—giving kids the *license* to learn, through free/libre/open (FLO) source software, as well as the *means* to learn through its community of learners and teachers working together to create a fun, safe, and welcoming *learn-by-doing* environment.

Based on my own experience as an educator for more than twenty years, I truly believe this organization has the potential to be a positive, disruptive force in education.

Sugar Labs has a history that dates back almost two decades, with methods (e.g. LOGO, constructionism, project-based learning) that date back more than half a century.

Yet, as an independent nonprofit, the organization itself is basically a startup. Having left our former umbrella organization Software Freedom Conservancy in 2020, we must now take on the challenges inherent to growing our own organization.

This independence brings challenges, such as finding stability and resilience. It also means, however, that we have an opportunity to build the kind of organization that truly serves our mission. I want to invite you to join us at this pivotal moment.

At the time of its founding more than sixteen years ago, Sugar Labs ran exclusively on one platform, created for One Laptop Per Child (OLPC), which was put into the hands of over three million children in over thirty-five countries.

Since that time, Sugar Labs has strategically expanded its scope and renewed its relevance. One way that we've accomplished this is by making the platform available on more devices through Sugar on a Stick (SoaS), maintained as a Fedora "Spin," and Raspberry Pi (RPi)—the latter for which [we made notable improvements over the summer](https://youtu.be/EW0b5OkxXVs).

We also created web-based applications such as Turtle Blocks, Music Blocks, and Sugarizer, which can run on any computer, regardless of operating system.

Music Blocks, in particular, has received recognition as an innovative tool for exploring music and programming.

Perhaps most notably, the Japanese government provided two years of funding to create a version of Music Blocks specifically to help Japan's elementary school students learn programming.

Additionally, Music Blocks was also part of a large-scale deployment of seven-hundred thousand tablets by the Peruvian Ministry of Education.

This year I've spent time ensuring that our finances are stronger and more transparent than ever before. I did this so that charitable donations can be made with confidence, ultimately helping every financial contribution we receive go further.

I won't go into all the details here, but one thing I did is to update and publish our 990s to our website.

All of our tax filings are now up to date and published on [sugarlabs.org/donate](https://www.sugarlabs.org/donate/) under "Our 990 tax filings."

I also helped Sugar Labs secure in-kind services that help our daily operations at no cost to us.

This year, we received Open Source Credits from Amazon Web Services (AWS) that are helping us test and develop new educational software; we received over one-hundred terabytes of data storage through Google Workspace for nonprofits; and we received other in-kind services that are helping us run our organization more efficiently.

I also started a series of live events online where past and current contributors and students have a platform to tell their stories, as well as to invite guests from other organizations to discuss the future of technology-in-education.

I did this because, although Sugar Labs's impact is somewhat obvious to the many who are active in the community, I've found that there are still many untold stories from community members whose lives are impacted positively.

As I've continued to speak to members of the community and published their stories, I've found that these previously untold stories continue to affirm the important role Sugar Labs plays in education.

For example, in [one of my interviews with Ibiam Chihurumnaya](https://youtu.be/JLsUiVzZ5Z0), Ibiam shares how the Sugar Learning Platform and the Sugar community introduced him and his classmates to programming from a young age and has given him skills he continues to use to this very day.

As for our work this summer, Sugar Labs participated in our fourteenth Google Summer of Code (GSoC) to assist students to work on eleven projects.

This, combined with our first-ever participation in Code4GovTech's Dedicated Mentorship Program (DMP), advanced our software development, mentoring a total of fourteen students who worked an estimated five-thousand hours on projects spanning the gamut from *Maintaining and Porting Twelve Activities to Flatpak,* to creating new math games, to creating promising new generative-AI services for both teachers and learners.

To get a better sense of all that we accomplished this summer, you are encouraged to watch the *Finale* series of students' presentations on our [YouTube channel](https://www.youtube.com/@SugarlabsOrg-EN).

We're proud of the work we've done so far this year. Yet, we know that we can do even more.

For example, in order to publicly deploy the five generative-AI services we created this summer, we'll need additional computational resources.

We understand that using resources on "AI" may seem like a luxury at this point in time, but we're persuaded that gen-AI will remain as a mainstay technology, and we owe it to our students to assist them in understanding and navigating this technology in a way that empowers them.

Plus, we've already created prototypes, such as an assistant for lesson plan creation and a bot to assist with learning the basics of programming in Python, that we have found to be helpful for our students to learn and cultivate important skills and new ways of looking at the world.

Just as we did when we created web-based software to run on any system or computer, we understand that we'll need to offer learning opportunities in gen-AI in order to stay current and relevant in an ever-evolving landscape.

That said, we haven't compromised on our fundamental values.

All of the services we created over the summer are licensed under a FLO license, allowing for freedom and full transparency so that learners can explore these systems at whatever level satisfies their curiosity.

And, of course, we design our software so that students are empowered to create with these tools and build a portfolio of their work.

All of these projects are exciting for us, and we hope that you're excited about them, too.

However, in order to successfully implement all these projects—plus the myriad grants that I've written, and continue to write—*we must expand our capacity as an organization*. And, in order to increase our capacity, we need to raise funds to hire more staff.

I dream of the day that we have a team of at least ten staff dedicated to assisting schools with their deployments and curricula, conducting ongoing research on how our tools are being used, helping with ongoing software maintenance, and running daily operations.

Having these sorts of resources would help us achieve learning outcomes for students and their teachers.

And it would also free up our volunteer community to focus on what they love about Sugar Labs: working on innovative projects under knowledgeable mentors to build and learn new skills.

We have set an initial goal for this fall of $25k to grow in our second year of operations.

Can you help us in this goal by contributing $3 or more? Your tax-deductible contribution will help us increase our capacity to continue to create innovative tools for learning, together with teachers and learners.

**[Donate to Sugar Labs today](https://www.paypal.com/donate?campaign_id=NEAV3YL4H6B5S)**

Donate today: [https://www.paypal.com/donate?campaign_id=NEAV3YL4H6B5S](https://www.paypal.com/donate?campaign_id=NEAV3YL4H6B5S)

We are hopeful for the future in large part because we've accomplished so much in the past.

We couldn't have gotten to where we are today without the contributions of hundreds of supporters over the years, both financial and volunteer efforts.

We continue to be a unique, positive community and a wonderful place where **youth can solve authentic tasks and learn by doing**.

Looking toward the next three to five years, we want to amplify all the great things in our community—mentorship, learning software, emphasis on problem solving is welcome and encouraged.

Your contribution can help us expand our reach, and it can help us do so much more.

From the bottom of my heart, thank you for reading this message and thank you for your time and consideration.

Sincerely,  
Devin Ulibarri  
Executive Director, Sugar Labs Inc.

P.S. Visit [https://www.sugarlabs.org/donate/](https://www.sugarlabs.org/donate/) to donate to, and support, our mission today!`,Ii=Object.freeze(Object.defineProperty({__proto__:null,default:ge},Symbol.toStringTag,{value:"Module"})),me=`---
title: "Board election results announcement: Three new members for the 2025-26 cycle"
excerpt: "The election results for the Sugar Labs Board of Directors have been announced. Devin Ulibarri, Sumit Srivastava, and Sebastian Silva will serve on the board for the 2025-26 cycle."
category: "COMMUNITY NEWS"
date: "2024-12-19"
slug: "board-election-results-2025-26"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "elections,governance,board,community,leadership,voting"
---
<!-- markdownlint-disable -->

# The results for the 2025-26 Sugar Labs board cycle have been determined.

The votes have been counted, and the [results](https://bettervoting.com/dp3xc7/) for the [2025-26 Sugar Labs board cycle](https://www.sugarlabs.org/community/2024/11/22/elections-extension/) have been determined.

The winners are **Devin Ulibarri, Sumit Srivastava, and Sebastian Silva**. They have all been notified and have agreed to serve on the Board of Directors for the 2025-26 cycle. For this election, we used [bettervoting.com](https://bettervoting.com) after doing research on various voting systems. Please read our [original election announcement](https://www.sugarlabs.org/community/2024/11/22/elections-extension/) for more information on how we decided upon this voting system.

The new members of the board will be filling the seats of two outgoing board members, **Lionel Laské and Alex Perez**, and one vacant seat.

The next election for three seats to the **2026-27 cycle** is planned for **August of next year**. All Sugar Labs members may vote, and members can:
- Run for election to the Board of Directors  
- Vote in the elections for the Board of Directors  
- Suggest referenda

As indicated in the [Sugar Labs Inc. bylaws](https://wiki.sugarlabs.org/go/Sugar_Labs/Governance), anyone with "significant and sustained" contributions to Sugar Labs is eligible for membership. If you believe you qualify for membership based on this criteria and are interested in [becoming an official member of Sugar Labs](https://wiki.sugarlabs.org/go/Sugar_Labs/Members), you are encouraged to send an email to <members@sugarlabs.org>.

If you were a member in the past but [did not vote in this election](https://www.sugarlabs.org/community/2024/11/22/elections-extension/), you will need to reapply for membership in order for your membership status to be reinstated. *(If you voted in this election, no further action is required.)* Registering for membership early will help ensure that you will be ready for the next election.

If you are interested in volunteering to assist with the next election in 2025, please contact <volunteering@sugarlabs.org> with your interest.

On behalf of the [Sugar Labs Board of Directors](https://www.sugarlabs.org/leadership/), we offer a big **Thank you!** to all who participated in this year's election.
`,Ai=Object.freeze(Object.defineProperty({__proto__:null,default:me},Symbol.toStringTag,{value:"Module"})),pe=`---
title: "Reflections as Parents and Teachers Sugar at home and in their classroom"
excerpt: "Sugar Labs Executive Director Devin Ulibarri shares personal experiences using the Sugar Learning Platform both as a parent with his son and as an educator in various classroom settings."
category: "SUGAR STORIES"
date: "2024-12-25"
slug: "reflections-as-parents-and-teachers-sugar-at-home-and-in-classroom"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "education,parenting,classroom,sugar-activities,learning,teaching,literacy,programming"
---
<!-- markdownlint-disable -->

**Reflections as a parent and teacher: Sugar at home and in the classroom**  
As the year comes to a close, I wanted to take some time to reflect upon how I've used Sugar both in the classroom and at home. I have a few hopes in mind as I share my experience engaging with Sugar both as a teacher and a parent. One hope is that it will show a window into some of the more grounded work Sugar Labs has done this year.

Much of the most recent testimony that we've shared from the [Sugar Labs community](/@sugarlabs) has been centered around software development. While the success of students creating software is certainly important, the purpose of such progress is grounded in helping teachers teach and to help learners learn. Another hope is that the following vignettes will dispel doubts around the efficacy of the Sugar Learning Platform as an effective tool for education, which I've heard from a few folks during conversations throughout [my first year as Sugar Labs's executive director](https://www.sugarlabs.org/press/2024/05/08/Sugar-Labs-announces-nonprofit-status-new-executive-director/). This article will address those doubts directly. My third hope is that my experiences will inspire others, whether parents or teachers (or both), to try Sugar themselves.

## The first few years as a parent

My son Kai was born in 2017, but it was about three years before his birth that I became involved in Sugar Labs. It's a story that I've told in more depth before, but I became interested in Sugar Labs because of their unique approach to education. At the time, I was doing research on the _implications of software-freedom-in-education_, which led me to conclude that the freedoms granted to users in free/libre/open (FLO) source software have [profound positive implications for education](https://wiki.sugarlabs.org/go/File:Education-needs-free-software.pdf). I attended a talk given by Sugar Labs founder Walter Bender, and we soon began working together to integrate music into [Turtle Blocks](http://activities.sugarlabs.org/en-US/sugar/addon/4027), in what is now known as [Music Blocks visual programming language](https://www.sugarlabs.org/music-blocks/). It was also around this time in 2014 that I received a One Laptop Per Child (OLPC) laptop from Walter that I used to familiarize myself with the Sugar Learning Platform.

Although I had shown Kai a few things on the OLPC when he was a toddler, such as creating a paint program for him in the Turtle Blocks Activity, it wasn't until he was about four years old that he really took to it. His first, most sustained, interest in the computer came when he was learning to read by himself. I remember that his desire to read was basically insatiable. In fact, he had memorized some sections of the graphic novel series _Dog Man_ by [Dav Pilkey](https://en.m.wikipedia.org/wiki/Dav_Pilkey), which I had read to him multiple times because he loved it so much. At four years old, Kai had memorized a lot of the story, but he wasn't yet reading himself; he was still dependent on others to read for him. It was at this point that he found the [Speak Activity](http://activities.sugarlabs.org/en-US/sugar/addon/4038) on his OLPC, and this is when he had a real breakthrough with reading.

![Kai](/assets/post-assets/stories/student1.webp)
*Kai, with his OLPC, running the Speak Activity on the Sugar Learning Platform.*

The basic way that the Speak Activity works is by taking typed input from a user and speaking it back to them when they press return. I remember Kai walking around the house, finding words on various things around the house, typing those words into the computer, and listening to the result. It was in this way that he memorized the spelling of a few words, and, soon enough, he was creating sentences and telling the computer to speak those words back to him (or to me). It was also around this time that we went on a long family road trip, where Kai sat in the back seat typing various words and sentences and learning more and more about language.

![Kai Again <3](/assets/post-assets/stories/students2.webp)
*Kai, helping one of my students get up and running in Sugar for her first time.*

Of course, I kept reading books to him, which is still invaluable to a child's development, but I am confident that the Speak Activity helped Kai become a more independent reader. The following year, Kai entered Kindergarten, where he learned phonics and he's been a solid reader ever since. He's now in second grade, and he often carries a few books around with him every day, everywhere he goes.

## Reflections as a teacher in 2024

This year, I had a few memorable moments as a teacher in the classroom. This year, I mentored high school students in git version control, mentored another teacher in leading a Music Blocks class, and I even taught a group class for kids ages five and six on the Sugar Learning Platform. I'll share a little bit of what I learned from each experience here.

![Student 3](/assets/post-assets/stories/student1.webp)
*Students in a Music Blocks class led by Rafael Moreno, who I guide as a teacher new to teaching programming.*

Before the summer, I reached out to an acquaintance, Neil Plotnik, who teaches cybersecurity at a nearby high school. I [met Neil during my time at the Free Software Foundation](https://www.fsf.org/blogs/community/free-software-in-education-and-free-software-education) (FSF). He suggested that I reach out to the Computer Science (CS) teacher at his high school. Long story short, I spent a few weeks getting these youth ready to help with coding, mainly teaching them how to use git version control. These students had done a few coding projects at their school, but hadn't yet contributed to a community project. They hadn't used git before, which is important to know for software development (and the underlying concepts are important skills for any endeavor), so I spent most of the time showing them the basics. To be honest, I was a little bit surprised to find myself teaching git to a CS class, but I suppose this highlights one of the many reasons why an organization such as Sugar Labs is important. Sugar Labs offers pathways into collaborative software development that textbook coding exercises do not.

Over the summer, I mentored a few contributors for Google Summer of Code (GSoC). A lot of this work is online, on our Medium blog and our YouTube channel. At the same time, however, I also worked with a student of mine, Nathan, who asked to have some internship experience over the summer. I've taught this particular student for almost ten years now. He's taken guitar lessons with me, and he's taken Music Blocks classes with Walter Bender and myself. First, I asked him to create some fun projects for kids, which he did with gusto. You can read about his projects here: [https://musicblocks.net/2024/08/05/nyc-interactive-subway/](https://musicblocks.net/2024/08/05/nyc-interactive-subway/) and [https://musicblocks.net/2024/07/18/sitar-tabla-and-tampura-for-makey-makey/](https://musicblocks.net/2024/07/18/sitar-tabla-and-tampura-for-makey-makey/). Then, I asked him to create lesson plans, which he also did very well. And then, near the end of the summer, I involved him with testing some of the latest development for Music Blocks, which included a few [AI projects](https://www.youtube.com/playlist?list=PLyTz5XRZyi-xR5NGo1fHLbYJYo2OwRFta). Testing these required that he set up a development environment, test the software as a user, and report the results as issues on GitHub. His work over the summer marked a good amount of growth and progress, which continues to this day.

![Student 6](/assets/post-assets/stories/student6.webp)
*Nathan, testing new features for Music Blocks.*

At the beginning of the school year in the fall, I began mentoring a fellow teacher who is leading a Music Blocks class on a weekly basis. I provide the teacher, Rafael Moreno, guidance in lesson planning and feedback on classes. Rafael is a singer from Panama, now living in Boston, MA, working as a teaching artist.

Also in the fall, I started teaching kindergarten and first grade students in a weekly computer class. This class happens at the same time as Rafael teaches Music Blocks. We decided to split the group by age, and I decided that my (younger) group would benefit most from doing something a little more open ended and basic. So, for the first day, I prepared some OLPC laptops for the kids, and I had them just try the Speak Activity. They had a blast. At one point, I tried to show them another Activity, but they insisted on continuing with the Speak Activity. The following week, we had a new student and I didn't have more than two OLPCs, so I prepared two Thinkpad X1s with Sugar Toast installed for the new student and for Kai, who joined us that day to show the group what else the computers could do. Kai did a wonderful job leading this second day of classes, and it was heartwarming to see him share his knowledge with his new friends in the class. As of now, I've taught this class for a few months, and the kids have explored several of the Activities, including [Maze](http://activities.sugarlabs.org/en-US/sugar/addon/4071), [Write](http://activities.sugarlabs.org/en-US/sugar/addon/4201), [Chat](http://activities.sugarlabs.org/en-US/sugar/addon/4069), [Turtle Blocks](http://activities.sugarlabs.org/en-US/sugar/addon/4027), and several of the [games](http://activities.sugarlabs.org/en-US/sugar/browse/type:1/cat:60). At the end of each class, the kids are asked to share with the class what they're working on. And, on the last day of class before the break, they presented their work to their parents.

![Student 4](/assets/post-assets/stories/student4.webp)
*Two of my students, smiling during their second class, using the Sugar Learning Platform on two OLPCs.*

One of the things that strikes me the most from this particular class is the _joy_ that the kids show as they're working on their activities. It reminds me of a study I read by Bloom, described in Robert J. Trotter's article for _Psychology Today_, July 1986, "The Mystery of Mastery". Studying how people achieve mastery, Bloom observed a few common factors among those who became experts as adults. The children who later became experts were introduced to the field as a playful activity, and learning at this stage was "like a game." As for Sugar, the kids in my class are learning a lot of things in the class, such as spelling, typing, and language, but the playfulness they exhibit is developmentally appropriate. This is consistent with the research on human development, and I've found it to hold true during my own work in the classroom.

![Process](/assets/post-assets/stories/process.webp)
*Here are the notes I took in college that I used to reference the above paragraph. I add it here because I no longer have access to the original article, and I could not find a copy online. If you find a link to a electronic copy, please drop it into the comments below.*

## Conclusions

As I alluded to earlier, I have sometimes heard criticism of the Sugar Learning Platform, suspecting that it may be out of touch with the needs of the students. The criticism is typically accompanied by an argument that youth should be preparing for job skills by using a platform more similar to what an office worker uses (e.g. _Shouldn't the kids be taught how to use Microsoft Word instead?_). However, as an educator, I've never bought that argument. And now that I've spent ten years with Sugar — both as an educator and as a parent — I wholly reject it. I can say confidently that youth learn very important skills through their engagement with Sugar. And perhaps most importantly, they are introduced to concepts in stages that are appropriate to their development.

![Student 5](/assets/post-assets/stories/student5.webp)
*One of the students in my Sugar class. She surprised me by coming in with this hand-drawn computer, which she made just a few days after taking one of her first classes.*

I'm more proud than I ever have been to be a part of the Sugar community, and my decades' long experience with youth from ages five through college, only gives me stronger conviction that we're creating something of unique value for education.`,Ti=Object.freeze(Object.defineProperty({__proto__:null,default:pe},Symbol.toStringTag,{value:"Module"})),be=`---
title: "The Sweet Spot – Issue 002"
excerpt: "The second issue of Sugar Labs' newsletter covering recent updates, events, volunteer opportunities, and community news from December 2024."
category: "COMMUNITY NEWS"
date: "2024-12-29"
slug: "the-sweet-spot-issue-002"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "newsletter,community,updates,elections,social-media,volunteer,outreach,education"
---
<!-- markdownlint-disable -->

# Recent news for December 29, 2024

Welcome to the second issue of the **"Sweet Spot"**, a newsletter for Sugar Labs-related news in development, student and teacher work, events, how to get involved, and other news and information. This newsletter will be published semi-regularly for now, but the plan is to publish it on a bi-monthly, perhaps even monthly, basis in the future. Our aim with this newsletter is to help keep the growing body of Sugar Labs contributors on the same page, all while documenting our growth for our own and others' reference.

These first issues are meant to set a precedent of communication and documentation, as well as to help inform the community of our current status, recent progress, and future plans. Its predecessor is the [Sugar Digest](https://lists.sugarlabs.org/archive/community-news/), which still serves as an important catalog of our activities. Like Sugar Digest, this newsletter is intended to keep community members in the loop about everything going on within Sugar Labs. It will highlight any recent publications from us. It will occasionally include links to third-party news and updates that our community finds relevant.

---

## Updates

### Today, help Sugar Labs continue to transform education

**December 3, 2024**

![An image with Sugar Labs teachers, volunteers, and students.](/assets/post-assets/donation-banner.webp?w=960&amp;fit=max)
*Your donation helps us in many ways.*

Sugar Labs is in the middle of a campaign to raise funds necessary for outreach, software development, project maintenance, mentorship, and more. Having left Software Freedom Conservancy in 2020, this year is the first that Sugar Labs is investing financially in its own growth, and we'd love to have your participation in this pivotal moment. We've been particularly heartened to see volunteers in our community assist with various aspects of this campaign, such as making improvements to our website. You may also participate in our fundraiser, while getting something nice for yourself or a loved one, by purchasing Sugar Labs merchandise from our new store on Bonfire.

Read executive director Devin Ulibarri's letter to the community to learn more about the work we've done this year, consider making a donation or purchasing merchandise, and please help spread the word.

- [Learn more about our work](https://www.sugarlabs.org/community/2024/12/03/help-SL-continue-to-transform-education/)
- [Donate now](https://www.paypal.com/donate?campaign_id=NEAV3YL4H6B5S)
- [Visit the new donation banner](https://www.sugarlabs.org/)
- [Get Sugar Labs merchandise](https://www.bonfire.com/sugar-labs-education/)

---

### Sugar Labs election information and results

**December 19, 2024**

Sugar Labs completed an election for three seats to its Board of Directors for the 2025–26 cycle. The results are out, and the winners are **Devin Ulibarri, Sumit Srivastava, and Sebastian Silva**. Read the articles to learn more about Sugar Labs's election process and how you can prepare to participate in the next election.

- [Election results](https://www.sugarlabs.org/community/2024/12/19/election-results/)
- [Elections extension](https://www.sugarlabs.org/community/2024/11/22/elections-extension/)
- [How to participate](https://www.sugarlabs.org/community/2024/11/08/fall-board-elections-how-to-participate/)

---

### Sugar Labs expands its social media presence to Bluesky and WhatsApp

**December 9, 2024**

Sugar Labs is now on **Bluesky** and **WhatsApp**. Sugar Labs continues to maintain a presence on X (formerly Twitter), Facebook, Mastodon, Instagram, YouTube, LinkedIn, and GitHub. We decided to join Bluesky and WhatsApp in an effort to expand our reach. For those active on any of these platforms, please follow Sugar Labs to help our outreach efforts.

- [Marketing announcement](https://lists.sugarlabs.org/archive/marketing/2024-December/004160.html)

**Newly joined social media platforms:**
- [Follow us on Bluesky](https://bsky.app/profile/sugarlabs.bsky.social)
- [Reach out on WhatsApp](https://wa.me/16177024088)

---

### Reflections from Constructing Modern Knowledge 2024

**November 27, 2024**

Sugar Labs executive director and Music Blocks co-maintainer **Devin Ulibarri** attended **Constructing Modern Knowledge (CMK)**. In this post, Ulibarri shares his experience at the teacher institute, what he learned, and what it could mean for Sugar Labs.

- [Read Devin's reflection on Medium](https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c)

---

### James Simmons's Sugar Story: Writing new Activities and sharing Sugar with youth

**September 3, 2024**

Sugar Labs community member **James Simmons** shares his story about his involvement with Sugar Labs. Simmons tells us how he began contributing to the Sugar Learning Platform by expanding the functionality of the Read Activity and adding support for e-texts.

- [Read James's story](https://medium.com/@sugarlabs/james-simmonss-sugar-story-writing-new-activities-and-sharing-sugar-with-youth-9282c66f9219)
- *Make Your Own Sugar Activities!*:
  - [English (Internet Archive)](https://archive.org/details/MakeYourOwnSugarActivities)
  - [Spanish (Internet Archive)](https://archive.org/details/ComoHacerUnaActividadSugar)
- [See all of James's Activities](https://activities.sugarlabs.org/en-US/sugar/user/45)

---

## (Volunteer) Help wanted

Sugar Labs is seeking volunteer assistance in various areas. If you are passionate about our mission and can commit time, we encourage you to apply.

- [Help Wanted wiki](https://wiki.sugarlabs.org/go/Help_Wanted)
- [Watch volunteer appeal](https://www.youtube.com/watch?v=W5ZLFBZkE34)

---

## Upcoming events and meetings

**Regular meetings:**

- **Music Blocks meetings**: Every Sunday at 7:00 EST (12:00 UTC)  
  [Join on Jitsi](https://meet.jit.si/ResponsibleMasksForecastHastily)
- **Sugar Activity meetings**: Every Wednesday at 7:00 EST (12:00 UTC)  
  [Join on Jitsi](https://meet.jit.si/ResponsibleMasksForecastHastily)
- **Sugar Labs Board of Directors meetings**: Every Wednesday at 14:30 EST (19:30 UTC)  
  [Join on Matrix](https://matrix.to/#/#sugar:matrix.org)

---

## About Sugar Labs

**Sugar Labs®** is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology for youth. Volunteers work together to develop activity-focused software for children.

Support Sugar Labs by donating at [www.sugarlabs.org/donate](http://www.sugarlabs.org/donate/).

---

## Social and Communication Links

Stay connected with Sugar Labs on the following platforms:

- [Bluesky](https://bsky.app/profile/sugarlabs.bsky.social)
- [Facebook](https://www.facebook.com/SugarLabsforall/)
- [GitHub](https://github.com/sugarlabs)
- [Instagram](https://www.instagram.com/sugarlabsforall/)
- [LinkedIn](https://www.linkedin.com/company/sugar-labs)
- [Mailing lists](https://wiki.sugarlabs.org/go/Mailing_Lists)
- [Mastodon](https://mastodon.social/@sugar_labs)
- [Matrix](https://matrix.to/#/#sugar:matrix.org)
- [Medium](https://medium.com/@sugarlabs)
- [Twitter/X](https://twitter.com/sugar_labs)
- [WhatsApp](https://wa.me/16177024088)
- [YouTube](https://www.youtube.com/@SugarlabsOrg-EN)

---

## Back issues of "The Sweet Spot"

Find this issue and past issues at: [sugarlabs.org/community-news](https://www.sugarlabs.org/community-news/)
`,Pi=Object.freeze(Object.defineProperty({__proto__:null,default:be},Symbol.toStringTag,{value:"Module"})),fe=`---
title: "Get and gift Sugar: Purchase new Sugar on a Stick USBs"
excerpt: "Sugar Labs now offers pre-installed Sugar on a Stick USB drives for purchase, making it easier for educators and supporters to use and share our educational software."
category: "COMMUNITY NEWS"
date: "2025-01-21"
slug: "get-and-gift-sugar-soas-usbs"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "products,merchandise,SoaS,USB,education,fundraising,open-source"
---

<!-- markdownlint-disable -->

A few times in recent months, we received questions from folks about how to buy Sugar. Until now, the only response we had was that we didn't offer them for sale but that you could [create your own by following our instructions](https://wiki.sugarlabs.org/go/Sugar_on_a_Stick/Installation). If you wanted to [run Sugar on a Stick](https://www.sugarlabs.org/booting-soas/), you had to flash a USB drive yourself before using it.

Of course, flashing a USB can be a great educational experience, and this will remain an option. However, what we heard from people asking this question was that they wanted a few things that they couldn't get from flashing a USB themselves. 

One is that they wanted the **convenience—and added assurance—of purchasing a USB from a reputable vendor**. Another is that some people were expecting something **branded with the Sugar Labs logo**. For some, it may be the ability to **gift a USB** for a friend or teacher. And, for the majority who reached out to us, it seemed that they wanted a way to **pay us for the software**, and, in so doing, **help sustain our work for years to come**.

Well, we're excited to share the news that you are **now able to purchase a Sugar Labs-branded USB with Sugar on a Stick pre-installed!**

![Two USB drives on a laptop. The Sugar Labs logo is prominent, and the drives are shiny.](/assets/post-assets/sugarlabs_soas_usb-two.webp?w=960&amp;fit=max)
*Samples of two USBs with Sugar on a Stick pre-installed. All profits from purchases will go to Sugar Labs to help develop current and future learning projects.*


We partnered up with USB Memory Direct for this particular offering. USB Memory Direct (UMD) has a history of supporting [free/libre/open source projects such as ours](https://www.sugarlabs.org/about-us/). They will also be handling inventory and shipping & handling, which means that we at Sugar Labs can keep focusing on what we do best: create learning software for education! Plus, UMD will give **all profits from sales to Sugar Labs**, which we will use to further our mission in Constructionist education.

Now that we have both clothing merchandise and SoaS USBs for purchase, we created a new [product page](https://www.sugarlabs.org/product/). 

- 🧁 [Buy Sugar on a Stick (SoaS) USBs](https://www.usbmemorydirect.com/store/novelty/sugarlabs/)
- 👕 [Buy Sugar Labs clothing merch](https://www.bonfire.com/store/sugar-labs-merch/)

Detailed product information and specifications are on the respective landing pages.

If you purchase a USB or clothing merchandise, **please let us know about it!** You can either [contact us](https://www.sugarlabs.org/contact-us/) directly, or you can create a post on social media with the hashtag [#SugarLabs](https://mastodon.social/tags/sugarlabs) for us to find.

📹 And if you create a video of your experience on YouTube, let us know and we can add it to [our Sugar on a Stick playlist](https://www.youtube.com/playlist?list=PLyTz5XRZyi-xuPdS7kReqP5Nu5TAlTu4f).

We love hearing from you!
`,Mi=Object.freeze(Object.defineProperty({__proto__:null,default:fe},Symbol.toStringTag,{value:"Module"})),we=`---
title: "2024 Annual Report"
excerpt: "A comprehensive overview of Sugar Labs' accomplishments, activities, and financial status throughout 2024, including development projects, outreach efforts, classroom implementations, and community growth."
category: "COMMUNITY NEWS"
date: "2025-03-24"
slug: "annual-report-2024"
author: "Devin Ulibarri"
description: "Executive Director"
tags: "annual-report,education,gsoc,outreach,classroom,finance,development,community"
---
<!-- markdownlint-disable -->

# Annual report for 2024

This report is meant to be an overview of the work Sugar Labs did in 2024. Looking back, we did a lot of work. We participated in events in the US and India. We mentored more than a dozen students over the summer for Google Summer of Code and the Dedicated Mentorship Program, the latter of which we participated in for the first time last year.

We launched a series of online videos to showcase our work to the public while simultaneously giving a platform for young contributors to reflect upon their progress and be introduced to a larger developer community. We created a handful of entirely new software projects for learning, such as new math games and Sugarizer activities. We improved our existing software—implementing new features, fixing bugs, and making our learning software available on more platforms. We did all this and more in 2024, which I detail below.

In many aspects, this report is highly personal. I share about my own journeys to conferences, photos of the people I met, and the students to whom I introduced Sugar. In 2024, I became Sugar Labs's first full-time staff member, which helped me fully dedicate myself to many aspects of the organization. We were also able to sponsor community members like Anindya Kundu to represent Sugar Labs internationally.

As you read this report, please understand that the vision for Sugar Labs as a nonprofit organization is to grow to be able to support more and more people like myself, so we can have an even wider reach. That said, Sugar Labs, being a free/libre/open source community-driven project, makes its tools available to the public under free licenses, so anyone may use what we've created to support teachers and classrooms in their communities, regardless of their "status" within the organization.

In other words, Sugar Labs is *not* a one-man-band. Instead, it's a community of orchestras and ensembles. The organization is meant to support those orchestras and ensembles, comprised of teachers and learners, listening to and responding to their needs.

It is my hope that 2025's annual report includes even more stories and photos from the broader Sugar Labs community. Sugar Labs welcomes your interest, support, and contributions. I encourage you to join our community of teachers, learners, and parents working together to create better tools and a supportive environment for learning.

I hope the annual publication of our work in the form of an executive summary will serve as a benchmark as we work toward continuous self-improvement as a nonprofit dedicated to serving our community of teachers and learners.

## Development in 2024

### Google Summer of Code (GSoC) and Dedicated Mentorship Program (DMP)

As for our work this summer, Sugar Labs participated in our fourteenth Google Summer of Code (GSoC) to assist students in working on [eleven projects](https://www.sugarlabs.org/press/2024/05/01/Sugar-Labs-receives-eleven-contributor-projects-for-GSoC-2024/). This, combined with our first-ever participation in Code4GovTech's Dedicated Mentorship Program (DMP), advanced our software development, mentoring a total of fourteen students who worked an estimated five thousand hours on projects ranging from maintaining and porting twelve activities to Flatpak, to creating new math games, to promising new generative-AI services for both teachers and learners.

To get a better sense of all that we accomplished this summer, you are encouraged to watch the Finale series of students' presentations on our YouTube channel at [https://www.youtube.com/@SugarlabsOrg-EN](https://www.youtube.com/@SugarlabsOrg-EN).

We also encourage you to check out the work in more detail by reading the reports published on Medium:

- [https://medium.com/@sugarlabs/list/google-summer-of-code-d90eae4b54fb](https://medium.com/@sugarlabs/list/google-summer-of-code-d90eae4b54fb)
- [https://medium.com/@sugarlabs/list/code4govtech-3377e03c6dd5](https://medium.com/@sugarlabs/list/code4govtech-3377e03c6dd5)

## Outreach and communications

### Online events

In 2024, I started a series of live events online where past and current contributors and students have a platform to tell their stories, as well as invite guests from other organizations to discuss the future of technology in education.

I did this because, although Sugar Labs's impact is obvious to many in the community, I've found that there are still many untold stories from community members whose lives have been impacted by our work. Publishing these stories has continued to affirm the important role Sugar Labs plays in education.

For example, in [my interview with Ibiam Chihurumnaya](https://youtu.be/JLsUiVzZ5Z0), he shared how the Sugar Learning Platform and community introduced him and his classmates to programming from a young age and gave him skills he continues to use to this day.

### Expanded social media presence

Last year, we expanded our presence on social media. In addition to Facebook, Instagram, YouTube, and LinkedIn, we are now on Bluesky, WhatsApp, and my personal favorite, Mastodon.

If you are on any of these platforms, please follow Sugar Labs and boost our posts to support our outreach. If you're interested in helping with our outreach, join our marketing mailing list and express your interest: [https://lists.sugarlabs.org/listinfo/marketing](https://lists.sugarlabs.org/listinfo/marketing).

### Reboot of regular newsletters

In 2024, we relaunched regular newsletters, now sent approximately once every three months. These newsletters share our progress as an organization and news valuable to our community:

- [https://www.sugarlabs.org/community/2024/09/20/sweet-spot/](https://www.sugarlabs.org/community/2024/09/20/sweet-spot/)
- [https://www.sugarlabs.org/community/2024/12/29/sweet-spot-002/](https://www.sugarlabs.org/community/2024/12/29/sweet-spot-002/)

### Newsletter email subscription

Our newsletters are published to the website and also sent via email. In 2024, we started using Buttondown to send newsletters to subscribers worldwide. If you're not subscribed yet, please do so: [https://buttondown.com/sugarlabs](https://buttondown.com/sugarlabs).

### Reboot of Sugar Stories

In 2024, we began collecting stories from our community. While it's still early, we've already received some fantastic articles.

- From [James Simmons](https://activities.sugarlabs.org/en-US/sugar/user/45): [Helping others to create their own Sugar Activities](https://www.sugarlabs.org/stories/2024/09/13/Writing-new-Activities-and-sharing-sugar-with-youth/)
- From me: [Reflections as Parents and Teachers](https://www.sugarlabs.org/stories/2024/12/25/Reflections-as-Parents-and-Teachers-Sugar-at-home-and-in-their-classroom/)

You can read these and more at: [https://www.sugarlabs.org/sugar-stories/](https://www.sugarlabs.org/sugar-stories/)

If you have a story, share it via [info@sugarlabs.org](mailto:info@sugarlabs.org) or through the mailing lists:

- Education: [https://lists.sugarlabs.org/listinfo/iaep](https://lists.sugarlabs.org/listinfo/iaep)
- Development: [https://lists.sugarlabs.org/listinfo/sugar-devel](https://lists.sugarlabs.org/listinfo/sugar-devel)

### Major improvements to our website

Throughout 2024, I worked on updating our website, which needed attention. Being unfamiliar with Jekyll (the framework it's built on), I struggled at first, but with help from the free software community, I learned enough to begin publishing updates more regularly.

Near the end of the year, more folks from the development community pitched in. Now, the site is in much better shape, and we are working toward a completely revamped version set to launch in April 2025.

Thanks to the many volunteers who helped! Interested in joining the web team? Visit [https://matrix.to/#/#sugarlabs-web:matrix.org](https://matrix.to/#/#sugarlabs-web:matrix.org).

### Conference talks

In 2024, we sent representatives to a few in-person conferences. With limited budget, we focused on visibility, sending me to several conferences in the US and sponsoring Anindya Kundu to represent us at the Opportunity Open Source Conference at IIT Kanpur.

### - LibrePlanet

In May, I attended the Free Software Foundation's annual LibrePlanet conference in Boston, MA. There, I [handed out flyers](https://mstdn.io/@codewiz/112384505018899979) and showed off a computer running the Sugar Desktop Environment.

![Devin with Zoe, with the address 51-55 Franklin St visible in the background.](/assets/post-assets/2024-annual-report/image30.webp?w=960&amp;fit=max)
*Devin Ulibarri and FSF executive director Zoë Kooyman, in front of the FSF office in Boston, MA. The FSF hosts the annual Libre Planet conference.*

### - 2024 Micro Camp

In June, I spent a weekend at a 2024 Micro Camp, a retreat for microtonal musicians, where I showcased the Music Blocks visual programming language. Music Blocks, a flagship Sugar Labs project, has rich microtonal capabilities. I showcased those features during one of the first talks of the retreat, and I even used Music Blocks as a musical instrument to perform a piece of music that requires twenty-two divisions of the octave—something for which I did not have a capable physical instrument, except for [a programmed instrument I created within Music Blocks](https://musicblocks.sugarlabs.org/index.html?id=1719093905649087&run=True).

At the conference, I was also pleasantly surprised to meet so many free/libre/open source developers and educators. A large percentage—much larger than at most music conferences—were developing software. In retrospect, it makes sense that there are so many microtonalists who develop software, because these musicians typically need to create instruments that play pitches differently from what you would find in most stores, and they use both physical and digital mediums to craft such unique instruments.

![22 EDO in Music Blocks.](/assets/post-assets/2024-annual-report/image29.webp)
*Music Blocks has many affordances for tuning and temperament, an important concept in music. The program in this screenshot performs a 22 equal-divisions-of-the-octave (EDO) pitch whenever you touch one of the mice.*

![Music Blocks as an instrument](/assets/post-assets/2024-annual-report/image20.webp)
*Devin (at right) performs a piece, written in 22 EDO, together with an ensemble using Music Blocks on a tablet.*

![Duo performance on Kite guitar and linnstrument](/assets/post-assets/2024-annual-report/image8.webp)
*The ideas that inspire Music Blocks come from musical concepts, instruments, and traditions. Devin (at left) performs together with composer and microtonalist Kite Giedraitis.*

### - CMK

In July, I attended Constructing Modern Knowledge (CMK), a retreat for teachers, in Manchester, NH. This retreat is a good fit for Sugar Labs as it is focused on Constructionism. CMK brings together passionate educators from around the world to work on new and creative projects, which they bring back to their respective schools.

![First Day at CMK](/assets/post-assets/2024-annual-report/image7.webp)
*Gary Stager is the organizer of CMK, a retreat for teachers to work together on Constructionism projects.*

![CMK projects](/assets/post-assets/2024-annual-report/image26.webp)
*CMK participants are expected to work in groups create a project. On the final day, each group presents their project.*

![Guest speakers](/assets/post-assets/2024-annual-report/image25.webp)
*The 2024 CMK brought two esteemed individuals working in music education, Tricia Tunstall (left) and Melissa Walker*

![Lego notation](/assets/post-assets/2024-annual-report/image4.webp)
*Devin (at left) collaborated with Jamie Chelel (MIT) to create lego notation for the blind.*

![Detailed notation](/assets/post-assets/2024-annual-report/image21.webp)
*Devin and Jamie created a simple and detailed notation system as a starting point to explore lego as a music notation system for the blind.*

![Fellow instructors](/assets/post-assets/2024-annual-report/image35.webp)
*CMK attracts many passionate instructors. Devin (far left) had the pleasure of working together with Josh Burker (left), Tracy Rudzitis (right) and many others.*

You can read my full article on the experience, as well as work done toward creating a system for using Lego blocks to encode musical data, here:  
[https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c](https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c).

### - FOSSY 2024

In August, I attended FOSSY, hosted by the Software Freedom Conservancy, in Portland, OR. I gave a talk titled "[Mentoring youth: The FOSS strategy we've been looking for](https://2024.fossy.us/schedule/presentation/202/)". You can watch the talk on our YouTube channel at  
[https://www.youtube.com/watch?v=mKBXSC9Veq8](https://www.youtube.com/watch?v=mKBXSC9Veq8).

I also ran two Birds of a Feather sessions. One was a Music Blocks workshop, where Bryan Ollendyke of [HAX](https://hax.psu.edu/) tested the limits of the JavaScript editor in Music Blocks. The other was a free/libre/open (FLO) music concert, where I joined [Aaron Wolf](https://blog.snowdrift.coop/author/wolftune/), [Timmy Barnett](https://gnulinux.love/), [Kite Giedraitis](https://tallkite.com/), and others to showcase [FLO](https://wiki.snowdrift.coop/about/free-libre-open) through instruments, software, and a variety of music.

![Hacking on musical Javascript](/assets/post-assets/2024-annual-report/image3.webp)
*Music Blocks has an export to Javascript feature, which got the attention of Bryan Ollendyke, creator of HAX.*

![Music Blocks's JS editor](/assets/post-assets/2024-annual-report/image45.webp)
*Music Blocks is a waypoint not a destination. That's why we offer learners the option to export to Lilypond, MIDI, and Javascript.*

![Two Birds of a feather](/assets/post-assets/2024-annual-report/image13.webp)
*At FOSSY, Devin gave one talk and led two Birds of a feather sessions. One session was for Music Blocks, and the other was a music concert.*

![Mariah Villarreal](/assets/post-assets/2024-annual-report/image49.webp)
*Sugar Labs Google Code-In mentor and Libre Learn Lab director Mariah Villarreal (left) has dedicated her career to STEAM education and free software.*

![Meeting with good friends](/assets/post-assets/2024-annual-report/image40.webp)
*Free software volunteer Jason Self attended FOSSY.*

![Making new connections](/assets/post-assets/2024-annual-report/image34.webp)
*Bryan Ollendyke (left), creator of HAX, and his son attended the Music Blocks workshop at FOSSY.*

![Live musical performances](/assets/post-assets/2024-annual-report/image5.webp)
*Devin performed together with microtonalist Kite Giedraitis at FOSSY.*

![FLO musicians](/assets/post-assets/2024-annual-report/image9.webp)
*There were many "FLO musicians" at FOSSY. Among the musicians who performed in the concert who also gave a talk were Aaron Wolf of Snowdrift (2nd from the left), Timmy Barnett (third from left), and Devin Ulibarri (2nd from the right).*

![Playful](/assets/post-assets/2024-annual-report/image33.webp)
*After the concert, audience members got a chance to play the instruments. Alternate tuning on the Linnstrument is made possible thanks to free/libre/open (FLO) source software, an important concept for Sugar Labs.*

### - Internet-in-a-box demonstration

Also in August, I attended a meetup to demonstrate [Internet-in-a-box](https://internet-in-a-box.org/) (IIAB), led by [Adam Holt](https://github.com/holta). Kids and teachers got an opportunity to see what IIAB does and to try it. [Sugarizer](https://sugarizer.org/), the web-based version of the Sugar Learning Platform, is among the packages chosen for IIAB, which empowers schools to use learning services that would otherwise require an internet connection.

![Internet in a Box](/assets/post-assets/2024-annual-report/image43.webp)
*Internet-in-a-Box (IIAB) is a solution for communities that do not have internet access. It acts as a server with educational software and services pre-installed.*

![Sugarizer](/assets/post-assets/2024-annual-report/image39.webp)
*Sugarizer is one of the programs that comes pre-installed on IIAB.*

### - GSoC Mentor Summit

Sugar Labs has participated in GSoC almost every year since 2009. This year, we worked on a number of projects. I was sent to represent Sugar Labs at the conference, hosted at Google headquarters. I met with other mentors, attended talks, and gave a lightning talk on our unique approaches to mentoring.

![Sameer Verma](/assets/post-assets/2024-annual-report/image17.webp)
*Sameer Verma (at left) is the organizer for OLPC San Francisco and has documented some of Sugar Labs's growth over the years in the form of interviews.*

![Karen Sandler](/assets/post-assets/2024-annual-report/image41.webp)
*Karen Sandler (at right) is the executive director for Software Freedom Conservancy, which acted as fiscal sponsor Sugar Labs until 2019.*

![Google Summer of Code mentors](/assets/post-assets/2024-annual-report/image32.webp)
*Google hosts many orgs and many, many mentors for GSoC every year. Devin is at lower-left.*

### - Opportunity Open Source Conference at IIT Kanpur

Sugar Labs was invited to present at the Opportunity Open Source Conference at IIT Kanpur. We sponsored community member and Music Blocks v4 maintainer, Anindya Kundu, to represent our organization. Anindya presented his journey in Sugar Labs through a talk titled *"The 'build to learn' guide for Google Summer of Code and beyond."*

![Anindya Kundu presenting at IIT Kanpur](/assets/post-assets/2024-annual-report/image51.webp?w=960&amp;fit=max)
*Former GSoC participant and Music Blocks v4 maintainer Anindya Kundu represented Sugar Labs at the Opportunity Open Source Conference at IIT Kanpur in August.*

Comment on, like, and share the original post: <https://www.instagram.com/p/C_S_ccSRlFR/>

Interested in representing Sugar Labs at a conference? Please reach out to us at [info@sugarlabs.org](mailto:info@sugarlabs.org) for presentation feedback and handout materials.

### - Boston Code Camp

Sugar Labs Executive Director Devin Ulibarri and board member Walter Bender led a session for [Boston Code Camp on November 23, 2024](https://www.bostoncodecamp.com/CC37/Schedule/SessionGrid) titled *"Create musical code with Music Blocks"*, where they introduced Music Blocks to an audience of educators and technologists.

![Music Blocks co-creators](/assets/post-assets/2024-annual-report/image37.webp)
*Devin Ulibarri (at left) and Walter Bender (at right) have been working together on Music Blocks since its start in 2014.*

![Phrase Maker widget](/assets/post-assets/2024-annual-report/image23.webp)
*Devin and Walter presented Music Blocks at Boston Code Camp in November.*

## Sugar Labs in the Classroom

### Music Blocks

This year marked significant progress in research and development for the Music Blocks visual programming language. Alongside the development work done during GSoC over the summer, I explored every opportunity to bring the new features to students, teachers, and classrooms.

I collaborated with one of my students, Nathan, who has studied music with me for about a decade and has also taken over a year of Music Blocks classes directly from Walter Bender. Together, we tested the new AI features, such as MIDI import, as well as experimental features like music transcription and lesson plan generators.

During the same period, I worked closely with teachers who were preparing innovative Music Blocks lessons. They provided valuable feedback by reporting bugs and suggesting new feature requests based on their classroom experiences.

![Nathan](/assets/post-assets/2024-annual-report/image22.webp)
*Nathan (at back) has studied with Devin for ten years. Over the summer, Nathan came in regularly to test new Music Blocks features that were being developed as part of Google Summer of Code.*

![Musician and programmer duo](/assets/post-assets/2024-annual-report/image12.webp)
*Two instructors for a summer camp at MAP Family Learning Center worked together to create lessons for different themes, such as Egypt, Spain, and India. One instructor is primarily a programmer, the other is a Berklee-trained musician.*

![Lesson plan generator](/assets/post-assets/2024-annual-report/image14.webp)
*One of the projects for GSoC was a LLM-enabled lesson plan generator. Nathan (at right) and I tested it as we were helping the instructors create lesson plans for five weeks of summer classes.*

![Music+Code](/assets/post-assets/2024-annual-report/image38.webp)
*Nathan was eventually recruited to help the instructors create lesson plans. He utilized his knowledge and understanding of both music and programming to create projects for the students.*

![Musical debugging](/assets/post-assets/2024-annual-report/image16.webp)
*Nathan created unique projects for Music Blocks, which are now uploaded to the Planet. He had to debug both the music and the logic in order to make his projects work.*

![Summer fun](/assets/post-assets/2024-annual-report/image2.webp)
*Lesson plans created by Nathan and the two teachers were used over the summer. The students had a great time, and we received important feedback to improve Music Blocks.*

### Sugar Learning Platform and Sugar Activities

In the fall, I began teaching a small group of kindergarten and first-grade students using the Sugar Learning Platform. We started with a few One Laptop Per Child (OLPC) laptops and later transitioned to newer hardware. The students quickly fell in love with their computers — calling the chat robot their "robot friend" — and eagerly created art, composed music, and played educational games.

Our sessions covered a variety of topics, from spelling to problem-solving. The foundation we built early on eventually led to the students learning to program using Turtle Blocks. The class is ongoing, and it has been both a joy for the students and an insightful experience for me.

Additionally, my time in the classroom has allowed me to provide valuable feedback to developers for future improvements to the platform.

![First introduction](/assets/post-assets/2024-annual-report/image44.webp)
*Devin ran "Sugar classes" for kindergarten and second grade in the fall.*

![Robot friend](/assets/post-assets/2024-annual-report/image31.webp)
*The students in Devin's class expressed much joy as they explored the tools in Sugar.*

![Computer surprise](/assets/post-assets/2024-annual-report/image18.webp)
*Soon after the computers were introduced to the students, one student brought in her own computer. She had drawn a computer with a monitor and keyboard, modeled after her experience using Sugar.*

![Students helping students](/assets/post-assets/2024-annual-report/image24.webp)
*Devin's son Kai (at right) helped the students in their first weeks.*

![First steps](/assets/post-assets/2024-annual-report/image6.webp)
*At first, the computers took some getting used to. Now, the students understand the basics.*

![Joyful learning](/assets/post-assets/2024-annual-report/image46.webp)
*The students had a blast learning together with the Sugar Learning Platform.*

### Teaching Git to Students of Everett High School

In the spring, a couple of teachers at a local high school approached me about training their students in collaborative software development practices. I met with the students twice and followed up with them via email and group chat to support their learning journey.
Together, we covered the basics of Git version control, using the command line, and making their first contributions to our repositories. It was a rewarding experience that gave the students practical skills and an introduction to open source collaboration.

![First inception into git](/assets/post-assets/2024-annual-report/image28.webp)
*The high school students were eager to contribute. Contributing to free/libre/open source projects like Sugar Labs typically requires version-control collaborative tools like git.*

![Students and teachers of Everett High School](/assets/post-assets/2024-annual-report/image42.webp)
*Devin (at left) met with the students of Everett High School two times to get them started as contributors for Sugar Labs.*

## Finances

Last year, I spent time working on our finances — where we keep our money, which platforms can be used to donate to our organization, and increasing the number of financial tools available to us. I did this work primarily to ensure that charitable donations can be made with confidence, ultimately helping every contribution we receive go further.

One of the major improvements I made to increase financial transparency was updating and publishing our 990 tax filings. All of our tax documents are now up to date and publicly available on our [donations page](https://www.sugarlabs.org/donate/) under the section "Our 990 tax filings."

In addition, I helped Sugar Labs secure in-kind services that directly support our day-to-day operations at no cost. This year, we received:

- **Open Source Credits from AWS**: These credits are helping us test and develop new educational software.
- **Over 100 terabytes of data storage** through Google Workspace for Nonprofits.
- **Other in-kind services** that allow us to run more efficiently and at a lower cost.

Lastly, I laid the groundwork for accepting financial contributions through a wide variety of platforms, including ACH, stocks, and even cryptocurrency. We were also added to the PayPal Giving Fund, which makes us discoverable through multiple corporate donation programs. Employers can now support Sugar Labs via Benevity, and all these channels are now live as of 2025 — a result of the foundational work completed in 2024.

### Ways to Give

- [every.org/sugar-labs](https://www.every.org/sugar-labs)
- [Benevity Causes](https://causes.benevity.org/causes/840-843289298)
- [MyGoodness by Benevity](https://mygoodness.benevity.org/community/cause/840-843289298/donate)
- [PayPal Giving Fund (for businesses)](https://www.paypal.com/us/fundraiser/charity/4357440)
- [Our Donations Page (up-to-date list)](https://www.sugarlabs.org/donate/)

### In-kind Donations

We received eleven ThinkPads (X1 Yogas) from Beacon Communities, LLC in April. These laptops feature touchscreens — a particularly useful feature for children — and have been used to teach both Sugar Activities and Music Blocks effectively.

![Installing Trisquel on the donated machines](/assets/post-assets/2024-annual-report/image47.webp)
*Trisquel is a distribution of GNU/Linux that offers a version for download that has the Sugar Learning Platform as its default.*

![Super Tux](/assets/post-assets/2024-annual-report/image19.webp)
*The computers were received near the end of the school year, so the obvious way to test them out was to let the kids play with them.*

![Teacher and intern training](/assets/post-assets/2024-annual-report/image1.webp)
*The donated computers helped us train teachers and interns to use Music Blocks.*

![Nine upcycled computers](/assets/post-assets/2024-annual-report/image27.webp)
*These nine computers are now property of Sugar Labs. They've been used since we've received them to teach Sugar and Music Blocks, as well as to test new code created by GSoC participants.*

![Touch screens](/assets/post-assets/2024-annual-report/image48.webp)
*All of the donated laptops have touchscreens.*

![Multimedia](/assets/post-assets/2024-annual-report/image36.webp)
*Students are able to interact with the computers via touch and with a mouse. They also ahve headphones they can use to hear sounds from the computers.*

### AWS Open Source Credits

In 2024, we applied for and were awarded **open-source credits worth $8,000** from Amazon Web Services (AWS). These credits will help us continue testing and developing the large language model (LLM) and neural network services we worked on over the summer.

### New Sugar Labs Merchandise for Sale

We added a fun twist to our fundraising efforts last year! Inspired by the community reaching out with questions like *"How can I buy Sugar?"*, we launched a variety of branded merchandise.

We now offer:

- **Clothing items** – Hoodies and t-shirts in a range of colors.
- **SoaS (Sugar on a Stick) USBs** – Bootable drives ready for use.

To minimize overhead and simplify logistics, we partnered with two trusted vendors:

- [**Bonfire**](https://www.bonfire.com/store/sugar-labs/) for apparel  
- [**USB Memory Direct**](https://www.usbmemorydirect.com/) for USB drives

All proceeds directly support Sugar Labs' mission to create educational software based on Constructionist learning principles.

![Landing page for USBs](/assets/post-assets/2024-annual-report/image15.webp)
*USB Memory Direct partnered with us to sell and distribute USBs with Sugar on a Stick (SoaS) pre-installed.*

![T-shirts and hoodies](/assets/post-assets/2024-annual-report/image10.webp)
*In 2024, we started a merchandise store through Bonfire.*

![SOAS delivered to your door](/assets/post-assets/2024-annual-report/image50.webp)
*The test package came with smarties and a sticker. The USB was tested and proven to work as expected.*

![Fun fashion](/assets/post-assets/2024-annual-report/image11.webp)
*Our store on Bonfire offers a range of colors and styles.*

*To view and purchase our merchandise, please go to:
[https://www.sugarlabs.org/products/](https://www.sugarlabs.org/products/).*

*Read more about the launch of our products:
[https://www.sugarlabs.org/community/2025/01/21/SoaS-USB-announcement/](https://www.sugarlabs.org/community/2025/01/21/SoaS-USB-announcement/).*


---

## 2024 Accounting Details: Revenue and Expenses

In 2024, Sugar Labs reported a **net loss of $62,629.28**.

### Revenue:  
- **Total**: $7,872.86

### Expenses:  
- **Total**: $70,502.14

#### Top Expenses:
1. Payroll: $45,136.99  
2. Contractor expenses: $9,978.19  
3. Taxes: $6,356.05  
4. Legal & accounting fees: $2,793.00  
5. Travel (conferences): $2,792.66  
6. Conference fees: $1,345.00  
7. Other (mail, marketing, insurance, government fees, web hosting): $2,100.25

#### Revenue Sources:
1. Google: $6,700.00  
2. Donations\\*\\*: $786.05  
3. Interest (US Bank checking account): $350.57  
4. Bonfire merchandise sales: $36.24  

\\*\\*Note: We use the cash accounting method. Donations sent in 2024 but not deposited until 2025 are not reflected here.

### In-Kind Donations

In addition to financial income, we received **$8,000 in AWS Open Source Credits** in Fall 2024, which we plan to use to test the tools developed during GSoC.

---

## Membership

In 2024, we made one significant change to how membership is maintained. In preparation for our annual election, we required community members to reapply for membership to ensure active participation, as our [bylaws](https://wiki.sugarlabs.org/go/Sugar_Labs/Governance) require a majority vote from members for some decisions.

Aside from this participation requirement, the eligibility criteria remain unchanged:

> "Any 'significant and sustained' contributor to Sugar Labs is eligible for membership... Contributions may be code, documentation, translations, maintenance of project-wide resources, running a Sugar deployment, or other non-trivial activities which benefit Sugar Labs."

If you're an active contributor — technical or non-technical — we encourage you to [apply for membership](https://wiki.sugarlabs.org/go/Sugar_Labs/Members). Membership gives you the right to vote in board elections and other key decisions.

---

## Election

Sugar Labs held its annual **Board of Directors election** in 2024. The results, announced on **December 19, 2024**, elected the following three individuals for the 2024–2025 term:

- **Devin Ulibarri**  
- **Sumit Srivastava**  
- **Sebastian Silva**

Learn more about the process and outcomes here:

- [How to participate in board elections (Nov 8)](https://www.sugarlabs.org/community/2024/11/08/fall-board-elections-how-to-participate/)
- [Elections extension notice (Nov 22)](https://www.sugarlabs.org/community/2024/11/22/elections-extension/)
- [Final election results (Dec 19)](https://www.sugarlabs.org/community/2024/12/19/election-results/)

---

## Management and Board

In 2024, [Devin Ulibarri was appointed Executive Director](https://www.sugarlabs.org/press/2024/05/08/Sugar-Labs-announces-nonprofit-status-new-executive-director/). Alongside his leadership, our membership also voted in three new board members, as noted in the section above, including one seat that had been previously vacant.`,Ci=Object.freeze(Object.defineProperty({__proto__:null,default:we},Symbol.toStringTag,{value:"Module"})),ye=`---
title: "The Sweet Spot – Issue 003"
excerpt: "Recent news from Sugar Labs including Sugarizer v1.9 release, annual report for 2024, contributor stories, and more community updates."
category: "COMMUNITY NEWS"
date: "2025-03-31"
author: "Devin Ulibarri"
tags: "markdown,parser,test,education,post,aigenerated"
---
<!-- markdownlint-disable -->

*Recent news for March 31, 2025*

Welcome to the third issue of *The Sweet Spot*, a newsletter for Sugar Labs-related news in development, student and teacher work, events, how to get involved, and other related news and information.

## Contents of this issue

- Sugarizer v1.9 is available for your device  
- Annual report for 2024  
- From beginner to number one on the contributors chart: My open-source journey  
- Devin Ulibarri: How Sugar Labs empowers education via FLOSS  
- Enhancing Sampler widget with drag and drop  
- Sugar Labs is a mentoring organization for GSoC 2025  
- Two new ways to donate: Every.org and Benevity  
- My open-source journey with Sugar Labs  
- Volunteers wanted  
- Upcoming events and meetings  
- About Sugar Labs  
- Social and communication links  
- Back issues of *The Sweet Spot*

---

## Updates

### Sugarizer v1.9 is available for your device  
**March 25, 2025**

Sugarizer maintainer Lionel Laské has announced a new release of the multi-platform clone to Sugar Learning Platform. This release includes:

- A new 3D volume activity (developed during GSoC)
- Improved stability
- A new "direct launch" feature to auto-start an activity on Sugarizer launch

Check out the full details:  
 [Release notes](https://lists.sugarlabs.org/archive/sugar-devel/2025-March/059881.html)  
 [Try it live](https://try.sugarizer.org/)

[youtube: r5yamM5j7rk]

---

### Annual report for 2024  
**March 24, 2025**

The newly released **Annual Report for 2024** includes highlights of our work in:

- Software development
- Sugar in classrooms worldwide
- Outreach and conferences  
- Preliminary financials

Read the report: [Annual report – 2024](https://www.sugarlabs.org/community/2025/03/24/annual-report/)

---

### From beginner to #1 on the contributors chart  
**March 21, 2025 – by Om Santosh Suneri**

Om shares his incredible journey from being new to open source to topping the contributors chart for Music Blocks. In his blog, he discusses his contributions, early learnings, and advice to newcomers.

Read the full article:  
 [My Open-Source Journey](https://medium.com/@omsuneri/from-beginner-to-1-on-the-contributors-chart-my-open-source-journey-a0c4d07e1818)

---

### 🎓 Devin Ulibarri: How Sugar Labs empowers education via FLOSS  
**March 12, 2025 – by Max Roveri**

In an interview with Linux Professional Institute, Devin Ulibarri dives into:

- Sugar Labs' mission  
- FLO (Free/Libre/Open) values  
- Challenges in scaling  
- Future goals for growth and mentorship

 [Read the Interview](https://www.lpi.org/blog/2025/03/12/devin-ulibarri-how-sugar-labs-empowers-education-via-floss/)

---

### Enhancing Sampler widget with drag and drop  
**March 6, 2025 – by Harshit Verma**

New contributor Harshit Verma upgraded the Music Blocks Sampler widget. You can now drag and drop sound samples directly into the browser to generate code.

 [Enhancement details](https://musicblocks.net/2025/03/06/enhancing-sampler-widget-with-drag-and-drop-support-to-add-samples-music-blocks/)

---

### Sugar Labs is a mentoring organization for GSoC 2025  
**February 28, 2025**

Sugar Labs will mentor students in this year's **Google Summer of Code**!

 Explore our project ideas  
 Submit proposals by **April 8th, 18:00 UTC**

 [Mastodon announcement](https://mastodon.social/@sugar_labs/114083771631725400)  
 [Project Ideas](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md)  
 [Mailing List post](https://lists.sugarlabs.org/archive/sugar-devel/2025-March/059892.html)

---

## Volunteers wanted

We're growing and need **volunteer support** in various areas—tech, outreach, design, documentation, and more.

If you're curious and committed, email us: [info@sugarlabs.org](mailto:info@sugarlabs.org)  
 Learn more: [Volunteering at Sugar Labs](https://www.sugarlabs.org/volunteering)

---

## Upcoming events and meetings

### Special Event  
**New website launch party**  
 April 25, 2025 at 13:00 EDT / 17:00 UTC  
 [YouTube Stream](https://www.youtube.com/watch?v=v76Mw9wqO6E)

### Regular Meetings  
**Music Blocks Weekly Meetups**  
 Every Sunday – 7:00 EDT / 11:00 UTC  
 [Join here](https://meet.jit.si/ResponsibleMasksForecastHastily)

---

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit dedicated to creating educational tools that promote technology exploration and learning for youth globally.

Support our work: [Donate here](https://www.sugarlabs.org/donate/)

---

## Social and Communication Links

- Bluesky: [@sugarlabs.bsky.social](https://bsky.app/profile/sugarlabs.bsky.social)  
- GitHub: [github.com/sugarlabs](https://github.com/sugarlabs)

---

## Back issues of *The Sweet Spot*

Find this and previous issues at:  
 [Sugar Labs Community News](https://www.sugarlabs.org/community-news/)
`,Li=Object.freeze(Object.defineProperty({__proto__:null,default:ye},Symbol.toStringTag,{value:"Module"})),ke=`---
title: "Live Session: Role of generative AI in education"
excerpt: "Join us with guest speaker Ken Kahn, PhD for a live session on the role of generative AI in education"
category: "EVENTS"
date: "2025-05-16"
slug: "role-of-generative-ai-education"
author: "Sugar Labs"
description: "Education Nonprofit"
tags: "gen-ai,education,live-session,guest-talk"
---
<!-- markdownlint-disable -->

**Join us live with researcher and author Ken Kahn, PhD for a live session on the role of generative AI in education. Watch live on Friday, May 16, 2025 at 13:00 EDT (17:00 UTC).**

## Event information

- **Title:** Live Session: Role of generative AI in education
- **Date:** May 16, 2025
- **Time:** 13:00 EDT (17:00 UTC)  
- **Watch Live:** [YouTube Link](https://www.youtube.com/watch?v=nn1jeQgKTOA)  
- **Platform:** [Sugar Labs YouTube Channel](https://www.youtube.com/@SugarlabsOrg-EN/streams)

## About Sugar Labs

Sugar Labs® is a US-based 501(c)(3) nonprofit organization with a global mission to create educational opportunities in technology to youth around the world. Volunteer mentors and contributors work together to develop activity-focused software for children. All software is developed with learning as the primary goal, necessitating the need for source code to be published publicly for study, licensed under a free/libre license for explicit permission to share and remix, and openly worked upon within a community where students are invited to make contributions, under guidance of experienced mentors.

Support our work: [Donate here](https://www.sugarlabs.org/donate/)
`,xi=Object.freeze(Object.defineProperty({__proto__:null,default:ke},Symbol.toStringTag,{value:"Module"})),ve=`---
title: "JavaScript Editor Updates and Future Features"
excerpt: "Overview of changes being made to the JavaScript editor tool in MusicBlocks v3, and future plans"
category: "DEVELOPER NEWS"
date: "2025-05-20"
slug: "JSeditor-updates"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
description: "GSoC Contributor"
tags: "gsoc, javaScript editor, development, contribution, debugger"
---

This is the first update report on the MusicBlocks JavaScript editor enhancement project for 
GSoC 2025. This and future reports will discuss the progress and future plans for the improvement 
of user experience and features for the editor.

## Contents
- Upcoming Features
- Motivation
- JavaScript to Music Blocks
- Debugger
- Syntax highlighting

---

### Upcoming Features
This project aims to significantly enhance the JavaScript editor within Sugar Labs'
MusicBlocks environment. By implementing translation from JavaScript code to
MusicBlocks visual blocks, users will gain a powerful tool for iterative learning and code
exploration. Additionally, the project will introduce a JavaScript visualizer for step-by-step
debugging and syntax highlighting to improve the editor's usability and appeal to young
learners. This upgrade will bridge the gap between visual programming and text-based coding,
promoting a deeper understanding of real programming and empowering kids to debug
effectively.

### Motivation
I believe that kids cannot learn to
code without coding. Although they can learn the concept of coding through MusicBlocks, they
still cannot learn text-based coding effectively. The JavaScript-to-MusicBlocks conversion feature
will enable them to better transition between visual block-based programming and
textual JavaScript coding. This promotes a deeper understanding of programming concepts and
has kids learn them more effectively. 

Even more important than learning how to code is learning how to problem solve. Debugging and 
problem solving skills provide kids with the knowledge to overcome problems of any kind, not 
just in programming. With the step by step debugger, kids will learn how to break a problem down, and 
identify where problems are and track them. 

### JavaScript to Music Blocks
The JavaScript to Music Blocks feature is fairly simple as an end product: implementing the ability
for users to convert the JavaScript code in the editor to music blocks. The execution of this feature 
is less simple. Currently, I have implemented support for all blocks from the rhythm, flow, number, and boolean palettes. There is also support for a few blocks from the pitch, tone, and action palettes. These implementations can be seen with the [first PR](https://github.com/sugarlabs/musicblocks/pull/4591) and the [second PR](https://github.com/sugarlabs/musicblocks/pull/4692).

This was all done using the following process:

1. Using the [acorn parser library](https://github.com/acornjs/acorn), convert the input code by the user in the editor into an
[**Abstract Syntax Tree**](https://en.wikipedia.org/wiki/Abstract_syntax_tree) (AST)
2. Convert the AST into a custom intermediate representation
    - In this case, it is a simpler tree consisting of all the different blocks that the code creates
    - For each block in the intermediate tree, there is information on its type, arguments, children, and/or value if it has one
3. Convert the intermediate tree into a blocklist
    - MusicBlocks generate blocks using the representation of a list of blocks, which are mostly in the form of  
    [id, name, x, y, [connections]]
    - Carefully parsing through the intermediate tree and dealing with the connections produce a list of such blocks,
    which MusicBlocks will then load into the visual programming blocks
    - The connections are made during the process of creating the blocks. 
        - For each block, if it has arguments, they will be created and connected with the block
        - Then its children are created and connected to each other
        - Finally the first child is then connected back to the block itself
    - During this process, vertical sizes of arguments are kept track of to insert the necessary amount of vertical spacers before the children

Although this process is proven to work very well as shown by the [merged PR](https://github.com/sugarlabs/musicblocks/pull/4591), 
adding future blocks is not yet as simple as it can be.

Thus, I am currently working on refactoring the code to use JSON config files to store pairs of AST to block mappings, which would
make adding new blocks an extremely quick and trivial process. The next report may go into more details on this.

### Debugger
The JavaScript editor debugger will be a tool located as a separate tab within the console space. I plan on implementing this tool as part of GSoC this summer. Although currently unavailable, I have created a simple design as to what it may look like.
![JSeditor debugger](/assets/post-assets/debugger.webp)

The debugger will have the following functionalities:
 - Ability to set one or multiple breakpoints
 - Have the state of all variables at breakpoints 
 - Show function call frames
 - User can run program all the way to the next breakpoint (stops in order until user goes to next one)
 - User can step forward line by line or evaluate by unit

### Syntax Highlighting
A good IDE or code editor will always have syntax highlighting. This makes the environment easier and more fun to work with. Thus,
this feature will also be added to the JavaScript editor in MusicBlocks. Although this also has not been implemented yet, I foresee this
part of the project being the fastest, as there are many established libraries that can provide syntax highlighting. Some candidates may include highlight.js, and CodeJar.

---

This concludes the first report on the MusicBlocks JavaScript editor enhancement project for GSoC 2025. Thanks for reading, and more updates will come soon!`,Gi=Object.freeze(Object.defineProperty({__proto__:null,default:ve},Symbol.toStringTag,{value:"Module"})),Se=`---
title: "GSoC ’25 Week 01 Update by Aditya Kumar Singh"
excerpt: "Refining human anatomy models and improving Sugarizer’s 3D Human Activity"
category: "DEVELOPER NEWS"
date: "2025-05-28"
slug: "2025-05-28-gsoc-25-AdityaKrSingh26-week01"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
description: "GSoC'25 Contributor at SugarLabs (Sugarizer Human Activity Pack)"
tags: "gsoc25,sugarlabs,week01,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-05-12 - 2025-05-18   

---

## Goals for This Week

- **Goal 1:** Identify missing human body assets in the current execution.
- **Goal 2:** Simplify models and increase spacing between organs.
- **Goal 3:** Remove redundant code from the current codebase and improve structure.

---

## This Week’s Achievements

1. **Identify missing human body assets in the current execution**  
   - Reviewed current assets and mapped out missing organs and systems (e.g., stomach, intestines, food pipe, kidneys, liver, eyes, brain, etc).  
   - This helps ensure educational completeness and anatomical accuracy for users.

2. **Simplify Z-Anatomy models and increase spacing between organs**  
   - Removed mesh clutter and enhanced spacing between vital organs like heart, lungs, liver to improve visibility and user interaction.
   - This change is aimed at improving user experience, especially on touch devices.
   ![screenshot-description](https://i.ibb.co/zHbVQ39Z/Screenshot-2025-05-14-130753.webp)  
   ![screenshot-description](https://i.ibb.co/hx8MSh0n/Screenshot-2025-05-14-130802.webp)  


3. **Remove redundant code from the current codebase and improve structure**  
   - Removed redundant or deprecated functions, improved file modularity, and standardized naming across \`activities\\HumanBody.activity\\js\\activity.js\`.
   - Resolved duplicate \`loader.load()\` usage: Consolidated the skeleton model loading logic into a reusable function and invoked it from both \`env.getEnvironment\` and \`onNetworkDataReceived\`, removing redundancy.
   - Optimized \`env.getEnvironment\` call: Now invoked only once and the result is reused where needed
   - Unified zoom functions: Replaced \`zoomInFunction\`, \`zoomOutFunction\`, \`zoomEqualFunction\`, and \`zoomToFunction\` with a single parameterized \`zoomCamera(type, targetFOV)\` function to streamline logic.
   - Links : PR [#1794](https://github.com/llaske/sugarizer/pull/1794).

---

## Challenges & How I Overcame Them

- **Challenge:** Code duplication across multiple model load functions and zoom handlers.  
  **Solution:** Abstracted the model loading into one reusable function to reduce maintenance overhead. Similarly, created a generalized zoom function with parameters for FOV and zoom type to replace multiple similar methods.

- **Challenge:** Finding suitable 3D models with the right level of mesh detail.  
  **Solution:** Spent time evaluating and testing various anatomy models and 3D datasets. Balanced between model quality and performance ensuring the mesh was detailed enough for educational use but light enough for smooth rendering in Sugarizer’s environment.

---

## Key Learnings

- Got hands-on with **3D modeling tools like Blender** for optimization and export for web use.
- Understood modular design and best practices for maintaining scalable code in large open-source projects.

---

## Next Week’s Roadmap

- Refine the 3D models ,remove and merge unecessary parts.
- Integrate Organs 3D models for the basic paint activity.
- Import and test Human Body model for visual alignment.

---


## Resources & References

- **Repository:** [github.com/AdityaKrSingh26/sugarizer](https://github.com/AdityaKrSingh26/sugarizer)
- **3D models used:**
    - "Human" (https://skfb.ly/6Z8LI) by aaron.kalvin,
    - "Realistic Human Lungs" (https://skfb.ly/oBDWI) by neshallads,
    - "Human heart, realistic anatomical model" (https://skfb.ly/oXBxZ) by 3d Eye Catcher,
    - "human-brain" (https://skfb.ly/6YqDO) by Yash_Dandavate,
    - Organs by Z-Anatomy (https://github.com/LluisV/Z-Anatomy)


---


## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [@AdityaKrSingh26](https://github.com/AdityaKrSingh26)
- Gmail: [adityakrsingh2604@gmail.com](mailto:adityakrsingh2604@gmail.com)
- LinkedIn: [Aditya Kumar Singh](https://www.linkedin.com/in/adityakrsingh26/)
- Twitter: [@AdityaKrSingh26](https://x.com/AdityaKrSingh26)

---
`,Wi=Object.freeze(Object.defineProperty({__proto__:null,default:Se},Symbol.toStringTag,{value:"Module"})),Ie=`---
title: "GSoC ’25 Week 02 Update by Aditya Kumar Singh"
excerpt: "Merging anatomical models and enhancing Sugarizer’s Human Body Activity"
category: "DEVELOPER NEWS"
date: "2025-05-29"
slug: "2025-05-29-gsoc-25-AdityaKrSingh26-week02"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
description: "GSoC'25 Contributor at SugarLabs (Sugarizer Human Activity Pack)"
tags: "gsoc25,sugarlabs,week02,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-05-19 - 2025-05-22   

---

## Goals for This Week

- **Goal 1:** Merge required segmented models into a single unified mesh.  
- **Goal 2:** Integrate 3D organ models required for the initial version of the paint activity.  
- **Goal 3:** Refactor and clean up code to improve maintainability of the Human Body Activity.  
- **Goal 4:** Import and test a Human body model.

---

## This Week’s Achievements

1. **Merged intestine models into a single mesh**  
   - Used Blender to unify multiple intestine segments into a single watertight mesh.  
   - Simplified mesh topology while preserving anatomical details for better performance in-browser.  
      ![screenshot-description](https://i.ibb.co/TM5r90b8/Screenshot-2025-05-19-200136.webp)   
      ![screenshot-description](https://i.ibb.co/svsp626J/Screenshot-2025-05-20-234105.webp)   


2. **Integrated 3D organ models for the basic paint activity**  
   - Selected essential models: heart, brain, lungs, and kidneys.  
   - Positioned and scaled them within the scene for the interactive paint activity.  
   - Confirmed interactivity through raycasting and model selection using three.js.  
      ![screenshot-description](https://i.ibb.co/spZpwD0P/Screenshot-2025-05-23-005734.webp)   
      ![screenshot-description](https://i.ibb.co/jPxMn9HN/image.webp)   


3. **Refactored and cleaned up existing code for Human Body Activity**  
   - Improved component structure and naming conventions in \`activity.js\`.   
   - PR merged: PR [#1794](https://github.com/llaske/sugarizer/pull/1794).  

4. **Imported and tested a Human body model**  
   - Imported an external Human body model and tested visual alignment.  
   - Adjusted scale, rotation, and pivot points in Blender.  

---

## Challenges & How I Overcame Them

- **Challenge:** Organs weren’t interacting properly in the paint activity due to non-unified object hierarchies.  
  **Solution:** Used grouping and bounding box checks to establish correct hit detection zones. Re-anchored object origins for each model.  

---

## Key Learnings

- Improved skills in 3D mesh merging.  
- Learned how to optimize **paintable 3D object interactions** within a browser canvas.  
- Gained experience in **codebase refactoring for open-source projects** to enhance maintainability.  


---

## Next Week’s Roadmap

- Create a \`credits.md\` file to document and attribute all third-party 3D models used, following proper open-source licensing guidelines.  
- Integrate additional organ models into paint mode to enrich the educational interactivity.  
- Bisect the human body model into appropriate anatomical sections (e.g., upper/lower torso, head, limbs) for easier interaction and labeling.  
- (Optional) Begin integrating the full human body model into paint mode, allowing users to interact with and label the complete anatomy structure.  


---


## Resources & References

- **Repository:** [github.com/AdityaKrSingh26/sugarizer](https://github.com/AdityaKrSingh26/sugarizer)
- **3D models used:**
    - “Z-Anatomy Human Body” (https://github.com/LluisV/Z-Anatomy)
    - "Human" (https://skfb.ly/6Z8LI) by aaron.kalvin.
    - Human Heart ,Lungs, etc from Sketchfab (refer Week 01 for links)


---


## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [@AdityaKrSingh26](https://github.com/AdityaKrSingh26)
- Gmail: [adityakrsingh2604@gmail.com](mailto:adityakrsingh2604@gmail.com)
- LinkedIn: [Aditya Kumar Singh](https://www.linkedin.com/in/adityakrsingh26/)
- Twitter: [@AdityaKrSingh26](https://x.com/AdityaKrSingh26)

---
`,Di=Object.freeze(Object.defineProperty({__proto__:null,default:Ie},Symbol.toStringTag,{value:"Module"})),Ae=`---
title: "GSoC '25 Week 1 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates"
category: "DEVELOPER NEWS"
date: "2025-06-07"
slug: "2025-06-07-gsoc-25-Elwin-Li-week01"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
description: "GSoC Contributor"
tags: "gsoc25,sugarlabs,week1,javaScript editor"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 1 Progress Report by Elwin Li

**Project:** [Advanced JavaScript Editor with MusicBlocks Interactions](https://github.com/sugarlabs/musicblocks/tree/gsoc-2025/elwin)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-06-02 - 2025-06-07

---

## Goals for This Week

- **Goal:** Complete and deploy code to blocks functionality.

---

## This Week’s Achievements

**Refactored code to be config driven**  
I refactored my code for code to block conversion to use a JSON config file so that the logic behind the conversion is as generic as possible.
An example config for a block is shown below:

         {
            "name": "repeat",
            "comments": "Repeat block in the Flow palette",
            "arguments": [
                {
                    "type": "NumberExpression"
                }
            ],
            "ast": {
                "identifiers": [
                    {
                        "property": "type",
                        "value": "ForStatement"
                    }
                ],
                "argument_properties": [
                    "test.right"
                ],
                "children_properties": [
                    "body.body"
                ]
            },
            "blocklist_connections": [
                "parent_or_previous_sibling",
                "argument",
                "first_child",
                "next_sibling"
            ],
            "default_vspaces": {
                "argument": 1
            }
         }

This config is for the repeat block, as conveniently stated in the comments section for readability. 
There are several pieces of information we need for a block for the conversion code to work:
- The name of the block
- The number of arguments, and their types
- The associated AST information
   - The identifiers, or the path to that block (needed for matching)
   - The paths to the argument and children properties from the AST
- The connections the block has in the blocklist [parent/previous sibling, argument(s), child(ren), next sibling]
- vspace information

Based on these pieces of information, the conversion code is generic enough to parse through and translate into blocklist format.
This is very important because this means that adding a new block for support is now as simple as adding a config like this to the JSON file.

---

## Challenges & How I Overcame Them

- **Challenge:** Coming up with the config format.

  **Solution:** Lots of trial and error, and using many different examples to make the code generic.

- **Challenge:** Argument handling was not working with configuration.

  **Solution:** Added a separate section in the config file for argument blocks, but made it as close to other blocks as possible.

---

## Key Learnings

- Deepened understanding of JSON configuration files.
- Improved skills in **debugging**, **code design**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Fully add all blocks that we want to support for code to block conversion, with corresponding documentation and error handling.
- Move on to next phase of the JSeditor project, which is the debugger
- Familiarize myself with the necessary files I will need to work with for the debugger
- Work on getting breakpoints to work

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [@ebeetles](https://github.com/ebeetles)
- Gmail: [elwin.s.li@gmail.com](mailto:elwin.s.li@gmail.com)
- LinkedIn: [Elwin Li](https://www.linkedin.com/in/elwinsli/)

---
`,_i=Object.freeze(Object.defineProperty({__proto__:null,default:Ae},Symbol.toStringTag,{value:"Module"})),Te=`---
title: "DMP ’25 Week 1 Update by Aman Naik"
excerpt: "This week's focus was exploring the write-activity codebase, finding appropriate grammar correction models & understanding Abiword documentations."
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-dmp-25-AmanNaik-week01"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
description: "Member and DMP'25 Contributor at SugarLabs"
tags: "dmp25,writeactivity,write,sugarlabs,week01,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 1 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## Goals for This Week

- **Goal 1:** Understand write activity's codebase.
- **Goal 2:** Explore pertinent grammar correction models for real time grammar correction
- **Goal 3:** Understand the [Abiword](https://github.com/AbiWord) word-processor documentation

---

## This Week’s Achievements

1. **Understood the activity's codebase**  
   - Gained a clear understanding of the overall structure and logic of the Write activity's codebase.
   - This includes identifying key components, data flow, and how the Abiword processor is leveraged for this activity.
2. **Explored pertinent grammar correction models**  
   - Shortlisted grammar correction models suitable for real time grammar correction and can be used with an open source software.
   - Created API endpoints using Hugging Face spaces for quick testing in sugar.

3. **Understood the Abiword processor**  
   - Abiword is an open source word processor, which is leveraged by the write activity.
   - It has a parser called 'link-grammar' that was recently developed, which might be useful for grammar correction as well.

---

## Challenges & How I Overcame Them

- **Challenge:** Difficulty in finding reliable grammar correction models on hugging face which can also be compatible open source software.  
**Solution:** Found link-grammar that could be an option for reliable grammar correction feature. Also, found some hugging face models(relevant license) after rigorously searching. 

- **Challenge:** Testing hugging face models with no inference points and testing them inside Sugar.  
**Solution:** Most Hugging Face models can’t be installed directly in Sugar because they require heavy dependencies like Torch and Transformers, which increase memory usage in a virtual machine. Therefore, I used hugging face spaces and ran the models there, which also provides API endpoints for quick testing inside Sugar.

---

## Key Learnings

- Gained a solid understanding of the Write activity's code structure and how it integrates the Abiword processor.
- Explored lightweight, open-source grammar correction models and successfully tested them using Hugging Face Spaces via API endpoints.
- Discovered that Abiword’s link-grammar parser might be leveraged for native grammar correction within the activity.

---

## Next Week’s Roadmap

- Finalise a grammar correction model and fine tune it if needed
- Create a FastAPI endpoint and upload the selected model on AWS for testing
- Integrate grammar correction into write-activity
- Explore better spelling correction models

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---

## Connect with Me

- GitHub: [@amannaik247](https://github.com/amannaik247)
- Gmail: [amancodes247@gmail.com](mailto:amancodes247@gmail.com)
- LinkedIn: [Aman Naik](https://www.linkedin.com/in/aman-naik/)

---
`,Ei=Object.freeze(Object.defineProperty({__proto__:null,default:Te},Symbol.toStringTag,{value:"Module"})),Pe=`---
title: "DMP '25 Week 01 Update by Anvita Prasad"
excerpt: "Improving Synth and Sample Features in Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-dmp-25-AnvitaPrasad-week01"
author: "Anvita Prasad"
description: "DMP'25 Contributor at SugarLabs (Music Blocks)"
tags: "dmp25,sugarlabs,week01,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## Goals for This Week
- **Goal 1:** Update Tone.js to the latest version
- **Goal 2:** Begin tuner implementation with pitch detection
- **Goal 3:** Create basic tuner visualization

---

## This Week's Achievements
1. **Updated Tone.js Library**
   - Successfully upgraded from version 15.0.4 to 15.1.22
   - Verified compatibility with existing codebase

2. **Implemented Pitch Detection**
   - Integrated YIN algorithm for pitch detection
   - Established foundation for note identification

3. **Created Basic Tuner Interface**
   - Implemented 11-segment tuner display
   - Added initial cents adjustment UI

---

## Key Learnings
- Gained familiarity with Tone.js API and audio processing
- Learned about pitch detection algorithms and their implementation

---

## Next Week's Roadmap
- Complete tuner implementation with accurate visualization
- Implement cents adjustment calculations
- Add fine-tuning to pitch detection system
- Test with various audio sources
- Write Week 02 blog post summarizing progress and learnings

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow DMP contributors for ongoing support. Had a productive meeting with mentors this week to discuss the implementation approach.

---

## Connect with Me
- GitHub: [@AnvitaPrasad](https://github.com/AnvitaPrasad)
- Email: [anvita.prasad1@gmail.com](mailto:anvita.prasad1@gmail.com)
- LinkedIn: [Anvita Prasad](https://www.linkedin.com/in/anvita-prasad)
`,ji=Object.freeze(Object.defineProperty({__proto__:null,default:Pe},Symbol.toStringTag,{value:"Module"})),Me=`---
title: "DMP ’25 Week 01 Update by Justin Charles"
excerpt: "Week 01 focused on understanding and creating the path file to render the outlines for the SVG Paths for different brick types."
category: "DEVELOPER NEWS"
date: "2025-06-09"
slug: "2025-06-09-dmp-25-justin212407-week01"
author: "Justin Charles"
description: "Member and DMP'25 Contributor at SugarLabs"
tags: "dmp25,sugarlabs,week01,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Justin Charles

**Project:** [Music Blocks 4 Masonry Module](https://github.com/sugarlabs/musicblocks-v4/issues/430)  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## Goals for This Week

- **Goal 1:** Figure out the constants required for building the outline of the different brick SVGs.
- **Goal 2:** Find out formulae for creation of dynamic parts for the creation of the brick outlines.
- **Goal 3:** Creating functions for rendering different brick types given a set of parameters.

---

## This Week’s Achievements

1. **Identified core constants for SVG brick outlines**  
   - Analyzed existing functions to extract constants and segment lengths.
   - Documented fixed edge sizes and arc parameters required for rendering base brick structure. Here is the doc regarding the same - https://docs.google.com/document/d/1AUlA2leDJIfV3ZXceLhCaITftExq6c5BcUBMZOtZBvE/edit?usp=sharing
2. **Derived dynamic formulae for brick segments**  
   - Broke down SVG path logic to understand variable-dependent segments (e.g., based on presence of notches or arguments).
   - Reverse-engineered svg paths into configurable logic blocks.

3. **Implemented param-based render logic for brick types**  
   - Created functions to output valid SVG paths.
   - Ensured functions deliver the correct kind of brick based on the parameters given to it. 

---

## Challenges & How I Overcame Them

- **Challenge:** Understanding how fixed and dynamic SVG path parts interac 
  **Solution:** Visually inspected path output, compared it to expected segments, and mapped patterns to conditional logic.

- **Challenge:** Ensuring proper rendering across all brick types
  **Solution:** Used example bricks for side-by-side validation; gradually modularized logic to support extensibility.

---

## Key Learnings

- Gained clarity on **brick geometry constants** and their significance in SVG construction.
- Improved ability to **translate SVG paths into conditional logic functions**.
- Strengthened understanding of **segment chaining**, **arc-to-curve translations**, and **parametric shape rendering**.

---

## Next Week’s Roadmap

- Complete the path file to begin rendering bricks dynamically via input-driven SVG generation.
- Create React components for different brick types.
- Collaborate with mentors to refine design and implementation plans.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---

## Connect with Me

- GitHub: [@justin212407](https://github.com/justin212407)
- Gmail: [charlesjustin2124@gmail.com](mailto:charlesjustin2124@gmail.com)
- LinkedIn: [Justin Charles](https://www.linkedin.com/in/justin-c-663840297/)
`,Bi=Object.freeze(Object.defineProperty({__proto__:null,default:Me},Symbol.toStringTag,{value:"Module"})),Ce=`---
title: "DMP ’25 Week 01 Update by Harshit Verma"
excerpt: "Week 01 focused on understanding the Pippy codebase, testing Sugar-AI endpoints, and evaluating AI models for the debugger."
category: "DEVELOPER NEWS"
date: "2025-06-09"
slug: "2025-06-09-dmp-25-therealharshit-week01"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week01,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## Goals for This Week

- **Goal 1:** Study Pippy codebase.
- **Goal 2:** Explore Sugar AI and test its endpoints.
- **Goal 3:** Research suitable AI models for debugging.

---

## This Week’s Achievements

1. **Studied the Pippy codebase**  
   - Spent time navigating through the Pippy repository to understand how activities are structured and how debugging might integrate.
   - Cloned and set up the development environment locally to test and experiment changes.
2. **Tested Sugar-AI API endpoints**  
   - Successfully ran the FastAPI server and tested endpoints like /ask and /ask-llm.
   - Validated the flow from input to model response, which sets the stage for integrating custom prompts and debugging logic.

3. **Evaluated model options for Pippy Debugger**  
   - Tested Codellama and Mistral locally using Ollama, which provided quick setup and testing on my local machine.
   - After discussing with my mentor, I’ve shifted focus to using models directly from Hugging Face, as it aligns better with our deployment plans and integration goals.

---

## Challenges & How I Overcame Them

- **Challenge:** Understanding the Pippy codebase and its dependencies.  
  **Solution:** Followed documentation and explored Sugar Labs learning resources. Used Ubuntu in a virtual machine to setup sugar desktop.

- **Challenge:** Running Sugar AI locally to test endpoints.  
  **Solution:** Followed the documentation to run the sever but the default model was taking too long to download so I changed it to a smaller model.

---

## Key Learnings

- Gained familiarity with the **Pippy codebase and its structure.**.
- Learned to work with **FastAPI**, **Linux** and **Virtual Machine**.
- Developed better understanding of **LLM system requirements**, **quantization**, and **local model serving**.

---

## Next Week’s Roadmap

- Create a basic FastAPI server **(/debug endpoint)** that accepts Python code and suggests debugging steps.
- Integrate the **selected LLM** to respond to debugging prompts.
- Collaborate with mentors to refine design and implementation plans.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,Ri=Object.freeze(Object.defineProperty({__proto__:null,default:Ce},Symbol.toStringTag,{value:"Module"})),Le=`---
title: "GSoC ’25 Week 03 Update by Aditya Kumar Singh"
excerpt: "Organ integration, anatomical bisection, and open-source attributions in Sugarizer's Human Body Activity"
category: "DEVELOPER NEWS"
date: "2025-06-02"
slug: "2025-06-02-gsoc-25-AdityaKrSingh26-week03"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
description: "GSoC'25 Contributor at SugarLabs (Sugarizer Human Activity Pack)"
tags: "gsoc25,sugarlabs,week03,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-05-23 - 2025-05-29   

---

## Goals for This Week

- **Goal 1:** Create a **credits.md** file to attribute and list licenses for all 3D assets used.  
- **Goal 2:** Integrate organ models into the interactive paint mode.  
- **Goal 3:** Bisect the full human body model into meaningful anatomical sections using Blender.  
- **Goal 4:** Time-permitting, begin integration of the bisected full-body model into paint mode.  


---

## This Week’s Achievements

1. **Created credits.md file for 3D model attribution**  
   - Documented sources, authors, and licenses for each 3D model used in the activity.  
   - Ensured compliance with open-source licensing (CC, GPL, etc.) where applicable. 


2. **Integrated additional organ models into paint mode**  
   - Added 3D human organs model containing: stomach, liver, intestines, etc to the interactive paint activity.  
   - Verified clickable regions and ensured raycasting targets are accurate and intuitive.  
   - Updated model hierarchy for smoother interactivity and better scene management. 
   - Refactored the existing click handler for better mesh selection using **screen-space testing**.
        ![screenshot-description](https://i.ibb.co/ZRCJbPX0/image.webp)   


3. **Bisected full human body model into anatomical sections**  
   - Used Blender’s Bisect tool to separate the full mesh into functional regions: head, torso, arms, and legs.  
   - Cleaned geometry to avoid overlapping or orphaned faces.  
   - Exported and tested the segmented meshes in the Three.js scene.
        ![screenshot-description](https://i.ibb.co/NgxGXNyz/Screenshot-2025-05-29-233012.webp)   
        ![screenshot-description](https://i.ibb.co/xS4yvMYr/Screenshot-2025-05-29-233650.webp)   
        ![screenshot-description](https://i.ibb.co/zH6K7RC2/Screenshot-2025-05-29-233659.webp)   


4. **(Bonus) Partial integration of bisected model into paint mode**  
   - Imported segmented torso and head into paint mode as a pilot test.  
   - Validated paint interactions on new sections to ensure consistency.  
        ![screenshot-description](https://i.ibb.co/XxymdWbF/image.webp)   

---

## Challenges & How I Overcame Them

- **Challenge:** Bisecting the human body mesh led to artifacts and unclean separations.  
  **Solution:** Used high-precision knife and cleanup tools in Blender and manually adjusted vertex groups. 

---

## Key Learnings

- Improved proficiency with Blender’s mesh slicing and cleanup tools.  
- Learned proper practices for open-source asset attribution.  

---

## Next Week’s Roadmap

- Write Weekly Blog Post summarizing progress, screenshots, and key learnings from Week 03.   
- Implement a model selection palette that allows users to toggle between different anatomical models (e.g., organs, skeleton, full body).   
- Integrate the full human body model into the paint activity to allow direct interaction and labeling across complete anatomy.   
- Rename labels in the skeleton model to reflect accurate anatomical terminology and improve educational clarity.   
- Add localization support for the 3D Human Body Activity to make it accessible in multiple languages.   


---


## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [@AdityaKrSingh26](https://github.com/AdityaKrSingh26)
- Gmail: [adityakrsingh2604@gmail.com](mailto:adityakrsingh2604@gmail.com)
- LinkedIn: [Aditya Kumar Singh](https://www.linkedin.com/in/adityakrsingh26/)
- Twitter: [@AdityaKrSingh26](https://x.com/AdityaKrSingh26)

---
`,Oi=Object.freeze(Object.defineProperty({__proto__:null,default:Le},Symbol.toStringTag,{value:"Module"})),xe=`---
title: "GSoC ’25 Week 01 Update by Bishoy Wadea"
excerpt: "Bonding and Four Color Map puzzle"
category: "DEVELOPER NEWS"
date: "2025-06-07"
slug: "2025-06-07-gsoc-25-BishoyWadea-week01"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week01,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Bishoy Wadea

**Project:** [Four Color Map Puzzle](https://github.com/Bishoywadea/Four-Color-Map)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-06-01 - 2025-06-07  

---

## Goals for This Week

- **Goal 1:** Define game features and core mechanics.
- **Goal 2:** Design and plan a child-friendly, interactive game UI.
- **Goal 3:** Implement the core game logic for map coloring and rule enforcement.

---

## This Week’s Achievements

1. **Initial Game Implementation**
   - Implemented the basic game loop, event handling, and win condition detection. This created the foundation for gameplay.
   - Added support for checking that no two adjacent regions have the same color.  
   - commit: [Gameplay Base](https://github.com/Bishoywadea/Four-Color-Map/commit/91eabce38439fc08da652d1de309b556393fcee3)

2. **UI Enhancements & Interaction Features**  
   - Designed and integrated colorful buttons, icons, and zoom functionalities to make the UI more appealing to children.
   - Added menu navigation for selecting countries and levels.
   - Added Undo, Erase, and Help buttons for better usability.  
   - commit: [UI Enhancment](https://github.com/Bishoywadea/Four-Color-Map/commit/4fe1c755c47696cc20e6dd757190ed1f3df98717)

3. **Map Data Integration**
   - Generated and added regional map data for Egypt, US, Nigeria, and India.
   - Developed a script to convert GeoJSON files into game-ready polygon data.
   - Screenshot of gameplay:  
   commit: [Data Integration](https://github.com/Bishoywadea/Four-Color-Map/commit/de018722d2d32d3ebd40429f8e59e1793cd34e9c)

---

## Challenges & How I Overcame Them

- **Challenge:** Generating accurate and clean polygon data from raw GeoJSON files.  
  **Solution:** Wrote a custom Python script to extract, simplify, and format the regions into usable coordinates while preserving geographical structure.

- **Challenge:** Preventing adjacent regions from being colored the same.  
  **Solution:** Implemented an adjacency-check function that verifies constraints during each coloring action.

---

## Key Learnings

- Gained proficiency in using **Pygame** for interactive game development.
- Improved understanding of **map projections** and **GeoJSON** parsing.
- Learned about structuring a project for open-source collaboration (commits, PRs, README, file organization).
- Practiced test-driven logic development and clean UI design tailored for children.

---

## Next Week’s Roadmap

- Checking if any bugs appears
- develop broken calculator game

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for the warm support and constant feedback during this bonding period.

---`,zi=Object.freeze(Object.defineProperty({__proto__:null,default:xe},Symbol.toStringTag,{value:"Module"})),Ge=`---
title: "GSoC ’25 Week 01 Update by Shubham Singh"
excerpt: "Creating UIs and visuals for addition of Lego Bricks "
category: "DEVELOPER NEWS"
date: "2025-06-07"
slug: "2025-06-07-gsoc-25-FirePheonix-week01"
author: "Shubham Singh"
description: "Maintainer and GSoC'25 Contributor at SugarLabs"
tags: "gsoc25,sugarlabs,week01,FirePheonix"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-01 - 2025-06-07

---

## Goals for This Week

- **Goal 1:** Basic UI for Image Upload/Real time Video upload and adjust.
- **Goal 2:** Putting the developed UIs onto the widget blocks.
- **Goal 3:** Searching for exisiting audios in the phrase maker and note blocks.

---

## This Week’s Achievements

1. **Interface for Image upload for Lego Notations**  
   - Music Blocks has a feature to detect the color of pixels generated from drawing within the program, but it cannot detect the color of pixels from images that are either uploaded or from a webcam. 
   - By adding a feature to detect color from both uploaded images and a live webcam stream, users would be able to implement Lego music notation for the blind and similarly interactive programs.
   
   ![screenshot-description](https://i.ibb.co/d0yVXJmP/Lego-Bricks-Google-Chrome-08-06-2025-01-12-56.webp)
   

2. **Live webcam feed and editing options**  
   - The following feature helps to use a real time video(webcam) onto the Lego Notation detection interface. Also, you may freely edit and move it around the canvas.
   ![screenshot-description](https://i.ibb.co/n8cswJsP/Lego-Bricks-Google-Chrome-08-06-2025-01-14-01.webp)

   - Here's the reference video regarding lego bricks as musical notes:
   [youtube: LOfrCPf3XJU]

   - Here's Devin's CMK project for color sensor project in music blocks:
   [Reflections from constructing modern knowledge](https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c) 
    
3. **Identified methods to making a new widget block in music blocks**  
   - I read and went through a lot of documentation, searching for how we can add a new widget block in music blocks. I figured out a few flaws and how can the documentation be improved for future contributors.
   ![screenshot-description](https://i.ibb.co/bVD8Z54/image.webp)
   - From what I've realized working on it, for adding a new block on the music blocks, I definitely think that for adding a new block, a lot of the code - UIs, features, etc. would already exist and you can just inherit those exisiting classes. And also, you'll have to edit and change a LOT of files and add new methods for your own new block.
    ![screenshot-description](https://i.ibb.co/hJRKV0Vq/Documentation.webp)

---

## Challenges & How I Overcame Them

- **Challenge:** Getting started on features and UIs with a lot of doubts about how it should look like.
- **Solution:** Consulting my mentors, presenting variations of "How it could be" to them, refering to EXISTING UIs in Music Blocks.

---

## Key Learnings

- Gained familiarity with **making new blocks**.
- Deepened understanding of **inheritance and code modularity**
- Improved skills in **exports, imports, code reusability**, **documentation**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Implement **mapping of musical notes to lego bricks' colors**.
- Refine **UIs** based on mentor feedback.
- Inherit the exisiting code inside **WidgetBlocks.js** code as UI.
- Target: Completing the **core implementation** in the week number 2 and 3.

---

## Acknowledgments

Thanks to some old pull requests and documentation available in music blocks, I was able to figure out on a lot about how new blocks are created on the music blocks interface. Will definitely add on more.

---

## Connect with Me

- GitHub: [@FirePheonix](https://github.com/FirePheonix)
- Gmail: [shubhsoch@gmail.com](mailto:shubhsoch@gmail.com)
- LinkedIn: [Shubham Singh](https://www.linkedin.com/in/shubham-singh-8a5643198/)
- Twitter: [@DevNinjaShubham](https://x.com/DevNinjaShubham)

---
`,Fi=Object.freeze(Object.defineProperty({__proto__:null,default:Ge},Symbol.toStringTag,{value:"Module"})),We=`---
title: "GSoC ’25 Week 01 Update by Mebin J Thattil"
excerpt: "Experimenting, Benchmarking and Researching"
category: "DEVELOPER NEWS"
date: "2025-06-06"
slug: "2025-06-06-gsoc-25-mebinthattil-week1"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week01,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-02 - 2025-06-06  

---
## Introduction & About Me
Hey, I'm Mebin 👋🏻! I'm a first year student at PES University, Bangalore, India, currently pursuing a BTech in Computer Science. I’ve had a deep passion for tech ever since I was 10, when I first learned in a CS class that you could write a couple of lines of code and build a (barely functional) website. That simple idea sparked something in me, and over the years, my love for computer science has only grown—especially while building a bunch of cool things along the way.

About a month ago, I launched my personal portfolio website: [mebin.in](https://mebin.in/). It runs on an 8-year-old Raspberry Pi sitting at home 🤩, so apologies in advance if the site is occasionally slow or down (power cuts are a real pain). I'll be posting a copy of these blogs there as well. Go check 'em out and a bunch of other blogs I've written there!

I'm also building a Bluesky client in the Nim programming language. I'm a strong advocate for education in technology. In the past, I built a web application aimed at connecting students in rural areas with those in urban areas to help foster a free and open peer-to-peer learning ecosystem.

To say that I’m thrilled to be working on the Speak Activity would be an understatement. I can’t wait for an amazing summer filled with learning, collaboration and helping enhance educational journey for millions of learners world-wide.

---

## Goals for This Week

- **Goal 1:** Benchmark and test various models and architectures.
- **Goal 2:** Evaluate the feasibility and implementation approach based on project constraints such as hardware limitations and size requirements.

---

## This Week’s Achievements

1. **Created a Streamlit benchmark app**  
   - A simple streamlit app was made to compare responses of different Large Language Models (LLMs) & Small Language Models (SLMs). This was done to understand which models were a good fit for our requirements.
   - Links: [Streamlit App](https://llm-benchmarking-sugar.streamlit.app/), [GitHub](https://github.com/mebinthattil/LLM-benchmarking).


---

## Selection Of Models and Challenges

- The selection of the LLM was fairly easy, as all the models in the 30-ish billion parameter range performed reasonably well without any fine-tuning. These models were _smart_ but required significant resources to run. That was fine, since the model was intended to be hosted on AWS and accessed via an API endpoint managed by Sugar-AI.
- The selection of the SLM was a bit tricky. Initially, we looked at models under 1B parameters like the Qwen3-0.6B, and the responses were hilariously bad as expected. Later, I experimented with a dual-model architecture, where one model would generate the answer and another model (or the same model with a different system prompt) would refine the answer. I tried this with the Gemma3-1B model as the generating model and the same Gemma3-1B(with a different system prompt), as the evaluation/refinement model. The results were surprisingly good! This model generated answers that were up there with the 30B parameter models! The only caveat is that it technically takes twice the time for inference, but considering the model is pretty small, it wasn’t too bad.
- That said, Gemma3-1B Instruct even after 4-bit quantization is still around 1GB in size, which is much more than we can package with the Speak activity. So now I’m going to be looking into even lighter models like TinyBERT and will update the benchmarks soon.
- Fine-tuning in the next step should hopefully improve the performance of these models as well. Considering that we also need to package the TTS model, we really need to make sure the SLM is as lightweight as possible.

**TLDR:**  
LLM selection was easy — they all perform pretty well. SLM poses some challenges. Dual-model (generation + evaluation/refinement) seems to produce much better responses. Size of the SLM needs to be reduced further (hopefully under 100MB).

  

---

## Key Learnings

- Dual model architecture (generation model + evaluation/refinement model) produces some great results, even if the individual models are very small or perform bad individually!

---

## Next Week’s Roadmap

- Setup AWS for fine-tuning the model.
- Finalize on the model to go forward with.
- Finalize on the dataset to start fine-tuning SLM with.
- Include much smaller models like TinyBert in the benchmark.
- Start fine-tuning TinyBert or any other SLM on the agreed upon dataset in the hopes to improve performance.


---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,Ui=Object.freeze(Object.defineProperty({__proto__:null,default:We},Symbol.toStringTag,{value:"Module"})),De=`---
title: "GSoC ’25 Week 01 Update by Nikhil"
excerpt: "Implemented repository creation via GitHub App, secure key generation, and metadata integration"
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-gsoc-25-Nikhil-Bhatt-week01"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week01,Nikhil-Bhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Nikhil Bhatt

**Project:** [Git backend for Musicblocks](https://github.com/BeNikk/git-backend)   
**Mentors:** [Walter Bender](https://github.com/walterbender)   
**Assisting Mentors:** [Sumit Srivastava](https://github.com/sum2it)   
**Reporting Period:** 2025-06-02 - 2025-06-08   

---

## Goals for This Week

- **Goal 1:** Implement GitHub App JWT + Installation Token Authentication
- **Goal 2:** Set Up Repository Creation from Backend 
- **Goal 3:** Write Metadata and Content Files to Repository
- **Goal 4:** Design Backend Folder Structure for Scalability


---

## This Week’s Achievements

1. **GitHub App JWT + Installation Token Auth Flow Implemented**
   - Created a Github app and installed it on a separate organisation account.
   - Implemented JWT generation using App ID and private key.
   - Fetched installation token dynamically to create repositories securely within the GitHub organization.


2. **Created Repositories via Backend with Files**
   - Built an Express-based controller to create repositories inside the organization.
   - On repository creation, wrote three files:
     - \`README.md\`
     - \`projectData.json\` (from frontend)
     - \`metaData.json\` (containing hashed key, theme, and timestamp)


3. **Implemented Unique Ownership via Hashed Keys**
   - Generated a random project key and stored a hashed version in metadata.
   - Only the original key holder (sent to frontend) can perform future edits, ensuring project ownership.


4. **Structured Clean Codebase for Scalability**
   - Organized backend into proper folders: \`controllers\`, \`services\`, \`utils\`, \`routes\`, \`config\`, and \`types\`.
   - Made the repo production-ready with readable service-based architecture.
   - Check the project at [Link](https://github.com/benikk/musicblocks-backend)

5. **Optimized Token Management & Project Creation**
   - Validated rate limits (15,000 requests/hour for GitHub App installation tokens).
   - Each request generates a fresh installation token, no collisions or race conditions observed so far.


---

## Challenges & How I Overcame Them

- **Challenge:** Writing multiple files to a new GitHub repository using Octokit caused noticeable delays
- **Solution:** Batched file uploads with asynchronous control using a loop and base64-encoded content, I plan to imrove it
  by exploring GitHub’s Create a tree and commit API to upload multiple files in a single commit for performance optimization.

---

## Key Learnings

- Deep understanding of GitHub App authentication using JWT + installation tokens.  
- Secure project ownership enforcement using hashing and metadata tracking.  
- Octokit’s repo/file handling APIs and best practices for GitHub integrations.  

---

## Next Week’s Roadmap

-  Add **edit project** functionality: Only owner (with original key) can update content.  
-  Implement **key-based ownership check middleware** to protect sensitive routes.  
-  Allow users to **open GitHub issues** on created repositories via the backend.  


---


## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [BeNikk](https://github.com/BeNikk)
- Gmail: [bhattnik442@gmail.com](mailto:bhattnik442@gmail.com)
- LinkedIn: [Nikhil](https://www.linkedin.com/in/nikhil-bhatt-3b37a0255/)
- Twitter: [Nikhil Bhatt](https://x.com/Be_Nikkk)

---
`,Ni=Object.freeze(Object.defineProperty({__proto__:null,default:De},Symbol.toStringTag,{value:"Module"})),_e=`---
title: "GSoC ’25 Week 1 Update by Safwan Sayeed"
excerpt: "Kickoff of Music Blocks 4 Program Engine development"
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-gsoc-25-sa-fw-an-week1"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week1,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 1 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## A Blog-style Retrospective

Last week marked the official start of the coding phase for the Music Blocks 4 Program Engine. I spent the first few days translating our planning sessions into a concrete technical specification. Crafting the spec helped me clarify the core constructs, their key properties, and how they will map to interfaces. The early draft already feels like a solid roadmap for the engine’s evolution.

Midweek, I teamed up with Karan Palan to begin coding the skeleton of our abstract classes. We paired on Replit to code the classes. 

---

## Goals for This Week

- Draft a comprehensive tech spec detailing engine constructs, class interfaces, and example workflows.  
- Implement the initial set of abstract classes in TypeScript.  
- Outline AST build steps and prepare a simple program example.

---

## This Week’s Highlights

1. **Tech Specification Draft**  
   - Wrote the first section of the tech spec covering .  
   - Link: [Tech Spec Document](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.otbw6ldsc32w)

2. **Abstract Classes Implementation**  
   - Started coding the core abstract classes in TypeScript alongside [Karan Palan](https://github.com/Karan-Palan).  
   - Link: [Replit: Engine Abstract Classes](https://replit.com/@karanpalan007/engine-abstract-classes?v=1#README.md)

3. **AST Discussion & Planning**  
   - Held discussions with Anindya on AST constructs, class instantiation workflow, and example program build.  
   - Outlined next steps for documenting AST examples in the tech spec.

---

## Challenges & Solutions

- **Syncing Edits on Replit:**  
  We initially clashed on file versioning.  
  *Solution:* Established a clear editing schedule and used commit comments to track changes.

- **Defining Spec Scope:**  
  The broad set of music constructs felt overwhelming.  
  *Solution:* Prioritized a core subset to include in the first draft.

---

## Key Learnings

- Mastered TypeScript abstract classes and interface patterns.  
- Reinforced the importance of early design documentation.  
- Gained clarity on AST building workflows through Anindya's feedback.

---

## Next Week’s Roadmap

- Finalize abstract class implementations and interfaces.  
- Expand the spec with AST examples and UML class diagrams if needed.

---

## Resources & References

- **Tech Spec:** [Google Docs](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.otbw6ldsc32w)  
- **Code Skeleton:** [Replit Engine Abstract Classes](https://replit.com/@karanpalan007/engine-abstract-classes?v=1#README.md)  

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their continual guidance and support.

---

## Connect with Me

- GitHub: [@sa-fw-an](https://github.com/sa-fw-an)  
- Email: [isafwansayeed@gmail.com](mailto:isafwansayeed@gmail.com)  
- LinkedIn: [Safwan Sayeed](https://www.linkedin.com/in/safwan-sayeed-6a3a482a9/)  
- Twitter: [@safwan_say](https://twitter.com/safwan_say)

---
`,Hi=Object.freeze(Object.defineProperty({__proto__:null,default:_e},Symbol.toStringTag,{value:"Module"})),Ee=`---
title: "GSoC ’25 Week 01 Update by Saumya Shahi"
excerpt: "Weekly Progress Report on the Masonry Module for GSoC '25"
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-gsoc-25-saumya-week01"
author: "Saumya Shahi"
description: "GSoC '25 Contributor at SugarLabs"
tags: "gsoc25,sugarlabs,masonry,week01,saumya-shahi"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Saumya Shahi

**Project:** [Masonry Module - Music Blocks v4](https://github.com/sugarlabs/musicblocks-v4)  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/), [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-01 - 2025-06-08

---

## Goals for This Week

- Understand the working of SVGs and path rendering logic.
- Create an exhaustive list of all configurations needed to render each visual brick type.
- Formulate the path rendering logic to dynamically generate each brick.
- Implement rendering logic for SVG bricks based on the provided configurations.
- Ensure each brick type renders correctly with various parameters.

---

## This Week’s Achievements

1. **Explored SVG-based Brick Rendering**  
   - Used [SVG Playground](https://yqnn.github.io/svg-path-editor/) to manually draw and style bricks.  
   - This helped me understand SVG path syntax, positioning, scaling, and how \`viewBox\` works for consistent rendering.  
   - Also referred to the [MDN SVG Docs](https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorials/SVG_from_scratch/Getting_started) for deeper insights into SVG internals.

2. **Compiled a Comprehensive List of Brick Types**  
   - Created a detailed list of all visually distinct brick types to be supported by the Masonry module.  
   - This helped identify variation across different bricks and how they interact in Music Blocks.  
   - [Brick Types Document](https://docs.google.com/document/d/1BswWHadyy4yC3_3vK6KHZnMn0u6jbbYiQ6JQWiqRMLw/edit?tab=t.0)

3. **Mapped Configurations for Each Brick Type**  
   - Listed out all the necessary configurations (similar to React props) for each brick — including label size, number of arguments, shape flags, etc.  
   - This configuration map allows dynamic rendering logic per brick type.  
   - [Configurations Document](https://docs.google.com/document/d/1UJXh3734S138BoTsGulzeTlZXstyvWd6syJK2eclMKI/edit?usp=sharing)

4. **Implemented SVG Brick Rendering**  
   - Successfully implemented dynamic SVG rendering logic.  
   - Given a configuration, each brick now generates an accurate path representation.  
   - The system supports variation in label length, slot types, and layout, making the rendering pipeline fully flexible.

---

## Challenges & How I Overcame Them

- **Challenge:** Brick structures vary significantly, making a one-size-fits-all rendering approach difficult.  
  **Solution:** Broke down commonalities across bricks and created modular rendering components that dynamically adapt based on type and config.

- **Challenge:** Path distortion with varying argument lengths and labels.  
  **Solution:** Used live preview tools and console-based debugging to isolate scaling issues. The SVG path editor was extremely useful in this phase.

---

## Key Learnings

- Gained strong understanding of **SVG path syntax** and dynamic drawing.
- Improved in building **config-driven rendering pipelines** with a clean separation of data and UI logic.
- Learned how to break down complex visual requirements into **reusable, parameterized components**.
- Realized that **explaining your thought process to mentors** is invaluable — it clarifies confusion and leads to better solutions.

---

## Next Week’s Roadmap

- Work on edge cases and introduce early validation of config inputs.
- Build a **basic layout logic**  that dynamically generates a SVGs for a tree of bricks (Multiple bricks rendering).
- Begin implementing **connection logic** based on bounding box / collision detection.

---

## Resources & References

- [Brick Types Doc](https://docs.google.com/document/d/1BswWHadyy4yC3_3vK6KHZnMn0u6jbbYiQ6JQWiqRMLw/edit?tab=t.0)
- [Brick Configurations Doc](https://docs.google.com/document/d/1UJXh3734S138BoTsGulzeTlZXstyvWd6syJK2eclMKI/edit?usp=sharing)
- [SVG Path Editor](https://yqnn.github.io/svg-path-editor/)
- [MDN SVG Tutorial](https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial)

---

## Acknowledgments

Grateful to my mentors Anindya, Walter, and Devin for their constant guidance and insightful feedback. Thanks to the Sugar Labs community for their welcoming support!

---

## Connect with Me

- GitHub: [@saumyashahi](https://github.com/saumyashahi)
- Gmail: [saumyashahi05@gmail.com](mailto:saumyashahi05@gmail.com)
- LinkedIn: [Saumya Shahi](https://www.linkedin.com/in/saumya-shahi/)

---
`,qi=Object.freeze(Object.defineProperty({__proto__:null,default:Ee},Symbol.toStringTag,{value:"Module"})),je=`---
title: "GSoC ’25 Week 01 Update by Diwangshu Kakoty"
excerpt: "Deploying a Streamlit app for testing"
category: "DEVELOPER NEWS"
date: "2025-06-04"
slug: "2025-06-04-gsoc-25-Diwangshu-week01"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week01,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [	Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-06-01 - 2025-06-07  

---

## Goals for This Week

- **Goal 1:** Refine prompt templates and instructions for the LLM.
- **Goal 2:** Host the project on Streamlit Cloud.
- **Goal 3:** Develop Fast API endpoints.
- **Goal 4:** Find an alternative cloud-based vector database.

---

## This Week’s Achievements

1. **Fast API Endpoints**  
   - Although I kept this task later in my proposal but it became necessary when I wanted to deploy the project for testing purposes. The endpoints /chat and /summary are used by the client-side app when having a conversation with the user. It is working perfectly in my local development environment, but it caused an issue when I tried to host the Fast API server on [Render](https://render.com/). After several trials, I found that the embedding model I am using - 'all-MiniLM-L6-v2' is a bit heavy, and the RAM usage given by the free service is not enough.
   But anyway, this is a success as we will need Fast API during the final deployment.


2. **Cloud based vector database - Qdrant**  
   - For development, I have been using ChromaDB, which is pretty good for testing and developing RAG applications locally. I have now opted to use Qdrant, which provides cloud-based vector database. It is working well with the Streamlit app.
   - [Qdrant](https://qdrant.tech/documentation/)

3. **Hosted Streamlit App**  
   - Because the Fast API server was not deployed, I simply wrote the RAG code in the Streamlit code itself. Now that it is hosted, mentors and contributors can test it and give feedback.
   - [Streamlit app](https://reflectionapp-2yoxtvn6sknvktme2zorvq.streamlit.app/)

4. **Refined Prompts**
   - Prompt Engineering is the key to get a well structured and quality response from any LLM. I improved the instructions for the LLM to ask follow up questions to get quality answers from users.

---

## Challenges & How I Overcame Them

- **Challenge:** Fast API deployment fails.  
  **Solution:** The overall goal was to deploy the project so that mentors can test it and give me feedback for the summer period. Therefore, I modified the streamlit code to handle the RAG application by itself. Hence, I tackled the problem by avoiding server deployment.

---

## Key Learnings

- I learned new technologies: Fast API and Streamlit. I watched tutorials on YouTube and read their documentations as well. 
- Learned how API endpoints work and how to manage API keys while deploying it.

---

## Next Week’s Roadmap

- Work on things suggested by mentors.
- Improve the analysis phase. This phase of the reflection learning cycle is suppose to compare and contrast user development over a period of time. Currently it uses a hardcoded summary but it needs to be dynamic.
- Write documentation for Music Blocks. Some topics still needs to get covered.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Ki=Object.freeze(Object.defineProperty({__proto__:null,default:je},Symbol.toStringTag,{value:"Module"})),Be=`---
title: "GSoC '25 Community Bonding and First Week by Krish"
excerpt: "A deep dive into the GTK4 migration journey for Sugar Labs - exploring the challenges, progress, and tooling setup"
category: "DEVELOPER NEWS"
date: "2025-06-04"
slug: "2025-06-04-gsoc-25-mostlyk-community-bonding"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
description: "GSoC'25 Contributor working on GTK4 migration for Sugar Labs"
tags: "gsoc25,sugarlabs,gtk4,mostlyk,community-bonding"
image: "assets/Images/GSOC.webp"
---


<!-- markdownlint-disable -->

# Community Bonding Period Progress Report by Krish Pandya

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)  
**Mentors:** [Walter Bender](https://github.com/walterbender) , [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky)       
**Organization:** Sugar Labs  
**Reporting Period:** May 15, 2025 till June 4, 2025  

---

## Introduction & About Me

Hey everyone! This is probably going to be my biggest blog post of the GSoC journey haha — and I'm excited to share my thoughts on the GTK4 migration project during the community bonding period and some work done till the first week. I will just give a short introduction—

I'm Krish Pandya aka MostlyK, a B.Tech student in Electronics and Communication Engineering at IIITH. While my degree says ECE, I've found myself gravitating toward robotics, graphics, software , and most imporatant of them all open source development. When I'm not debugging ~~C++~~ (Rust/Python now) code or setting up new linux systems, you'll find me reading philosophy (currently juggling reading Sartre's Nausea and Red Rising), creating music, or tinkering with RISC-V processors. I believe in doing things properly , whether it's writing neat code, understanding the philosophy behind API changes, or setting up development workflows that actually make sense. And writing stuff so coming back , anyone can just give a glance and thank me for writing this, I know my future self is going to read this a lot!

The Sugar desktop environment currently relies on GTK3, which is approaching end-of-life. My mission? Modernize Sugar by completing its migration to GTK4, ensuring long-term sustainability, improved performance, and access to modern UI features. This involves porting the core toolkit (sugar-toolkit-gtk3), porting an activity to GTK4 and making a new activity along with the new features that will be added and testing the changes.

---

## My Approach & Tooling Setup

Before diving into the actual porting work, I spent considerable time setting up an efficient development workflow. Coming from other projects, I knew that having quick way to test my changes, that is currently I just have to build the toolkit first but later on testing , it helps to have a faster way to test stuff, I may even bring out some tmux scripts later down the weeks but as of now the following is enough:

### Development Scripts That Saved My Sanity

I created a couple of shell snippets that became essential during this period:

\`\`\`bash
# Replace system sugar3 with development version
# This ensures activities use the modified toolkit instead of the old system version
sudo rm -rf /usr/lib/python3.13/site-packages/sugar3;sudo cp -r ./src/sugar3 /usr/lib/python3.13/site-packages/sugar3

# Complete rebuild and install cycle
sudo ./autogen.sh;sudo make clean;sudo make;sudo make install
\`\`\`

The first script is particularly crucial - it replaces the system's sugar3 package with my development version. Without this, Sugar activities would continue using the old GTK3 toolkit, making it impossible to test the GTK4 migration properly. The second command handles the full build cycle, all these small changes help a lot in the long run. I also knew that because I had to write a lot, I developed my own espanso setup and added stuff like em dashes , en dashes, some template code, and a bunch of stuff that come useful while writing.

### The Work Begins

1. **Started with the obvious**: Updated all \`gi.require_version\` calls from GTK 3.0 to 4.0
2. **Build system updates**: Modified GIR includes to use Gtk-4.0 and Gdk-4.0
3. **The part to work around**: Dealing with GTK4's opaque structures and API changes

---

## The Challenges & My Thought Process

### 1: GdkEvent Becomes Opaque

This was my first real "welcome to GTK4" moment. In GTK3, you could directly access event fields like \`event->type\` or \`event->grab_broken.keyboard\`. GTK4 said "nope!" and made GdkEvent structures completely opaque.

**My approach:**
- Systematically went through each event controller file
- Replaced direct field access with proper accessor functions
- \`event->type\` became \`gdk_event_get_event_type()\`
- \`event->touch.x/y\` became \`gdk_event_get_position(event, &x, &y)\`

**The human moment:** I'll be honest, this felt tedious at first. But then I realized GTK4's approach actually makes the code more maintainable and future-proof. The accessor functions provide better type safety and clearer intent.

### 2: GDK_GRAB_BROKEN Disappears

The \`GDK_GRAB_BROKEN\` event type just... vanished. After diving into GTK4 documentation, I learned that GTK4 handles grab management automatically now.

**Solution:** Removed the grab broken handling entirely. Well I am not sure if that's a good choice , let's see what happens next week, if we have to come here!
### 3: Goodbye GdkPoint, Hello Custom Structures

GTK4 removed the \`GdkPoint\` structure that Sugar was using. So naturally, I created a custom \`SugarPoint\` structure:

\`\`\`c
typedef struct {
    double x;
    double y;
} SugarPoint;
\`\`\`

**The learning:** Sometimes migration isn't just about updating APIs, it's about understanding when to create your own abstractions.

---

## Current Progress Snapshot

Here's where things stand after the community bonding period:

### Completed
- Updated all \`gi.require_version\` calls to 4.0 in Python files
- Updated import statements across the codebase
- Fixed build system GIR includes (Gtk-4.0, Gdk-4.0)
- **Fixed GdkEvent opaque struct access** in sugar-event-controller.c
- **Migrated all event controllers** to GTK 4 event handling
- **Created and implemented SugarPoint** structure to replace GdkPoint

### In Progress
- Hunting down remaining 3.0 version references (they're sneaky!)
- Fixing eggaccelerator errors (legacy code is fun, right?)

### Next on the Roadmap
- Replace GtkToolbar with GtkBox
- Migrate GtkEventBox to GtkWidget + EventControllers
- Update GtkContainer usage to new child management APIs
- Convert draw() methods to snapshot()
- Update size request/allocation APIs

---

## Key Learnings & Insights

This period taught me that migration projects are as much about understanding the philosophy behind changes as they are about updating code. GTK4 isn't just GTK3 with new version numbers,  it represents this shift toward:

- Better memory safety with opaque structures
- Cleaner event handling with dedicated controllers
- Modern rendering with the snapshot model

 The most valuable skill I've developed is learning to read the porting doc, and understand where to add my own implementation or follow the documentation. I try to reason my changes, so most of the time I am trying to argue to myself why this change compared to something else.

---

## Resources & References

- Project Page – [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- Sugar Toolkit Repository(original) – [sugar-toolkit-gtk3](https://github.com/sugarlabs/sugar-toolkit-gtk3)
- Draft PR ( on the gtk4 repository ) – [Initial GTK4 Migration Work](https://github.com/sugarlabs/sugar-toolkit-gtk4/pull/1/)
- GTK4 Migration Guide – [docs.gtk.org/gtk4/migrating-3to4.html](https://docs.gtk.org/gtk4/migrating-3to4.html)

---

## Acknowledgments

Huge thanks to Walter Bender for the guidance during this exploration phase, and to the Sugar Labs community for maintaining such well-documented code. I will be contacting other Mentors for their guidance as well and to know their thoughts!.

---

Looking forward to sharing more updates,


---
`,Vi=Object.freeze(Object.defineProperty({__proto__:null,default:Be},Symbol.toStringTag,{value:"Module"})),Re=`---
title: "GSoC ’25 Week 01 Update by Om Santosh Suneri"
excerpt: "Refining the JSON to text convertor code and creating a basic streamlit debugger app UI"
category: "DEVELOPER NEWS"
date: "2025-06-07"
slug: "2025-06-07-gsoc-25-omsuneri-week01"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week01,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-02 - 2025-06-07  

---

## Goals for This Week

- **Goal 1:** To refine the JSON to text convertor code.
- **Goal 2:** To convert the convertor's Javascript code to Python.
- **Goal 3:** To create a basic Streamlit debugger app UI.

---

## This Week’s Achievements

1. **JSON to Text Converter Refinement**  
   - I focused on refining the JSON to Text Converter for Music Blocks. I improved the metadata representation of the "start" block to make it more accurate and readable in the text format. Additionally, I added support for more block types, ensuring that their text representations are consistent with the design format.
   - This refinement is important because the JSON to Text Converter is a core part of our AI-powered Debugger. A clear and structured text format makes it easier for both the AI model and human users to understand the program logic.

2. **Javascript to Python Conversion**  
   - Following suggestions from mentors Walter and Devin, I began creating a Streamlit-based debugger interface. Since Streamlit is a Python framework, my first step was to convert the existing JSON to Text Converter—originally written in JavaScript—into Python. This involved translating the logic and formatting rules to ensure the output remained consistent.
   - This conversion is crucial because it enables seamless integration of the converter into the Streamlit app, which will serve as the initial interface for our debugger. By moving the code to Python, I ensured compatibility with the app’s backend, allowing further development like live user queries, debugging and feedback—all in one cohesive Python environment.

3. **Streamlit Debugger App UI Creation**  
   - As a beginner to Streamlit, I started building the UI for the debugger app. I successfully created a basic Streamlit interface that allows users to input text queries. To handle these queries, I integrated the free Google Gemini API, enabling the app to return LLM-generated responses. Currently, the app supports simple user input and displays the corresponding Gemini response.
   - This is an important first step in building an interactive AI-powered debugger. Even though it’s still in an early stage, this app lays the foundation for integrating core features like JSON-to-text conversion, error analysis, and user feedback. The goal is to evolve this into a fully functional debugging tool that enhances the Music Blocks experience.

---

## Challenges & How I Overcame Them

- **Challenge:** Learning the Streamlit framework and creating a basic UI app as a complete beginner.  
  **Solution:** To overcome this, I referred to the official Streamlit documentation, followed beginner tutorials, and experimented with small components to understand the structure. This hands-on approach helped me build a working basic UI that takes user input and integrates it with the Gemini API.

- **Challenge:** Converting all methods and functions from JavaScript to Python was time-consuming and introduced several errors.  
  **Solution:** I carefully mapped the logic from JavaScript to Python, using Pythonic alternatives where necessary. I used print-based debugging and Python’s error messages to identify issues. Although some minor bugs remain, I have a clear plan to fix them in the coming days and will be testing each function thoroughly for accurate output.

---

## Key Learnings

- I gained an understanding of Streamlit’s basic architecture and learned how to build and deploy a Streamlit app
- I explored advanced Python techniques to effectively translate the JavaScript code into Python for smoother integration.

---

## Next Week’s Roadmap

- My goal for the next week is to fully convert the JSON to Text Converter, originally written in JavaScript, into Python. 
- I also plan to integrate this Python version directly into the Streamlit debugger app to enable seamless JSON conversion within the app interface. 
- Additionally, I aim to make the basic functionality of the app usable so that users can begin interacting with it and provide initial feedback. This feedback will help identify usability issues early and guide further improvements in the UI and debugging workflow.

---

## Resources & References

- **Repository:** [AI-powered-Debugger-for-MB(JSON convertor)](https://github.com/omsuneri/AI-powered-Debugger-for-MB/blob/main/Convertor/converting-json-txt.js)  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Ji=Object.freeze(Object.defineProperty({__proto__:null,default:Re},Symbol.toStringTag,{value:"Module"})),Oe=`---
title: "SSoC ’25 Week 01 Update by Muhammad Haroon"
excerpt: "Kick off Generative AI Instrument Sample Generation for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-ssoc-25-MuhammadHaroon-week01"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week01,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## Progress

I am excited to announce that I have been selected for Sugar Summer of Code 2025. This summer I would be working on creating a Generative AI tool that would create endless sound samples that can be then used in Music Blocks.

This week I kicked off my project, I had a meeting with my mentors, and discussed my approach with them. For the next week, it was decided to create a basic frontend using streamlit and for the backend will be using [MusicGen](https://audiocraft.metademolab.com/musicgen.html).

I will begin by testing some prompts and generating some samples from it, to test whether they can be used in Music Blocks or further refinement of the pipeline is needed.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Xi=Object.freeze(Object.defineProperty({__proto__:null,default:Oe},Symbol.toStringTag,{value:"Module"})),ze=`---

title: "Community Bonding & Week 1 Update by Karan Palan"
excerpt: "From compiler theory deep-dives to brick-rendering math—mentoring the 2025 Music Blocks Masonry & Engine cohorts."
category: "DEVELOPER NEWS"
date: "2025-06-09"
slug: "2025-06-09-KaranPalan-week01"
author: "Karan Palan"
description: "GSoC 2024 mentee, now volunteering and peer-mentoring on Music Blocks 4"
tags: "gsoc25,sugarlabs,communitybonding,week1,karanpalan"
---

<!-- markdownlint-disable -->

# Community Bonding + Week 1 Progress Report

**by Karan Palan**

**Projects:** Music Blocks 4 **Masonry** & **Program Engine**  
**Role:** Volunteer & Peer-Mentor (GSoC 2024 alumnus)  
**Mentor:** [Anindya Kundu](https://github.com/meganindya/)  
**Mentees:** [Justin Charles](https://github.com/justin212407), [Saumya Shahi](https://github.com/saumyashahi) (Masonry) • [Safwan Sayeed](https://github.com/sa-fw-an) (Engine)  
**Reporting Period:** 2025-05-20 → 2025-06-08  

---

Community bonding this year felt less like “hello world” and more like an accelerated CS grad course. Anindya flipped the script: before writing a single line of code we dissected *how* languages work, explored compiler pipelines, and compared micro-compilers.

### Mapping Bricks to LLVM IR

Armed with that theory, each of us reverse-mapped **Music Blocks bricks → LLVM intermediate representation** to ground our designs in real compiler constructs. My early spreadsheet of brick vs. IR became a north star for future optimizations.

### Defining Music Blocks Grammar

After digesting JavaScript’s formal grammar, we drafted a Music Blocks-specific one that is lean, kid-friendly, but still transpilable to JS. This fed directly into the Engine tech spec.

### Meeting with Andres

Anindya set up a fireside chat with his former manager **Andrés**, giving us a crash-course in real-world engineering. Andrés drilled home that *“quick fixes live for 18 months,”* scope must be ruthlessly trimmed, and the true mark of a pro is writing code a stranger can maintain five years later, all while treating teammates (coders or not) with respect.

### Two Tracks, One Vision

We split weekly calls:

| Track   | Focus                           | Key Doc                                                                                                    |
| ------- | ------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| Masonry | SVG brick generation & formulae | [Brick Sides & Formulae](https://docs.google.com/document/d/1AUlA2leDJIfV3ZXceLhCaITftExq6c5BcUBMZOtZBvE/) |
| Engine  | AST, runtime, class hierarchy   | [Engine Tech Spec + AST](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/) |

---

## Highlights So Far

1. **Project-wide Knowledge Base**
   *Spreadsheet* of compiler concepts & Music Blocks parallels—anchors every design choice.
   Link ➜ [Mentor Context Sheet](https://docs.google.com/spreadsheets/d/1LFuIlzRiMlEfeLr21x8_SYnVIQ5baVQv8tz2GWN9PfU/)

2. **Brick Taxonomy Drafted**
   Classified each brick against LLVM constructs for easy reasoning about side-effects and type constraints.
   Link ➜ [Brick ↔️ LLVM Mapping](https://docs.google.com/document/d/1BswWHadyy4yC3_3vK6KHZnMn0u6jbbYiQ6JQWiqRMLw/)

3. **Brick Geometry Formulae**
   With Justin & Saumya, derived parametric equations for every brick edge—vital for responsive SVG.
   Link ➜ [Brick Formulae Doc](https://docs.google.com/document/d/1AUlA2leDJIfV3ZXceLhCaITftExq6c5BcUBMZOtZBvE/)

4. **Engine Class Skeleton**
   Safwan and I scaffolded core *abstract* and initial *concrete* classes in TypeScript.
   Code ➜ [Replit Workspace](https://replit.com/@karanpalan007/engine-abstract-classes?v=1)



## Key Learnings

* **Teach, then build:** A solid mental model of compilers made later coding decisions friction-less.
* **Visual specs pay off:** Equation-driven SVG means less pixel-pushing, more deterministic rendering.
* **Peer-mentoring ≠ lecturing:** Guiding Justin, Saumya, and Safwan taught me to ask leading questions instead of prescribing answers.

---

## Next Week’s Roadmap

* **Masonry:** Finish implementing '_generateLeft()' so *all* brick types respect left-side notches.
* **Engine:** Flesh out 'Expression' subclasses and prototype a minimal AST → JS transpile step.
* **Docs & CI:** Auto-publish rendered SVG examples in PR previews to catch geometry regressions early.

---

## Resources & References

* Mentor Notes → [Spreadsheet](https://docs.google.com/spreadsheets/d/1LFuIlzRiMlEfeLr21x8_SYnVIQ5baVQv8tz2GWN9PfU/)
* Brick ↔️ LLVM Mapping → [Google Doc](https://docs.google.com/document/d/1BswWHadyy4yC3_3vK6KHZnMn0u6jbbYiQ6JQWiqRMLw/)
* Engine Tech Spec → [Google Doc](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/)
* Brick Geometry → [Formulae Doc](https://docs.google.com/document/d/1AUlA2leDJIfV3ZXceLhCaITftExq6c5BcUBMZOtZBvE/)
* Code Skeleton → [Replit](https://replit.com/@karanpalan007/engine-abstract-classes?v=1)

---

## Acknowledgments

Huge thanks to **Anindya** for the deep-dive lectures and mentoring, and to **Justin, Saumya, and Safwan** for matching my energy sprint-for-sprint. SugarLabs’ culture of mentoring forward keeps the snowball rolling.

---

## Connect with Me

* GitHub: [@Karan-Palan](https://github.com/Karan-Palan/)
* Email: [karanpalan007@gmail.com](mailto:karanpalan007@gmail.com)
* LinkedIn: [karan-palan-476472289/](https://www.linkedin.com/in/karan-palan-476472289/)
* Twitter: [Karan_Palan7](https://x.com/Karan_Palan7)

---
`,$i=Object.freeze(Object.defineProperty({__proto__:null,default:ze},Symbol.toStringTag,{value:"Module"})),Fe=`---
title: "GSoC ’25 Week 04 Update by Aditya Kumar Singh"
excerpt: "localization for 3D Human Activity in Sugarizer, palette switcher, and skeletal improvements."
category: "DEVELOPER NEWS"
date: "2025-06-10"
slug: "2025-06-10-gsoc-25-AdityaKrSingh26-week04"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
description: "GSoC'25 Contributor at SugarLabs (Sugarizer Human Activity Pack)"
tags: "gsoc25,sugarlabs,week04,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-05-30 - 2025-06-05   

---

## Goals for This Week

- **Goal 1:** Add a model selection palette UI to toggle between models.  
- **Goal 2:** Integrate the Human-body model into the paint activity and set the Human-body human model as the default view.  
- **Goal 3:** Refactor and improve naming conventions for bones in the skeleton model.  
- **Goal 4:** Localize the Human Body Activity using i18next.js, supporting English and French.  


---

## This Week’s Achievements

1. **Model Palette Implementation**  
    - Developed a new model selection palette in the UI allowing users to switch between:
        - Human body
        - Skeleton
        - Organs 
    - Set the Human body as the default model loaded on activity start.
    - Palette updates the 3D scene dynamically without requiring a full reload.
           ![screenshot-description](https://i.ibb.co/SDSYFJf7/image.webp)   


2. **Human-Body Model Paint Integration**  
    - Integrated the Human body model with the interactive paint activity.  
    - Ensured hierarchical structure for smooth interactivity and logical mesh grouping  
        ![screenshot-description](https://i.ibb.co/4wqNymfG/image.webp)   


3. **Improved Bone Naming in Skeleton Model**  
    - Refactored the skeletal model for accurate and educational naming:
        - Replaced generic labels like “Lower Leg” with specific names like **Tibia** and **Fibula**.
        - Split forearm into **Radius** and **Ulna**, adjusting geometry and mesh positions.



4. **Implemented i18next.js to support internationalization.**  
    - Implemented **i18next.js** to support internationalization.
    - Completed full translation of Human Body Activity in **English** and **French**.  
    - Translation files follow standard .json structure for easy future expansion.  
    - Example image for French:
        ![screenshot-description](https://i.ibb.co/99ggYBDj/image.webp)   


---

## Challenges & How I Overcame Them

- **Challenge:** Naming skeleton bones accurately without anatomical overlap.  
  **Solution:** Cross-referenced medical diagrams and validated model mesh mapping manually in Blender.

---

## Key Learnings

- Deepened understanding of scene management in Three.js and optimized mesh rendering for performance.  
- Gained experience in internationalization using i18next.js  
- Developed more precise anatomical terminology awareness and importance of educational clarity.

---

## Next Week’s Roadmap

- Write Weekly Blog Post summarizing progress, screenshots, and key learnings.   
- Fix Organs model. Distance between eyes and mouth seems to be more than required, reduce that and see if there is some alignment issue.   
- Integrate the full human body model into the paint activity to allow direct interaction and labeling across complete anatomy.   
- Merge Paint and Learn mode to show a popup at bottom of screen when user click a part

---


## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [@AdityaKrSingh26](https://github.com/AdityaKrSingh26)
- Gmail: [adityakrsingh2604@gmail.com](mailto:adityakrsingh2604@gmail.com)
- LinkedIn: [Aditya Kumar Singh](https://www.linkedin.com/in/adityakrsingh26/)
- Twitter: [@AdityaKrSingh26](https://x.com/AdityaKrSingh26)

---
`,Yi=Object.freeze(Object.defineProperty({__proto__:null,default:Fe},Symbol.toStringTag,{value:"Module"})),Ue=`---
title: "GSoC '25 Week 2 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates"
category: "DEVELOPER NEWS"
date: "2025-06-14"
slug: "2025-06-14-gsoc-25-Elwin-Li-week02"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week2,javaScript editor"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 2 Progress Report by Elwin Li

**Project:** [Advanced JavaScript Editor with MusicBlocks Interactions](https://github.com/sugarlabs/musicblocks/tree/config_driven_conversion/elwin)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-06-07 - 2025-06-14

---

## Goals for This Week

- **Goal:** Complete and deploy code to blocks functionality with full documentation and begin work on debugger.

---

## This Week’s Achievements

**Added All Blocks for Code to Blocks Support**  

I added all blocks that are supported for block to code conversion to be supported for code to blocks conversion. I also added all necessary unit tests, and very [detailed documentation](https://github.com/sugarlabs/musicblocks/blob/master/js/js-export/CONVERSION_GUIDE.md) on how to add new blocks for support.

**Optimized Files**

I added a script to minify the JSON config so that musicblocks doesn't need to load the entire large file. I also merged many blocks that have the same path in the AST so that the config looks cleaner, and adding new blocks of the same path is even easier.

**Deployed Project**

The code to blocks project has been complete and deployed, as seen in this [merged PR](https://github.com/sugarlabs/musicblocks/pull/4707). To test, simply write your musicblocks program in Javascript in the editor and press the convert button. Note that the only blocks supported are those supported by block to code conversion, so it won't work on every single block possible, but will work on most of them.

<a href="https://ibb.co/qLNNyH8W"><img src="https://i.ibb.co/V0ggjFGQ/Screenshot-2025-06-14-at-2-25-05-PM.webp" alt="Conversion Example"></a>

---

## Challenges & How I Overcame Them

- **Challenge:** Minimizing file size of config file

  **Solution:** Merging configs, and using minified JSON for loading.

- **Challenge:** Never-seen-before git errors when trying to push commit

  **Solution:** Image size as part of the documentation was too large, had to compress it.

---

## Key Learnings

- Deepened understanding of git.
- Improved skills in **debugging**, **code design**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Begin debugger project
- Being able to set breakpoints in the code
- Add ability to trigger status block in the code as the debugger

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Qi=Object.freeze(Object.defineProperty({__proto__:null,default:Ue},Symbol.toStringTag,{value:"Module"})),Ne=`---
title: "GSoC ’25 Week 02 Update by Mebin J Thattil"
excerpt: "Fine-Tuning, Deploying, Testing & Evaluations"
category: "DEVELOPER NEWS"
date: "2025-06-14"
slug: "2025-06-14-gsoc-25-mebinthattil-week2"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week02,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-08 - 2025-06-14  

---

## Goals for This Week

- **Goal 1:** Setup AWS for Fine-Tuning.
- **Goal 2:** Fine-Tune a small model on a small dataset.
- **Goal 3:** Deploy the model on AWS and create an API endpoint.
- **Goal 4:** Test the endpoint using a python script.
- **Goal 5:** Evaluate the model responses and think about next steps.

---

## This Week’s Achievements

1. **Setup AWS for Fine-Tuning**  
   - Setup AWS SageMaker.
   - Provisioned GPUs on AWS SageMaker to fine-tune Llama3-1B foundation model.
    
2. **Dataset & Cleaning**
   - Used an open dataset. It was a dataset about conversations between a student and a teacher.
   - The dataset was cleaned and converted into a format that Llama needed for fine-tuning.
   - Wrote a small script to convert the dataset into a format that Llama can understand.
   - The dataset along with the script is available [here](https://github.com/mebinthattil/Education-Dialogue-Dataset).

3. **Fine-tuning**
   - Fine-tuned the model on a small set of the dataset, just to see how it performs and to get familar with AWS SageMaker.
   - The training job ran on a \`ml.g5.2xlarge\` instance.
   - The hyperparameters that were set so as to reduce memory footprint and mainly to test things. I'll list the hyperparameters, hoping this would serve as documentation for future fine-tuning.
   
   **Hyperparameters**:

    | Name                             | Value                                              |
    |----------------------------------|----------------------------------------------------|
    | add_input_output_demarcation_key | True                                               |
    | chat_dataset                     | True                                               |
    | chat_template                    | Llama3.1                                           |
    | enable_fsdp                      | False                                              |
    | epoch                            | 5                                                  |
    | instruction_tuned                | False                                              |
    | int8_quantization                | True                                               |
    | learning_rate                    | 0.0001                                             |
    | lora_alpha                       | 8                                                  |
    | lora_dropout                     | 0.08                                               |
    | lora_r                           | 2                                                  |
    | max_input_length                 | -1                                                 |
    | max_train_samples                | -1                                                 |
    | max_val_samples                  | -1                                                 |
    | per_device_eval_batch_size       | 1                                                  |
    | per_device_train_batch_size      | 4                                                  |
    | preprocessing_num_workers        | None                                               |
    | sagemaker_container_log_level    | 20                                                 |
    | sagemaker_job_name               | jumpstart-dft-meta-textgeneration-l-20250607-200133|
    | sagemaker_program                | transfer_learning.py                               |
    | sagemaker_region                 | ap-south-1                                         |
    | sagemaker_submit_directory       | /opt/ml/input/data/code/sourcedir.tar.gz           |
    | seed                             | 10                                                 |
    | target_modules                   | q_proj,v_proj                                      |
    | train_data_split_seed            | 0                                                  |
    | validation_split_ratio           | 0.2                                                |
     
4. **Saving the model**
    - The safetensors and other model files were saved in an AWS S3 bucket. The URI of the bucket is: \`\`\` s3://sagemaker-ap-south-1-021891580293/jumpstart-run2/output/model/ \`\`\`

5. **Deploying the model**
    - The model was deployed on AWS SageMaker and an API endpoint was created.

6. **Testing the model**
    - A python script was written to test the model using the API endpoint.
  
7. **Evaluation**
    - The model responses were tested using the same questions used in my [benchmark](https://llm-benchmarking-sugar.streamlit.app/) done before.
  

---

## Unexpected Model Output

- After fine-tuning the model, I noticed that the model was producing some unexpected output. I expected the model to behave like general chatbot but in a more friendly and teacher-like manner. While the model's responses did sound like a teacher, the model would often try to create an entire chain of conversations generating the next response from a students perspective and then proceeed to answer itself.
- This behaviour was becaues of the way the dataset was strucutred. The dataset was enssentially a list of back and forth conversations between a student and a teacher. So it makes sense that the model would try to create a chain of conversations. But this is not what we need from the model. 
- The next step is to change the strucutre of the dataset to make it just answer questions, but also to make it more conversational and understand the nuaces of a chain of conversations.
- The temporary fix was the add a stop statement while generating responses and also tweaking the system prompt. But again, this is not the right way to go about it. The right was is to change the dataset structure.

---

## Sample model output with stop condition

![sample model output](https://mebin.shop/Mebin-test-FT-model-tesponses.webp)

---

## Key Learnings

- Structure of dataset needs to be changed, in order to make it more conversational and understand the nuances of a chain of conversations.
  
---

## Next Week’s Roadmap

- Re-structure the dataset
- Re-Train and Fine-Tunethe model on the new dataset
- Deploy, create endpoint and test the model on the new dataset
- Evaluate the model on the new dataset and add to benchmarks

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,Zi=Object.freeze(Object.defineProperty({__proto__:null,default:Ne},Symbol.toStringTag,{value:"Module"})),He=`---
title: "GSoC '25 Week 2 Update by Shubham Singh"
excerpt: "Adding the entire prototyped interface ON TO the music blocks"
category: "DEVELOPER NEWS"
date: "2025-06-14"
slug: "2025-06-14-gsoc-25-firepheonix-week02"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week02
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 2 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-08 – 2025-06-15  

---

## Goals for This Week

- Basic UI for Image Upload/Real-time Video upload and adjustment.
- Integrating the developed UIs onto the widget blocks within Music Blocks.
- Researching existing audio integration patterns in the phrase maker and note blocks.

---

## This Week's Achievements

1. **Interface Implementation for Lego Notations**  
   - Successfully integrated the LegoBricks block directly onto the Music Blocks canvas.
   - Modified 6 different files to implement an entirely new block type.
   - Music Blocks already has sophisticated color detection for internal pixels, but couldn't detect colors from external sources like uploaded images or webcam feeds — this limitation was addressed.
   - The codebase proved beautifully encapsulated and thoroughly documented, making the learning curve smoother.
        ![Interface Implementation](https://i.ibb.co/d0X9zXjF/1st.webp)

2. **Real-time Video Integration**  
   - Implemented real-time video functionality through webcam integration.
   - Added full editing capabilities and canvas manipulation for live video feeds.
   - Interface provides seamless interaction between video feed and detection algorithms.
        ![Real-time Video Feature](https://i.ibb.co/cXL4Hpxq/2nd.webp)

3. **Export Mechanism Research**  
   - Conducted extensive research into existing export mechanisms within Music Blocks.
   - Deep-dived into Phrase Maker widget documentation and codebase.
   - Studied how different blocks export output as both MIDI files and action blocks.
        ![Export Research](https://i.ibb.co/bVD8Z54/image.webp)

---

## Challenges & How I Overcame Them

- **Challenge:** UI integration complexity — getting the UI integrated into Music Blocks proved more challenging than expected due to intricate dependencies and specific implementation patterns required by the block system.
**Solution:** Leveraged multiple resources including mentor consultations, existing documentation on "how to add new blocks," and analyzed previous implementations for reference patterns.

- **Challenge:** User workflow design — determining optimal user workflow for the Lego Bricks block required careful consideration of user interaction patterns and integration with existing functionality.
**Solution:** Scheduled focused discussion with mentor during regular meeting to analyze phrase maker export functionality, gaining crucial insights into user experience patterns and technical approaches.

---

## Key Learnings

- Gained comprehensive understanding of **output mechanisms** and how different blocks handle their output generation and processing.
- Deepened appreciation for **code architecture** including inheritance patterns, code modularity, and custom return types within the Music Blocks ecosystem.
- Improved skills in **development workflow** including exports, imports, code reusability, documentation practices, and collaborative development workflows.

---

## Next Week's Roadmap

- Implement comprehensive mapping of musical notes to Lego brick colors.
- Complete the core implementation during weeks 2 and 3, ensuring robust functionality and thorough testing.
- Focus on algorithmic challenges for note-to-color mapping system.

---

## Resources & References

- **Project Issue:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)
- **Music Blocks Repository:** [sugarlabs/musicblocks](https://github.com/sugarlabs/musicblocks)
- **Documentation:** Music Blocks Developer Guide

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Special thanks to Walter for his advice during our biweekly meeting on how the phrase maker exports output as ACTION blocks.

---`,es=Object.freeze(Object.defineProperty({__proto__:null,default:He},Symbol.toStringTag,{value:"Module"})),qe=`---
title: "GSoC '25 Week 2 Update by Krish Pandya"
excerpt: "From initial GTK4 porting to building a solid foundation with separate C and Python libraries"
category: "DEVELOPER NEWS"
date: "2025-06-14"
slug: "2025-06-14-gsoc-25-mostlyk-week02"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week02,mostlyk"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 2: Strategic Pivot and Foundation Building

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)       
**Reporting Period:** June 06, 2025 till June 14, 2025  

---


## The Meeting that changed everything

On Friday(06-06-2025), we had a pivotal video call with Juan Pablo Ugarte and Ibiam Chihurumnaya that completely reshaped the porting approach.
What started as a discussion about my initial porting work evolved into something much more strategic and forward-thinking.

> While the time of writing this, another meet that happened on 13-06-2025 , we discussed about the API versioning and updating with pytest, ideas about testing, more porting golden advice, more about this on next week's blog.

### The New Architecture Vision

The mentors introduced a brilliant modular approach that addresses the core challenges of the GTK4 migration:

**1. Two Separate Libraries Strategy**
- C Library 'sugar-ext': Core objects and reusable GTK widgets
- Python Wrapper Library: Python widgets and wrapper functions

![GTK4 Planning](assets/Images/gtk4drawing.webp)

> Subject to change

**2. Independent Development & Testing**
Each library will be developed in its own repository with simple Python example scripts. This approach offers several advantages:
- Clear separation of concerns between C and Python components
- Easier debugging and testing
- Better CI/CD pipeline management
- Modular, incremental development that reduces complexity

**3. Meson Build System Foundation**
We'll use Meson's shared library template from GNOME Builder as our base. This gives us:
- Modern build system designed for GTK4
- Better dependency management
- Cleaner project structure

### Why This Approach Made Sense

The more I thought about this strategy, the more I realized how elegant it is. Instead of trying to port everything at once (my initial approach, by changing the orignal toolkit and it's systems), we're building a solid foundation that can support the entire Sugar ecosystem. This modular approach means:

- Maintainability — Each component can be updated independently
- Testing — Smaller, focused libraries are easier to test thoroughly
- Future-proofing — The architecture can adapt as GTK continues to evolve
- Support — Due to the new build system, we would have more support and we can also remove things we find deprecated.
---

## Implementation

Following the meeting  – I immediately got to work implementing. 
The result that came out was [Pull Request #1](https://github.com/sugarlabs/sugar-ext/pull/1) in the new 'sugar-ext' repository.

### What I Built

**Project Structure:**
- Complete Meson build system setup
- GObject Introspection integration for seamless Python bindings
- Initial API implementation (starting with XO Colors for testing)
- Comprehensive documentation and development tools

**Key Technical Decisions:**
\`\`\`c
// API versioning strategy
api_version = '1.0'     // Maintaining compatibility with existing SugarExt
package_version = '0.122.0'  // Following Sugar's versioning convention

// GIR configuration for Python bindings
symbol_prefix: 'sugarext'
identifier_prefix: 'SugarExt'
\`\`\`

> This was discussed later in the meet and we decided to keep the packages version 2.0 or 4.0 because GTK4. Will be confirmed by the next blog,

- Included comprehensive build and test scripts

### Testing Framework

The project includes a robust testing setup:
\`\`\`bash
meson test -C builddir
\`\`\`

This runs the test suite, validating that the C library builds correctly and the test written should pass.

---

### To my Fellow Devs

- I have few files that can help you get your setup right. If you like clangd and use it as your LSP. Here's the .clangd configuration I used for sugar-ext.

\`\`\`yaml
CompileDatabase: ./builddir

If:
  PathMatch: .*\\.(c|h)$
CompileFlags:
  Add: [
    -I./src,
    -I./builddir,
    -I/usr/include/gtk-4.0,
    -I/usr/include/glib-2.0,
    -I/usr/lib/glib-2.0/include,
    -I/usr/include/pango-1.0,
    -I/usr/include/harfbuzz,
    -I/usr/include/fribidi,
    -I/usr/include/gdk-pixbuf-2.0,
    -I/usr/include/cairo,
    -I/usr/include/freetype2,
    -I/usr/include/libpng16,
    -I/usr/include/pixman-1,
    -I/usr/include/graphene-1.0,
    -I/usr/lib/graphene-1.0/include,
    -I/usr/include/libmount,
    -I/usr/include/blkid,
    -I/usr/include/sysprof-6,
    -I/usr/local/include/sugar-ext,
    -D_FILE_OFFSET_BITS=64
  ]

Diagnostics:
  ClangTidy:
    Add: [
      readability-*,
      bugprone-*,
      performance-*,
      misc-*
    ]
    Remove: [
      modernize-*,
      readability-isolate-declaration,
      readability-function-cognitive-complexity
    ]
  UnusedIncludes: Strict

InlayHints:
  Enabled: Yes
  ParameterNames: Yes
  DeducedTypes: Yes

Hover:
  ShowAKA: Yes

Index:
  Background: Build

Completion:
  AllScopes: Yes

Format:
  Style: GNU
\`\`\`

- And if you are using VSCode and the C/C++ extension, here's the c_cpp_properties.json.
\`\`\`json
{
    "configurations": [
        {
            "name": "Linux",
            "includePath": [
                "\${workspaceFolder}/**",
                "\${workspaceFolder}/builddir",
                "/usr/include/gtk-4.0",
                "/usr/include/pango-1.0",
                "/usr/include/fribidi",
                "/usr/include/harfbuzz",
                "/usr/include/gdk-pixbuf-2.0",
                "/usr/include/cairo",
                "/usr/include/freetype2",
                "/usr/include/libpng16",
                "/usr/include/pixman-1",
                "/usr/include/graphene-1.0",
                "/usr/lib/graphene-1.0/include",
                "/usr/include/glib-2.0",
                "/usr/lib/glib-2.0/include",
                "/usr/include/libmount",
                "/usr/include/blkid",
                "/usr/include/sysprof-6"
            ],
            "defines": [
                "_FILE_OFFSET_BITS=64"
            ],
            "cStandard": "gnu11",
            "cppStandard": "c++17",
            "intelliSenseMode": "linux-gcc-x64",
            "compilerPath": "/usr/bin/gcc",
            "compileCommands": "\${workspaceFolder}/builddir/compile_commands.json"
        }
    ],
    "version": 4
}
\`\`\`

## Lessons from the PR Review Process

- To be added on week 3 as it gets merged!


# Migration List 

- Here Use as-is means if we decide to keep it we use it or it's newer version or alternatives. Port meaning we would have to change stuff, and whenever I have mentioned GTK4 we will use the new API directly rather than implementing from scratch. 
##  C Objects Migration List

| Object | Dependencies | Purpose | Port/Use GTK4 |
|--------|--------------|---------|---------------|
| sugar-grid.c/h | GLib + GDK | Grid-based layout calculations | Port |
| sugar-fatattr.c/h | Pure C, sys headers | FAT filesystem attribute utilities | Use as-is |
| acme-volume.c/h | GLib, ALSA | Audio volume control | Use as-is |
| acme-volume-alsa.c/h | GLib, ALSA | ALSA backend for volume control | Use as-is |
| sugar-wm.c/h | GLib, GDK, X11 | Window manager interaction utilities | Port |
| sugar-clipboard.c/h | GLib, GTK3 | Clipboard helper functions | Port (GdkClipboard) |
| eggdesktopfile.c/h | GLib, GTK3, GDK | Desktop file parsing and launching | Port |
| sugar-key-grabber.c/h | GLib, GDK, X11 | Global key binding system | Port (GTK4 shortcuts) |
| sugar-cursor-tracker.c/h | GLib, GDK, X11, XInput2 | Mouse cursor visibility tracking | Port (GTK4 events) |
| sugar-gesture-grabber.c/h | GLib, GDK, X11, XInput2 | Global gesture capture system | Port (GTK4 gestures) |
| sugar-event-controller.c/h | GLib, GTK4 | Base event controller | Port |
| sugar-long-press-controller.c/h | GLib, GTK4 | Long press gesture detection | Port |
| sugar-swipe-controller.c/h | GLib, GTK4 | Swipe gesture detection | Port |
| sugar-touch-controller.c/h | GLib, GTK4 | Touch event handling | Port |
| sugar-zoom-controller.c | GLib, GTK4 | Zoom gesture detection | Port |
| sugar-rotate-controller.c | GLib, GTK4 | Rotation gesture detection | Port |
| eggaccelerators.c/h | GLib, GTK3, GDK, X11 | Keyboard accelerator handling | Port |
| eggsmclient.c/h | GLib | Session management client | Use as-is |
| eggsmclient-xsmp.c/h | GLib, X11, ICE, SM | XSMP session management backend | Use as-is |
| gsm-app.c/h | GLib | Session management application handling | Use as-is |
| gsm-client.c/h | GLib | Session management client base | Use as-is |
| gsm-client-xsmp.c/h | GLib, X11, ICE, SM | XSMP client implementation | Use as-is |
| gsm-session.c/h | GLib | Session management core | Use as-is |
| gsm-xsmp.c/h | GLib, X11, ICE, SM | XSMP protocol implementation | Use as-is |



## Next Steps: Building the Foundation

### Immediate Priorities (Week 3)

1. Finalize C Library Scaffold
- Address remaining PR feedback
- Implement proper copyright and licensing
- Add core Sugar widgets starting with \`sugar-grid\`
- Sugar-Grid was added on 14-June-2025 while I am writing this.

2. Begin Python Wrapper Development
- Set up the Python-side repository
- Create example scripts demonstrating usage



---


## Resources & References

- Project Page – [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- New C Library - [sugar-ext repository](https://github.com/sugarlabs/sugar-ext)
- Active PR - [Establish C library base template with Meson for GTK4](https://github.com/sugarlabs/sugar-ext/pull/1)
- Sugar Toolkit Repository(original) – [sugar-toolkit-gtk3](https://github.com/sugarlabs/sugar-toolkit-gtk3)
- GTK4 Migration Guide – [docs.gtk.org/gtk4/migrating-3to4.html](https://docs.gtk.org/gtk4/migrating-3to4.html)


---

## Acknowledgments

Huge thanks to Juan Pablo Ugarte first of all for being the official mentor and Ibiam Chihurumnaya for the guidance that that changed this project's direction. Their architectural vision has transformed porting into a comprehensive modernization effort. Thanks also to Walter Bender for mentorship.

---

THe architecture is building itself, and I'm excited to lay down the foundations!

`,ns=Object.freeze(Object.defineProperty({__proto__:null,default:qe},Symbol.toStringTag,{value:"Module"})),Ke=`---
title: "GSoC '25 Week 02 Update by Saumya Shahi"
excerpt: "This week focused on documenting the brick tree structure, refining SVG path generation, and learning testing tools like Storybook."
category: "DEVELOPER NEWS"
date: "2025-06-14"
slug: "2025-06-14-gsoc-25-saumya-shahi-week02"
author: "@/constants/MarkdownFiles/authors/saumya-shahi.md"
tags: "gsoc25,sugarlabs,week02,saumya-shahi"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Saumya Shahi

**Project:** [Masonry Module - Music Blocks v4](https://github.com/sugarlabs/musicblocks-v4)  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-08 – 2025-06-14  

---

## Goals for This Week

- Refine and complete configuration-driven rendering logic.
- Test rendering of multiple brick types and validate correctness using sample input.
- Document how brick configurations and connections should be modeled.
- Start building foundational elements for brick tree rendering.

---

## This Week's Achievements

1. **Dynamic SVG Brick Rendering**  
   - Finalized implementation for rendering SVG paths dynamically based on type-specific configurations.  
   - Different bricks (e.g., nested bricks, simple bricks, expression bricks) now render accurately according to their label sizes, scale, and other config props.  
   - Output adjusts responsively with different numbers of arguments, notches, and labels.

2. **Rendered Output Validation & Screenshots**  
   - Verified each visual brick against expected path geometry.  
   - Screenshots below show rendered bricks:
        ![Simple Brick](/assets/Images/simple-bricks.webp)
        ![Brick with Arguments](/assets/Images/expression-bricks.webp)
        ![Nested Brick](/assets/Images/nested-bricks.webp)

2. **Bug Fix: Left SVG Path Issue**

   * Fixed a critical error in path rendering for bricks — the left edge generation wasn’t calculating offsets correctly.
   * Cleaned up related path logic to improve readability and scalability for future nested structures.

3. **Storybook & Testing Familiarization**

   * Understood how Storybook is used for visual component testing.
   * Learnt how to set up unit tests and component test files.
   * Setup groundwork for adding future test cases.

---

## Challenges & How I Overcame Them

- **Challenge:** Mapping the brick tree vs AST was initially confusing.
**Solution:** Spent focused time breaking down what each structure is supposed to represent and clarified use cases.

- **Challenge:** SVG left path errors were hard to trace visually.
**Solution:** Used visual diffing and debugger to narrow down bounding box and stroke-width miscalculations.

---

## Key Learnings

- Improved understanding of **SVG rendering logic** and path construction.
- Got hands-on exposure to **Storybook**, and how visual tests can improve modular development.
- Understood the **difference between data representations** for view (brick tree) and logic (AST).


---

## Next Week's Roadmap

- Start implementing **multi-brick layout rendering**: bricks with children rendered as a tree in the workspace.
- Introduce bounding box calculation utilities for each rendered brick.
- Plan initial strategy for brick connection detection and snapping logic.

---

## Resources & References

- **Brick Rendering:** [Google Doc](https://docs.google.com/document/d/1UJXh3734S138BoTsGulzeTlZXstyvWd6syJK2eclMKI/edit?tab=t.dxoea5urpxyl#heading=h.wa29sjgrasfn)
- **SVG Path Reference:** [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/Paths)
- **Playground for Manual SVG Paths:** [SVG Path Editor](https://yqnn.github.io/svg-path-editor/)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for support and insightful feedback throughout the week.

---
`,ts=Object.freeze(Object.defineProperty({__proto__:null,default:Ke},Symbol.toStringTag,{value:"Module"})),Ve=`---
title: "DMP ’25 Week 2 Update by Aman Naik"
excerpt: "This week's focus was on creating a story builder feature in such a way that it engages creativity of the children."
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "2025-06-15-dmp-25-AmanNaik-week02"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week01,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 2 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-06-09 – 2025-06-15  

---

## Goals for This Week

- **Goal 1:** Design a story builder feature to help children write stories  
- **Goal 2:** Explore ways to integrate AI into the feature  
- **Goal 3:** Document the architecture and workflow  
- **Goal 4:** Focus on developing creative features that support learning  

---

## This Week’s Achievements

1. **Explored Engaging Approaches to Story Writing**  
   - Through guidance from mentors in biweekly and one-on-one meetings, I explored effective ways to encourage children to write creatively. This included analyzing architecture ideas that support active participation in storytelling.

2. **Finalized the Architecture for the Story Builder Feature**  
   - After research and discussions, I finalized an architecture that aids students in story writing while ensuring that the AI guides rather than writes the story for them.

   ![Question-Answer workflow](assets/Images/aman_naik_week2_img1.webp)

   ![Create a framework using the context gained from the Q&A](assets/Images/aman_naik_week2_img2.webp)

3. **Created Documentation for Future Reference**  
   - I’ve documented the feature's flow and design so it can be referred to later. [Link](https://docs.google.com/document/d/14V_FreatUU-gGgiHRdlvNDUXUgmBTWIeFyDaap38RnA/edit?usp=sharing)

---

## Challenges & How I Overcame Them

- **Challenge:** The grammar correction feature was too strict for learning environments.  
  **Solution:** Since the goal is to foster creativity, I decided to shift focus from strict grammar correction to more engaging, story-focused features. Grammar support can be introduced later as an enhancement.

- **Challenge:** Stories don’t always follow a fixed pattern (e.g., not every story has a villain).  
  **Solution:** I designed the AI to categorize responses into typical story elements automatically. This adaptive framework allows story parts like “villain” or “sidekick” to remain optional and dynamically appear based on user input.

- **Challenge:** Prevent the AI from writing the story directly.  
  **Solution:** Due to the resource constraints of Sugar’s environment, I couldn’t run large models locally. I used Hugging Face Spaces to host the models externally and used their APIs inside Sugar for lightweight testing. This also helped keep the feature lightweight and modular.

---

## Key Learnings

**Developed Engaging Pedagogical Strategies for Story Writing**  
   - Mentors helped me explore interactive ways to encourage children’s creativity, shifting from passive AI responses to more guided interactions.

**Designed and Finalized a Guided AI Architecture**  
   - I developed a modular design that prompts students to build stories step by step, ensuring they stay involved and learn narrative structure.

**Learned Effective Student-AI Interaction Techniques**  
   - I realized that giving the AI a playful personality that gently prompts students can make the writing process more enjoyable and educational.

---

## Next Week’s Roadmap

- Begin coding the designed architecture  
- Develop a basic Streamlit application to test the feature outside Sugar  
- Work on feedback provided by mentors  

---

## References

Here’s an insightful video shared by Walter Bender:  
[CBS: The Thinking Machine (MIT Film, 1961)](https://www.youtube.com/watch?v=HCl19WKrfeg)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for their continued support and encouragement!

---
`,as=Object.freeze(Object.defineProperty({__proto__:null,default:Ve},Symbol.toStringTag,{value:"Module"})),Je=`---
title: "DMP’25 Week 02 Update by Justin Charles"
excerpt: "Completed SVG path logic for all brick types and documented props and rendering states"
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "2025-06-15-dmp-25-justin212407-week02"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week2,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 2 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/) 
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)   
**Reporting Period:** 2025-06-09 - 2025-06-15  

---


## Goals for This Week

- Finalize SVG path logic for all three types of bricks  
- Categorize and document all props passed into bricks  
- Identify all visual states a brick can be rendered in  
- Differentiate props and states across brick types  
- Write comprehensive tests to verify correctness

---

## This Week’s Highlights

### 1. Full SVG Path Generation Logic

- Completed \`generatePath\` support for all three brick types (Simple, Expression and Compound)  
- Rendering now properly reflects scaling, argument slots, top/bottom notches, and label widths  
- Edge cases such as bricks with long labels or stacked arguments handled correctly

### 2. Brick Input Prop Categorization

- Catalogued all props across types (\`strokeWidth\`, \`scaleFactor\`, \`bBoxLabel\`, \`bBoxArgs\`, etc.)  
- Documented their role in layout computation and how they influence final SVG shape

### 3. Brick State Documentation

- Mapped out all possible states a brick can be rendered in (e.g. with/without label, multiple args, missing notches)  
- This will help improve clarity for both debugging and future features

### 4. Type-wise Prop/State Differentiation

- Clearly separated the logic for how each brick type handles its props and rendering states  
- This abstraction allows brick-specific customizations without breaking general rendering flow

### 5. Unified Brick Test File

- Created a comprehensive Jest test file to validate path generation against expected output  
- Covers edge cases like empty arguments, multiple stacked args, and variable heights

📄 Reference: [Props & States Document – Tab 3](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.99d6uc7vheda)

---

## Challenges & Solutions

**Challenge: Mismatched Bounding Box Heights in Some Brick Types**  
In initial tests, actual brick heights didn’t match the combined heights of \`bBoxLabel\` and \`bBoxArgs\`.  
**Solution:** Identified a calculation flaw in vertical layout stacking. Corrected it by properly summing scaled heights and applying consistent spacing logic in path computation.

**Challenge: Supporting All Brick Variants with Shared Logic**  
Bricks share many layout rules, but also diverge in rendering.  
**Solution:** Broke down \`generatePath\` into side-specific functions (\`_generateLeft\`, \`_generateRight\`, etc.) with override support depending on brick type and features like notches.

---

## Key Learnings

- Improved understanding of scalable vector graphics and path-based layout systems  
- Gained hands-on experience in building testable, modular rendering logic  
- Developed systematic thinking around UI state modeling and prop-driven rendering behavior  

---

## Next Week’s Roadmap

- Create React Components(View) to render the bricks with all its properties.
- Create the Model components for the different Brick Types.

---

## Resources & References

- [Props & States Document](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.99d6uc7vheda)  
- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  

---

## Acknowledgments

Thanks to my mentors for helping review the rendering logic and for encouraging a structured approach to SVG layout systems. Their early feedback made the path code significantly more robust and maintainable.

---
`,os=Object.freeze(Object.defineProperty({__proto__:null,default:Je},Symbol.toStringTag,{value:"Module"})),Xe=`---
title: "DMP ’25 Week 02 Update by Harshit Verma"
excerpt: "To develop a basic FastAPI server and integrate it with Pippy."
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "2025-06-15-dmp-25-therealharshit-week02"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week02,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-09 - 2025-06-15  

---

## Goals for This Week

- **Goal 1:** Set up a basic FastAPI server.
- **Goal 2:** Integrate a Hugging Face model.
- **Goal 3:** Add 'Run and Debug' buttons to Pippy UI.
- **Goal 4:** Connect Pippy to the FastAPI Server.

---

## This Week’s Achievements

1. **Built FastAPI Server with \`/debug\` Endpoint**  
   - Created a simple FastAPI app that listens for POST requests at \`/debug\`.
   - The endpoint accepts raw Python code, forwards it to the model, and returns debug tips.

2. **Integrated Hugging Face Model**  
   - Loaded a lightweight model (Qwen/Qwen2.5-1.5B-Instruct) from Hugging Face using \`transformers\`.
   - Connected the model with the \`/debug\` endpoint to generate relevant debugging suggestions.

3. **Updated Pippy UI with Debugging Controls**  
   - Added 'Run and Debug' buttons to the Pippy interface.
    ![Pippy UI: Run and Debug](assets/Images/pippy_run&debug.webp)
   - This was designed to trigger actions like execute code and get debugging feedback.

4. **Connected Pippy to the FastAPI Server**  
   - Implemented functionality to extract code from the Pippy editor.
    \`\`\`Python
    #To extract the source code

    def _get_current_code(self):
        pippy_tmp_dir = '%s/tmp/' % self.get_activity_root()
        current_file = os.path.join(
            pippy_tmp_dir,
            self._source_tabs.get_current_file_name()
        )

        try:
            with open(current_file, 'r') as f:
                return f.read()
        except Exception as e:
            print(f"Error reading file {current_file}: {e}")
            return None
    \`\`\`   
   - Successfully set up an API call from Pippy to the FastAPI server when the 'Run and Debug' button is clicked.

---

## Challenges & How I Overcame Them

- **Challenge:** Running the model locally on CPU.  
  **Solution:** Faced performance limitations due to lack of GPU support. I resolved this by selecting a small, efficient model from Hugging Face.

- **Challenge:** Using GTK for Pippy UI integration.  
  **Solution:**  Since GTK was new to me, adding buttons and handling events required exploring GTK documentation and existing Sugar activity patterns. With guidance and trial-and-error, I successfully added and wired up the 'Run and Debug' button to Pippy’s interface.

---

## Key Learnings

- Learned how to build and structure an API with FastAPI.
- Gained experience integrating Hugging Face models programmatically.
- Understood how to bridge frontend (Pippy) with backend (FastAPI) effectively.
- Improved at working across virtual machines, ports, and networking setups.

---

## Next Week’s Roadmap

- Improve prompt engineering for better debugging tips.
- Add visual display of debug tips in the Pippy interface.
- Integrate sugar-ai with Pippy.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,is=Object.freeze(Object.defineProperty({__proto__:null,default:Xe},Symbol.toStringTag,{value:"Module"})),$e=`---
title: "GSoC ’25 Week 02 Update by Bishoy Wadea"
excerpt: "Broken Calculator"
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "gsoc-25-BishoyWadea-week01"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week02,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Bishoy Wadea

**Project:** [Broken Calculator](https://github.com/Bishoywadea/Broken-Calculator)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-06-08 - 2025-06-15 

---

## Goals for This Week

- **Goal 1:** Define game features and core mechanics.
- **Goal 2:** Design and plan a child-friendly, interactive game UI.
- **Goal 3:** Implement the core game logic.

---

## This Week’s Achievements – *Broken Calculator Game*

1. **Initial Setup & Core Functionality**
   - Added starter files and project structure.
   - Implemented basic game manager functionality to handle state, inputs, and equation validation.
   - commit: [Initial Commit](https://github.com/Bishoywadea/Broken-Calculator/commit/9615fe64467e538e4b2d3df2ba6a0059177d31a7)

2. **UI Foundation and Target Display**
   - Created basic UI layout with the target number display.
   - Integrated equation panel and on-screen keyboard for child-friendly input.
   - commit: [UI Target + Equation Panel](https://github.com/Bishoywadea/Broken-Calculator/commit/fb52777a698d0846b3012140a796024edef5e577)

3. **Button Logic and Interaction**
   - Added calculator buttons and implemented event handling logic.
   - Created class-based structure for reusable buttons and interactions.
   - commit: [Calc Buttons Logic](https://github.com/Bishoywadea/Broken-Calculator/commit/f5201b9cf17c37fb70502fda55fd190b2143bca2)

4. **Gameplay Enhancements**
   - Added scoring system and validation logic for player input.
   - Implemented completion message upon solving the puzzle correctly.
   - commit: [Game Logic & Completion](https://github.com/Bishoywadea/Broken-Calculator/commit/2f985799faab59d590adae38b349c20dc0b432f9)

5. **Visual & UX Improvements**
   - Introduced dark theme palette for better visual experience.
   - Added menu buttons, teacher image, and stars animation for child appeal.
   - Relocated help button for better accessibility.
   - commit: [UI/UX Polish](https://github.com/Bishoywadea/Broken-Calculator/commit/c97ade0610d606672a99522b944ed4ec24018c02)

---

## Challenges & Solutions

- **Challenge:** Handling math equation input using only a restricted set of digits/operators.  
  **Solution:** Wrote logic to dynamically validate inputs and compute results with constraints.

- **Challenge:** Making the interface engaging for children.  
  **Solution:** Added animations, character images, and accessible visual elements.

---

## Key Learnings

- Gained proficiency in using **Pygame** for interactive game development.
- Improved understanding of **map projections** and **GeoJSON** parsing.
- Learned about structuring a project for open-source collaboration (commits, PRs, README, file organization).
- Practiced test-driven logic development and clean UI design tailored for children.

---

## Key Learnings

- Enhanced skills in **Pygame** UI design and interaction patterns.
- Practiced breaking down UI into components (buttons, input panels, layout regions).
- Understood how to make gameplay intuitive without written instructions—especially for kids.

## Next Week’s Roadmap

### Soma Cubes Game: Initial Insights & Exploration
- Begin designing core mechanics and gameplay flow for a Soma Cubes puzzle activity.
- Prototype user interactions: piece manipulation, rotation, and snapping into place.
- Investigate how to integrate puzzle constraints and feedback for users.
- Sketch out UI layout and controls tailored for children.

---

### Fix Open Issues

#### Four-Color Map Activity
- **[#1 Move buttons on the activity canvas to the activity toolbar](https://github.com/Bishoywadea/Four-Color-Map/issues/1)**  
  Adjust UI so that control buttons (e.g., Undo, Help, Menu) are relocated from the map canvas into a consistent toolbar above or beside it.
- **[#2 Sugarize activity icon](https://github.com/Bishoywadea/Four-Color-Map/issues/2)**  
  Update the icon to conform with Sugar activity design standards—ensure correct dimensions, transparency, and consistency with Sugar's visual language.

#### Broken Calculator
- **[#1 Make calculator fill activity canvas](https://github.com/Bishoywadea/Broken-Calculator/issues/1)**  
  Refactor layout to scale the calculator panel to full canvas size at any screen resolution or window rescaling.
- **[#2 Improve UI](https://github.com/Bishoywadea/Broken-Calculator/issues/2)**  
  Polish button styles, spacing, theme consistency (light/dark), and overall visual clarity based on user feedback.

---
`,ss=Object.freeze(Object.defineProperty({__proto__:null,default:$e},Symbol.toStringTag,{value:"Module"})),Ye=`---
title: "GSoC '25 Week 02 Update by Nikhil Bhatt"
excerpt: "Implemented edit functionality for project repositories and introduced a forking mechanism for collaborative workflows."
category: "DEVELOPER NEWS"
date: "2025-06-10"
slug: "2025-06-10-gsoc-25-nikhilbhatt-week02"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week02,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Nikhil Bhatt

**Project:** [Git backend for Musicblocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-06-7 – 2025-06-14  

---

## Goals for This Week

- **Implement an edit route** to allow users to update project data securely using hashed keys.
- **Design and implement a forking mechanism** where users can fork existing project repositories into new independent ones.
- **Integrate project origin tracking** in forked repos through metadata.

---

## This Week's Achievements

1. **Edit Project Functionality**
   - Created a secure API endpoint that allows users to update their project repository content using a key-authenticated system.
   - The backend checks the key hash stored in the \`metaData.json\` before applying any updates.
   - PR: [Edit Project API](https://github.com/BeNikk/musicblocks-backend/commit/1f61a089de7d8dbede2d46a101611133a1190bf6)

2. **Fork Project Repository**
   - Developed a new feature that enables students to fork other students' public projects into their own repositories under the same organization.
   - Forked repositories retain original content (\`projectData.json\`, \`metaData.json\`) and include the original repository link in the metadata (\`forkedFrom\` field).
   - PR: [Fork Feature](https://github.com/BeNikk/musicblocks-backend/commit/d1b7220476dc1fd58c1b38dc59c8a4991871ac45)

3. **Project Metadata Enhancements**
   - Updated the metadata structure to support fork tracking and improve key validation.
   - Ensured consistency between project ownership, fork source, and editing rights.

---

## Challenges & How I Overcame Them

- **Challenge:** Understanding and handling GitHub’s \`SHA\` and \`Base64\` requirements when editing file content through the API.  
  **Solution:** Read GitHub API docs and integrated \`Buffer.from(...).toString('base64')\` and used file \`sha\` to ensure proper file overwrites.

- **Challenge:** Unsure if re-initializing Octokit and generating a new installation token per request was optimal.  
  **Solution:** Kept this approach for now as each request is stateless and works correctly. Optimization will be explored after baseline features are stable.

---

## Key Learnings

- Learned how to **authenticate and authorize edits** to GitHub repos using hashed keys and GitHub’s content API.
- Understood the internal structure of GitHub forks and metadata handling.
- Improved knowledge of **Octokit**, GitHub APIs, and best practices for writing file content (\`projectData.json\`, \`metaData.json\`) to a repo.

---

## Next Week's Roadmap

- Add **pull request functionality** between forked and original projects.
- Improve project listing UI with fork indicators.
- Begin planning for collaborator permissions and PR review workflow.

---

## Resources & References

- **GitHub API Docs:** [REST Reference](https://docs.github.com/en/rest)
- **Octokit:** [octokit/rest.js](https://github.com/octokit/rest.js)
- **MetaData Example:** \`metaData.json\` includes \`hashedKey\`, \`theme\`, and \`forkedFrom\`.

---

## Acknowledgments

Thank you to my mentors and the Sugar Labs community for guidance and feedback, and to the GitHub community for their detailed API documentation and tooling support.

---
`,rs=Object.freeze(Object.defineProperty({__proto__:null,default:Ye},Symbol.toStringTag,{value:"Module"})),Qe=`---
title: "GSoC '25 Week 2 Update by Safwan Sayeed"
excerpt: "Memory Module Architecture and CRUD Operations Development"
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "2025-06-15-gsoc-25-sa-fw-an-week2"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week2,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 2 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-09 - 2025-06-15  

---

## A Blog-style Retrospective

This week was all about diving deep into the memory architecture for the Music Blocks program engine. After completing our comprehensive AST framework in week 1, we shifted focus to building the foundational memory management system that will power program execution. The challenge was designing a three-scope memory hierarchy (Global, Thread, Local) with full CRUD operations while keeping the implementation clean and focused.

Working alongside Karan Palan, we expanded our tech spec to include detailed memory module specifications. The mentors provided crucial guidance on scope requirements, emphasizing the need for thread isolation, and multi-level local scope support.

---

## Goals for This Week

- Complete the memory module technical specification with three-scope architecture details.
- Develop full CRUD operations for global variables accessible from any scope.
- Implement it with tests.

---

## This Week's Highlights

1. **Memory Module Tech Specification**  
   - Expanded the tech spec with comprehensive memory architecture documentation covering three-scope system.
   - Detailed CRUD operation requirements for global, thread, and local scope variables.
   - Link: [Tech Spec Document - Memory Section](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.3xe7coiooljb#heading=h.s3q9swsg3ifd)


2. **Memory Module CRUD Operations**  
   - Started Implementing the CRUD Operations for the Scopes

---

## Challenges & Solutions

- **Understanding Scope Hierarchy Complexity:**  
  The three-scope system (Global, Thread, Local) with proper variable shadowing was conceptually challenging.  
  *Solution:* Studied the existing reference implementation and created detailed diagrams to visualize scope relationships.


---

## Key Learnings

- Mastered hierarchical data structure design with proper encapsulation and scope isolation.
- Gained deep understanding of variable shadowing and scope resolution mechanisms.
- Enhanced collaboration skills working on complex architecture with multiple contributors.

---

## Next Week's Roadmap

- Begin symbol table implementation building on the memory module foundation.
- IR Implementation
- Write comprehensive unit tests for all memory module CRUD operations.

---

## Resources & References

- **Tech Spec:** [Memory Module Architecture](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.3xe7coiooljb#heading=h.s3q9swsg3ifd)  
- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)
- **Reference Implementation:** [For conceptual guidance](https://github.com/sugarlabs/musicblocks-v4-lib/tree/develop/src/execution/scopeexecution/scope) 

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their detailed guidance on memory architecture design and scope management. Their clarification on keeping the focus on memory module fundamentals was crucial for this week's progress.

---`,ls=Object.freeze(Object.defineProperty({__proto__:null,default:Qe},Symbol.toStringTag,{value:"Module"})),Ze=`---
title: "GSoC ’25 Week 02 Update by Diwangshu Kakoty"
excerpt: "Multi-AI Agent Chat Model"
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "diwangshu-kakoty"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week02,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-06-08 - 2025-06-14  

---

## Goals for This Week

- **Goal 1:** Develop a chat model consisting of multiple AI agents/mentors.
- **Goal 2:** Improve the 'Analysis' generation.
- **Goal 3:** Try and test different embedding models.
- **Goal 4:** Fix bugs occured by these changes.

---

## This Week’s Achievements

1. **AI Mentors**  
   - From the last meeting with my mentor, I received feedback on having specialised AI mentors for areas of expertise, such as music and coding. Hence, I have implemented a way to have conversations with mentors in music, code, and meta.

   - *Music Mentor* : Handles reflection for music learning.

   - *Code Mentor* : Handles programming concepts and debugging reflection. Users can paste their simplified project code for better feedback and guidance.

   - *Meta Facilitator* : Guides general reflective thinking (learning goals, struggles, progress).

2. **Improve Analysis Generation**  
   - As mentioned in the last report, the analysis was inaccurate. I have refined the instructions, and now it functions effectively. It did not take much time.

3. **Tested various Embedding Model**  
   - Embedding models are machine learning models that convert complex data such as text, images, or audio into numerical representations called embeddings. I am using \`all-MiniLM-L6-v2\`, which is lightweight and fast. Although it is lightweight, it is still quite effective. I have not found better models than this, so I will stick with this model for now. 

---

## Challenges & How I Overcame Them

- **Challenge 1 :** The LLM needs to be invoked with the user query, retrieved context, and message history. Since this project involves multiple AI agents, it is somewhat tricky to decide what kind of memory space to use. Possible ways to store messages:

  i) Shared memory space: Each agent will use one common message history with named tags to differentiate among themselves. This way, the AI agents won't repeat questions.

  ii) Separate memory space: Each agent will have their own space. This way, we can prevent confusion for the LLM. However, the trade-off is space. Additionally, we need to pass these message histories separately for summary generation.

  **Solution:** I first implemented the second option because it is simple and works fine, but the summary generation needs to be done separately for each agent, which I don't think is ideal. Therefore, I have decided to try the first option. I have already started working on it. I need to fix some bugs, and it will be completed by tomorrow (2025-06-16).

- **Challenge 2 :** Retrieved context is irrelevant when the project code is passed. The retriever component returns three chunks arranged in priority. However, a project code can contain many keywords, making the retriever not particularly useful.

  **Solution:** I am considering scanning all the keywords (like block names) first and passing their information to the LLM. This data will be stored in a dictionary. Example:

\`\`\`python
blocks = {
    "Action": "An Action block contains a sequence of actions that will only be executed when the block is referred to by something else, such as a start block.",
    "Start": "A Start Block is an Action that will automatically be executed once the start button is pressed."
}
\`\`\`
This way the LLM can understand block structure and their meaning as well.

---

## Key Learnings

- The prototype for this project is developing in Streamlit, and I am learning Streamlit a lot.
- Also gainig experience in LangChain as this is the primary tool of development.

---

## Next Week’s Roadmap

- Work on things suggested by mentors.
- Fix challenge no. 2 as mentioned above.
- Start preparing for the frontend interface.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)


---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,ds=Object.freeze(Object.defineProperty({__proto__:null,default:Ze},Symbol.toStringTag,{value:"Module"})),en=`---
title: "GSoC ’25 Week 02 Update by Om Santosh Suneri"
excerpt: "To Develop a Basic RAG Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-06-14"
slug: "2025-06-14-gsoc-25-omsuneri-week02"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week02,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-08 - 2025-06-14

---

## Goals for This Week

- **Goal 1:** Enhance and Polish the Converter code
- **Goal 2:** To Make the JSON to Text Converter Publicly Accessible
- **Goal 3:** To Develop a Basic RAG Debugger for Music Blocks

---

## This Week’s Achievements

1. **Enhance and Polish the Converter code**  
   - I refined the output of the JSON to Text Converter by improving how blocks, parameters, and nested structures are represented. I also optimized the formatting and added clearer visual symbols to make the structure easier to follow.
   - A well-structured and readable output is critical for debugging and learning. These enhancements make the converter not only functional but truly useful, especially for beginners who may be overwhelmed by raw JSON. The clarity improvements bridge the gap between raw code and conceptual understanding.
   - GitHub Repository: [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)

2. **To Make the JSON to Text Converter Publicly Accessible**  
   - I deployed the Music Blocks JSON to Text Converter as a static web tool using GitHub Pages. This involved setting up the project structure for deployment, ensuring browser compatibility, and verifying that the tool works seamlessly for any user without needing local installation.
   - By making the converter publicly accessible, I’ve removed a major barrier for non-technical users who want to understand or debug Music Blocks projects. Now, anyone can paste their JSON and instantly see a human-readable text format, making it easier to interpret the project logic, especially for educators and learners.
   - JSON to Text Converter: [Live Demo](https://omsuneri.github.io/JSON-to-Text-representation/)

3. **To Develop a Basic RAG Debugger for Music Blocks**  
   - I created the initial version of a Retrieval-Augmented Generation (RAG) app that acts as a debugger for Music Blocks. It uses Google Gemini (free API) for natural language responses and Qdrant as a vector database to search over relevant Music Blocks documentation and sample project data.
   - This is the first step toward an AI-powered assistant that can help users understand errors, debug project files, and learn concepts interactively. It lays the groundwork for a smarter, more accessible debugging experience tailored specifically to the Music Blocks environment.
   - GitHub Repository: [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)

---


## Challenges & How I Overcame Them

- **Challenge:** Error 99 – Deployment Failure due to Network Binding  
  **Solution:** I updated the Gemini API implementation to avoid explicitly binding to a local address and ensured it followed the correct networking model for serverless deployment. I also verified that no hardcoded host values (like 127.0.0.1) were used and that the requests use standard internet routes.

- **Challenge:** Reducing Container Size from 7.1 GB to Under 4 GB  
  **Solution:** I explored two approaches:
   - Optimization: I removed redundant or unused files from the embedding directory and ensured the vector database stored only the most relevant documents.
   - Cloud-based Embeddings: I evaluated storing the embeddings externally (e.g., by using a hosted Qdrant instance or remote storage) so that the app could load them at runtime, rather than bundling them in the container.These optimizations brought the container size within limits and made the app deployable on Railway.

---

## Key Learnings

- Deployment environments have strict constraints that require optimization and flexibility
I learned that successful deployment isn’t just about writing functional code — it's equally about managing resources (like container size) and handling platform-specific limitations, such as networking and storage.
- Early-stage AI apps benefit greatly from clear modularity and cloud-ready design
While building the RAG debugger, I realized the importance of designing components (like embeddings, API logic, and vector search) to be loosely coupled and scalable, which helps avoid technical roadblocks during cloud deployment.

---

## Next Week’s Roadmap

- Deploy the AI-Powered Debugger App to a Cloud Hosting Platform.
- Create Embeddings from Music Blocks Project Text Representations.
- Improve LLM Response Language for Kids and Junior Learners.

---

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,cs=Object.freeze(Object.defineProperty({__proto__:null,default:en},Symbol.toStringTag,{value:"Module"})),nn=`---
title: "SSoC ’25 Week 02 Update by Muhammad Haroon"
excerpt: "Setting up AudioGen locally and building a simple user interface using Streamlit for generating audio from text."
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "2025-06-15-ssoc-25-MuhammadHaroon-week02"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week02,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-09 - 2025-06-15  

---

## Goals for This Week

- **Goal 1:** Set up AudioGen locally.
- **Goal 2:** Create a UI using streamlit.

---

## This Week's Achievements

1. **Set up AudioGen locally**  
   - I was able to set up AudioGen locally for that I followed [AudioGen docs](https://github.com/facebookresearch/audiocraft/blob/main/docs/AUDIOGEN.md). I also created a virtual environment and a requirements.txt file to make the project easier to run.

2. **Create a UI using streamlit**  
   - I also created a UI using streamlit with the help of the [Streamlit docs](https://docs.streamlit.io/).

---

## Challenges & How I Overcame Them

- **Challenge:** The challenge I actually faced was due to limited resources. AudioCraft (which provides AudioGen) requires a GPU with at least 16 GB of memory for running inference with the medium-sized models (~1.5B parameters). For generating 5 minutes duration of audio, it took around 15-20 minutes.  
- **Solution:** I ran the model and used the waiting time to complete other tasks. I plan to deploy the model on AWS, where I expect significantly better performance. 

---

## Key Learnings

- Gained familiarity with **Streamlit**

---

## Next Week's Roadmap

- Generate more samples using AudioGen and save them in Google Drive.
- Experiment with temperature and top_p parameters in AudioGen.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,us=Object.freeze(Object.defineProperty({__proto__:null,default:nn},Symbol.toStringTag,{value:"Module"})),tn=`---
title: "GSoC ’25 Week 05 Update by Aditya Kumar Singh"
excerpt: "UI improvements, model fixes, skeletal updates, and continued localization work for the 3D Human Activity in Sugarizer."
category: "DEVELOPER NEWS"
date: "2025-06-17"
slug: "2025-06-17-gsoc-25-AdityaKrSingh26-week05"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
description: "GSoC'25 Contributor at SugarLabs (Sugarizer Human Activity Pack)"
tags: "gsoc25,sugarlabs,week05,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-05-06 - 2025-06-12  

---

## Goals for This Week

- **Goal 1:** Fix and enhance model selection palette to reflect current selection.  
- **Goal 2:** Refine and divide bones in the skeleton model for improved clarity and continue localization efforts for Human Activity.    
- **Goal 3:** Improve organ model proportions (eye-mouth distance).  
- **Goal 4:** Update UI layout for model filter (mode selector).  
- **Goal 5:** Merge Paint and Learn mode to show a popup at bottom of screen when user click a part  

---

## This Week’s Achievements

1. **Model Selection Palette Fix**  
    - Resolved issue where the palette UI did not reflect the currently selected model.
    - Now dynamically highlights the active selection across Human, Skeleton, and Organs views.
           ![Updated Tool](https://i.ibb.co/k2jLsdZ1/image.webp)   
           ![Mode pallete](https://i.ibb.co/vCtQr98B/image.webp)   

2. **Skeleton Bone Naming and Splitting Update**  
    - Expanded the skeletal model by splitting compound bones and renaming:
     - For example, **“Arm”** is now divided into **Humerus**, **Radius**, and **Ulna**.
     - Ensured correct orientation and geometry alignment across these divisions.


3. **Localization Progress**  
    - Continued translation integration using **i18next.js**.
    - Initiated support for dynamically changing labels based on selected language.


4. **Organ Model Alignment Fix**  
   - Reduced the gap between eyes and mouth in the 3D organ model.
   - Realigned surrounding features to maintain anatomical accuracy.
     ![Organ Alignment Fix](https://i.ibb.co/W4SVHnGx/image.webp)


6. **Vertical Mode Selector UI Implementation**  
    - Reworked the mode selection UI to display vertically.
    - Inspired by Dollar Street UI design, this improves accessibility.
    - Earlier :  
        ![Mode selector earlier](https://i.ibb.co/bR32J4bm/image.webp)
    - Now :  
        ![Mode selector Now](https://i.ibb.co/60NHStQy/image.webp)


7. **Merged Paint and Learn mode**
    - Implemented a modal system that appears in the bottom-right corner when users click on body parts in paint mode.
    - Added fade-in/fade-out transitions with CSS transforms for better user experience and added duplicate prevention system that removes existing modals before showing new ones.
     ![Paint Modal](https://i.ibb.co/7tW0PdzH/image.webp)
     


---

## Challenges & How I Overcame Them

- **Challenge:** Maintaining proper alignment while modifying 3D organ models.  
  **Solution:** Used Blender’s measurement tools to iteratively adjust spacing, followed by live testing in the Sugarizer environment.  

- **Challenge:** Creating paint mode notifications that don't interfere with 3D interaction.  
  **Solution:** Developed bottom-right positioned modals with smooth animations and automatic cleanup to maintain workflow continuity while providing clear user feedback.  


---

## Key Learnings

- Gained experience in internationalization using i18next.js  
- Learned UI layout best practices for improving accessibility across devices.
- Gained practical Blender experience for precision model editing. 
- Developed more precise anatomical terminology awareness and importance of educational clarity.

---

## Next Week’s Roadmap

- Write Weekly Blog Post summarizing progress, screenshots, and key learnings.   
- Reduce file size of the organ model to improve load time and performance across devices (optimize meshes, reduce texture resolution).   
- Add an onboarding tutorial for users   
- Create and integrate .json files containing metadata (name, position, mesh reference) for body parts and organs to simplify mesh mapping and future i18n support.   
- Begin developing shared logic for **Paint Mode** and **Tour Mode**.   

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

## Connect with Me

- GitHub: [@AdityaKrSingh26](https://github.com/AdityaKrSingh26)
- Gmail: [adityakrsingh2604@gmail.com](mailto:adityakrsingh2604@gmail.com)
- LinkedIn: [Aditya Kumar Singh](https://www.linkedin.com/in/adityakrsingh26/)
- Twitter: [@AdityaKrSingh26](https://x.com/AdityaKrSingh26)

---
`,hs=Object.freeze(Object.defineProperty({__proto__:null,default:tn},Symbol.toStringTag,{value:"Module"})),an=`---
title: "GSoC ’25 Week 06 Update by Aditya Kumar Singh"
excerpt: "Model optimizations, onboarding tutorial, adding json for body parts, and Shared mode enhancements in Paint Mode for the 3D Human Activity in Sugarizer."
category: "DEVELOPER NEWS"
date: "2025-06-20"
slug: "2025-06-20-gsoc-25-AdityaKrSingh26-week06"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week06,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-05-12 - 2025-06-18  

---

## Goals for This Week

- **Goal 1:** Optimize organ model to reduce file size and improve performance.  
- **Goal 2:** Add a onboarding tutorial for users.    
- **Goal 3:** Improve organ model proportions (eye-mouth distance).  
- **Goal 4:** Create and integrate \`.json\` file for body parts and organs.  
- **Goal 5:** Enhancing shared mode logic for **Paint Mode**.  

---

## This Week’s Achievements

1. ***Organ Model Optimization**  
    - Reduced the organ model size from **19MB to 5.92MB** by applying **Merge Vertices by Distance** and **Mesh Decimation** in Blender.  
    - These steps simplified mesh geometry while retaining anatomical accuracy.  
    - Resulted in faster loading on low-end devices and web platforms without compromising visual quality. 

2. **Onboarding Tutorial Integration**  
    - Implemented an interactive onboarding experience using the **Intro.js** library, following Sugarizer's developer tutorial guidelines.  
    - Integrated a custom help button in the toolbar (\`help.svg\`) to trigger the tutorial on demand.  
    - Defined tutorial steps in a dedicated \`tutorial.js\` module using \`introJs().setOptions()\` to guide users through the UI.  
    - Customized the UI using Sugarizer-themed CSS classes for a consistent visual style.  
    - Enabled full localization support using \`l10n.get()\` to adapt tutorial text based on the user’s language settings.  
        ![Tutorial screen](https://i.ibb.co/TBbQPbLv/image.webp)   
        ![Tutorial screen](https://i.ibb.co/q3tNbkRV/image.webp)   


3. **Body Parts Metadata via JSON**  
   - Introduced a new \`.json\` file structure to define:
     - **Name**  
     - **Mesh name**  
     - **Position (x, y, z)**  
   - Enables simpler mapping between UI and 3D model meshes.  
   - Supports future work on localization, click handling, and performance enhancements.  
     \`\`\`json
     {
        { "name": "Hair", "mesh": "Hair_mesh", "position": [-0.01, 7.03, -0.32] },
        { "name": "LeftEyebrow", "mesh": "Mesh0207_1", "position": [0.06, 6.69, 0.63] },
        { "name": "RightEyebrow", "mesh": "Mesh0207_3", "position": [0.06, 6.69, 0.63] },
        { "name": "Left Ear", "mesh": "leftear_mesh", "position": [0.62, 6.42, -0.13] },
        { "name": "Right Ear", "mesh": "righear_mesh", "position": [-0.53, 6.4, -0.13] },
        { "name": "Face", "mesh": "Face_mesh", "position": [0.05, 6.35, 0.36] },
        { "name": "Neck", "mesh": "Neck_mesh", "position": [0.04, 5.54, -0.23] },
        { "name": "Chest", "mesh": "Chest_mesh", "position": [0.04, 4.55, 0.11] },
        { "name": "Back", "mesh": "back_mesh", "position": [0.04, 3.78, -0.83] },
        { "name": "Stomach", "mesh": "stomach_mesh", "position": [0.04, 2.41, 0.2] },
        ...
     }


4. **Shared Mode enhancements for Paint Mode**   
    - **Model sync:** when any participant switches to a different anatomical model, the client now emits a \`switchModel\` event; all connected users load the same model instantly.  
    - **Shared painting:** a \`paintPart\` broadcast (object name, color, body-part name, painter ID) lets everyone see the newly painted part in real time. A modal on each peer shows **“<user>     painted: <part>”** for clear attribution.  
        ![Shared mode](https://i.ibb.co/fV4KLx1d/image.webp)   


---

## Challenges & How I Overcame Them

- **Challenge:** Displaying context-aware feedback for painting actions without breaking UX flow.  
  **Solution:** Built a shared modal system that shows **“User X painted: Part Y”** without interrupting interactions. Ensured consistent color application using hex values and mesh IDs.

- **Challenge:** Keeping the tutorial visually aligned with Sugarizer UI guidelines while supporting localization.  
  **Solution:** Customized Intro.js with Sugarizer-style buttons, icons, and tooltips. Integrated \`l10n.get()\` to provide multilingual support across tooltips, button labels, and descriptions.


---

## Key Learnings

- Gained practical experience in implementing **real-time collaboration** using socket-based event broadcasting for 3D interactions.  
- Learned how to **synchronize complex state changes** (like model switching, paint actions, and UI mode transitions) across multiple clients in a shared environment.  
- Deepened understanding of **modular and scalable architecture** by separating shared logic into dedicated handlers and avoiding code duplication.  

---

## Next Week’s Roadmap

- Write Weekly Blog Post summarizing progress, screenshots, and key learnings.   
- Reduce file size of the organ model to improve load time and performance across devices (optimize meshes, reduce texture resolution).   
- Add an onboarding tutorial for users   
- Create and integrate .json files containing metadata (name, position, mesh reference) for body parts and organs to simplify mesh mapping and future i18n support.   
- Begin developing shared logic for **Paint Mode** and **Tour Mode**.   

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,gs=Object.freeze(Object.defineProperty({__proto__:null,default:an},Symbol.toStringTag,{value:"Module"})),on=`---
title: "DMP ’25 Week 3 Update by Aman Naik"
excerpt: "This week's focus was developing a working demo for the Story Builder feature using Streamlit and gathering mentor feedback for further improvements."
category: "DEVELOPER NEWS"
date: "2025-06-21"
slug: "2025-06-21-dmp-25-AmanNaik-week03"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week03,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 3 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-06-16 – 2025-06-21  

---

## Goals for This Week

- **Goal 1:** Develop a working demo of the Story Builder feature  
- **Goal 2:** Implement the demo using Streamlit  
- **Goal 3:** Gather feedback from mentors and plan improvements  

---

## This Week’s Achievements

1. **Developed a Demo of the Story Builder Feature**  
   - Created a functional web application using Streamlit to demonstrate how the story builder AI guides students through storytelling. The demo mimics the question-and-answer-based flow and simulates an AI companion.  
   - Find the demo [here](https://story-builder-ai.streamlit.app/)

   ![Chat responses](assets/Images/aman-naik-week3-img1.webp)

   ![Framework built using the chat messages](assets/Images/aman-naik-week3-img2.webp)

2. **Presented the Demo to Mentors**  
   - Shared the working version with my mentors. I received positive feedback and valuable suggestions on what could be improved and how the feature can be enhanced with new ideas.

---

## Challenges & How I Overcame Them

- **Challenge:** Designing a feedback loop where the AI accumulates all context from the student’s responses  
  **Solution:** After repeated iterations and research, I realized that assigning a distinct personality to the LLM helps it collect and remember context more naturally. This personality-driven approach ensures a more engaging and coherent interaction throughout the story-building process.

---

## Key Learnings

**Built and Deployed a Streamlit Demo to Simulate Story Interaction**  
   - Gained practical experience in using Streamlit to build and deploy web apps that demonstrate AI interaction flow for educational use cases.

**Learned the Importance of AI Personality in Context Retention**  
   - Discovered that crafting an AI assistant with a personality improves its ability to retain context and makes the storytelling experience more relatable and fun for children.

---

## Next Week’s Roadmap

- Begin fine-tuning a language model using AWS  
- Build a system where the AI recommends books similar to the student's story at the end of the conversation  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for their continuous guidance and valuable feedback!

---
`,ms=Object.freeze(Object.defineProperty({__proto__:null,default:on},Symbol.toStringTag,{value:"Module"})),sn=`---
title: "GSoC '25 Week 3 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates"
category: "DEVELOPER NEWS"
date: "2025-06-21"
slug: "2025-06-21-gsoc-25-Elwin-Li-week03"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week3,javaScript editor"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 3 Progress Report by Elwin Li

**Project:** [Advanced JavaScript Editor with MusicBlocks Interactions](https://github.com/sugarlabs/musicblocks/tree/config_driven_conversion/elwin)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-06-14 - 2025-06-21

---

## Goals for This Week

- **Goal:** Start on debugger for musicblocks and JS editor.

---

## This Week’s Achievements

**Made Working Debugger**

This week, I made a working debugger tool for Music Blocks JS editor. I added a button in the JS editor that is a toggle for the debug mode. On debug mode, users are able to add a breakpoint in any line of the code using buttons on the side of the line numbers. When the user then converts the code back to blocks, there are new debugger statement blocks that shows up.

Then, when the user runs their code, execution will be paused at every debugger statement, and a status block with all the user defined and musicblocks defined variables up till that point will appear, showing the user those values, making it easy to debug. The user can then choose which variables they want to keep, and continue execution. This tool works perfectly with the run slowly and run step by step buttons, in order for more careful debugging.

Also, I made block highlights contrast much more from original block colors, for easier tracking of which block is being executed.

[youtube: jEJuXpyQbS8]

---

## Challenges & How I Overcame Them

- **Challenge:** Status blocks default to a set macro of variables

  **Solution:** Was able to go through the blocklist and single out needed variables to put in the status block instead

---

## Key Learnings

- Deepened understanding of how music blocks execution works
- Improved skills in **debugging**, **code design**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Finish debugger project (fix bugs)
- Add syntax highlighting to JSeditor code

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,ps=Object.freeze(Object.defineProperty({__proto__:null,default:sn},Symbol.toStringTag,{value:"Module"})),rn=`---
title: "GSoC ’25 Week 03 Update by Mebin J Thattil"
excerpt: "Re-thinking training dataset structure"
category: "DEVELOPER NEWS"
date: "2025-06-21"
slug: "2025-06-21-gsoc-25-mebinthattil-week3"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week03,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-14 - 2025-06-21  

---

## Goals for This Week

- **Goal 1:** Fix the issue for continious generation of chain of responses from model

---

## This Week’s Achievements

Note: _I'm officially on leave for this week and the next week, but I have however been taking calls and attending meetings, and did some light work in the background._ 

1. **Re-formatted the dataset to avoid generating chain of responses**
   - Before the dataset had a records of conversations between a student and a teacher. Each record would have around 5-10 back-and-forth questions and interactions between the student and teacher. 
   - Since we were training on this dataset format, the model would also try to replicate this format - ie. it would start generating a chain of question-answer back and forths between the student and teacher. This is obviously something that we don't want.
   - I initially kept it this way to teach the model better conversational flow, but this approach does more harm than help.
   - So I have broken up the conversations and re-structured the conversations. 
   - I will now fine-tune it again on a subset of the dataset and deploy just to test it (_this is yet to be done_)
  

---

## Key Learnings

- Structure of dataset needs to be changed, in order to make it more conversational and understand the nuances of a chain of conversations.
  
---

## Next Week’s Roadmap

- Train the model and evaluate it
- Also try to run [my model](https://huggingface.co/MebinThattil/FT-Llama3.2-1B/tree/main) that is on HF via Sugar-AI.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,bs=Object.freeze(Object.defineProperty({__proto__:null,default:rn},Symbol.toStringTag,{value:"Module"})),ln=`---
title: "GSoC '25 Week 3 Update by Krish Pandya"
excerpt: "From initial GTK4 porting to building a solid foundation with separate C and Python libraries"
category: "DEVELOPER NEWS"
date: "2025-06-21"
slug: "2025-06-21-gsoc-25-mostlyk-week03"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week03,mostlyk"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 3: Development on the C estabhlishment

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)
**Reporting Period:** June 14, 2025 till June 21, 2025

---


## Following the meet of big change

> On last to last Friday(06-06-2025), we had a pivotal video call with Juan Pablo Ugarte and Ibiam Chihurumnaya that completely reshaped the porting approach.
What started as a discussion about my initial porting work evolved into something much more strategic and forward-thinking.

As discussed about these changes in the past week's blog, I have been continuing to update the C library. I have ported

### Commited:

- Sugar File Attributes ( in discussion of do we need to modernize or no)
- Event Controllers for Sugar ( handles clicks, movement etc. )
- Long Press Controllers

### Local:

- Sugar Touch Controllers
- Building on top of them, zoom, swipe and rotate.


## Demonstration of the Controllers:

<iframe width="560" height="315" src="https://www.youtube.com/embed/m0gwwo_0ZDE?si=M0ljKFFGuwAqAzrf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

This video shows working example of Event Controller and Long Press controller.

---

## PR Deep Dive

### Review & Iteration

The review process was thorough and collaborative, with mentors providing feedback on:

- API and Versioning: Ensuring symbol and identifier prefixes followed conventions, and clarifying versioning strategy to align with Sugar’s release cycle.
- Code Structure: Moving away from including XO Colors in the C library (to be handled in Python).
- Licensing: Correctly attributing copyright and following LGPL-2.1. ( As discussed in last week's blog for the versioning ).
- Formatting: Retaining original code formatting for readability, and avoiding unnecessary changes from auto-formatters.
- Build System: Making examples optional in the build, and keeping the project modular.

### Modernization Decisions

A key discussion was around modernizing the file attributes utility using GLib APIs. My rationale was to unify the codebase under a modern standard, leveraging GLib for better error handling and maintainability. However, Ibiam and James highlighted the importance of compatibility with filesystems like FAT32, and the need to test on real hardware. I will be formatting my USB to test this soon. I will keep it as a TODO for now.

### Testing

Every ported module includes comprehensive tests. Just do the following to test:

\`\`\`bash
meson test -C builddir
\`\`\`

The tests cover attribute creation, setting/getting values, and simulating real-world activity workflows. I plan to continue this rigorous testing approach for all future modules as always , yours truly Krish.

### Lessons Learned

- Consistency matters - Unifying the codebase under GLib/GTK4 improves maintainability, but must be balanced with legacy compatibility.
- Testing is critical - Automated and example-based tests are essential for safe modernization.
- Documentation and commit messages - Clear explanations of why changes are made (not just what) are crucial for future maintainers.

 _I am still learning on how to improve all of these , especially commit messages_

---

# Apart from Porting

Outside of the core Sugar porting work, I also spent some time tinkering (_I love music_) some side projects for MusicBlocks and SL:

- AWS & SoundScape: I continued working on [SoundScape](https://soundscape.streamlit.app/), the audio processing web app.
This week, I wanted to update the platform to include an SheetMusic-To-MusicXML model in addition to existing Audio-to-Sheet-Music model and  Audio-to-MIDI functionality.
I sadly was using Oemer and my own system rqreuiement were not capable enough to run it .

- Machine Learning Experiments: I tried running [Oemer](https://github.com/BreezeWhite/oemer), an open-source Optical Music Recognition tool.So I’m planning to set up a dedicated AWS instance for further testing and integration. And if that works out I can deploy by dockerizing SoundScape.

Overall, I like tinkering with these kinds of projects and learn more about foundational models.

To someone who is interested in research and wants a tool to have beside reading papers you can check [Dread-Rising](https://dread-rising.streamlit.app/). It can also be used for someone who just wants to read a book , or an article, you can get highlighted version of the PDF, multiple understanding and can do in-depth.

These small problems that I tackle using my pre-existing knowledge on LLMs and Python help me in porting as well, even though it's a completely different side of project which is writing a C library right now, the skills and thinking translate a lot and I have fun!

## Resources & References

- Project Page – [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- New C Library - [sugar-ext repository](https://github.com/sugarlabs/sugar-ext)
- Active PR - [Establish C library base template with Meson for GTK4](https://github.com/sugarlabs/sugar-ext/pull/1)
- Sugar Toolkit Repository(original) – [sugar-toolkit-gtk3](https://github.com/sugarlabs/sugar-toolkit-gtk3)
- GTK4 Migration Guide – [docs.gtk.org/gtk4/migrating-3to4.html](https://docs.gtk.org/gtk4/migrating-3to4.html)


---

## Acknowledgments

Huge thanks to Juan Pablo Ugarte first of all for being the official mentor and Ibiam Chihurumnaya for the guidance that that changed this project's direction. Their architectural vision has transformed porting into a comprehensive modernization effort. Thanks also to Walter Bender for mentorship.
`,fs=Object.freeze(Object.defineProperty({__proto__:null,default:ln},Symbol.toStringTag,{value:"Module"})),dn=`---
title: "DMP’25 Week 03 Update by Justin Charles"
excerpt: "Completed SVG path logic for all brick types and documented props and rendering states"
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "2025-06-22-dmp-25-justin212407-week03"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week3,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 3 Progress Report by Justin Charles

**Project:** Music Blocks 4 Maosonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-15 - 2025-06-22  

---


## Goals for This Week

- Design an algorithm for parsing and rendering the brick tree via React components  
- Expose bounding box and connection point data from the model layer  
- Create a prop interface for passing this spatial data into the rendering layer  

---

## This Week’s Highlights

### 1. **Visual Tree Parsing and Rendering Algorithm**

Developed a clean, maintainable algorithm to traverse and render the brick tree structure:
- Each tree node is transformed into a React component, preserving parent-child and neighbor relationships
- Recursive traversal ensures dynamic rendering of nested bricks
- Designed to integrate seamlessly with \`BrickTreeManager\` and individual brick models

### 2. **Exposed Geometric Metadata in Brick Models**

Implemented structured public getters and setters to handle:
- **Bounding Box (bbox)**: x, y, width, and height of each rendered brick
- **Connection Point Coordinates**: Vary based on brick type (Simple, Expression, Compound)
- Enables precise layout, collision detection, and advanced interaction logic downstream

### 3. **Visual Data Propagation via React Props**

Added a new prop to the core brick rendering components:
- Accepts a callback function
- Receives \`bbox\` and connection point data as arguments after render
- Supports future enhancements like:
  - Overlay-based debugging
  - Adaptive layout reflows
  - External visualization tools

📄 Reference for parsing algorithm: [Tab 5](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.99d6uc7vheda)

---

## Challenges & Solutions

**Challenge: Finding the right parsing algorithm for parsing the tree**   
**Solution:** Implemented stack based traversal with visited node tracking and component key management

**Challenge:  The tree parsing algorithm struggled to correctly identify and maintain parent-child relationships when bricks had multiple connection points or nested expressions**  

**Solution:** Implemented a two-pass algorithm - first pass builds the node structure, second pass establishes parent-child references and validates connection integrity

---

## Key Learnings

- Algorithm Design

Recursive Patterns: Learned how to structure recursive algorithms for tree traversal that map cleanly to React component hierarchies
Data Structure Mapping: Understanding how to translate tree data structures into renderable React components

---

## Next Week’s Roadmap

- Render the tree upon the storybook given any configuration of bricks.
- List down all the bricks and their configurations.
- Create the pallete UI with all types of bricks present in it.

---

## Resources & References

- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  
- [musicblocks-v4 Tech Spec Document](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.0#heading=h.gtbrgbbwfht3)
---

## Acknowledgments

Thanks to my mentors for helping review the algorithm logic for rendering the tree. Their early feedback made the path code significantly more robust and maintainable.

---
`,ws=Object.freeze(Object.defineProperty({__proto__:null,default:dn},Symbol.toStringTag,{value:"Module"})),cn=`---
title: "DMP '25 Week 03 Update by Anvita Prasad"
excerpt: "Implementation of tuner visualization system and dual-mode interface"
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "2025-06-22-DMP-25-AnvitaPrasad-week03"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week03,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-16 - 2025-06-22  

---

## Goals for This Week
- **Goal 1:** Implement dual-mode tuner interface
- **Goal 2:** Complete basic cents adjustment UI implementation
- **Goal 3:** Enhance tuner visualization system
- **Goal 4:** Test with various audio sources and instruments

---

## This Week's Achievements

1. **Dual-Mode Tuner Implementation**
   - Successfully implemented a toggle button interface for switching between two tuner modes
   - Developed chromatic mode where target pitch moves based on input pitch
   - Implemented logic for finding closest chromatic pitch within +/- 50 cents
   - Added cent deviation value display under the tuner
   - Started work on specific target pitch mode implementation
   - Gathered feedback for further refinements

2. **Cents Adjustment UI Development**
   - Implemented basic cents adjustment interface

3. **Tuner Visualization Enhancements**
   - Made refinements to last week's visualization system
   - Added clear visual feedback for cent deviation
   - Enhanced visual clarity for pitch detection feedback

4. **Testing Progress**
   - Conducted initial testing with various audio sources
   - Identified areas for improvement in pitch detection
   - Created a test suite for tuner accuracy verification

5. **Audio Processing Improvements**
   - Implemented low-pass filtering to handle high-frequency noise
   - Enhanced pitch detection accuracy using parabolic interpolation
   - Optimized signal processing for better performance

---

## Challenges & How I Overcame Them

- **Challenge:** Creating an intuitive UI for mode switching
  **Solution:** Implemented a clear toggle interface with visual indicators for current mode

- **Challenge:** Dealing with high-frequency noise in audio signal
  **Solution:** Implemented low-pass filtering to improve signal quality and enhance pitch detection accuracy

---

## Key Learnings

- Learned about signal processing techniques like low-pass filtering and its impact on audio quality
- Gained insights into sub-cent accuracy through parabolic interpolation in pitch detection

---

## Next Week's Roadmap

- Complete and refine target pitch mode implementation
- Implement manual cent adjustment functionality
- Finalize design for cent adjustment interface
- Conduct comprehensive testing with various audio sources and instruments
- Deliverable: Fully functional tuner with cents adjustment

---

## Resources & References

- [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [Audio Filters Guide](https://blog.native-instruments.com/audio-filters-guide/)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support. 

--- `,ys=Object.freeze(Object.defineProperty({__proto__:null,default:cn},Symbol.toStringTag,{value:"Module"})),un=`---
title: "GSoC ’25 Week 03 Update by Bishoy Wadea"
excerpt: "Broken Calculator"
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "gsoc-25-BishoyWadea-week03"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week03,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Bishoy Wadea

**Project:** [Broken Calculator](https://github.com/Bishoywadea/Broken-Calculator)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-06-22 - 2025-06-28 

---

## Goals for This Week

- **Goal 1:** Fix issues in Four Color Map game opened by ibiam [Move buttons from canvas to tool bar](https://github.com/Bishoywadea/Four-Color-Map/issues/1), [Sugarize activity icon](https://github.com/Bishoywadea/Four-Color-Map/issues/2), [adding lisence to activity](https://github.com/Bishoywadea/Four-Color-Map/issues/3).

![image to show difference between before and after](https://i.postimg.cc/vmWPFd6q/b4e81f67-3e05-4389-a67d-82eb71a14899.webp)

- **Goal 2:** Fix issues in Broken Calculator game opened by ibiam [change UI to be more focused](https://github.com/Bishoywadea/Broken-Calculator/issues/2).

![image to show difference between before and after](https://i.postimg.cc/7LsNyYZN/download.webp)
---

## This Week’s Achievements

### *Goal 1: Fix Issues in Four Color Map Activity*

1. **Moved Control Buttons to Toolbar**  
   - Relocated in-canvas buttons (Undo, Help, Menu) to a proper activity toolbar for a more intuitive UI layout.  
   - PR: [Move Buttons to Toolbar](https://github.com/Bishoywadea/Four-Color-Map/pull/5)

2. **Sugarized the Activity Icon**  
   - Designed and applied a new icon that follows Sugar activity standards in shape, color, and transparency.  
   - PR: [Sugarized Icon](https://github.com/Bishoywadea/Four-Color-Map/pull/6)

3. **Added License File**  
   - Included a standard open-source license file in the repo, ensuring compliance with FOSS guidelines.  
   - PR: [Add License](https://github.com/Bishoywadea/Four-Color-Map/pull/7)

---

### *Goal 2: Improve Broken Calculator UI & UX*

1. **Redesigned UI for Focused Gameplay**  
   - Refactored layout to fill the canvas with the calculator interface and decluttered extra elements.  
   - commit: [Canvas Layout Update](https://github.com/Bishoywadea/Broken-Calculator/commit/7ec076475ae1c7e77c96a6ae155b151681fa724a)

---

## Challenges & Solutions

- **Challenge:** Migrating control elements from canvas to toolbar in Four Color Map.  
  **Solution:** Familiarized myself with the Sugar toolbar API and successfully relocated buttons, improving UI consistency.

- **Challenge:** Making the interface engaging for children.  
  **Solution:** Added animations, character images, and accessible visual elements.

---

## Key Learnings

- Deepened experience working with **Sugar activity design standards**, including toolbars and icon sugarization.
- Gained hands-on experience applying **open-source contribution practices**—issue tracking, commit hygiene, licensing, and documentation.
- Practiced creating UI/UX for young learners, focusing on minimalism, feedback clarity, and visual accessibility.

---

## Next Week’s Roadmap

### Soma Cubes Game: Initial Insights & Exploration
- Begin designing core mechanics and gameplay flow for a Soma Cubes puzzle activity.
- Prototype user interactions: piece manipulation, rotation, and snapping into place.
- Investigate how to integrate puzzle constraints and feedback for users.
- Sketch out UI layout and controls tailored for children.

---

### Fix Open Issues

#### Four-Color Map Activity
- **[#4 Make activity pep8 compliant](https://github.com/Bishoywadea/Four-Color-Map/issues/4)**  
  The activity isn't pep8 compliant.

---
`,ks=Object.freeze(Object.defineProperty({__proto__:null,default:un},Symbol.toStringTag,{value:"Module"})),hn=`---
title: "GSoC '25 Week 03 Update by Nikhil Bhatt"
excerpt: "Set up backend routes for creating and viewing pull requests on MusicBlocks project repositories."
category: "DEVELOPER NEWS"
date: "2025-06-17"
slug: "2025-06-17-gsoc-25-nikhilbhatt-week03"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week03,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-06-15 – 2025-06-21  

---

## Goals for This Week

- Add backend support for creating pull requests when someone edits a forked project.
- Allow project maintainers to view all incoming pull requests to their original project repo.
---

## This Week's Achievements

1. **Created Pull Request Route**
   - Built a route where students who forked a project can submit updates.
   - The backend automatically creates a **new branch on the original repository**, updates the \`projectData.json\`, and creates a pull request from that branch to the main branch.
   - We use the original repository info stored in \`metaData.json\` of the forked project.
   - Only two values are required from the frontend: the name of the fork repo and the updated \`projectData\`.

2. **View All Pull Requests Route**
   - Added another route that **lists all open pull requests** for a given repository.
   - Maintainers can use this to preview incoming contributions.
   - In the future, clicking “merge” on the frontend will trigger the same \`edit\` route we already have, safely updating the project.

---

## Challenges & How I Overcame Them

- **Challenge:** GitHub’s API does not allow opening pull requests between two repos in the **same organization** (which is our setup for MusicBlocks).  
  **Solution:** Instead of trying to PR from a forked repo to the original, we create a **new branch directly in the original repo** and update content from the backend. Then we make a PR from that new branch to \`main\`.

- **Challenge:** Figuring out the cleanest flow with the least frontend involvement.  
  **Solution:** Used the backend to handle metadata extraction, branch creation, commit, and PR creation automatically, so the frontend only needs to pass minimal data.

---

## Key Learnings

- Understood GitHub's limitations when working with forks in the same organization.
- Learned how to manage pull request creation with custom branches and automated commits.
- Improved backend architecture by centralizing logic and reducing frontend responsibility.

---

### An interesting problem to solve

Currently, since all project repositories (original and forks) are created under the same GitHub organization using a central GitHub App, all commits and pull requests appear to be made by the original repo,and since our setup is such that we create Pull request through a branch in the original repository (We cannot do that from a repo in the same org account) we cannot keep a track of which fork's commit was merged. 

Workaround

As a workaround, fork project's details can now be stored in the \`metaData.json\` of each forked project. When viewing pull requests via the custom route, this data can be used to show who contributed what.


## Next Week's Roadmap

- **Start frontend development**: Add interfaces for users to view, submit, and merge pull requests.
- Add UI indicators for forked projects and pull request status.
- Improve display of \`projectData\` in pull request previews.

---

## Resources & References

- **GitHub PR API Docs:** [docs.github.com/rest/pulls](https://docs.github.com/en/rest/pulls/pulls)
- **Octokit REST Library:** [github.com/octokit/rest.js](https://github.com/octokit/rest.js)
- **Backend Repo:** [musicblocks-backend](https://github.com/benikk/musicblocks-backend)

---

## Acknowledgments

Big thanks to my mentors and the Sugar Labs community for their guidance and patience. Also grateful to GitHub’s documentation which helped solve tricky API issues.

---
`,vs=Object.freeze(Object.defineProperty({__proto__:null,default:hn},Symbol.toStringTag,{value:"Module"})),gn=`---
title: "GSoC '25 Week 3 Update by Safwan Sayeed"
excerpt: "AST to IR Compilation Logic and Pseudocode Implementation"
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "2025-06-22-gsoc-25-sa-fw-an-week3"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week3,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 3 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-16 - 2025-06-22  

---

## A Blog-style Retrospective

This week marked a significant milestone in our Music Blocks program engine development as we transitioned from the foundational memory architecture to the core compilation logic. The focus shifted to implementing the AST-to-IR (Intermediate Representation) translation layer - the crucial bridge between our abstract syntax tree representation and executable code.

The challenge was designing a static compilation system that converts AST nodes into a linear sequence of IR instructions, following the three-address code format. Working with complex expression hierarchies and statement blocks required careful consideration of instruction ordering and variable management.

Our mentors provided invaluable guidance on maintaining the static nature of the compilation process, emphasizing that we're translating program structure rather than executing runtime calculations. This distinction was crucial for keeping our implementation focused and efficient.

---

## Goals for This Week

- Complete the AST-to-IR compilation logic technical specification with detailed pseudocode patterns.
- Implement evaluate() methods for all expression classes returning instruction lists.
- Develop pseudocode for simple statements following the established IR generation patterns.
- Design the instruction chaining mechanism for complex nested expressions.

---

## This Week's Highlights

1. **IR Compilation Logic Specification**  
   - Expanded the tech spec with comprehensive AST-to-IR translation documentation covering expression and statement compilation patterns.
   - Detailed instruction list generation requirements and variable management strategies.
   - Link: [IR Compilation Logic](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.i655udul8zuq)

2. **AST-to-IR Pseudocode Implementation**  
   - Implemented evaluate() methods for all expression classes (Literal, Binary/Unary Operators, Arrays, Dictionaries, etc.)
   - Developed instruction list generation patterns following three-address code format
   - Created symbol table integration using sym_query, sym_declare, and sym_assign operations
   - Link: [Tech Spec Document - AST to IR Methods](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.87123fra3s4#heading=h.gqjcwrtkdgvq)

3. **Simple Statements Compilation Logic**  
   - Implemented pseudocode for VariableDeclarationStatement, VariableAssignmentStatement, FunctionCallStatement, and JumpStatement
   - Established parameter passing patterns for evaluate() methods ensuring proper instruction dependency chains

---

## Challenges & Solutions

- **Understanding Static vs Runtime Compilation:**  
  Initially confused about whether we were performing runtime calculations or static code translation.  
  *Solution:* Mentors clarified that this is purely static AST-to-IR conversion with no runtime execution, helping focus the implementation approach.


---

## Key Learnings

- Mastered the distinction between static compilation and runtime execution in compiler design.
- Gained deep understanding of three-address code generation and instruction dependency management.
- Enhanced skills in designing clean pseudocode patterns that can be translated to actual implementation.
- Learned the importance of maintaining consistent parameter passing patterns across class hierarchies.

---

## Next Week's Roadmap

- Implement pseudocode for compound statements.
- Design basic block generation logic for control flow structures.
---

## Resources & References

- **Tech Spec:** [IR Compilation Logic](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.i655udul8zuq)  
- **Tech Spec:** [AST to IR Methods](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.87123fra3s4#heading=h.gqjcwrtkdgvq)
- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their crucial guidance on compiler design principles and static compilation concepts. Their clarification on the AST-to-IR translation approach and emphasis on maintaining clean instruction generation patterns was essential for this week's successful progress.

---`,Ss=Object.freeze(Object.defineProperty({__proto__:null,default:gn},Symbol.toStringTag,{value:"Module"})),mn=`---
title: "GSoC ’25 Week 03 Update by Diwangshu Kakoty"
excerpt: "AI with Reasoning Capabilities"
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "2025-06-22-gsoc-25-diwangshu-week03"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week03,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-06-15 - 2025-06-21  

---

## Goals for This Week

- **Goal 1:** Implement streaming response by LLM.
- **Goal 2:** Improve context passing for project code.
- **Goal 3:** Experiment and test different Gemini models and their capabilities.
- **Goal 4:** Fix bugs occured by these changes.
- **Goal 5:** Test the multi-agent chat model.

---

## This Week’s Achievements

1. **Implemented streaming response by LLM**  
   - I have implemented streaming responses from the LLM. This allows the model to send partial responses as they are generated, which is particularly useful for long responses. The implementation is straightforward and works well with the current setup.

2. **Improved context passing for project code**  
   - As mentioned in the last report, the retrieved context was not particularly useful when passing project code. 

   - I have improved this by scanning all keywords (like block names) first and passing their information to the LLM. This data is stored in a dictionary, which allows the LLM to understand the block structure and their meanings better.

3. **Experiment and test different Gemini models and their capabilities**  
   - I have experimented with various Gemini models, including \`gemini-1.5-flash\`, \`gemini-2.0-flash\`, \`gemini-2.0-flash-lite\` and \`gemini-2.5-flash\`. 

   - The most interesting one is \`gemini-2.5-flash\`, because of its 'thinking' capability. I did not know that Gemini models had this feature. The 'thinking' capability provides quality responses by breaking down complex queries into smaller, manageable parts. This could be very useful for the LLM to understand the project code or any other complex queries.  
   
   - The RPM (Requests per minute) of \`gemini-2.5-flash\` is 10 and TPM (Tokens per minute) is 250,000. When 'thinking\` is enabled a different token is used called 'thinking token'. We can specify the number of thinking tokens to be used or it can be set to auto. Threrefore, the thinking capability should be used for complex queries only, as it consumes more tokens and is slower than the regular response.

---

## Challenges & How I Overcame Them

- **Challenge :** I am trying to implement the 'thinking' capability of the Gemini model, but I am facing some issues with the response format. The model is not returning the expected structured response when 'thinking' is enabled. Their are not many resources on this topic.

  **Solution:** I found that the official Gemini documentation is the best resource for understanding how to implement this feature. I am currently working on it and hope to resolve the issue soon.

---

## Key Learnings

- I have realised one thing for sure, that a developer has to rely on the official documentation of any technology or library they are owrking on. As a student I often tend to look for tutorials or blog posts, but they are not always reliable or up-to-date. The official documentation is the most accurate and comprehensive resource.

---

## Next Week’s Roadmap

- Work on things suggested by mentors. This could include:
  - Improving the multi-agent chat model.
  - Testing the multi-agent chat model with different Gemini models.
- Discuss with mentors about the 'thinking' capability of the Gemini model. On what kind of queries it can be used.
- Implement the 'thinking' capability in the multi-agent chat model.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Is=Object.freeze(Object.defineProperty({__proto__:null,default:mn},Symbol.toStringTag,{value:"Module"})),pn=`---
title: "GSoC’25 Week 03 Update by Om Santosh Suneri"
excerpt: "To Develop a Basic RAG Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "2025-06-22-gsoc-25-omsuneri-week03"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week03,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-15 - 2025-06-21

---

## Goals for This Week

- **Goal 1:** Deploy the AI-Powered Debugger App to a Cloud Hosting Platform
- **Goal 2:** Create Embeddings from Music Blocks Project Text Representations  
- **Goal 3:** Improve LLM Response Language for Kids and Junior Learners  

---

## This Week’s Achievements

1. **Deploy the AI-Powered Debugger App to a Cloud Hosting Platform**  
   - This week, I successfully deployed the AI-Powered Debugger application on Streamlit Cloud, making it publicly accessible to anyone interested in testing it. The deployment process included optimizing the app structure for cloud compatibility, setting up environmental variables securely, and ensuring a smooth user experience. The live deployment now allows users—especially educators, learners, and developers—to interact with the debugger without needing to set up anything locally.
   - Making the debugger accessible via the web marks a major step in making AI tools more usable and available to the community. It enables initial-stage testing by real users, which is essential for collecting feedback and observing how the debugger performs across different user behaviors. This helps build a feedback loop that will guide future improvements and robustness of the tool, making it more valuable in the long term.

2. **Create Embeddings from Music Blocks Project Text Representations**  
   - After performing some minor improvements to the Music Blocks JSON-to-text converter, I selected 14 representative projects from the Music Blocks examples directory. These projects span across a range of tags and categories—such as music composition, transcription, games, utilities, and miscellaneous projects. I then generated vector embeddings for the textual representations of these projects and stored them in a Qdrant vector database cluster.
   - These embeddings serve as the foundation for teaching the LLM about the structure and semantics of real-world Music Blocks projects. By creating a searchable knowledge base of real examples, we are equipping the LLM with contextual understanding of how blocks are logically connected and used in different domains. This will significantly improve the LLM’s ability to understand, explain, and debug Music Blocks code based on actual use cases, making it more intelligent and helpful in practice.

3. **Improve LLM Response Language for Kids and Junior Learners**  
   - To make the debugger more inclusive and approachable for younger audiences, I updated the LLM prompt with additional guidance that instructs the model to assume the user is a child or junior learner. This involved reworking how queries are framed when sent to the LLM, prompting it to respond in a simpler, clearer, and more encouraging language style suitable for kids.
   - Music Blocks is widely used in educational environments, especially among school-age children learning to code. By making the language of AI responses more kid-friendly, we ensure that young learners can better understand and learn from the debugger’s suggestions. This step plays a key role in increasing the educational value, accessibility, and inclusivity of the project, ultimately making learning more fun and effective for our target audience.

---


## Challenges & How I Overcame Them

- **Challenge:** Improving ingest.py to Create Embeddings Efficiently  
  **Solution:** I enhanced the ingest.py script to process the improved text representations generated from various Music Blocks projects. I created and configured a Qdrant cluster to store the generated embeddings. This allowed me to index 14 representative projects across different categories. The modified script now supports smoother ingestion of data into Qdrant, and the embeddings are successfully retrievable for use by the LLM. This improvement lays the foundation for more intelligent, context-aware search and reasoning by the debugger.

- **Challenge:** Handling Environment Variables in Streamlit Cloud  
  **Solution:** After some thorough research and trial-and-error, I realized that Streamlit Cloud requires environment variables to be set via their Secrets Manager, not directly via .env files or code. I restructured the way the debugger reads sensitive values like API keys, moving everything into Streamlit's secure secrets.toml configuration. Once set properly, the application worked as expected in the cloud environment. This not only solved the deployment issue but also ensured better security practices moving forward.

---

## Key Learnings

- Deploying the AI debugger to Streamlit Cloud taught me the importance of environment-specific configurations, especially handling environment variables securely using platform-specific methods like Streamlit’s Secrets Manager. It highlighted how even small deployment details can significantly impact the usability and accessibility of an application.
- Creating embeddings from Music Blocks project representations and integrating them into a Qdrant vector database deepened my understanding of how LLMs can be enhanced with contextual knowledge. I also learned how to structure data ingestion pipelines effectively for scalable and meaningful semantic search.
- Tweaking the LLM prompt to generate child-friendly responses helped me appreciate the importance of audience-aware design in educational tools. It reinforced the idea that technology should be not just functional, but also inclusive, approachable, and aligned with the learning level of its users.

---

## Next Week’s Roadmap

- Integrate the JSON convertor directly into the Debugger Streamlit app 
- Testing the Debugger with Intensive Prompting
- Improving the Quality of LLM Responses

---

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,As=Object.freeze(Object.defineProperty({__proto__:null,default:pn},Symbol.toStringTag,{value:"Module"})),bn=`---
title: "GSoC '25 Week 03 Update by Saumya Shahi"
excerpt: "This week focused on implementing a comprehensive brick tree model with hierarchical connections, graph-like notch connections, and robust tree management for the Masonry module."
category: "DEVELOPER NEWS"
date: "2025-06-21"
slug: "2025-06-21-gsoc-25-saumya-shahi-week03"
author: "@/constants/MarkdownFiles/authors/saumya-shahi.md"
tags: "gsoc25,sugarlabs,week03,saumya-shahi"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Saumya Shahi

**Project:** [Masonry Module - Music Blocks v4](https://github.com/sugarlabs/musicblocks-v4)  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-15 – 2025-06-21  

---

## Goals for This Week

- Design and implement a comprehensive brick tree model for managing hierarchical connections
- Implement connection validation based on brick types and notch availability
- Create robust tree management with proper merging and splitting behavior
- Develop comprehensive test coverage for all tree operations

---

## This Week's Achievements

### 1. **Comprehensive Brick Tree Model Implementation**

Developed a \`BrickTreeManager\` class that handles:
- **Tree Structure Management**: Each tree has a unique ID that changes when connections/disconnections occur
- **Hierarchical Connections**: Parent-child relationships where disconnecting a parent keeps children connected
- **Connection Validation**: Ensures bricks can only connect if their notches are compatible and available

### 2. **Advanced Connection System**

Implemented a dual connection approach:
- **Top-Bottom Connections**: Hierarchical parent-child relationships
- **Left-Right Notch Connections**: Graph-like where bricks connect only if their right and left notches are free
- **Nested Notch Support**: Support for complex nested brick structures
- **Connection State Tracking**: Real-time tracking of which notches are occupied or available

### 3. **Tree Management**

Created tree operations:
- **Tree Merging**: When bricks connect, their respective trees merge into a single tree
- **Tree Splitting**: When bricks disconnect, new trees are formed preserving child relationships
- **Hierarchical Disconnection**: Disconnecting a parent preserves child connections and forms new trees
- **UUID Management**: Each brick has a unique UUID, and trees have dynamic IDs that change with connections

### 4. **Comprehensive Test Suite**

Developed extensive test coverage including:
- **Connection Tests**: Validating proper tree merging when bricks connect
- **Disconnection Tests**: Ensuring correct tree splitting behavior
- **Hierarchical Tests**: Testing parent-child relationship preservation
- **Notch Validation Tests**: Verifying connection rules based on notch availability
- **Edge Case Tests**: Handling complex scenarios with multiple connections

### 5. **Type Safety and Validation**

Enhanced the type system with:
- **Brick Type Definitions**: Clear interfaces for Simple, Expression, and Compound bricks
- **Connection Validation**: Type-safe connection checking based on brick types
- **Notch Compatibility**: Validation ensuring only compatible notches can connect
- **Error Handling**: Comprehensive error handling for invalid operations

---

## Technical Implementation Details

### Brick Tree Structure
\`\`\`typescript
interface BrickTree {
  id: string;
  bricks: Map<string, Brick>;
  connections: Map<string, Connection>;
  rootBricks: Set<string>;
}
\`\`\`

### Connection Types
- **Hierarchical Connections**: Top-bottom parent-child relationships
- **Notch Connections**: Left-right graph-like connections
- **Nested Connections**: Complex nested brick structures

### Key Features
- **Automatic Tree ID Generation**: Trees get new IDs when connections change
- **Connection Validation**: Ensures only valid connections are allowed
- **Hierarchical Preservation**: Child relationships are maintained during disconnections

---

## Challenges & How I Overcame Them

### Challenge 1: Hierarchical vs Graph-like Connections
**Problem**: Balancing hierarchical parent-child relationships with graph-like notch connections was complex.
**Solution**: Implemented a dual connection system where hierarchical connections manage the tree structure, while notch connections provide the visual puzzle-like behavior.

### Challenge 2: Tree Splitting Logic
**Problem**: Ensuring that disconnecting a parent brick correctly preserves child relationships and forms new trees.
**Solution**: Developed a algorithm that traverses the tree structure, identifies connected components, and creates new trees while maintaining all valid connections.

### Challenge 3: Connection Validation
**Problem**: Ensuring that bricks can only connect when their notches are compatible and available.
**Solution**: Created a comprehensive validation system that checks notch types, availability, and compatibility before allowing connections.

### Challenge 4: Test Coverage
**Problem**: Creating comprehensive tests for complex tree operations and edge cases.
**Solution**: Developed a systematic testing approach covering all major operations, edge cases, and error conditions with clear test descriptions.

---

## Key Learnings

- **Tree Data Structures**: Deep understanding of tree management, merging, and splitting operations
- **Graph Theory**: Applied graph concepts for notch-based connections
- **Type Safety**: Enhanced TypeScript skills with complex type definitions and validation
- **Testing Strategies**: Learned systematic approaches to testing complex data structures
- **Algorithm Design**: Developed algorithms for tree traversal and component identification

---

## Code Quality Improvements

- **Comprehensive Documentation**: Added detailed JSDoc comments for all public methods
- **Type Safety**: Enhanced TypeScript interfaces and type checking
- **Test Coverage**: Achieved high test coverage with edge case testing

---

## Next Week's Roadmap

- **Visual Tree Rendering**: Implement visual representation of the brick tree structure
- **Palette Creation UI**: Create palette interface for rendering list of all bricks
- **Performance Optimization**: Optimize tree operations for large brick structures
- **Integration Testing**: Test the tree model with the existing brick rendering system

---

## Resources & References

- **Tree Data Structures**: [MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Working_with_Objects)
- **TypeScript Advanced Types**: [TypeScript Handbook](https://www.typescriptlang.org/docs/handbook/advanced-types.html)
- **Testing Complex Data Structures**: [Jest Documentation](https://jestjs.io/docs/getting-started)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their guidance and support. Special thanks to the community for providing valuable feedback on the tree model design and implementation.

---
`,Ts=Object.freeze(Object.defineProperty({__proto__:null,default:bn},Symbol.toStringTag,{value:"Module"})),fn=`---
title: "SSoC ’25 Week 03 Update by Muhammad Haroon"
excerpt: "Experimenting with temperature and top_p parameters in AudioGen model."
category: "DEVELOPER NEWS"
date: "2025-06-22"
slug: "2025-06-22-ssoc-25-MuhammadHaroon-week03"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week03,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 03 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-16 - 2025-06-22  

---

## Goals for This Week

- **Goal 1:** Generate more samples using AudioGen and save them in Google Drive.
- **Goal 2:** Experiment with temperature and top_p parameters in AudioGen.

---

## This Week's Achievements

1. **Generated more samples using AudioGen model**  
   - I was able to generate more samples from AudioGen model and saved them in [Google Drive](https://drive.google.com/drive/folders/10UZzts_AuIe1AypJm9v4ll0NQ0tdkHEI?usp=drive_link).

2. **Experimented with different values of temperature and top_p**  
   - I created a [Google Sheet](https://docs.google.com/spreadsheets/d/1tFjL4bXAyB-Z7Fxj4cqiS4_pRkAGo3gKgs-CZVmkFYk/edit?gid=0#gid=0) where I experimented with generating sound samples using different temperature and top_p values. By recording the results, I was able to determine which parameter settings produce more meaningful sound samples.

---

## Key Learnings

- I gained an understanding of the key parameters temperature and top_p, which are used to tune the output for specific use cases. This [article](https://medium.com/@1511425435311/understanding-openais-temperature-and-top-p-parameters-in-language-models-d2066504684f) was helpful in understanding these concepts.

---

## Next Week's Roadmap

- To further explore the effects of the temperature and top_p parameters.
- To find an effective method for removing silence and noise from the audio.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Ps=Object.freeze(Object.defineProperty({__proto__:null,default:fn},Symbol.toStringTag,{value:"Module"})),wn=`---
title: "DMP ’25 Week 03 Update by Harshit Verma"
excerpt: "Week 3 focused on refining the AI prompt for better debugging suggestions, exploring UI ideas for displaying tips, and testing Sugar AI integration with Pippy."
category: "DEVELOPER NEWS"
date: "2025-06-23"
slug: "2025-06-23-dmp-25-therealharshit-week02"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week03,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-16 - 2025-06-22   

---

## Goals for This Week

- **Goal 1:** Refine the base prompt for debugging tips.
- **Goal 2:** Explore multiple UX approaches for displaying debug output.
- **Goal 3:** Test Sugar AI integration with Pippy.

---

## This Week’s Achievements

1. **Refine the base prompt for debugging tips**  
   - Refine the base prompt sent to the AI model to make debugging suggestions clearer and more relevant.
   - Iterated by testing different wording styles and instruction formats, which led to noticeably better model output.

2. **Explore multiple UX approaches for displaying debug output**  
   - Considered multiple UX designs for displaying debug tips, such as:
     * **Inline** messages near code lines.
     * A **side panel** exclusively for displaying suggestions..
     * A **Dedicated Debugging Terminal** for interactive debugging.
   - Evaluated each method in terms of ease of integration, readability, and user experience.
   - Concluded that a dedicated debugging terminal offers the best balance of usability and flexibility.
   - Plan to design a UI mockup for this approach in the upcoming week.

3. **Test Sugar AI integration with Pippy**  
   - Successfully tested the connection between Pippy and Sugar-AI.
   - Verified that the Python code written in Pippy is extracted correctly, sent to the /ask-llm endpoint, and the response is generated.

---

## Challenges & How I Overcame Them

- **Challenge:** Crafting prompts that consistently lead to relevant and useful debugging suggestions.  
  **Solution:** Studied prompt engineering best practices and experimented with structure, examples, and explicit instructions to guide the model better.

- **Challenge:** Deciding how to present debug output in a child-friendly and non-intrusive way.  
  **Solution:** Brainstorm some UI ideas, reviewed how other tools display feedback, and consulted with mentors on what would best align with the Sugar UX philosophy.

---

## Key Learnings

- Gained deeper insight into prompt engineering and its impact on LLM output quality.
- Developed a design-focused mindset for user-centric debugging tools.

---

## Next Week’s Roadmap

- Plan to design a UI mockup for debugging terminal.
- Implement a first version of the debug output inside Pippy.
- Collect feedback from mentors on debug message placement and design.

---

**Note:** This week, I was mostly away from the keyboard, so I couldn’t dedicate as much time to coding as usual.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,Ms=Object.freeze(Object.defineProperty({__proto__:null,default:wn},Symbol.toStringTag,{value:"Module"})),yn=`---
title: "GSoC '25 Week 03 Update by Shubham Singh"
excerpt: "Mapped Music from Synthutils to LegoBricks. Completed LegoBricks Wdiget UIs"
category: "DEVELOPER NEWS"
date: "2025-06-25"
slug: "2025-06-25-gsoc-25-firepheonix-week03"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week02
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 3 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-16 – 2025-06-22 

---

## Goals for This Week

- Complete UIs for image upload, webcam integration to Music Blocks.
- Integrating audios from Synth Sampler to LegoBricks widget.
- Researching existing audio integration patterns in the phrase maker and note blocks.

---

## This Week's Achievements

1. **Complete Image upload facility into Lego Bricks Widget.**  
   - Integrated image upload support within the LegoBricks widget, enabling external image input directly on the Music Blocks canvas.
   - Created a new block type by modifying six core files across the codebase.
   - The codebase proved beautifully encapsulated and thoroughly documented, making the learning curve smoother.
        ![Completed UIs](https://i.ibb.co/39pZpDGv/Music-Blocks-Google-Chrome-28-06-2025-07-13-38.webp)

        ![Putting images on lego bricks widget](https://i.ibb.co/203Mjsdk/Music-Blocks-Google-Chrome-28-06-2025-07-14-47.webp)

2. **Real-time Video Integration**  
   - Implemented real-time video functionality through webcam integration.
   - Enabled real-time video streaming, with support for dynamic canvas manipulation and block interaction.
   - Made grided interface for addition of both image and webcam. Made changes for adjusting.

        <iframe width="800" height="400" src="https://www.youtube.com/embed/HG6C0ZX7QRA?si=OIGvtD4qpwxMmb8W" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

3. **Addition of music notations to Lego Bricks widget**  
   - Researched about where audio samples lie.
   - Deep-dived into Phrase Maker, Synth Sampler widget documentation and codebase.
   - Applied music samples to Music Blocks.

        <iframe width="800" height="400" src="https://www.youtube.com/embed/PwuPtACP8WM?si=NpfkLI-4SUVkVeU7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---

## Challenges & How I Overcame Them

- **Challenge:** Music Blocks didn't have any code for integrating webcam video on to the Music Blocks interface.
**Solution:** Researched some stack overflow resources and added the webcam video on to the legobricks widget canvas.
- **Challenge:** Finding out where the SVGs and existing phrase maker and synthsampler audio files lie.
**Solution:** Asked my mentor, Walter Bender in Wednesday's meet. Saw some previous PRs inside of music blocks itself, related to phrase maker, related to synth sampler.

---

## Key Learnings

- Gained comprehensive understanding of **synth utils** and how **music samples are being exported to other blocks**
- Deepened appreciation for **code architecture** including inheritance patterns, code modularity, and custom return types within the Music Blocks ecosystem.
- Improved skills in **development workflow** including exports, imports, code reusability, documentation practices, and collaborative development workflows.

---

## Next Week's Roadmap

- Implement complete Core Implementation of Scanning the Lego Blocks image on the X-axis.
- Next to Next week -> Test for shadow handling
- Focus on algorithmic challenges for note-to-color mapping system.

---

## Resources & References

- **Project Issue:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)
- **Music Blocks Repository:** [sugarlabs/musicblocks](https://github.com/sugarlabs/musicblocks)
- **Documentation:** Music Blocks Developer Guide

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Special thanks to Walter. A lot of code of Music Blocks was written by Walter, he has a very good knowledge of this code base. Can completely rely on him for help. He also helped this week as well.

---`,Cs=Object.freeze(Object.defineProperty({__proto__:null,default:yn},Symbol.toStringTag,{value:"Module"})),kn=`---
title: "DMP ’25 Week 4 Update by Aman Naik"
excerpt: "This week focused on building a basic UI for the chatbot within Sugar and implementing a book recommendation system using the Google Books API."
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-22-dmp-25-AmanNaik-week04"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week04,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 4 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-06-22 – 2025-06-28  

---

## Goals for This Week

- **Goal 1:** Create some UI to test the demo chatbot inside Sugar  
- **Goal 2:** Develop a book recommendation feature for the demo application  

---

## This Week’s Achievements

1. **Built a Basic Chatbot UI Inside Sugar**  
   - Created an initial UI within Sugar using the demo logic from the Streamlit version as reference.  
   - Implemented a basic sidebar within the activity that allows students to converse with the chatbot while simultaneously viewing the story context.  
   - The framework generated from the conversation is currently being saved as a JSON file. UI for displaying the framework is still under development and will be added later.

   ![User interface(sidebar) and AI generated responses](assets/Images/aman-naik-week4-img1.webp)

2. **Implemented Book Recommendation Feature**  
   - Integrated the Google Books API to recommend the top 3 similar books based on the conversation with the AI assistant.  
   - The goal is to inspire children by connecting their creative stories with real-world books.  
   - Based on mentor feedback, I will prioritize refining the chatbot and story framework builder before expanding the recommendation feature.

   ![Book recommendations based on the conversation fro streamlit demo](assets/Images/aman-naik-week4-img2.webp)
   
---

## Challenges & How I Overcame Them

- **Challenge:** Integrating the chatbot into Sugar and dealing with GTK  
  **Solution:** As I had limited experience with GTK, I faced difficulties while setting up the interface. Additionally, the initial setup used Groq's SDK, which wasn’t compatible with Sugar. I refactored the code to use the \`requests\` module for calling Groq’s API instead, which made integration possible without extra dependencies.

- **Challenge:** Displaying the final story framework after clicking the "Create Framework" button  
  **Solution:** I’m currently working on UI design ideas to present the story structure in a child-friendly and intuitive way. I’ll be discussing different visual layouts with my mentors in the upcoming meeting to finalize a clear and engaging format.

---

## Key Learnings

**Integrated AI Chatbot Into Sugar's UI Framework**  
   - Learned how to work with GTK and adapt web-based chatbot logic into a desktop environment suitable for Sugar.

**Designed Book Recommendation Feature Using Google Books API**  
   - Built a feature that enriches the student’s experience by recommending related books based on the story they are writing.

**Improved Problem-Solving Skills While Debugging API and GTK Issues**  
   - Encountered real-world software integration issues and learned how to handle dependency mismatches and platform limitations effectively.

---

## Next Week’s Roadmap

- Finalize the UI for the story framework display  
- Focus on polishing the conversational flow of the AI assistant  
- Exploring LLM's to be used instead of Groq API for AWS integration  

---

## Acknowledgments

Grateful to my mentors, the Sugar Labs community, and fellow contributors for their continuous support and insightful suggestions throughout the week!

---
`,Ls=Object.freeze(Object.defineProperty({__proto__:null,default:kn},Symbol.toStringTag,{value:"Module"})),vn=`---
title: "GSoC ’25 Week 04 Update by Bishoy Wadea"
excerpt: "Soma Cube"
category: "DEVELOPER NEWS"
date: "2025-06-28"
slug: "gsoc-25-BishoyWadea-week04"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week04,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Bishoy Wadea

**Project:** [Soma Cube](https://github.com/Bishoywadea/Soma-Cube)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-06-22 - 2025-06-28 

---

## Goals for This Week

- **Goal 1:** Make Four Color map game pep8 compliant [#4 Make activity pep8 compliant](https://github.com/Bishoywadea/Four-Color-Map/issues/4)

- **Goal 2:** Start implementing Soma Cube game
---

## This Week’s Achievements

### *Goal 1: Fix Issues in Four Color Map Activity*

1. **Make Four Color map game pep8 compliant**  
   - commit: [Make main.py, activity.py PEP 8 compliant](https://github.com/Bishoywadea/Four-Color-Map/commit/45b2dd77e39a6d822d9d4ba0a12fbf1c31e1f04b)

---

### *Goal 2: Start implementing Soma Cube game*
1. **3D Environment & Controls**
    - Set up a 3D scene with movement and camera control.
    - commit: [add 3d space with cube](https://github.com/Bishoywadea/Soma-Cube/commit/c917f9d2af509cc4f405f9b72fe8d479e1f3f56f)
    - commit: [add wasd controls](https://github.com/Bishoywadea/Soma-Cube/commit/7dc779dbecd693794a2ae96f25ef3aa3dd174c83)

![Demonstration of 3D environment. You can zoom in and out and rotate.](https://i.postimg.cc/W4mpdVC6/01.gif)

2. **Soma Pieces & Core Mechanics**
    - Added the 7 pieces and enabled, rotation, and collision.
    - commit: [add the 7 basic pieces](https://github.com/Bishoywadea/Soma-Cube/commit/5ace6710608720ba05bad05df3dac26bbd1907e9)
    - commit: [add collision support](https://github.com/Bishoywadea/Soma-Cube/commit/9e1f60943b64718c4efc6deca1a0a077f1e94475)

![Demonstration of soma pieces. The various geometries are now in the 3D environment.](https://i.postimg.cc/9fsSHwJL/02.gif)

3. **Interaction & UI Elements**
    - Implemented help system, completion message, and on-screen controls.
    - commit: [add help button](https://github.com/Bishoywadea/Soma-Cube/commit/f00c1661fc94a9c29e3325c83c916d215a2b1c32)
    - commit: [add controls map on screen](https://github.com/Bishoywadea/Soma-Cube/commit/325d9197cedc5dfa6643382fcaf246b681201806)

4. **Texturing & Visuals**
    - Added textures for floor, sky, and Soma pieces with improved lighting.
    - commit: [add sky texture](https://github.com/Bishoywadea/Soma-Cube/commit/be08b1c314dccc7f0c984585a1ee19e27664ce89)
    - commit: [add texture for the 7 objects](https://github.com/Bishoywadea/Soma-Cube/commit/8b69f60a615037266dc2ae8e89d8ed09a231c1ea)

![Texture and other effects are now possible within the 3D model.](https://i.postimg.cc/zB1jkCdY/03-Conv-Gif.gif)

---

## Challenges & Solutions

- **Challenge:** Implementing precise snapping and collision for 3D puzzle pieces.  
  **Solution:** Designed a snapping algorithm with bounding box checks and added a collision detection system to prevent overlaps.

- **Challenge:** Enhancing the visual quality of the 3D scene.  
  **Solution:** Introduced floor, sky, and object textures; adjusted lighting and shadows for a more polished and immersive look.

- **Challenge:** Allowing intuitive piece manipulation with both keyboard and mouse.  
  **Solution:** Integrated context-aware WASD controls and mouse-based dragging/rotating mechanisms for smooth interaction.

- **Challenge:** Guiding users through gameplay without overwhelming them.  
  **Solution:** Added an on-screen control map, a help button, and a success message to support the player experience.

- **Challenge:** Maintaining code readability during rapid feature additions.  
  **Solution:** Regularly removed redundant code, followed PEP8 guidelines, and modularized logic for easier updates.

---

## Key Learnings

- Strengthened understanding of **3D graphics programming** using transformations, lighting, textures, and real-time rendering.
- Gained practical experience in **interactive puzzle game design**, including snapping mechanics, collision handling, and visual feedback.
- Improved skills in **UI/UX design for educational tools**, balancing usability, clarity, and visual appeal.
- Practiced clean coding habits with **modular design**, PEP8 compliance, and ongoing refactoring.
- Learned to integrate **multi-modal controls** (keyboard + mouse) for intuitive 3D manipulation.


---

## Next Week’s Roadmap

- Fix any feedback provided by members of the organization.  
- Start implementing the 16-puzzle game.
---
`,xs=Object.freeze(Object.defineProperty({__proto__:null,default:vn},Symbol.toStringTag,{value:"Module"})),Sn=`---
title: "GSoC '25 Week 4 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates"
category: "DEVELOPER NEWS"
date: "2025-06-28"
slug: "2025-06-28-gsoc-25-Elwin-Li-week04"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week4,javaScript editor"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 4 Progress Report by Elwin Li

**Project:** [Advanced JavaScript Editor with MusicBlocks Interactions](https://github.com/sugarlabs/musicblocks/tree/config_driven_conversion/elwin)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-06-21 - 2025-06-28

---

## Goals for This Week

- **Goal:** Complete the debugger project

---

## This Week’s Achievements

**Reworked Status Block for Debugger Tool**

The main goal of this week was to work out difficulties with the status block and status matrix in regards to the debugger tool. There has been many pivots in terms of the UX design, and it is now going in a cleaner direction.

How the debugger tool currently works:
- The user can set debugger statements either through the debugger block itself, or adding breakpoints in the JSeditor and converting to blocks.
- The user can now begin debugging through one of three methods:
  - Run slowly button
  - Run step by step button
  - Clicking on a block itself (e.g. an action block)
- This will run the blocks and pause at the debugger block(s)
- The user can then choose to inspect variables by dragging out a status block
  - The status block will be automatically prepopulated by all the custom variables that are used in the users code
  - The status window will also automatically pop up and show the user their variables

**Small UI fixes**
- I made it so that block highlighting only highlights the current block being executed, for easier code tracing when using run slowly or run by step.
- I made debugger blocks have no effect when using the normal play button, since that's for a finished product, but it will pause execution when ran slowly, by step, or a user manually runs a stack of blocks
- Changed behavior of manually clicking on blocks to run it default to run slowly, as it is for debugging purposes.
- Fixed bug where execution will continue even if you change/delete blocks

---

## Challenges & How I Overcame Them

- **Challenge:** Having a "debug mode" was not a clean solution

  **Solution:** Instead of having a "debug mode", we now distinguish in terms of the play buttons, with the run slowly and run by step buttons being meant for debugging

- **Challenge:** Status block doesn't work as intended, and dragging a status block manually behaves differently from the one triggered by the debugger block. There could also be multiple status blocks at the same time, which messed up the status window.

  **Solution:** Constrained the maximum number of status blocks to one, and updated the logic for all status blocks to automatically include the custom variables in the blocklist.

---

## Key Learnings

- Improved skills in UX design and keeping tools simple for the user
- Deepened understanding of how music blocks execution works
- Deepened understanding of how the blocks are designed and the whole flow of a block
- Improved skills in **debugging**, **code design**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Complete and deploy debugger project
- Add syntax highlighting to JSeditor code

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Gs=Object.freeze(Object.defineProperty({__proto__:null,default:Sn},Symbol.toStringTag,{value:"Module"})),In=`---
title: "GSoC '25 Week 4 Update by Krish Pandya"
excerpt: "Python Library Graphics "
category: "DEVELOPER NEWS"
date: "2025-06-28"
slug: "2025-06-28-gsoc-25-mostlyk-week04"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week04,mostlyk"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 4: Development on the Python Library

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)

**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)

**Reporting Period:** June 21, 2025 till June 28, 2025

---


## Style , MenuItem and Changes

I seem to have missed updating about the Python start on the last week's blog.
This week has 2 videos and less of text! Sorry about that , I will try to summarize the video trascripts for my beloved reading enthusiasts.

<iframe width="560" height="315" src="https://www.youtube.com/embed/OD1PBOK3g94?si=NT8wfgk7UkQt6gxl" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

This short video covers the initial Python layout and CI pipeline. I’ve structured the repo cleanly:

- \`make ci-test\` now runs a clean, install, test and build.
- Removed the linting stage since we're not enforcing strict import ordering (consistent with GTK3’s sugar-toolkit style). So it is always going to fail on the top import, but I have kept the formatting check!.
- Wheel gets built automatically , and is stored inside \`dist/\`. Following this we can also build tar using \`make tarbell\`, also stored inside \`dist/\`.

On the graphics front, I wired up a base activity with \`XOColors\`, and a simple close button. This will expand soon as more components are added.
I'm planning to move forward with alert icons, styled windows, and the tool bar to give our activities the "sugary" look.

> So that was written on Sunday (22nd) and while at the time of writing some more things are added mentioned and demoed in the next video!.


I urge you to go to [sugar-toolkit-gtk4-py](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)'s README as it also has a quick start activity which you can directly bump up. Cheers!

And the next video which is a bit long (_6 mins_) where I talk about what I did this week is:

<iframe width="560" height="315" src="https://www.youtube.com/embed/-WTojjHpQLs?si=m0msTtsXOvzDTTP-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

This longer video goes into the real dev work of the week.

- Fixed deprecated API usage in styles by warning users when they try to use old GTK3-style methods, and re-routing to the newer alternatives. I have shown this in video specifically.
- Built a \`MenuItem\` wrapper that supports icons, keyboard accelerators, as used \`Gtk.Button\` rather than \`GtkImageMenuItem\`  which is deprecated.
- On styles, I added something more like \`primary\`, \`success\`, etc. The last section in style example shows this.
- Demonstrated accelerators (\`Ctrl+O\`, \`Ctrl+S\`, \`Ctrl+Q\`).  these are now working using the newer GTK4 shortcut handling instead of relying on \`GtkImageMenuItem\` and it's older signal.


## Sneak Peek & Road Ahead

Near around 3-4 min mark I started giving the sneak peeks haha, and take this as for the work of week 5-6, and let's see how fast it can be pushed. A bit rough, but fun stuff:

- Vertical tray widgets with clickable icons and buttons.
- Fullscreen and window information tools.
- Sugar artwork preview with randomized XO colors. ( sanity check if colors are working again v2)
- First version of the window and tray abstraction layers (some bugs but foundational).
- Starting experiments with \`Palette\`, \`Tray\`, and \`Toolbar\`.

This is the first time I'm actively trying to integrate things built in Week 3 and 4 into full activity flows.
The idea is to not just build features in isolation but make sure they cooperate.

Ideally I want to have some sort of more quick start activity which uses bunch of these Palettable, Toolbar, Style etc. to see everything in action.

## Resources & References

- Project Page – [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- New C Library - [sugar-ext repository](https://github.com/sugarlabs/sugar-ext)
- New Python Library - [sugar-toolkit-gtk4-py ](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- Active PR - [Establish C library base template with Meson for GTK4](https://github.com/sugarlabs/sugar-ext/pull/1)
- Sugar Toolkit Repository(original) – [sugar-toolkit-gtk3](https://github.com/sugarlabs/sugar-toolkit-gtk3)
- GTK4 Migration Guide – [docs.gtk.org/gtk4/migrating-3to4.html](https://docs.gtk.org/gtk4/migrating-3to4.html)


---

## Acknowledgments

Thanks to all the mentors whose guidance and support have been strong in helping me navigate the Port.
`,Ws=Object.freeze(Object.defineProperty({__proto__:null,default:In},Symbol.toStringTag,{value:"Module"})),An=`---
title: "DMP’25 Week 04 Update by Justin Charles"
excerpt: "Completed SVG path logic for all brick types and documented props and rendering states"
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-dmp-25-justin212407-week04"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week4,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 4 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)   
**Reporting Period:** 2025-06-22 - 2025-06-29  

---


## Goals for This Week

- Finalize SVG path logic for all three types of bricks  
- Categorize and document all props passed into bricks  
- Identify all visual states a brick can be rendered in  
- Differentiate props and states across brick types  
- Write comprehensive tests to verify correctness

---

## This Week’s Highlights

### 1. Brick Inventory Compilation

- Catalogued different distinct bricks across categories such as Rhythm, Tone, Flow, Graphics etc.  
- Created a centralized metadata list including notches, label types, and slot counts for each.

### 2. JSON Schema for Brick Types

- Authored a strict \`bricks-schema.json\` enforcing required fields like \`type\`, \`label\`, \`notches\`.  
- Validated all brick entries programmatically and corrected inconsistencies (e.g. naming errors and missing defaults).

### 3. Palette UI Implementation

- Built a dynamic React Palette UI that maps categories and bricks from the schema directly.  
- Enabled hover previews showing live-rendered brick paths and labels.  
- Schema-driven architecture allows zero-maintenance scalability.

📄 Reference: [Palette – Tab 6](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.2dd4jqek61qh#heading=h.nicqc6ugqkyy)

---

## Challenges & Solutions

**Challenge: Handling Bricks with Special Properties**  
Some bricks (e.g., compound or expression bricks) required special handling due to nested structures, variable slots, or dynamic notches.  
**Solution:** Added metadata flags to the brick definitions (e.g., \`hasNotchTop\`) and incorporated them into both the schema and UI logic.


**Challenge: Bricks with Ambiguous Labels or Duplicate Names**  
A few bricks had similar or identical display labels, which caused confusion in UI previews and JSON definitions. 
**Solution:** Assigned internal id fields distinct from display labels. The id ensures uniqueness in JSON and tests, while label stays user-friendly in the UI.

---

## Key Learnings

- Source-code scraping can outperform manual documentation in accuracy and speed.  
- JSON Schema offers powerful safeguards when used with validation tooling.  
- UI scalability improves drastically when tied to a schema-first approach.  

---

## Resources & References

- [Palette](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.2dd4jqek61qh#heading=h.nicqc6ugqkyy)  
- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  

---

## Acknowledgments

Thanks to my mentors for helping review the UI and desgin for the palette. Their early feedback made the path code significantly more robust and maintainable.

---
`,Ds=Object.freeze(Object.defineProperty({__proto__:null,default:An},Symbol.toStringTag,{value:"Module"})),Tn=`---
title: "DMP '25 Week 04 Update by Anvita Prasad"
excerpt: "Completion of target pitch mode and implementation of manual cent adjustments pie menu"
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-DMP-25-AnvitaPrasad-week04"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week04,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-23 - 2025-06-29  

---

## Goals for This Week
- Complete and refine target pitch mode implementation
- Implement manual cent adjustment functionality and interface
- Research icons for chromatic and target pitch mode
- Conduct comprehensive testing with various audio sources and instruments
- Research different tuning systems

---

## This Week's Achievements

1. **Dual-Mode Tuner Implementation**
   - Completed target pitch mode implementation with enhanced functionality
   - Integrated target pitch selector with pie menu interface
   - Implemented logic for precise pitch matching and deviation calculation
   - Added comprehensive display for octave, semitone, and cent deviations
   - Gathered and incorporated feedback for interface refinements

![](assets/Images/tuner-interface-week4.webp)

2. **Manual Cents Adjustment Development**
   - Designed and implemented an intuitive pie menu for cent adjustments with:
     - Center Area (Controls):
       * Grey circular area with three buttons
       * "+" button for positive values
       * "-" button for negative values
       * "×" button for menu exit
     - Inner Wheel (Fine Adjustments): Numbers 1-10
     - Middle Wheel (Medium Adjustments): Numbers 20-50
     - Outer Wheel (Large Adjustments): Numbers 60-100

3. **Testing Progress**
   - Conducted initial testing with various audio sources
   - Identified areas for improvement in pitch detection
   - Created a test suite for tuner accuracy verification

---

## Challenges & How I Overcame Them

- **Challenge 1: Event Bubbling in Pie Menu**  
  The pie menu's nested event listeners for note, accidental, and octave selection were triggering multiple unintended actions due to incorrect event propagation.  
  **Solution 1:**  
  Added event.stopPropagation() at the appropriate event handlers and restructured the event listener hierarchy to ensure events were captured at the correct level only.

- **Challenge 2: State Management Complexity**  
  Managing three interdependent states (note, accidental, octave) in the tuner widget led to synchronization issues and undefined states during updates.  
  **Solution 2:**  
  Implemented a centralized state update method that handles all three components atomically and validates the complete state before triggering any dependent calculations.

---

## Key Learnings

- Gained deep understanding of Music Blocks' pitch pie menu interface and its implementation patterns
- Learned about various tuning systems including Equal Temperament, Pythagorean, and Just Intonation

---

## Next Week's Roadmap

- Implement fully functional tuner with comprehensive features
- Complete and refine manual cent adjustment functionality
- Conduct extensive testing with various audio sources and instruments
- Consider implementation of different tuning systems
- Make fine refinements to tuner interface and functionality
- Write blog post for Week 05

---

## Resources & References

- [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [Different Tuning Systems](https://www.musiccrashcourses.com/lessons/tuning_systems.html)
- [Tuning Systems and Equal Temperament](https://www.earmaster.com/music-theory-online/ch06/chapter-6-2.html)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support and valuable feedback on the new features.

--- `,_s=Object.freeze(Object.defineProperty({__proto__:null,default:Tn},Symbol.toStringTag,{value:"Module"})),Pn=`---
title: "DMP ’25 Week 04 Update by Harshit Verma"
excerpt: "Developed a working prototype."
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-dmp-25-therealharshit-week04"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week04,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-23 - 2025-06-29   

---

## Goals for This Week

- **Goal 1:** Design a UI mockup for the debugging terminal.
- **Goal 2:** Develop the debugging terminal in Pippy.
- **Goal 3:** Connected the debugger LLM server with Pippy.
- **Goal 4:** Feed LLM responses into the debugging terminal.

---

## This Week’s Achievements

1. **Design a UI mockup for the debugging terminal**  
   - Plan the layout and user experience for how debug tips should appear inside Pippy.
   - Design the UI of the debugging terminal, prioritized clarity and accessibility, especially for children.

2. **Develop the debugging terminal in Pippy**  
   - Added a new Virtual Terminal Emulator (VTE) widget to Pippy using GTK.
   - Integrated the terminal into the existing layout with proper toggling between output and debug views.
   ![Pippy UI: Output Terminal](assets/Images/pippy_output-terminal.webp)
   ![Pippy UI: Debug Terminal](assets/Images/pippy_debug-terminal.webp)

3. **Connected the debugger LLM server with Pippy**  
   - Wired up Pippy to make API calls to the FastAPI server.
   - Verified complete flow: \`code is extracted → sent to /debug → response displayed in the debug terminal\`.

4. **Feed LLM responses into the debugging terminal**  
  - Successfully passed LLM-generated debug suggestions into the terminal.
  - Added simple formatting: newline, spacing, removed markdown syntax elements.
---

### Complete Demo: &nbsp; [Watch here](https://drive.google.com/file/d/1Dzomam9dc3U4tHjHhYFGjRbs7-cwJHmM/view?usp=drive_link)

---

## Challenges & How I Overcame Them

- **Challenge:** GTK app crashing on API call.  
  **Solution:** The crash was due to API response handling on the main GTK thread. I fixed it by offloading the network request to a separate thread using Python’s \`threading\` module and updating the UI safely with \`GLib.idle_add()\` to avoid blocking or GTK context violations.

- **Challenge:** Rendering formatted output inside the terminal widget.  
  **Solution:** GTK doesn’t support Markdown, so I simulated structure using spacing, and removed marksown syntax elements to enhance readability.

---

## Key Learnings

- Gained hands-on experience with Python threading to perform non-blocking API calls and prevent UI freezes or crashes.
- Learned how to work with GTK widgets and using CSS in GTK, especially Gtk.Stack, Gtk.Box, and VTE terminal building responsive interfaces.

---

## Next Week’s Roadmap

- Format the LLM response to be more child friendly.
- Develop a custom mardown parser for GTK.
- Begin working on model selection logic and performance optimization.

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger) : I have pushed my code for Pippy here.
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server) : The FastAPI server which I am using as of now.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,Es=Object.freeze(Object.defineProperty({__proto__:null,default:Pn},Symbol.toStringTag,{value:"Module"})),Mn=`---
title: "GSoC ’25 Week 04 Update by Mebin J Thattil"
excerpt: "A new voice for Speak & laying down pipelines"
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-gsoc-25-mebinthattil-week4"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week04,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-22 - 2025-06-29  

---

## Goals for This Week

- **Goal 1:** Integrate Kokoro into Speak  
- **Goal 2:** Create a pipeline to quickly quantize and run a model hosted on 🤗

---

## This Week’s Achievements

_Note: I was on leave this week till the 26th due to my final exams. But I still managed to do a bunch of cool stuff after that._

1. **Kokoro meets Speak - A new chapter**
   - One of the three major parts of my proposal was to integrate a more modern, natural-sounding TTS model into Speak.
   - I used Kokoro and integrated it with the activity.
   - We now have access to the entire catalog of voices that Kokoro comes with. This will be helpful for our idea of having different personas—each persona could have a different voice.
   - The current implementation of the code is a _rather hacky_ way of integrating Kokoro. I say this because the audio pipeline currently looks like this:  
     > Text → Kokoro → Outputs a temporary WAV file → Read by GStreamer → Audio output can be heard
   - This is not ideal for obvious reasons. We don't want Kokoro to save an audio file every time and then read from it again. This is slow because Kokoro has to process the entire text, convert it to a WAV, and then GStreamer has to read and output it. For smaller text inputs it's still fine, but it’s not optimal.
   - The better approach would be to have Kokoro stream the audio directly, which GStreamer can then stream and output. This would reduce perceived latency significantly. Kokoro currently does not have a function / API that works like this. I would have to make one.
   - But for now, this is just an initial implementation to get feedback from mentors and peers, optimization can come later.
   - Kokoro also uses the espeak-ng engine as a fallback. Since Speak already uses espeak, I’ll try to go under the hood and tweak Kokoro to use espeak instead. This would reduce additional dependencies.
   - Currently, I was able to get this working with just 125KB of additional dependencies.

Video demo:
<iframe src="https://drive.google.com/file/d/19oUe3oIlMIO_pFUHVZatR6uWP1u23oU7/preview" width="740" height="480" allow="autoplay"></iframe>

_Note that the recording has a slight echo, but that's the recordings issue, it sounds perfectly fine inside of speak._

2. **Quantization Pipeline**
   - This is fairly simple. I created a script that:
  > pulls a model hosted on 🤗 → sets up all local dependencies → quantizes the model → exports it as a GGUF → and uses a plugin script (model dependent) to run it in chat mode.
   - Currently, this works only for chat-styled models.
   - This was essential because we are fine-tuning foundational models, and after fine-tuning we get unquantized models. It doesn't make sense to benchmark these unquantized versions. We need to evaluate their performance post-quantization to truly understand their behavior.
   - This script could also be useful for other contributors training models intended to run locally.
   - The config for the script is shown below and can adjusted to match whichever model you intend to use:
     \`\`\`bash
     # Model Config

     MODEL_REPO="hfusername/modelname"
     GGUF_OUT="output_model_name.gguf"
     GGUF_QUANT="output_model_name-q4.gguf"
     N_CTX=2048
     BUILD_DIR="build"
     SAVED_DIR_NAME_HF="output_dir_name"
     \`\`\`
   - Another thing to note is the URL to the plugin inference script:
     \`\`\`bash
     RAW_URL="https://raw.githubusercontent.com/mebinthattil/template_llama_chat_python/main/chatapp.py"
     \`\`\`
   - This script tries to be OS agnostic, and attempts to detect which OS you're on to run commands accordingly. It’s not fully comprehensive yet, but it works well on macOS, as that’s the only platform I’ve tested it on.

---

## Next Week’s Roadmap

- Integrate the SLM into Speak  
- Test out different Kokoro voices  
- Lay the foundations for different personas and automatic voice selection  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,js=Object.freeze(Object.defineProperty({__proto__:null,default:Mn},Symbol.toStringTag,{value:"Module"})),Cn=`---
title: "GSoC '25 Week 04 Update by Nikhil Bhatt"
excerpt: "Integrated the frontend with the Git backend and enabled project creation, editing, and forking via the UI in MusicBlocks."
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-gsoc-25-nikhilbhatt-week04"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week04,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-06-22 – 2025-06-28  

---

## Goals for This Week

- Integrate the frontend with the backend Git routes.
- Enable project creation and editing via UI.
- Build a dashboard to list and manage all projects.

---

## This Week's Achievements

###  Frontend-Backend Integration

I created a dedicated branch in the MusicBlocks repo to begin integrating the Git backend routes.

- Created API calls to interact with the backend for:
  - Creating a new project.
  - Editing an existing one.
  - Forking a project.


###  Create & Edit Projects from UI

Users can now:

- Create new projects from the frontend.
- Edit and update existing ones.

This is made possible by sending project name and data to the backend, which handles Git commit and push operations.

---

###  Project Dashboard

Built a new page to display **all projects** (original and forked) in a list format.

Features include:

- “Open in MusicBlocks” to edit any project.
- “Fork” to create a copy with the current user as owner.
- Display of metadata like project name, fork status, and last updated time.

**All Projects Dashboard**
![All Projects Page](assets/Developers/Nikhil/project-dashboard.webp)

---

## Challenges & How I Solved Them

- **Challenge:** Avoiding Git complexity on the frontend.  
  **Solution:** All operations like branch creation, commits, and metadata updates are handled server-side. Frontend only triggers them.

- **Challenge:** Keeping fork lineage visible.  
  **Solution:** Stored original repo metadata inside \`metaData.json\` of each fork.

---

## Key Learnings

- How to bridge frontend interfaces with a Git-based backend.
- Improved UI/UX by keeping it simple, made it similar to existing planet page for students to learn.

---

###  Fun Debug Moment

Accidentally forked a fork of a fork and ended up with a hilarious recursive repo tree.  
But it confirmed my fork metadata system worked perfectly across multiple levels!

---

## Next Week's Roadmap 

- Build UI to submit pull requests from forks.
- Display list of pull requests and metadata.

---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [GitHub REST API for PRs](https://docs.github.com/en/rest/pulls/pulls)
- [Octokit REST.js Library](https://github.com/octokit/rest.js)

---

## Acknowledgments

Thanks again to my mentors and the Sugar Labs community for feedback and support!  
Looking forward to next week’s frontend PR features. 

`,Bs=Object.freeze(Object.defineProperty({__proto__:null,default:Cn},Symbol.toStringTag,{value:"Module"})),Ln=`---
title: "GSoC '25 Week 4 Update by Safwan Sayeed"
excerpt: "AST to IR Implementation"
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-gsoc-25-sa-fw-an-week4"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week4,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 4 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-23 - 2025-06-29  

---

## A Blog-style Retrospective

This week marked a significant milestone in our Music Blocks program engine development as we transitioned from the foundational memory architecture to the core compilation logic. The focus shifted to implementing the AST-to-IR (Intermediate Representation) translation layer - the crucial bridge between our abstract syntax tree representation and executable code.

---

## Goals for This Week

- Complete the AST-to-IR compilation logic technical specification with detailed pseudocode patterns.
- Implement the AST Parsing logic for all expression classes returning instruction lists.
---

## This Week's Highlights

1. **AST-to-IR Compilation Logic Specification**  
   - Expanded the tech spec with comprehensive AST-to-IR translation documentation covering expression and statement compilation patterns.
   - Detailed instruction list generation requirements and variable management strategies.
   - Link: [IR Compilation Logic](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.i655udul8zuq)

2. **Implemented AST Parsing Logic**
   - Developed parsing logic for all expression classes, ensuring they return the correct instruction lists.  

---

## Challenges & Solutions

- **Understanding Static vs Runtime Compilation:**  
  Initially confused about whether we were performing runtime calculations or static code translation.  
  *Solution:* Mentors clarified that this is purely static AST-to-IR conversion with no runtime execution, helping focus the implementation approach.


---

## Key Learnings

- Gained a deeper understanding of static compilation principles and the importance of maintaining clean instruction generation patterns.
- Learned how to effectively manage variable scopes and dependencies during the AST-to-IR translation process.

---

## Next Week's Roadmap

- Finalize the AST-to-IR compilation logic implementation for all expression and statement classes.
- Begin integrating the IR generation with the memory management system to ensure proper variable resolution.
- Start working on the execution engine that will interpret the generated IR instructions.
---

## Resources & References

- **Tech Spec:** [AST to IR Methods](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.87123fra3s4#heading=h.gqjcwrtkdgvq)
- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their crucial guidance on compiler design principles and static compilation concepts. Their clarification on the AST-to-IR translation approach and emphasis on maintaining clean instruction generation patterns was essential for this week's successful progress.

---`,Rs=Object.freeze(Object.defineProperty({__proto__:null,default:Ln},Symbol.toStringTag,{value:"Module"})),xn=`---
title: "GSoC ’25 Week 04 Update by Diwangshu Kakoty"
excerpt: "Implementing a Reasoning-Enabled AI Model"
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-gsoc-25-diwangshu-week04"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week04,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-06-22 - 2025-06-28  

---

## Goals for This Week

- **Goal 1:** Leveraging Gemini's Thinking Feature.
- **Goal 2:** Code Migration: LangChain → Gemini SDK.
- **Goal 3:** Clean up the codebase.
- **Goal 4:** Make sample summaries to test the 'Analyis' feature.
- **Goal 5:** Fix bugs occured by these changes.

---

## This Week’s Achievements

1. **Using Gemini's 'Think' Capability for Enhanced Responses**  
   - I have implemented the 'thinking' capability of the Gemini model in the multi-agent chat model. This allows the LLM to break down complex queries into smaller, manageable parts, leading to more accurate and relevant responses. 

   - But it came with a challenge, as LangChain's Gemini module does not support the 'thinking' capability directly (more on this in the challenges section).

2. **Code Migration: LangChain → Gen AI SDK**  
   - As mentioned in the last point, LangChain's Gemini module does not support the 'thinking' capability. Therefore, I have started migrating the 'generation' code from LangChain to the official Gen AI SDK. This migration allows us to use the 'thinking' capability and other features of the Gemini model dynamically.

   - The official Gen AI SDK allows us to use the 'think' dynamically, which means the LLM can decide when to use the 'thinking' capability based on the complexity of the query. It also allows us to specify the number of thinking tokens aka 'thinkingBudget' to be used or set it to auto. This flexibility is crucial for optimizing the performance and cost of using the Gemini model.

3. **Cleaning Up the Codebase**  
   - I have cleaned up the codebase by structuring the code into separate files, functions and modules. This makes the code more organized and easier to maintain.

---

## Challenges & How I Overcame Them

- **Challenge :** LangChain's Gemini module does not support the 'thinking' capability directly. This project uses RAG (Retrieval-Augmented Generation) with LangChain, which is a popular framework for building LLM applications. While the retrieval part works well, the generation part needs to be changed. But it is not that simple. The Gen AI SDK uses its own library for storing conversations, which is different from LangChain.

  **Solution:** There's no doubt that leveraging the reasoning capabilities of the Gemini model can significantly enhance response quality. However, as this is still an evolving technology, full support in LangChain is likely to emerge soon. For testing purposes, a complete migration isn't necessary at this stage. Therefore, I've implemented two separate classes: \`llm\` and \`reasoning_llm\`, which initialize \`Gemini-1.5-flash\` and \`Gemini-2.5-flash\`, respectively. The \`llm\` class handles general queries, while \`reasoning_llm\` is dedicated to writing algorithms for the project code when passed as a query. The \`Gemini-2.5-flash\` is the model that supports and uses the 'thinking' capability by default. 

  This is a temporary arrangement. If I get positive feedback from the mentors, I will proceed with the complete migration of the 'generation' code to the official Gemini SDK.

---

## Key Learnings

- While working on this project, I explored extensive documentation for both Gemini and LangChain. This deep dive significantly enhanced my understanding of LLMs, including concepts like structured output, function calling, code execution, reasoning capabilities, and various prompting techniques.

---

## Next Week’s Roadmap

- Build a developer settings in the sidebar to allow testers to choose between the 'llm' and 'reasoning_llm' classes for each query. 
- Work on things suggested by mentors. This could include:
  - Full migration of the 'generation' code to the official Gen AI SDK.
- Developing sample summaries to test the 'Analysis' feature.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Os=Object.freeze(Object.defineProperty({__proto__:null,default:xn},Symbol.toStringTag,{value:"Module"})),Gn=`---
title: "GSoC’25 Week 04 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-gsoc-25-omsuneri-week04"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week04,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-22 - 2025-06-28

---

## Goals for This Week

- **Goal 1:** Testing the Debugger with Intensive Prompting
- **Goal 2:** Improving the Quality of LLM Responses 
- **Goal 3:** Making the Debugger Interactive and Kid-Friendly 

---

## This Week’s Achievements

1. **Testing the Debugger with Intensive Prompting**  
   - I carried out extensive testing of the debugger by feeding it a wide range of Music Blocks projects and crafting diverse prompts to simulate how real users — especially children — might ask questions or seek help. This allowed me to observe how the LLM interprets different project structures and how effectively it can guide users toward understanding and improving their project.
   - Debugging is not just about fixing errors — it’s also about discovering new possibilities. Through this intensive testing, I was able to identify how the debugger could become a more intuitive assistant. Ensuring it understands various project contexts means kids can explore their creativity more freely, knowing they have a tool that helps them understand what’s happening and what more they can do. It moves the debugger from being reactive to being proactively supportive.

2. **Improving the Quality of LLM Responses**  
   - I focused on tuning the LLM prompts to ensure that the responses it generates are not only accurate but also clear, structured, and easy to understand for children. I experimented with different prompt formats, simplified technical jargon, and shaped the tone to be more friendly and encouraging. The goal was to make every response feel like it’s coming from a helpful companion, not a complicated machine.
   - For many young learners, especially those just starting their journey into coding and music, complex feedback can be discouraging. By improving the quality of responses, I’ve made the debugger more approachable and effective as an educational tool. This change ensures that kids receive feedback they can truly learn from. 

3. **Making the Debugger Interactive and Kid-Friendly**  
   - One of my main goals this week was to make the debugger feel more alive and responsive. I improved the system prompts to encourage a more interactive and friendly tone. Additionally, I introduced a feature where the debugger can automatically detect key elements of a project right after it is loaded — such as the instruments used, patterns in sequences, or loops — and immediately offer feedback or suggestions. This turns the debugger into more of a conversational partner than just a tool.
   - Young minds learn best when they feel engaged and supported. By making the debugger more interactive and giving it the ability to respond to a project from the moment it is initialized, the experience becomes more seamless and enjoyable. Kids no longer have to wait or guess what to do next — they’re gently guided and encouraged to explore, learn, and improve. It transforms the debugger into a playful mentor that supports learning through interaction, discovery, and fun.

---

## Deployed Project
- **Music Blocks Debugger:** [Live Demo](https://debuggmb.streamlit.app/)

<a href=""><img src="https://i.ibb.co/p6H5y3Bw/Screenshot-2025-06-28-at-10-41-28-AM.webp" alt="Music Blocks Debugger"></a>

- **JSON to Text Converter:** [Live Demo](https://omsuneri.github.io/JSON-to-Text-representation/)

<a href=""><img src= "https://i.ibb.co/ycNPrKVs/Screenshot-2025-06-28-at-10-42-38-AM.webp" alt="JSON to Text Converter"></a>

## Challenges & How I Overcame Them

- **Challenge:** Refining System Instructions for Better LLM Responses  
  **Solution:** One key challenge I encountered was fine-tuning the system instructions to consistently get high-quality, relevant responses from the LLM. The solution was to conduct extensive testing using a variety of prompts and project types. This helped me understand how the model interprets different contexts and allowed me to iteratively improve the instructions for more accurate, helpful, and kid-friendly outputs.

---

## Next Week’s Roadmap

- Integrate real-time response improvement based on project complexity.
- Enhance system prompts further through prompt-chaining and context tuning.
- Improving the Quality of LLM Responses

---

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,zs=Object.freeze(Object.defineProperty({__proto__:null,default:Gn},Symbol.toStringTag,{value:"Module"})),Wn=`---

title: "GSoC '25 Week 04 Update by Saumya Shahi"
excerpt: "This week focused on implementing advanced tree rendering with nested, stacked, and argument brick support, dynamic sizing for the masonry module."
category: "DEVELOPER NEWS"
date: "2025-06-29"
slug: "2025-06-29-gsoc-25-saumya-shahi-week04"
author: "@/constants/MarkdownFiles/authors/saumya-shahi.md"
tags: "gsoc25,sugarlabs,week04,saumya-shahi"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Saumya Shahi

**Project:** [Masonry Module - Music Blocks v4](https://github.com/sugarlabs/musicblocks-v4)  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-22 – 2025-06-29  

---

## Goals for This Week

- Implement advanced tree rendering with nested, stacked, and argument brick support
- Develop dynamic brick sizing based on content and children
- Create comprehensive validation systems for brick connections
- Establish robust rendering algorithms with proper traversal strategies
- Integrate the complete tree rendering system into the storybook

---

## This Week's Achievements

### 1. **Advanced Tree Rendering System Implementation**

Developed a brick tree rendering system that handles three distinct connection types:

#### **Stacked Tree Rendering**
- **Vertical Stacking**: Bricks can be connected vertically in sequence below their parent
- **Cumulative Height Calculation**: Total height of stacked trees is calculated by summing individual brick heights
- **Width Optimization**: Stacked trees maintain optimal width by taking the maximum width of all stacked bricks
![stacked bricks in storybook](assets/Images/storybook_stacked_bricks.webp)

#### **Argument Brick Rendering**
- **Expression-Only Validation**: Implemented validation ensuring only Expression bricks can be used as arguments
- **Slot-Based Positioning**: Argument bricks are positioned at specific argument slots on their parent bricks
- **Dynamic Slot Management**: Parent bricks automatically adjust their argument slots based on the number of arguments
![argument bricks in storybook](assets/Images/storybook_argument_bricks.webp)

#### **Nested Tree Rendering**
- **Multi-Level Nesting**: Implemented support for bricks nested inside compound bricks, which can themselves contain nested bricks
- **Dynamic Sizing**: Parent bricks automatically resize based on their nested children's bounding boxes
- **Proper Positioning**: Nested bricks are positioned at calculated connection points within their parent containers
![nested bricks in storybook](assets/Images/storybook_nested_bricks.webp)

### 2. **Dynamic Brick Sizing and Layout System**

#### **Label Width Adjustment**
- **Dynamic Text Measurement**: Implemented canvas-based text measurement for accurate label width calculation
- **Real-Time Updates**: Brick dimensions update automatically when labels change
- **Fallback System**: Robust fallback for server-side rendering when canvas is unavailable
![argument bricks position according to label bounding box calculations](assets/Images/storybook_label_Bbox.webp)

#### **Child-Based Resizing**
- **Bounding Box Calculation**: Parent bricks recalculate their bounding boxes based on their children's dimensions
- **Compound Brick Layout**: Compound bricks expand their nested regions to accommodate all nested children
- **Automatic Geometry Updates**: Brick geometry updates trigger re-rendering with new dimensions
![expanded nested region according to child bricks](assets/Images/storybook_nested_Bbox.webp)

### 3. **Advanced Rendering Algorithms**

#### **Two-Phase Rendering Strategy**
- **Phase 1 - Preorder Traversal**: Calculate all bounding boxes and dimensions from root to leaves
- **Phase 2 - Postorder Traversal**: Render from leaves to root, ensuring children appear on top of parents
- **Z-Index Management**: Proper layering prevents visual conflicts between nested elements

#### **Bounding Box Computation**
\`\`\`typescript
function computeBoundingBoxes(allNodes: Map<string, ExtendedTreeNode>) {
  // Preorder traversal for dimension calculation
  // Handles nested, argument, and stacked children
  // Updates compound brick layouts with nested content
  // Returns comprehensive bounding box map
}
\`\`\`

### 4. **Comprehensive Validation Systems**

#### **Brick Type Validation**
- **Nesting Validation**: Only Compound and Simple bricks can be nested inside other bricks
- **Argument Validation**: Only Expression bricks can be used as arguments
- **Connection Validation**: Ensures compatible brick types for different connection types

#### **Connection Point Validation**
- **Notch Compatibility**: Validates that connecting bricks have compatible notch types
- **Slot Availability**: Ensures argument slots are available before allowing connections
- **Nested Space Validation**: Verifies sufficient space in compound bricks for nested children

### 5. **Brick Model System**

Refined the brick model architecture with advanced features:
- **SimpleBrick**: Basic statement bricks with configurable notches and argument support
- **ExpressionBrick**: Value-holding bricks with expression support and argument-only usage
- **CompoundBrick**: Container bricks with nested children support and dynamic sizing

---

## Technical Implementation Details

### Advanced Tree Structure
\`\`\`typescript
interface ExtendedTreeNode extends TTreeNode {
  isNested?: boolean;    // Indicates nested brick
  argIndex?: number;     // Argument slot index
  children?: {
    nested: ExtendedTreeNode[];
    args: ExtendedTreeNode[];
    stacked: ExtendedTreeNode[];
  };
}
\`\`\`

### Dynamic Sizing Algorithm
\`\`\`typescript
function updateCompoundBrickLayouts(nodes: Map<string, ExtendedTreeNode>) {
  // Calculate total nested content dimensions
  // Update compound brick's bboxNest array
  // Trigger geometry recalculation
  // Update connection points
}
\`\`\`

### Validation System
\`\`\`typescript
function validateBrickConnection(parent: BrickModel, child: BrickModel, type: ConnectionType) {
  switch(type) {
    case 'nested':
      return parent.type === 'Compound' || parent.type === 'Simple';
    case 'argument':
      return child.type === 'Expression';
    case 'stacked':
      return child.type !== 'Expression'; // expression brick can't be stacked
  }
}
\`\`\`

---

## Challenges & How I Overcame Them


### Challenge 1: Compound Brick Layout with Multiple Nested Children
**Problem**: Compound bricks needed to accommodate multiple nested children with varying sizes and positions.               
**Solution**: Implemented a two-phase approach: first calculate all child dimensions, then update parent bounding boxes and trigger geometry recalculation. Developed a recursive algorithm that calculates bounding boxes bottom-up, then renders top-down with proper z-indexing to ensure children appear above parents.

### Challenge 2: Label Width Calculation and Dynamic Updates
**Problem**: Bricks needed to resize based on their label text, requiring accurate text measurement and real-time updates.
**Solution**: Implemented canvas-based text measurement with fallback for server-side rendering, and integrated it into the brick geometry update system.

![Brick Layout with Multiple Nested Children](assets/Images/storybook_compundBrick_multipleLevels.webp)

---

## Key Learnings

- **Advanced Tree Algorithms**: Deep understanding of preorder/postorder traversal for different rendering phases
- **Dynamic Layout Systems**: Learned how to implement responsive layouts that adapt to content changes
- **Canvas Text Measurement**: Mastered techniques for accurate text measurement in web environments
- **Z-Index Management**: Gained expertise in managing visual layering in complex nested structures
- **Type-Safe Validation**: Enhanced skills in creating comprehensive validation systems with TypeScript

---

## Resources & References

- **Tree Traversal Algorithms**: [MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Working_with_Objects)
- **Canvas Text Measurement**: [MDN Canvas Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API)
- **TypeScript Validation Patterns**: [TypeScript Handbook](https://www.typescriptlang.org/docs/handbook/advanced-types.html)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their guidance and support. Special thanks to the community for providing valuable feedback on the tree model design and implementation.

---
`,Fs=Object.freeze(Object.defineProperty({__proto__:null,default:Wn},Symbol.toStringTag,{value:"Module"})),Dn=`---
title: "GSoC ’25 Week 07 Update by Aditya Kumar Singh"
excerpt: "Enhanced shared mode synchronization for Tour and Doctor activities, improved scoring visualization, and camera state persistence in the 3D Human Activity."
category: "DEVELOPER NEWS"
date: "2025-06-30"
slug: "2025-06-30-gsoc-25-AdityaKrSingh26-week07"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week07,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-06-19 - 2025-06-25   

---

## Goals for This Week

- **Goal 1:** Implement shared mode synchronization for Tour activity  
- **Goal 2:** Enhance Doctor mode to show XO Icons and name with real-time scoring visualization  
- **Goal 3:** Persist camera zoom and orientation across sessions   
- **Goal 4:** Add support for side and back view positioning in Tour   

---

## This Week’s Achievements

1. **Shared Tour Mode**  
    - Implemented broadcast message \`tourStep\` carrying the part index & name; the host fires it and peers replay it to keep camera position and mesh highlight in lock-step.  
    - Added graceful join-in-progress sync: newcomers receive the current step and camera pose on \`syncAllPaintData\`, so nobody is “mid-tour-lost”.  
    ![Shared tour mode](https://i.ibb.co/TDsVpPpN/image.webp)
    \`\`\`javascript
        // Broadcast tour step to other users
        presence.sendMessage(presence.getSharedInfo().id, {
            user: presence.getUserInfo(),
            action: "tourStep",
            content: {
                index: tourIndex,
                partName: part.name
            }
        });

        // Sync handler
        function syncTourStep(index, partName) {
            const part = bodyParts[index];
            const currentMesh = currentModel.getObjectByName(part.mesh);
            
            // Highlight mesh
            currentMesh.material = new THREE.MeshStandardMaterial({
                color: new THREE.Color("#ffff00"),
                emissive: "#ffff00",
                emissiveIntensity: 0.2
            });

            // Position camera
            camera.position.set(
                part.position[0], 
                part.position[1], 
                part.position[2] + 5
            );
            camera.lookAt(part.position[0], part.position[1], part.position[2]);
        } 

2. **Shared Doctor Mode**  
    - Re-used the Presence layer from Paint mode to emit nextQuestion / answer / scoreUpdate events.  
    - First-correct-gets-the-point logic now lives entirely on the host  
    - Peer-to-peer visual feedback: *correct click flashes the mesh green, wrong click red*; scores float next to each user’s XO badge  
        ![Doctor mode screen](https://i.ibb.co/XxMzh5NS/image.webp)   
        ![Doctor mode Wrong answer](https://i.ibb.co/vvYyyZ0v/image.webp)   
        ![Doctor mode Correct answer](https://i.ibb.co/NgDVpG7f/image.webp)   


3. **Camera & Zoom Persistence**  
   - Stored \`cameraPosition\`, \`cameraTarget\`, and \`cameraFov\` in the Journal JSON when the Stop icon is pressed.   
   - On activity resume we restore both orbit target and FOV, giving users continuity—especially useful after deep-dive zooms into organs.  
     \`\`\`javascript
        // Saving camera state
        function saveCameraState() {
            return {
                position: {
                x: camera.position.x,
                y: camera.position.y,
                z: camera.position.z
                },
                target: {
                x: orbit.target.x,
                y: orbit.target.y,
                z: orbit.target.z
                },
                fov: camera.fov
            };
        }
        // Restoring camera state
        function restoreCameraState(state) {
            camera.position.set(state.position.x, state.position.y, state.position.z);
            orbit.target.set(state.target.x, state.target.y, state.target.z);
            camera.fov = state.fov;
            camera.updateProjectionMatrix();
            orbit.update();
        }

4. Side and Back View Support for Tour
- Extended body part data (\`organParts.json\`) to include \`sideView\` and \`frontView\` flags.
- Tour camera now automatically adjusts orientation:
  - **Side view** → +X
  - **Back view** → −Z
  - **Front view** → +Z (default)
- Created adaptive camera logic in \`activity.js\` to interpret these flags.
        ![Side View](https://i.ibb.co/JW5JNMVD/image.webp)   
        ![Back View](https://i.ibb.co/kZLLt0F/image.webp)   


---

## Key Learnings

- Three.js Camera Control: Mastered advanced camera manipulation techniques
- Real-time Sync Patterns: Developed robust synchronization for 3D interactions
- Educational UX: Learned principles for effective learning feedback systems

---

## Next Week’s Roadmap

- Write Weekly Blog Post summarizing progress, screenshots, and key learnings.   
- Fix remaining issues for Human body mentioned in PR
- Start to implement the dashboard features of the stickman activity: draw, move
- Start with implementing the Frame part of the stickman activity, add a frame, remove a frame,

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Us=Object.freeze(Object.defineProperty({__proto__:null,default:Dn},Symbol.toStringTag,{value:"Module"})),_n=`---
title: "SSoC ’25 Week 04 Update by Muhammad Haroon"
excerpt: "Experimenting with prompts parameter in AudioGen model."
category: "DEVELOPER NEWS"
date: "2025-06-30"
slug: "2025-06-30-ssoc-25-MuhammadHaroon-week04"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week04,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-23 - 2025-06-30    

---

## Goals for This Week

- **Goal 1:** To further explore the effects of the temperature and top_p parameters.
- **Goal 2:** To find an effective method for removing silence and noise from audio.

---

## This Week's Achievements

1. **Explored the effects of the temperature and top_p parameters**  
   - After experimenting with different temperature and top_p values, I found that AudioGen performs well with temperature = 1 and top_p = 1 values, generating audio that closely matches the prompt.

2. **Found effective method for removing silence and nosie form audio**  
   - I found python libraries for removing silence (pydub) and noise (noisereduce) from the audio and it gave good results.

---

## Next Week's Roadmap

- Generate more samples using different prompts.
- Explore how to connect backend with the frontend using FastAPI.
- Explore how to deploy the backend on AWS.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Ns=Object.freeze(Object.defineProperty({__proto__:null,default:_n},Symbol.toStringTag,{value:"Module"})),En=`---
title: "GSoC '25 Week 04 Update by Shubham Singh"
excerpt: "Pivoted from Point Scanner to Line Scanner, got some real results."
category: "DEVELOPER NEWS"
date: "2025-07-01"
slug: "2025-07-01-gsoc-25-firepheonix-week04"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week02
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 4 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-23 – 2025-06-30

---

## Goals for This Week

- Implement complete Core Implementation of Scanning the Lego Blocks image on the X-axis.
- Focus on algorithmic challenges for note-to-color mapping system.

---

## This Week's Achievements

1. **Tested out the scanning errors. Realized the scanning single pixels isnt' gonna work.**  
   - So after testing out multiple errors, I realized that the DOT scanning method just isn't working that accurately(only ~40% accuracy). It's completely because of the core functionality of how the method itself works.
   - So, I realized there has to be a better method than this. Scanning have been taking place for a long time. There had to be a better method than this.
   - Began reverse engineer everything. Questioning every decision I've made for this project. Going to the very core of how the entire process, storage, time complexity is going on with the dot method.
        ![Pros and Cons of DOT scanner](https://i.ibb.co/jZM2cXzc/dot-Scanner.webp)

2. **Tested out spherical method. Failed.**  
   - Implemented the spherical method. It basically takes an AVERAGE of all the pixels underneath it rather than a scanning a single pixel. I did this keeping in mind more and more accuracy,
   - Little did I know, I ran into more errors and worse accuracy than before.

        ![Pros and Cons of Spherical (average) scanner](https://i.ibb.co/q3rJLNgb/sphere-Scanner.webp)

3. **Finally reached an optimal, LINE scanner. Highly balanced. Got to a VERY good accuracy level.**  
   - Learned it the hard way why all bar code scanners are line type scanners. Why all machines (like, even your local printer machine/ or laser scan) follow the line scanning method. Got the best results and very a good accuracy.

        ![Reasons why Line scanner is the BEST for our Lego Blocks case.](https://i.ibb.co/7dsjzRct/line-Scanner.webp)
    
    - Now, this doesn't mean that the line scanner doesn't have it's cons. It has cons like the texture-confusion in a place where the block's edge is there, and the green background. But, such a confusion edge is only for a VERY small time. I predict it to be < 0 ms, hence automatically being ignored by the algorithm. And there are some issues still left to be fixed.

4. **Made an output system for TESTING the accuracy of algorithm.**  
   - I ofc was not able to see how my output is through a mere array{{}} type console.log().
   - So, I developed this method of outputting of the colors on .webp type image. To make it visually seem like the image itself for a DIRECT comparision.

        ![Input I gave](https://i.ibb.co/YzttknX/lego-Notation.webp)

        ![Output I got(very close to my actual input)](https://i.ibb.co/bghJwFq9/color-detection-1751401094449.webp)
    
    - Now I am rather thinking of making use of THIS .webp output instead, it's simply good. Should I? Or should I not? Gonna have to ask from my mentors and do some research on this.


---

## Challenges & How I Overcame Them

- **Challenge:** Was getting stressed about why am I not able to get the accuracy I need.
**Solution:** Reverse engineered stuff. Thought on my own. Research on youtube- how do scanning algorithms actually work?
- **Challenge:** Not being to see if my algorithm is accurate or not.
**Solution:** Made it output the array in the format of a .webp format instead of a simple console.log(array).

---

## Key Learnings

- Reverse engineering always works. Dive in the BASICS. See the core of how everything is working. Make your human brain work more than asking AI for suggestions. It's possible that you're making things complicated with AI when the answer is really simple and lies in basic thinking.
- Figuring out what will work <<<< Figuring out what DOES NOT WORK.

---

## Next Week's Roadmap

- Implement the exisiting music blocks number to color mapping system that already exists (as suggested by my mentor, Walter)
- Implementing the dynamic input of NOTES like in the phrase maker.
- Figure out how the phrase maker has many different instuments with different audio files and LOADING them into legobricks.js
- Fix some more issues in the scanning that are visible to me.
- Once the above is done, we can move to mapping the lengths to corresponding notation lengths and production of musical notations. Initial weeks will be mostly figuring out the method for figuring out length of each block for each notation, am I going to use grid? Or will I use The lengths? Or will it be the time?

---

## Resources & References

- **Some youtube videos related to arduino color detection** 

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Special thanks to Devin. I had typhoid last week due which I had a week of backlog in my work. He didn't mind at all. Happy have such cooperative mentors :p .
P.S.: I've finally caught up to the work I missed.

---`,Hs=Object.freeze(Object.defineProperty({__proto__:null,default:En},Symbol.toStringTag,{value:"Module"})),jn=`---
title: "DMP ’25 Week 5 Update by Aman Naik"
excerpt: "This week focused on improving the story framework display UI and attempting to deploy an LLM model on AWS."
category: "DEVELOPER NEWS"
date: "2025-07-05"
slug: "2025-06-05-dmp-25-AmanNaik-week05"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week05,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 5 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-06-29 – 2025-07-05  

---

## Goals for This Week

- **Goal 1:** Finalize the UI to display the generated story framework  
- **Goal 2:** Create an API endpoint to host an LLM model on AWS  

---

## This Week’s Achievements

1. **Worked on Story Framework Display UI**  
   - Designed and implemented a widget within Sugar to display the generated story framework.  
   - Although the basic version is functional, it still needs design improvements to make it more engaging and intuitive for children.

   ![Framework dispay: Current version(will be adding more changes)](assets/Images/aman-naik-week5-img1.webp)

   ![Chat messages](assets/Images/aman-naik-week5-img2.webp)


2. **Attempted AWS LLM Deployment**  
   - Made an initial attempt to deploy an LLM model on AWS.  
   - Faced permission issues during the process, which blocked progress. I plan to resolve this in discussion with mentors and continue deployment next week.

---

## Challenges & How I Overcame Them

- **Challenge:** Creating a child-friendly UI for the framework display  
  **Solution:** Designing a UI that clearly represents story elements while remaining easy to understand for young learners was tricky. Through trial and error, and repeated testing, I managed to connect the output with the UI successfully.

- **Challenge:** AWS deployment blocked by permission issues  
  **Solution:** Will consult with mentors to resolve the issue and resume progress on hosting the LLM next week.

---

## Key Learnings

**Learned the Complexity of Designing Educational UIs**  
   - UI for children must be both simple and informative. Building the framework display taught me how to balance functionality with visual clarity.

**Encountered and Tackled Real-World Deployment Hurdles**  
   - Faced permission-related roadblocks during AWS deployment. This helped me understand the practical challenges of managing cloud-based services.

**Learned the Importance of LLM Selection and Hosting Before Testing Flow**  
   - Since I am working with a Groq API using llama-versatile-70b model for testing. But due to license issues this wont be the final API used for deployment.  
   - Realized that choosing and hosting the right LLM model is critical before properly testing the conversation flow. The AI’s behavior is tightly linked to the model used, making this step a top priority for the coming week.

---

## Next Week’s Roadmap

- Finalize the LLM model and deploy it on AWS  
- Complete and finalize the story framework display UI  

---

## Acknowledgments

Thank you to my mentors and the Sugar Labs community for their continued feedback, guidance, and patience as I work through these technical and design challenges.

---
`,qs=Object.freeze(Object.defineProperty({__proto__:null,default:jn},Symbol.toStringTag,{value:"Module"})),Bn=`---
title: "GSoC '25 Week 5 Update by Krish Pandya"
excerpt: "Animations, Toolbars, and a Playable Game"
category: "DEVELOPER NEWS"
date: "2025-07-05"
slug: "2025-07-05-gsoc-25-mostlyk-week05"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week05,mostlyk"
image: "assets/Images/GSOC.webp"
---

# Week 5: Animations, Toolbars, and a Playable Game

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)

**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)

**Reporting Period:** June 22, 2025 – June 28, 2025

---

## Travel and Context

This week started with an 8-hour flight from Hyderabad to Diu ( my hometown ) between Sunday and Monday.
And _YES_ , I am home, sweet home. It was fun working on animations , toolbars and the game.


## Animations and Toolbars

So as discussed and sneak peeked in last week, first part was finishing the toolbar integration and that was done! I also added animations.py.
I have always been a big fan of animations, my first addition to my [PKMS Site](https://pkms.vercel.app/) ( Personal Knowledge Management System ) was a handcrafted and personal documentation of Manim which a python animation library.

Now it has a lot of things but it started as a manim documentation.

### Animations

Added a few clean effects:

- \`fade-in\` and \`fade-out\`
- \`color\` transitions
- \`scale-down\`


### Toolbars

Features include and tested in example:

- Full range of buttons: open, save, undo, redo, cut, copy, paste
- Multi-select toggles, zoom controls, view modes
- Toolbuttons ( This requires palette somehow so will be updated next week. Sorry for the wait! )
- And because of that if someone wants to play the game, you would have to wait till next week for the palette finish and the ToolButton addition in library.


## Why Not HelloWorld Yet?

The actual HelloWorld example has more dependencies than just graphics. It needs:

- \`widgets.py\`
which further needs:
  - \`RadioButton\`, \`ToolButton\`, \`ToolBarButton\`, \`PaletteMenuBox\` etc.
  - A bunch of internal glue that isn't finalized yet

A good HelloWorld will take a few more weeks to land, realistically.
It requires almost all graphics-related components working in unison. Instead of rushing a half-baked HelloWorld, I decided to make something fun using what I already have.


## The Game: Super Ball Dodge

<iframe width="560" height="315" src="https://www.youtube.com/embed/B517C_LTCns?si=u4zGfRp0yEJca8_O" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

So I built a game. It's simple, but fully interactive, and it uses the toolkit as it currently exists ( well it uses ToolButton which is half baked, so you would be able to play it by next week, can watch the video to see what it is though! ).

### Game Mechanics

- Use \`WASD\`, arrow keys, or toolbar buttons to move
- Press \`P\` to pause, \`R\` to restart
- Touch the red ball and you lose
- Hitting walls increases your speed and randomizes your color
- Max speed is capped to keep it playable

This game is both a stress test and a fun break. It's a good way to validate rendering, event handling, animation, and user interaction at once.
Also it kind of stands like a hello world alternative for now before everything is done in unison and final decisions are made.


## Summary of Progress

- Built and finalized core animations
- Integrated and tested full-featured toolbar
- Added working event bindings and accelerators
- Created Super Ball Dodge as a game/activity testbed

---

## Next Steps

- Refactor window tests (they're not up to standard yet)
- Finalize and commit \`widgets.py\`, \`ToolButton\`, and all of \`pallete\` stuff.
- Start building the actual HelloWorld once widget infra is stable

---

## Links

- [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- [Toolkit Repo (Python)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [sugar-ext (C bindings)](https://github.com/sugarlabs/sugar-ext)
- [Game Demo Video](https://youtu.be/B517C_LTCns)


## Closing Thoughts

It's funny how animations were the thing that got me into this headspace of _I GOTTA DO SOMETHING DYNAMIC_ , and I have always loved geometry and maths. And I got to introduce and do something related to that this week and this game was the result of what came out this week and I am glad I got to do it.

Until next week,
Krish!
(P.S. If you couldn’t tell already , I love hiding pop culture references and breaking the fourth wall in these posts. So yes, you, yup, you alright, the reader.... enjoy.)
`,Ks=Object.freeze(Object.defineProperty({__proto__:null,default:Bn},Symbol.toStringTag,{value:"Module"})),Rn=`---
title: "GSoC ’25 Week 05 Update by Bishoy Wadea"
excerpt: "Fifteen Puzzle"
category: "DEVELOPER NEWS"
date: "2025-07-05"
slug: "gsoc-25-BishoyWadea-week05"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week05,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 04 Progress Report by Bishoy Wadea

**Project:** [Fifteen Puzzle](https://github.com/Bishoywadea/FifteenPuzzle)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-06-29 - 2025-07-05 

---

## Goals for This Week

- **Goal 1:** Start implementing Fifteen Puzzle Game
---

## This Week’s Achievements

### *Goal 1: add helpful video tutorial in Soma Cube Game*

1. **add video in help button**  
   - commit: [modify code to handle help videos](https://github.com/Bishoywadea/Soma-Cube/commit/63a7daaa8009f5f54791cdf9081e765846135f70)
![illistration tutorial video](https://github.com/Bishoywadea/Soma-Cube/blob/main/help.mp4)
---

### *Goal 2: Start implementing Fifteen Puzzle Game*
1. **UI Foundation & Game Board**
    - Set up the game window with a functional 4x4 puzzle grid and animated tile movements.
    - commit: [add basic board UI](https://github.com/Bishoywadea/FifteenPuzzle/commit/ee2a8ec0a87949a93f0093b558de5d760ef66d59)
    - commit: [add animation for the board](https://github.com/Bishoywadea/FifteenPuzzle/commit/a09f407451cb0772eff80d605509854d76522d17)

![image for board UI](https://github.com/Bishoywadea/FifteenPuzzle/blob/main/screenshots/en/01.webp?raw=true)

2. **Core Logic & Gameplay**
    - Added full logic for tile shifting, move counting, and puzzle completion detection.
    - commit: [add game logic](https://github.com/Bishoywadea/FifteenPuzzle/commit/28d835400fb80c32d0eebba7c08f83fcfe9f9c63)

3. **Help System & UI Integration**
    - Introduced help instructions and integrated the help button into the top toolbar for easier access.
    - commit: [add help button](https://github.com/Bishoywadea/FifteenPuzzle/commit/494f212f83e469fe2f3c24dd54e398c903a77dcc)

![image for help panel](https://github.com/Bishoywadea/FifteenPuzzle/blob/main/screenshots/en/02.webp?raw=true)
![image for success animation](https://github.com/Bishoywadea/FifteenPuzzle/blob/main/screenshots/en/03.webp?raw=true)


---

## Challenges & Solutions

- **Challenge:** Creating a responsive and user-friendly tile movement system.  
  **Solution:** Implemented smooth tile animations and move validation logic to ensure accuracy and a satisfying user experience.

- **Challenge:** Designing a clean UI that adapts to game states like playing, winning, or seeking help.  
  **Solution:** Built a modular UI with conditionally rendered elements such as move counters, help overlays, and success animations for clarity and flow.
---

## Key Learnings

- Gained hands-on experience in building grid-based puzzle logic, including tile shifting, move tracking, and win condition detection.

---

## Next Week’s Roadmap

- Fix any feedback provided by members of the organization.  
- Start implementing the Euclid’s Game.
---
`,Vs=Object.freeze(Object.defineProperty({__proto__:null,default:Rn},Symbol.toStringTag,{value:"Module"})),On=`---
title: "GSoC '25 Week 5 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates"
category: "DEVELOPER NEWS"
date: "2025-07-05"
slug: "2025-07-05-gsoc-25-Elwin-Li-week05"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week5,javaScript editor,debugger,syntax highlighting"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 5 Progress Report by Elwin Li

**Project:** [Advanced JavaScript Editor with MusicBlocks Interactions](https://github.com/sugarlabs/musicblocks/tree/config_driven_conversion/elwin)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-06-29 - 2025-07-05

---

## Goals for This Week

- **Goal:** Complete the debugger project and add syntax highlighting

---

## This Week’s Achievements

**Made PR for Debugger Project**

The debugger project has been complete and a [PR has been made](https://github.com/sugarlabs/musicblocks/pull/4717). The functionalities that have been described in the [previous weeks post](https://www.sugarlabs.org/news/developer-news/2025-06-28-gsoc-25-Elwin-Li-week04) are all included in this PR, and the demonstration video is below:

[youtube: ZVqi7zIJ9kw]

**Basic Syntax Highlighting**

I've added basic syntax highlighting to the JS editor, making it more pleasing to the eye.

<a href="https://ibb.co/23vbzVqq"><img src="https://i.ibb.co/RT35Xr22/Screenshot-2025-07-06-at-12-28-58-AM.webp" alt="Syntax Highlight"></a>

---

## Key Learnings

- Improved skills in UX design and keeping tools simple for the user
- Deepened understanding of highlightjs
- Improved skills in **debugging**, **code design**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Complete syntax highlighting to JSeditor code (including error highlighting)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Js=Object.freeze(Object.defineProperty({__proto__:null,default:On},Symbol.toStringTag,{value:"Module"})),zn=`---
title: "GSoC ’25 Week 05 Update by Mebin J Thattil"
excerpt: "New brains and new voices for Speak!"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-gsoc-25-mebinthattil-week5"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week05,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-29 - 2025-07-06

---

## Goals for This Week

- **Goal 1:** Test out different Kokoro voices  
- **Goal 2:** Integrate the SLM into Speak  

---

## This Week’s Progress

### **1. Hey Kokoro, you sound different today**

This week, I tested out different voices of Kokoro in two different ways:

1. I tested them inside Speak, within Sugar, and it worked. It still uses the _hacky_ way of creating a temporary WAV file and then playing it via GStreamer, but it works. Streaming will be introduced soon.  

    **Under-the-hood changes:**
    - Kokoro currently uses the following stack:  
      > Text → Kokoro → handle phonemes via G2P engine → Misaki (primary G2P) → fallback → Espeak-ng  
    - Speak already uses Espeak.  
    - So I swapped Misaki's fallback with Espeak (instead of Espeak-ng) to reduce dependencies.  
    - I’ve yet to encounter a case that triggers the fallback, as Misaki is already quite good.

2. I deployed a web app that lets you generate and mix audio. You can try it out [here](https://newstreamlit-frontend.blackpond-9921706d.eastus.azurecontainerapps.io/).
    - The primary reason this was built as a web app is so that we can get kids to test this out and having things as a web app makes it easier. It's cruical for us to get real world feedback before proceeding with the implementation.
    - This web app allows you to try out a plethora of different voices and also mix and match different voices to create basically infinite combinations. It's truly amazing the kind of voices you can create with this.

    ![UI of web app](https://mebin.shop/Kokoro-Streamlit-UI.webp)

    - It's a container app, meaning both the frontend (Streamlit) and backend (Kokoro - FastAPI) run as separate Docker containers hosted on Azure.  
    - The [Kokoro - FastAPI](https://github.com/mebinthattil/Kokoro-FastAPI) exposes an OpenAI-compatible API to generate audio.  
    - This allows us to stream audio output to a client using OpenAI’s Python libraries, like so:

    \`\`\`python
    from openai import OpenAI

    client = OpenAI(
        base_url="http://my_kokoro_backend:8880/v1", api_key="not-needed"
    )

    with client.audio.speech.with_streaming_response.create(
        model="kokoro",
        voice="af_sky+af_bella",  # single or multiple voicepack combo
        input="Hello world!"
    ) as response:
        response.stream_to_file("output.mp3")
    \`\`\`

    - Another potential application of this setup (deploying as separate containers) is to bring Kokoro into pre-existing Speak with minimal dependency changes.  
    - This would work on low end machines with a stable internet connection, as audio is generated server-side and streamed to the client.  
    - While this wasn’t in the original plan, the current architecture makes it a _possibility_ worth exploring.
    - The original plan was to have an offline only version of Kokoro that Speak uses for it's voice. 

#### _Understanding and playing with Kokoro:_

- **How voice names are read**

    Kokoro has a catalog of voices like \`af_bella\` or \`af_sky\`.  
    The first letter of the voice name indicates the language:
    - \`a\` for American English
    - \`b\` for British English
    - \`j\` for Japanese
    - \`m\` for Mandarin Chinese
    - \`s\` for Spanish
    - \`f\` for French
    - \`h\` for Hindi
    - \`i\` for Italian
    - \`p\` for Brazilian Portuguese

    The second letter indicates gender:
    - \`m\` for male  
    - \`f\` for female  

    So \`af_bella\` would be American English, female.

- **Different language options:**

    These do two things:
    1. Speak the text with an accent.
    2. Handle the language-specific text more effectively.

    Example: Using \`hf_alpha\` with both Hindi and English:  
    Input:
    > नमस्ते, आप कैसे हैं? I can also speak in English as well!

    Output audio:  
    <iframe src="https://drive.google.com/file/d/1vd0V3hoZlEYQBhm9clSeeDz25qwtwXEE/preview" width="450" height="50" allow="autoplay"></iframe>

    I speak Hindi, and I can confirm it sounds correct.  
    This is a great example of how Kokoro can help kids learning new languages by combining accent and language aware pronunciation.

- **Voice mixing:**

    - You can mix any of the available Kokoro voices.
    - Mixing is done by assigning weights (between 0 and 1) to each voice.
    - For example, mixing two voices with 0.5 weight each gives a 50-50 blend.
    - Mixing three voices with weights 0.6, 0.3, and 0.1 gives a 60-30-10 blend.
    - This allows for basically infinite voice combinations.

    This could be super useful for building *personas* in Speak, as each persona could have a unique voice!

    ![Image showing how the waveforms are combined](https://github.com/mebinthattil/Kokoro-FastAPI/raw/master/assets/voice_analysis.webp)

**Links:**
- [Streamlit web app](https://newstreamlit-frontend.blackpond-9921706d.eastus.azurecontainerapps.io/)
- [Kokoro - Fast API](https://github.com/mebinthattil/Kokoro-FastAPI)
- [Streamlit Source Code](https://github.com/mebinthattil/Streamlit-Kokoro-Voice-Mixer-Demo)

---

### **2. New brains for Speak**

- I used the previously quantized Tiny Llama 1B GGUF model with llama-cpp-python inside Sugar, using it as the backend for Speak’s chatbot.  
- Using llama-cpp gave great performance boosts, but there's a catch:  
    - Llama-cpp needs to be built for each OS and architecture.
    - This complicates distribution and packaging.  
    - We can’t shift the build process to the client since most of them are using constrained hardware.

- So I tried a different approach: fine-tune a smaller model that doesn't need such optimizations.
- I chose [Llama 135M](https://huggingface.co/amd/AMD-Llama-135m) (yes, *M*, not *B* 😄) and fine-tuned it on my [educational conversation dataset](https://github.com/mebinthattil/Education-Dialogue-Dataset).
- I cleaned and extended the dataset (cleanup scripts are in the repo).
- The model was fine-tuned on AWS Sagemaker. You can find the files [here](https://huggingface.co/MebinThattil/Llama-135M-FT/tree/main).
- The unquantized size is ~500MB, so post-quantization it should shrink further.

But...

- I didn’t proceed with quantization because the raw performance post finetuning wasn’t up to expectations.
- So next step: gather better data, retrain, and re-evaluate.
- Will also discuss next directions with mentors after the next fine-tune round.

---

## Next Week’s Roadmap

- Work on mechanics for voice switching and personas inside sugar.  
- Improve dataset quality.  
- Fine-tune the model again and evaluate performance.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,Xs=Object.freeze(Object.defineProperty({__proto__:null,default:zn},Symbol.toStringTag,{value:"Module"})),Fn=`---
title: "GSoC '25 Week 05 Update by Shubham Singh"
excerpt: "Building and testing out the Image to video player"
category: "DEVELOPER NEWS"
date: "2025-07-05"
slug: "2025-07-05-gsoc-25-firepheonix-week05"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week05
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 5 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-01 – 2025-07-07

---

## Goals for This Week

- Fix some more issues in the scanning that are visible to me.
- Implementing the dynamic input of NOTES like in the phrase maker.

---

## This Week's Achievements

1. **Implemented dynamic input of Notes like in phrase maker.**  
   - So the very good thing about music blocks is, if you want to implement something, it's most LIKELY already there. Haha. So I scanned through the entire code of phrase maker's code and found out the code responsible for what type of input is taking place. Since I already extended the class LegoBricksBlock with StackClampBlock class, the input already worked, but for print block, since I used it as a dummy for future.
   - Well turns out everything fell right into place and I figured out NOT only just the input, but the output of how phrase maker took place and I implemented it on to my own LegoBrick.js . I now completely understand how the output is working out.
        ![Implementation of input and output with OOPs and using existing code and classes.](https://i.ibb.co/4npgBd1Z/Widget-Blocks-js-Working-Tree-Widget-Blocks-js-musicblocks-Cursor-13-07-2025-05-21-24.webp)

        <iframe width="800" height="405" src="https://www.youtube.com/embed/ObNYq29QHZw?si=uoYPchoQUhbEnmY4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


2. **Implemented the complete phrase maker pitch functionality by adding PitchBlocks.js.**  
   - I figured out how to configure the notes, yet struggled with hardcoded value on the octave, which is by default, 4.
   - So I had to literally, manually go over the entire pitch-blocks.js and a few files. After making adjustments inside some of those files, I was finally able to get the octave as well.

        ![Had to change multiple files (14 files). This ultimately improves the way how code is being reused over and over. Rather than coding and making LegoBricks.js 10,000+ lines of code, I've kept it under 2000 using this methodology.](https://i.ibb.co/V0WsmFXX/musicblocks-Cursor-13-07-2025-05-09-24.webp)

        <iframe width="800" height="405" src="https://www.youtube.com/embed/XpgFTjimPyc?si=fi9HxuN5o8BOP26J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

3. **Finally - Testing out Devin's CMK'24 project.**  
   - I finally did what I've always wanted. It was Devin's experiments that inspired me to take up this ,project in core Javascript for music blocks. So, here's a quick summary, haha:

   - Devin led a project called “Lego Musical Notation for the Blind” during the CMK workshop, aiming to create a tactile music system using Lego bricks for visually impaired users. Working with Jamie Chelel from MIT’s K12 Maker Lab, they built a prototype where pitch was mapped vertically and time horizontally on a Lego baseplate. Different brick lengths represented note durations, and a special marker block acted like a clef to guide pitch reference.

    ![Devin's CMK project idea. You can read the entire blog https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c ](https://i.ibb.co/kgPsNR4x/image-2025-07-13-041505518.webp)

   - After building the basic physical model, Devin shifted focus toward digitizing the system. Devin, created a functional prototype of this scanning system, he encountered challenges when trying to assign precise, meaningful pitches within Scratch’s limitations.

    <iframe title="vimeo-player" src="https://player.vimeo.com/video/983707992?h=0b765ba25a" width="800" height="405" frameborder="0"    allowfullscreen></iframe>
    
    - Now, as you can read in my previous, week04 blog, I was able to completely overcome the Technical Hurdle of not being able to detect colors with a very high accuracy from static images.

    - And, finally here's how the scanning result looks like.

        ![Here's the cropped, put image my mentor, Devin sent. It's not clicked from the TOP, but from the bottom side, it has some edges as we can that taking 1/2 a row space even and causing some disruptions here and there. There are HOLLOW type blocks here with a little shadow inside of them which is making the color detection difficult. The red STUBS weren't predicted at first, but they were here. This photo was taken way back during CMK'24, so things weren't ](https://i.ibb.co/vChzCmWg/Music-Blocks-Google-Chrome-13-07-2025-07-47-09.webp)

        ![The image output as scanned](https://i.ibb.co/QvQTGCzt/Devins-Test.webp)
    
    - I realize that the output is coming ONE ROW down. also, the print functionality, it's automatically adjusting the rows ONE down. Still left with some adjustments to make something to show across all the blocks.

    - This still won't cut it. It has to be more accurate than this. I'll continue to optimize further, but I'll move on to the next phase, which is music generation from next week.

    ![Side by side comparison. (VERY ACCURATE, but just that it generated and EXTRA row at the top, which shouldn't be there. Otherwise, due the image not being taken from the TOP, there are shadows and EDGES which lead to incorrect prediction in rows. Otherwise, only row corresponding to E4 is incorrect, I'll have to see why.)](https://i.ibb.co/0pgQ8pDh/image-2025-07-13-121929214.webp)

---

## Challenges & How I Overcame Them

- **Challenge:** Reading through multiple files  
  **Solution:** No solution, just did the old-fashioned, long way. Also read some documentation
- **Challenge:** Have a lot of college related in the upcoming week.  
  **Solution:** Woke up 2-3 sleepless nights to get more time?? Yeah that's what I did.

---

## Key Learnings

- If you're building something, for example, a full-stack frontend backend website, you shouldn't vibe code it with AI and THEN run into errors. Create a basic frontend -> Send post requests with some tool -> Then connect the backend. . And this applied here as well since I put the NOTES as input functionality first THEN the pitch. Build in steps. Plan it out better. Even better, use some LLM to plan it out for you step by step.
- I tried learning a LOT of stuff this week. I'm learning how CORE JAVASCRIPT in itself works and it's an amazing opportunity. I never knew any of the browser storage concepts, or for that matter, time complexity practical use case before hand. I'm just learning so in-depth. It's crazy good.

---

## Next Week's Roadmap

- Now we are getting on the main part, which is producing musical sounds with the printed output. I still have to figure out a way ALONG with that I also have my college related work I've got to do.
- Figuring out the when does music production START. This was mentioned by my mentor, Walter, that the music should start playing the moment the algorithm bumps into the FIRST color change from green. That's a START point.

---

## Resources & References

- **Nothing much, just Music Blocks documentation sufficed** 

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. I like how Devin actually reads everyone's blogs every single week. He's an inspiring person.
PS: If you're reading this blog Devin, I hope you're enjoying the details.

---`,$s=Object.freeze(Object.defineProperty({__proto__:null,default:Fn},Symbol.toStringTag,{value:"Module"})),Un=`---
title: "GSoC '25 Week 05 Update by Nikhil Bhatt"
excerpt: "Implemented historical forking using Git CLI to preserve commit history and securely update metadata for downstream workflows."
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-gsoc-25-nikhilbhatt-week05"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week05,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-06-29 – 2025-07-06  

---

## Goals for This Week

- Investigate and solve the issue of missing commit history in forked repositories.
- Switch from GitHub API–based file copying to full repo cloning with Git CLI.
- Ensure \`metaData.json\` updates include a new hashed key and get committed to the fork.
- Maintain clean repo history and secure edit permissions for each forked project.

---

## This Week's Achievements

###  Switched to \`forkWithHistory\` via Git CLI

Previously, when users forked a project, only the latest files (\`projectData.json\` and \`metaData.json\`) were copied into a new repository via GitHub's REST API. This approach **did not preserve commit history**, making it impossible to trace past changes.

To fix this:

- I implemented a new backend function \`forkWithHistory()\` using \`git clone\`, \`git remote\`, and \`git push\` with a Personal Access Token (PAT).
- This ensured that **full commit history is retained** in forked repositories.
- Each fork gets its own hashed key securely stored in the updated \`metaData.json\`.

- Commits now reflect actual history  
- Forks maintain lineage via \`forkedFrom\` metadata  
- All content and hashes are committed and pushed as part of the first commit

---

### 🔐 MetaData Commit Confirmation

- I ensured that after updating the hash and \`forkedFrom\` link, the file is committed and pushed using Git CLI commands (\`git add\`, \`git commit\`, \`git push\`).
- The Git identity is explicitly set for the commit using:

---

## Challenges & How I Solved Them

- **Challenge:** Missing commit history in GitHub API forks  
  **Solution:** Switched to using Git CLI and a service account PAT to clone and push the entire repository.

- **Challenge:** Rate Limits with PATs  
  **Solution:** We're currently using a single org service account PAT. The rate limits (5,000 requests/hour) are more than enough for current needs, but we may consider switching to app-based or scoped PATs if traffic scales up.

---

## Key Learnings

- Learned how to automate git commands securely in Node.js (using child_process.execSync).
- Understood the limitations of GitHub’s REST API for repo-level history and collaboration.

---

## Next Week's Roadmap 

- Discuss and analyse possible downsides of the current approach, ensuring good fallbacks 
- Create a commit history feature students can see how their project evolved with time

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [Octokit REST.js Library](https://github.com/octokit/rest.js)

---

## Acknowledgments

Thanks again to my mentors and the Sugar Labs community for feedback and support!  
Looking forward to next week’s frontend PR features. 
`,Ys=Object.freeze(Object.defineProperty({__proto__:null,default:Un},Symbol.toStringTag,{value:"Module"})),Nn=`---
title: "GSoC '25 Week 5 Update by Safwan Sayeed"
excerpt: "Implementing the Symbol Table and Memory Module Integration"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-gsoc-25-sa-fw-an-week5"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week5,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 5 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-30 - 2025-07-06  

---

## A Blog-style Retrospective

This week I implemented the Symbol Table and integrated it with the Memory Module to manage variable scopes and dependencies effectively. This was a crucial step in preparing for the Abstract Syntax Tree (AST)-to-Intermediate Representation (IR) compilation logic, ensuring that our program engine can handle variable resolution correctly during the translation process.

---

## Goals for This Week

- Design the Symbol Table.  
- Implement the Symbol Table in the Memory Module.  
---

## This Week's Highlights

1. **Symbol Table Design and Implementation**  
   - Designed the Symbol Table to manage variable scopes and dependencies effectively.
   - Integrated the Symbol Table with the Memory Module to ensure proper variable resolution during AST-to-IR translation.
   - Documented the design and usage patterns for future reference.

---

## Challenges & Solutions

- **Managing Variable Scopes:**  
  Initially faced challenges in ensuring that variable scopes were correctly maintained across different blocks of code.  
  *Solution:* Implemented a robust Symbol Table that tracks variable declarations and their scopes, allowing for accurate resolution during the AST-to-IR translation.  


---

## Key Learnings

- Gained a deeper understanding of how to manage variable scopes and dependencies in a compiler context.  
- Learned how to design and implement a Symbol Table that integrates with the Memory Module to facilitate variable resolution during the AST-to-IR translation process.  

---

## Next Week's Roadmap

- Start working on the execution engine that will interpret the generated IR instructions.  
- Begin implementing the first set of IR instructions.  
---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their crucial guidance on compiler design principles and static compilation concepts. Their clarification on the AST-to-IR translation approach and emphasis on maintaining clean instruction generation patterns was essential for this week's successful progress.

---`,Qs=Object.freeze(Object.defineProperty({__proto__:null,default:Nn},Symbol.toStringTag,{value:"Module"})),Hn=`---
title: "GSoC ’25 Week 05 Update by Diwangshu Kakoty"
excerpt: "Reflection Learning Widget in Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-gsoc-25-diwangshu-week05"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week05,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-06-29 - 2025-07-05  

---

## Goals for This Week

- **Goal 1:** Develop a 'reflection' widget in Music Blocks.
- **Goal 2:** Update Fast API server code.
- **Goal 3:** Fix bugs occured by these changes.

---

## This Week’s Achievements

1. **Develop a 'reflection' widget in Music Blocks**  
   - For this week, I have finally got the green light to work on the frontend of the project. I have started developing a 'reflection' widget in Music Blocks and it is almost comleted. It can be found in the Widget section.

   - The conversation history is stored in the client side. For every query, the widget sends a request to the FastAPI server with payloads like \`query\`, \`messages\` and \`mentor\`. The server then processes the request and returns a response. The response is then displayed in the widget.

  <a href="https://ibb.co/NdLhh6DX"><img src="https://i.ibb.co/21j227Vw/first-Reflection.webp" alt="first-Reflection" border="0"></a>

2. **Update Fast API server code**  
   - As mentioned in my first week's report that I made the Fast API endpoints \`/chat\` and \`/summary\`, I have now updated the code to handle the new 'reflection' widget. 

   - The \`/chat\` endpoint now expects a payload with \`query\`, \`messages\`, and \`mentor\`.

   - The messages include only the conversation history between the user and the AI, excluding the system message. This is because each mentor has a unique system message, which is dynamically set by the server based on the mentor field in the payload. So, we can say that the client-side is not storing any kind of prompts or system message.

---

## Challenges & How I Overcame Them

- **Challenge 01:** I found difficulties in integrating the 'reflection' widget with the FastAPI server. The widget was not handling the response correctly.

  **Solution:** Although I was familiar with async/await and promises in JavaScript, I lacked sufficient hands-on experience. To ensure the widget properly awaited the server response before updating the UI, I revisited these concepts. I also implemented error handling to address any potential issues during API calls.

- **Challenge 02:** The widget was not initializing the messages after re-opening it.

  **Solution:** This was a simple bug where I forgot to initialize the messages array in the widget's state. I fixed it by ensuring that the messages array is initialized when the widget is opened.
---

## Key Learnings

- I gained hands-on experience with integrating a frontend widget with a backend server using FastAPI.
- I learned how to handle asynchronous operations in JavaScript, which is crucial for building responsive web applications.
- I improved my understanding of how to structure API requests and responses for a better user experience.

---

## Next Week’s Roadmap

- From the last meeting with my mentors, I have learned that saving a reflection session is very necessary. It will allow users to revisit their reflections later and also helps a lot in testing. Therefore, I will be implementing saving and loading reflection sessions in the Streamlit app. Infact, I have already made a download button that downloads a JSON file containing the conversation history.

- I was also informed that the AI is asking too many follow-up questions, which is not ideal. I will be working on refining the prompts to reduce unnecessary follow-ups and give it a more natural conversation flow.

- Implement other features like 'generate summary' and 'generate analysis' in the widget. 

- Store the conversation summaries in user's browser using localStorage, so that the user can revisit their reflections later. This will also help in testing the 'analysis' phase of the reflection learning cycle.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)
- **Streamlit App:** [Reflection App](https://reflectionapp-2yoxtvn6sknvktme2zorvq.streamlit.app/)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Zs=Object.freeze(Object.defineProperty({__proto__:null,default:Hn},Symbol.toStringTag,{value:"Module"})),qn=`---
title: "GSoC’25 Week 05 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-gsoc-25-omsuneri-week05"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week05,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-29 - 2025-07-05

---

## Goal for This Week

**Migrating Music Blocks JSON-to-Text Converter to Streamlit App**

---

## This Week’s Achievements

### Introduction

This week, I focused on one of the key deliverables of the project — **integrating the JSON-to-Text Representation Converter into a Streamlit application**. This marks a major step in our plan to create a seamless debugging experience for Music Blocks users. The converter, which was originally built using JavaScript, is now fully functional in Python via Streamlit and ready for integration with the AI-powered debugger.

### What I Did

#### Goal

The previous tool was a **client-side JavaScript converter** that parsed JSON representations of Music Blocks projects and produced a structured, readable **tree-view text format**. The aim this week was to **translate this logic into Python** and build a **Streamlit interface** to make the tool backend-friendly and easily integrable with the AI Debugger app.

#### Migration from JavaScript to Python

Converting the JavaScript-based logic to Python wasn’t a simple one-to-one translation. It involved rethinking data structures, managing recursion differently, and carefully ensuring that **each Music Blocks "block" type was accurately represented** in the output.

Key technical components of the migration included:

* **Parsing the block structure**:

  * Each block in the JSON is structured like \`[block_id, block_type, ..., connections]\`
  * The Python version uses dictionaries (\`block_map\`) and recursion to follow nested or sequential connections (\`clamp\` and \`stack\` logic).

* **Handling specific block types**:

  * Each block type (like \`start\`, \`setmasterbpm2\`, \`newnote\`, \`repeat\`, etc.) has a distinct logic for representation.
  * For example, the \`setmasterbpm2\` block may include a divider block to represent beat values (like \`4/4 = 1.00\`), which must be parsed recursively.

* **Redacting base64-encoded content**:

  * Just like in the JS version, the Python converter checks for base64 strings (e.g., audio/image data) and replaces them with \`"data"\` to keep the output clean and safe.

* **Maintaining tree formatting**:

  * I replicated the \`├──\` and \`│\` styled tree structure for visual clarity.
  * Indentation is handled dynamically based on the depth of recursion.

#### Enhancements Added

While rewriting, I also took the opportunity to **extend the support to more block types** that weren’t handled earlier — for example:

* \`arc\`
* \`incrementOne\`
* \`pitch\`
* \`text\`
* \`settransposition\`

This ensures that even **newer or more complex Music Blocks projects** are parsed correctly and comprehensively.

#### The Streamlit App

Once the backend logic was ready, I integrated it with a user-friendly Streamlit interface. The app consists of:

* A **text area** for JSON input.
* A **convert button** to trigger the parsing.
* A cleanly formatted **output section** with scrollable, monospaced text.
* Error handling for invalid or empty JSON.

---

### Why It Matters

Music Blocks is used in educational environments. One of the biggest challenges new users face is **understanding how blocks connect and function** under the hood. By converting the visual block code into a readable text format, this tool:

* Makes debugging more accessible for students.
* Helps educators explain project logic in class.
* Provides an exportable, printable format of block logic.

#### Foundational Component for the Debugger

This converter will play a **crucial role** in the **AI-powered Music Blocks Debugger**. By giving a structured, simplified text representation of the project:

* The LLM (Large Language Model) will better understand the project logic.
* It enables **embedding**, **chunk retrieval**, and **semantic search** for debugging.
* Users will be able to see both their visual project and a clean text summary on the same platform.

#### Seamless Integration Ahead

Now that the converter is in Streamlit (and Python), integrating it into the AI Debugger system becomes straightforward:

* No need to mix JavaScript and Python — the backend stays unified.
* Users can input JSON and debug in the **same interface**.
* It aligns with the vector database and LLM pipeline we’re building.

### 📸 Preview

Here’s a quick preview of the app:

<a href=""><img src="https://i.ibb.co/XZt6MF9k/Screenshot-2025-07-05-at-3-09-15-PM.webp" alt="Convertor Streamlit interface"></a>


### Final Thoughts

Rewriting an entire logic-heavy JavaScript app into Python was both challenging and rewarding. It made me deeply understand how each block works in Music Blocks and how a simple but well-structured parser can bring clarity to even the most complex visual projects.

--- 

## Next Week’s Roadmap

* Integrate the Streamlit-based converter directly into the AI Debugger interface.
* Improve the understanding of actions in the project by enhancing the LLM prompts.

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)


## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,er=Object.freeze(Object.defineProperty({__proto__:null,default:qn},Symbol.toStringTag,{value:"Module"})),Kn=`---
title: "SSoC ’25 Week 05 Update by Muhammad Haroon"
excerpt: "Generated additional samples using various prompts, which were then evaluated by mentors."
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-ssoc-25-MuhammadHaroon-week05"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week05,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-30 - 2025-07-06  

---

## Goals for This Week

- **Goal 1:** Generated more samples using various prompts, which were then evaluated by mentors.
- **Goal 2:** Explored FastAPI and AWS.

---

## This Week's Achievements

1. **Generated more samples using various prompts**  
   - I generated more samples using [various prompts](https://docs.google.com/spreadsheets/d/1lxMHoiE-4YB5oDYlXfSP9TK5iXWkGYWC33ll8weJIO8/edit?usp=sharing). These samples were stored in [Google Drive](https://drive.google.com/drive/folders/1jee1MAmsyNddbh-pTIOX9K6Wctbd6Cf9?usp=drive_link) and shared with the mentors. The mentors scored the sounds using the following Google Sheets: [Walter's Score](https://docs.google.com/spreadsheets/d/1gzh7w2o8TeUUaePqOSlN2bt1T7fofFeRNoGzxq97PPM/edit?usp=sharing) and [Devin's Score](https://docs.google.com/spreadsheets/d/1ozwnBbXLQKZY_EQ-p7I4y0PRtzkqUauYOwstVnvjxFU/edit?usp=sharing). The scores that could be assigned were: bad (1), fair (2), and good (3). Both Devin and Walter gave an average score of 1.485, indicating that the overall output quality was closer to bad than fair. After reviewing the score, it became evident that a new model was needed.

2. **Explored FastAPI and AWS**  
   - I explored FastAPI for connecting the backend with the frontend and AWS for deploying our backend.

---

## Next Week's Roadmap

- Find another open-source model to generate high quality sound samples.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,nr=Object.freeze(Object.defineProperty({__proto__:null,default:Kn},Symbol.toStringTag,{value:"Module"})),Vn=`---
title: "DMP’25 Week 05 Update by Justin Charles"
excerpt: "Setup a visual playground with drag-and-drop brick placement from a palette UI"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-dmp-25-justin212407-week05"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week5,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 5 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-29 - 2025-07-06  

---

## Goals for This Week

- Set up the core **Playground UI** to serve as the editable workspace  
- Build a **Palette** with available brick types and integrate it visually into the Playground  
- Enable **drag-and-drop interactions** from the palette into the workspace  

---

## This Week’s Highlights

### 1. **Playground Workspace Setup**

Created a dedicated layout component for the brick workspace:
- Positioned using CSS grid to support side-by-side palette and canvas
- Styled with scrollable overflow to allow panning and scaling in future updates
- Prepares the base for rendering brick instances using spatial coordinates  


### 2. **Brick Palette UI**

Added Palette UI to playground:
- Lists all brick types with color-coded icons and labels
- Styled for compact visibility, allowing quick scanning of available bricks
- Each brick is draggable and includes metadata for \`type\`, \`defaultProps\`, and visual ID

🎨 Gives users clear visual feedback about available building blocks before use

### 3. **Drag-and-Drop from Palette to Playground**

Implemented full drag-and-drop pipeline:
- **OnDragStart**: Attaches metadata (\`type\`, \`defaultProps\`) to the drag event
- **OnDrop**: Computes drop position relative to workspace container
- **Dispatch**: Triggers creation of a new brick model at the drop location via Recoil

Supports extensibility for:
- UUID generation
- Position snapping
- Drag preview overlays

---

## Challenges & Solutions

**Challenge:** Drop positioning was inaccurate due to nested containers and scroll  
**Solution:** Used \`getBoundingClientRect()\` to normalize the offset and compute absolute drop coordinates

**Challenge:** Drag behavior caused unwanted rerenders across unrelated components  
**Solution:** Memoized drag metadata using \`useRef\` and lifted shared handlers to a centralized manager  

---

## Key Learnings

- **Component Composition**  
  Learned how to break large UI logic into isolated playground, palette, and renderer components for clarity

- **Event Normalization**  
  Understood how native drag events behave in nested layouts and how to calculate relative drop points robustly

- **State Orchestration**  
  Tied together UI state (hover/drag) and business state (brick model updates) using Recoil and internal \`BrickFactory\` functions

---

## Next Week’s Roadmap

- Implement dragging of bricks in the playground.
- Implement Collision Maps for colliding objects.
- Create a reverse mapping utility file to fetch all connection points.
---

## Resources & References

- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  
- [MDN Drag and Drop Guide](https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API)  
- [RecoilJS Docs](https://recoiljs.org/)

---

## Acknowledgments

Thanks to the my mentor Anindya Kundu team for helping me align on visual structure of palette.

---
`,tr=Object.freeze(Object.defineProperty({__proto__:null,default:Vn},Symbol.toStringTag,{value:"Module"})),Jn=`---
title: "DMP ’25 Week 05 Update by Harshit Verma"
excerpt: "This week, I built a custom Markdown parser for VTE (Virtual Terminal Emulator), began evaluating model performance, and discussed age appropriate debugging practices with mentors."
category: "DEVELOPER NEWS"
date: "2025-07-07"
slug: "2025-07-07-dmp-25-therealharshit-week05"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week05,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-30 - 2025-07-06   

---

## Goals for This Week

- **Goal 1:** Develop a custom Markdown parser for VTE (Virtual Terminal Emulator).
- **Goal 2:** Begin model selection and optimization.
- **Goal 3:** Discuss best debugging practices for children.

---

## This Week’s Achievements

1. **Built a Lightweight Markdown Parser for VTE**  
   - Created a simple parser to interpret basic Markdown (like \`**bold**\`, \`- bullets\`, \`### headers\`) and display it using ANSI-style formatting in the VTE terminal.
   - Iterated by testing different wording styles and instruction formats, which led to noticeably better visual output.
   ![Pippy UI: Parsed markdown response in vte](assets/Images/pippy_markdown-parser.webp)

2. **Started Model Evaluation and Optimization**  
   - Compared several models (like Mistral, CodeLlama, and others from Hugging Face) to balance output quality with local performance.
   - The response was good but it was taking a lot of time to generate the response.

3. **Had a Discussion on Debugging Practices for Children**  
   - Talked with mentors about how to present debugging in a way that encourages curiosity rather than frustration.
   - Key ideas included: focusing on helpful language, start with contextualization, and offering clear, step-by-step suggestions.

---

## Challenges & How I Overcame Them

- **Challenge:** Parsing Markdown in a VTE terminal widget.  
  **Solution:** Since VTE doesn't support rich text natively, I built a custom parser to translate basic Markdown into stylized terminal output using spacing, symbols, and ANSI codes.

- **Challenge:** Running the model locally on CPU.  
  **Solution:** Faced performance limitations due to lack of GPU support. To address this, I explored the option of offloading model inference to AWS.

---

## Key Learnings

- Gained experience in building a custom parser, handling string pattern detection and safe rendering within VTE.
- Practiced simplifying technical content for young learners, focusing on clarity over complexity.

---

## Next Week’s Roadmap

- Work on setting CSS for Debugging terminal, to style it.
- Finalize model selection and prepare integration with Sugar-AI.
- Start working on saving debug history to Sugar Journal.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,ar=Object.freeze(Object.defineProperty({__proto__:null,default:Jn},Symbol.toStringTag,{value:"Module"})),Xn=`---
title: "GSoC ’25 Week 08 Update by Aditya Kumar Singh"
excerpt: "Resolved key issues in shared Paint & Tour workflows, introduced a real-time XO-icon leaderboard in Doctor mode, and bootstrapped the Stickman activity scaffold."
category: "DEVELOPER NEWS"
date: "2025-07-09"
slug: "2025-07-08-gsoc-25-AdityaKrSingh26-week08"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week08,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)   
**Mentors:** [Lionel Laské](https://github.com/llaske)   
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)   
**Reporting Period:** 2025-07-03 – 2025-07-09  

---

## Goals for This Week

- **Goal 1:** Bug-hunt Shared Paint & Tour PR  (Restore zoom-out capability when a session starts at a custom FOV, Guarantee that newcomers instantly receive every painted mesh, Ensure the palette reflects the host-selected mode (Paint / Tour / Doctor) on join.)
- **Goal 2:** Finish Doctor refactor – replace the legacy username-only leaderboard with XO icons tinted to each participant’s Sugar colour.    
- **Goal 3:** Kick-off Stickman Activity – create a blank shell with full toolbar assets ready for upcoming features.  


---

## This Week’s Achievements

1. **Fixed Zoom-Out Limitation**  
    - **Issue:** When the Human Body activity was opened with a custom zoom level, users were unable to zoom out due to improper FOV (Field of View) limits.  
    - **Fix:**  
        - Implemented clamped zoom logic by calculating and bounding the \`camera.fov\` value between 5° and 75°.  
        - Both scroll wheel and toolbar zoom now honor the same constraints.  
    - This method ensures that camera zoom respects a realistic viewing range, preventing the camera from getting stuck in an unusable state.
    \`\`\`javascript
        function getFov(zoom) {
            return Math.min(Math.max(zoom, 5), 75); // clamp zoom to valid FOV range
        }
2. **Shared Paint Mode – Late Joiner Synchronization**  
    - **Issue:** When a new user joined an already shared Paint session, the previously painted parts weren’t visible to them.  
    - **Fix:**  
        - The host maintains a complete list of painted parts and their corresponding color mappings in paintedPartsList.  
        - When a new user joins, the host invokes: \`sendFullPaintDataToNewUser(presenceId)\`   
        - This sends all \`meshName → hexColor\` mappings via the \`syncAllPaintData\` action.  
        - Peers then replay this data and apply consistent material colors to each 3D mesh
    - This method ensures that camera zoom respects a realistic viewing range, preventing the camera from getting stuck in an unusable state.


3. **Mode Palette Sync Across Clients**  
   - **Issue:** The palette mode (Paint, Tour, Doctor) would sometimes display inconsistently across users in a shared session.
    - **Fix:** 
        - Centralized mode state and now rebroadcast on every mode change.  
        - When any user joins, their client listens to \`syncCurrentMode\` and updates icons accordingly:   
    - **Effect:** UI remains consistent regardless of when users join or switch modes.


4. **Redesigned Doctor Mode Leaderboard with XO Icons**   
    - **Objective:** Replace the old leaderboard (just usernames and scores) with a Sugar-style UI using XO icons and user colors. 
    - **Implementation Highlights:**
        - \`generateXOLogoWithColor(userColor)\`: A dynamic SVG generator that outputs an XO icon with the user’s stroke and fill colors, derived from Sugar presence data.
        - \`showLeaderboard()\`: Constructs a ranked visual layout showing each user’s XO icon, name, and score—updated in real time with every correct answer.
    - **Algorithm Steps:**
        - Maintain a scoreBoard object mapping presenceId → {score, userInfo}.
        - Upon a correct answer:
            - Host sends a \`scoreUpdate\` broadcast.
            - All peers update their UI leaderboard.
        - Leaderboard HTML is re-rendered using updated user data and SVG icons.
        ![Shared Doctor Mode](https://i.ibb.co/jkLPqWDP/image.webp)   


3. **Stickman Activity – Initial Scaffold**  
    - Created an initial version of the activity.
    - Toolbar now displays all expected icons (draw, move, add frame, delete frame, play, stop).
    - Currently, button clicks do nothing—but the structure is laid out to integrate drawing and animation logic next week.
    ![Stickman Basic UI](https://i.ibb.co/mCpmRp3J/image.webp) 



---

## Challenges & How I Overcame Them

- **Challenge:** Simultaneous paint broadcasts leading to race conditions.  
  **Solution:** Ensured all paints are stored only on host, then synced post-join via a single action.

- **Challenge:** Dynamic XO SVGs without image files.  
  **Solution:** Used inline SVG with JS string templates to create colored icons on-the-fly.


---

## Key Learnings

- Gained in-depth understanding of Three.js camera manipulation and persistence.  
- Built a robust synchronization pattern using presence broadcasts and authoritative state snapshots.  
- Practiced UI/UX consistency across Sugarizer activities with reusable SVG elements and Sugar-specific color schemes.  

---

## Next Week’s Roadmap

- Write Weekly Blog Post summarizing progress, screenshots, and key learnings.   
- Fix Remaining Issues in Human Body Activity   
- Stickman Dashboard – Draw & Move   
- Stickman Frame Management   

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,or=Object.freeze(Object.defineProperty({__proto__:null,default:Xn},Symbol.toStringTag,{value:"Module"})),$n=`---
title: "DMP ’25 Week 6 Update by Aman Naik"
excerpt: "This week involved integrating the LLM's story framework into the UI, user testing with school children, and successfully resolving AWS deployment issues."
category: "DEVELOPER NEWS"
date: "2025-07-12"
slug: "2025-07-12-dmp-25-AmanNaik-week06"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week06,midterm,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 6 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-07-06 – 2025-07-12  

---

## Goals for This Week

- Build a user interface for the generated story framework  
- Integrate LLM-generated responses into the UI  
- Get feedback from real students using the demo application  
- Deploy an LLM model on AWS  

---

## This Week’s Achievements

1. **Built the Story Framework UI**  
   - Designed and implemented the story framework display using GTK and GTK CSS.  
   - The UI now dynamically displays the story structure based on the JSON response received from the LLM.  
   - The framework was successfully demonstrated to mentors, who gave positive feedback on the overall integration and experience.

2. **Integrated LLM Response Into the UI**  
   - Parsed the JSON response from the LLM and displayed each story element in dedicated sections within the app.  
   - Incorporated error handling for missing or blank story categories.

   ![Framework UI(WIP) with LLM genrated response](assets/Images/aman-naik-week6-img1.webp)

3. **Gathered Real-User Feedback Through a School Demo**  
   - Mentor [Devin Ulibarri](https://github.com/pikurasa) organized a hands-on testing session with 12 students across four different activity stations:  
     - LLM-Speak  
     - Story Builder  
     - Personas  
   - Students reflected on their experience via handouts. I’ll be analyzing their feedback to better understand their thoughts and identify areas of improvement.

   ![Image of the handout given by Devin Ulibarri](assets/Images/aman-naik-week6-img2.webp)

4. **Resolved AWS Permissions Issue**  
   - Successfully resolved the permission issue that previously blocked AWS access.  
   - Now have access to SageMaker and am prepared to deploy the LLM model as planned in the upcoming week.

---

## Challenges & How I Overcame Them

- **Challenge:** Handling incomplete or empty story categories in LLM responses  
  **Solution:** Added placeholders in the UI for missing categories. These placeholders guide the student with helpful questions (e.g., "What could be the turning point in your story?") to encourage further development. Future updates will include buttons for AI-generated suggestions.  

- **Challenge:** Gaining access to deploy on AWS  
  **Solution:** Through clear and timely communication with mentors, I was able to get the necessary permissions and understand more about how access control and user roles work in AWS.

---

## Key Learnings

**Learned How to Build and Parse Adaptive Story Frameworks in UI**  
   - Learned how to dynamically map LLM outputs into GTK UI components and ensure the experience remains useful even when some inputs are missing.  
   - Code of try and except block parsing the response given by the LLM to update story info:  

   \`\`\`python
   try:
        start_idx = analysis.find('{')
        end_idx = analysis.rfind('}') + 1
        if start_idx != -1 and end_idx != -1:
            json_str = analysis[start_idx:end_idx]
            story_data = json.loads(json_str)
            return story_data
    except Exception:
        pass
    # Return default structure if parsing fails
    return {
        "title": "",
        "setting": "",
        "character_main": "",
        "character_side": "",
        "goal": "",
        "conflict": "",
        "climax": "",
        "helpers": "",
        "villains": "",
        "ending": "",
        "theme": ""
    }
   \`\`\`   

**Valuable Experience from Real User Testing**  
   - Understood how students react to the tool, what excites them, and what confuses them — essential insights to shape the next phase of development.

**Improved My Understanding of AWS Deployment Workflows**  
   - Resolved previous blockers and now have a clearer picture of how cloud model hosting works and how access can be securely managed.

---

## Next Week’s Roadmap

- Finalize the deployment of the selected LLM model using AWS SageMaker  
- Make the sidebar panel collapsable so it can be accessed when needed  
- Understand feedback of the UI based on student and mentor feedback    

---

## References

_Quote from Devin Ulibarri (Mentor):_  
> "Since these are experimental, I was mildly concerned that a student might find something inappropriate, but nothing of the sort happened. One student made a story about a "Blob of Poop", but it wasn't too bad."  

This has prompted me to think about on how to make LLM responses more child-friednly and create strict restrictions for inappropriate content.  

---

## Midterm Progress Summary

Over the past six weeks, I’ve made significant progress toward building an AI-powered assistant for the Write Activity:

- **Week 1–2:** Explored different approaches to creative writing and finalized a guided AI-assisted architecture for story building.
- **Week 3:** Built a working demo using Streamlit and received initial mentor feedback.
- **Week 4:** Began integrating the demo into the Sugar Activity and created the first UI prototype with a sidebar chatbot.
- **Week 5:** Designed a widget to display the story framework and attempted to deploy the LLM model on AWS (later resolved).
- **Week 6:** Fully integrated LLM JSON responses into the app's UI, tested the tool(using the demo application) with 12 students, and gathered real-world feedback. Also successfully resolved the AWS access issue for upcoming deployment.

These weeks have been packed with learning—from UI design for young learners to API integration, cloud model deployment, and real-user testing. With foundational blocks in place, I’m now ready to polish the experience and begin iterative improvements with real feedback in mind.  

---

## Acknowledgments

A huge thank you to my mentors, especially Devin Ulibarri for arranging the user testing session. I’m also grateful to Walter, Ibiam, and the Sugar Labs community for their continued support and constructive feedback every week.

---
`,ir=Object.freeze(Object.defineProperty({__proto__:null,default:$n},Symbol.toStringTag,{value:"Module"})),Yn=`---
title: "DMP’25 Week 06 Update by Justin Charles"
excerpt: "Added drag and drop support from palette to workspace, rendered interactive blocks, and built a collision map with linear and quad tree detection"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-dmp-25-justin212407-week06"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week6,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 5 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-06-06 - 2025-07-13   

---

## Goals for This Week

- Add React Aria and Recoil for State Management of bricks in WorkSpace  
- Generate a real-time collision map tracking overlapping bricks  
- Implement and compare two spatial collision algorithms: linear scan and quadtree  

---

## This Week’s Highlights

### 1. **Add React Aria and Recoil for State Management of bricks in WorkSpace**

Enabled Smooth dragging of Bricks in and around the workspace using React Aria and Recoil:
- Created Draggable components for bricks to make them move in the workspace.
- Update State and position of bricks each time it is updated and moved. 

### 2. **Collision Map Infrastructure**

Created a collision detection engine to register overlapping bricks:
- On each render/update, all bounding boxes are passed into the collision space
- Outputs collision pairs with \`id\` references
- Visual debug overlay available to inspect overlaps

Supports both brute-force and spatial-partitioned (quadtree) strategies via strategy pattern  

### 3. **Implemented Two Collision Detection Algorithms**

**a. Linear Brute-Force Algorithm**  
- O(n) pairwise check between all visible bricks  
- Ideal for ≤ 20 bricks  

**b. Quad Tree Algorithm**  
- Spatially partitions the workspace into quadrants recursively  
- Reduces unnecessary checks by limiting comparisons to nearby bricks  
- Scales well to large projects  

---

## Challenges & Solutions

**Challenge:** Drag offsets weren’t accurate when dropping bricks inside nested towers  
**Solution:** Used bounding client rect and scroll offsets to normalize cursor position  

**Challenge:** Collision map flickered on high-frequency updates  
**Solution:** Debounced update cycle and implemented memoized collision bounding box comparison  

---

## Key Learnings

- **Drag and Drop Mechanics**  
  Learned native drag/drop lifecycle (dragstart, dragover, drop) and integrating with component state

- **Spatial Algorithms**  
  Compared brute-force vs quadtree models and saw practical scaling tradeoffs in the playground

- **State-Driven Rendering**  
  Deepened understanding of how Recoil-based atom changes trigger dynamic rendering in React  

---
## Mid Term Summary: 

**Week 01**
The first week was dedicated to understanding the core geometry behind the SVG path rendering of bricks. I focused on identifying constants required to construct the outlines of different brick types and reverse-engineered how variable features like notches or arguments influenced the structure. This involved translating SVG commands into modular logic and laying the groundwork for a parameter-driven rendering system that would scale across all types of bricks.

**Week 02**
Building on the SVG foundation, I completed the path generation logic for all three core brick types — Simple, Expression, and Compound. I also categorized all props and visual states a brick can have and documented the variations clearly across types. With the rendering engine in place, I authored a comprehensive test suite to ensure output correctness and visual consistency, setting the stage for a stable rendering system.

**Week 03**
This week marked the shift from static SVG rendering to dynamic tree-based rendering. I built a recursive parser that transformed a brick tree structure into React components, preserving hierarchy and sibling order. Additionally, I exposed spatial data like bounding boxes and connection points from the model layer and passed them through the rendering pipeline, allowing for downstream layout and interaction logic to be implemented in a clean, scalable way.

**Week 04**
I focused on creating the palette system by compiling all brick types from the source code and organizing them into a visual schema. A JSON schema was also defined to ensure consistency across brick definitions. This schema was then used to power a dynamic, searchable, and category-aware Palette UI. It enabled brick previews and made the rendering layer schema-driven, simplifying future maintenance and scalability.

**Week 05**
The main highlight this week was setting up the interactive playground. I created the workspace layout and integrated the palette directly into it. I implemented full drag-and-drop functionality allowing bricks to be dragged from the palette and dropped into the canvas. On drop, brick metadata was used to create a model instance at the appropriate position. This built the bridge between UI interaction and the underlying data model.

**Week 06**
The focus shifted to interactivity and spatial intelligence. I enabled in-canvas dragging of placed bricks using React Aria and Recoil. Alongside that, I built a collision detection engine capable of detecting overlapping bricks. Two algorithms were implemented: a simple linear scan and a performance-optimized quadtree. This introduced real-time spatial awareness into the system and laid the groundwork for advanced features like snapping, grouping, and constraint-based layouts.


## Next Week’s Roadmap

- Enable snapping logic during drag-drop using collision hints  
- Highlight drop zones using bounding box heatmaps  

---

## Resources & References

- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  
- [Quadtree Implementation Ref](https://en.wikipedia.org/wiki/Quadtree)  
- [Collision Detection Implementation Plan](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.ma5nmu1mlnke#heading=h.esqcxx854myo)

---

## Acknowledgments

Thanks to my mentor Anindya Kundu for for the consistent feedback and support.

---
`,sr=Object.freeze(Object.defineProperty({__proto__:null,default:Yn},Symbol.toStringTag,{value:"Module"})),Qn=`---
title: "GSoC '25 Week 6 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates"
category: "DEVELOPER NEWS"
date: "2025-07-12"
slug: "2025-07-12-gsoc-25-Elwin-Li-week06"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,midterm,week6,javaScript editor,debugger,syntax highlighting"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 6 Progress Report by Elwin Li

**Project:** [Advanced JavaScript Editor with MusicBlocks Interactions](https://github.com/sugarlabs/musicblocks/tree/config_driven_conversion/elwin)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-07-05 - 2025-07-12

---

## Goals for This Week

- **Goal:** Complete syntax/error highlighting, and conclude the project

---

## This Week’s Achievements

**Made PR for Syntax highlighting project**

The syntax/error highlighting project has been complete and a [PR has been made](https://github.com/sugarlabs/musicblocks/pull/4723). This project adds syntax highlighting and error highlighting to the JS editor, making the editor easier to work with. The syntax highlighting was done using
the highlightjs library, and the error highlighting was done by using the acorn library to parse the JavaScript code, and marking down the location
of any errors, and doing some calculations to highlight the associating places red.

Any syntax errors will not only cause the place of errors to be highlighted, but it will also print an error message in the console log. This will additionally make it easier for the user to understand when and where an error occurs. A demo of the highlighting is displayed below:

<a href="https://ibb.co/VpVMyZFM"><img src="https://i.ibb.co/yB0gT1zg/Screenshot-2025-07-12-at-9-01-37-PM.webp" alt="Syntax Highlight"></a>

<a href="https://ibb.co/1YTRYQFx"><img src="https://i.ibb.co/Y4hf4QHG/Screenshot-2025-07-12-at-9-01-48-PM.webp" alt="Error Highlight"></a>

**Made prototype for prompt to valid JavaScript code that can convert to MusicBlocks AI**

This week, I have also made a gemini wrapper that takes in a prompt such as "Play twinkle twinkle little star with the guitar" and outputs JavaScript code that specifically works with MusicBlocks, so the user can copy paste the result into the JSeditor, convert the code to blocks, and play the result. This was done with a Google gemini API call along with extensive prompt engineering making sure it knows exactly what kind of code works with MusicBlocks, and what kind of code will cause errors if attempted to convert to blocks.

[youtube: BFY3Bbi8V2g]

[youtube: TEGWOAf5iO4]

## Midterm Progress Summary

**Over the 6 weeks of GSoC, I have accomplished the following**

### Community Bonding: Project Foundation
- **Planning and Research**: Defined project scope and educational goals
- **Initial Implementation**: Started with basic JavaScript-to-blocks conversion for rhythm, flow, number, and boolean palettes
- **Architecture Design**: Planned the overall system architecture and feature roadmap

### Week 1: Architecture Breakthrough
- **Config-Driven Refactoring**: Developed JSON-based configuration system for block mappings
- **AST Integration**: Implemented Acorn parser for JavaScript code analysis
- **Pattern Matching**: Created flexible AST pattern matching for complex JavaScript constructs
- **Extensibility**: Made adding new blocks as simple as updating configuration files

### Week 2: Complete Implementation
- **Full Block Support**: Extended system to support all compatible block types
- **Optimization**: Implemented JSON minification and config consolidation
- **Documentation**: Created comprehensive conversion guide and unit tests
- **Production Deployment**: Successfully deployed feature through merged PR

### Week 3: Debugger Development
- **Interactive Debugger**: Built working debugger with breakpoint system
- **Variable Inspection**: Implemented real-time variable display and tracking
- **Visual Integration**: Connected debugger statements to visual blocks
- **Educational Features**: Added step-by-step execution and status block integration

### Week 4: Debugger Refinement
- **UX Optimization**: Simplified debug mode and improved user interface
- **Status Block Enhancement**: Optimized variable management and display
- **Execution Control**: Enhanced integration with existing play controls
- **Bug Fixes**: Resolved execution flow and block behavior issues

### Week 5: Final Integration
- **Debugger Completion**: Finalized debugger with comprehensive PR
- **Syntax Highlighting**: Added basic syntax highlighting to JavaScript editor
- **Production Ready**: Completed all planned features and deployed to production
- **Documentation**: Finalized user guides and technical documentation
---

## Key Learnings

- Improved skills in UX design and keeping tools simple for the user
- Deepened understanding of highlightjs
- Learned Gemini API calls
- Improved skills in prompt engineering
- Improved skills in **debugging**, **code design**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Fine tune an LLM to work better with MusicBlocks specific requests

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,rr=Object.freeze(Object.defineProperty({__proto__:null,default:Qn},Symbol.toStringTag,{value:"Module"})),Zn=`---
title: "GSoC '25 Week 6 Update by Krish Pandya"
excerpt: "Palettes, Groups, and GTK4 Decisions "
category: "DEVELOPER NEWS"
date: "2025-07-15"
slug: "2025-07-15-gsoc-25-mostlyk-week06"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week06,mostlyk,midterm"
image: "assets/Images/GSOC.webp"
---


# Week 6: Palettes, Windows, and GTK4 Decisions

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)
**Reporting Period:** July 7, 2025 – July 15, 2025

---

## Why This Blog is Two Days Late

First off, a confession: this update is getting written on 15th instead of the usual Saturday, I was travelling back to my university and this week's work was plenty and important.
I wanted to make sure I gave the proper write-up it deserves, especially since it's also the time for **midterm** evaluations. So if you are reading this, thank you for patience.


## Midterm Evaluations: Reflections

For this week we had to write about midterm evaluations and after 6 weeks we have the halfway point. To look back what's been done , what changed and why. This project has been as much about architectural decisinos and learning as it has been about code or just porting in itself.

- Weeks 1–2: Laying the foundation, setting up the C and Python split, and getting the Meson build system working.
- Weeks 3–4: We move into event controllers, file attribute utilities, and the starting of python library.
- Weeks 5–6: Animations, toolbars, and a full rework of the palette system for GTK4 python library now.

### What changed and why?

- Modern GTK4 patterns: Embracing controllers, gestures, and popovers has improved both code quality and user experience.
- Testing and documentation: Every major change is now accompanied by example scripts and documentation, making it easier for others (and my future self) to pick up where I leave off.

### Personal growth:
Beyond the code, the first half taught me a lot about communcation, documenting decisions and working with mentors across time zones. I'have learned to reason and think about changes, justify architectural decisions, think broad and wide and accept that sometimes the best solutions are just compromise!
I look forward for the next half where I can finalizing the widgets and graphics and get one or two activities ported.

## The Palette Rewrite of '25

The palette system was one of the most challenging and complex rewrites till now, it wasn't a find and replace, original implementation was tied to our own gestures. And event model and widget hierarchy which has been changed significantly in GTK4.


### What's the update in the Palettes?


- Will be sharing the example videos on next week! But here's the technical gist that I remember is big:

-   \`Gtk.Popover\` is King: Instead of manually managing popup windows, the new \`Palette\` class now uses \`Gtk.Popover\` for the menu implementation.

-   Controllers over Signals: The tangled web of event signals is gone. All interaction is now handled by \`Gtk.EventController\` and \`Gtk.Gesture\` objects.
For example, hover detection in \`WidgetInvoker\` now uses \`Gtk.EventControllerMotion\`, and clicks are captured with \`Gtk.GestureClick\`.

-  Real Widgets for Menu Items: \`PaletteMenuItem\` is no longer a \`Gtk.EventBox\`. It is now a proper \`Gtk.Button\`, which gives us accessibility, theming, and correct behavior for free. CSS is used to style it to look like a menu item, removing the need for manual background color changes on hover.


- \`ToolButton\`: The GTK3 \`Gtk.ToolButton\` is deprecated. So as the replacement we have \`Gtk.Button\` subclass styled with CSS to be our toolbutton, integrated with the \`ToolInvoker\` and palette system. It handles the activate state drawing and accelerator setup using modern \`Gtk.Application\` actions.

-  Streamlined Invokers: All invoker classes (\`WidgetInvoker\`, \`CursorInvoker\`, \`ToolInvoker\`, \`TreeViewInvoker\`) have been refactored to use the new controller-based system.

### Some Threads and Docs:

- https://gitlab.gnome.org/GNOME/gimp/-/issues/7700
- https://docs.gtk.org/gtk4/class.EventControllerMotion.html
- https://valadoc.org/gtk4/Gtk.Popover.html
- https://docs.gtk.org/gtk4/class.GestureClick.html

---


## Progress Snapshot

-   Palette System: Complete rewrite for GTK4, including \`Palette\`, \`PaletteGroup\`, \`PaletteMenuItem\`, and all \`Invoker\` types.
-   ToolButton: A new, modern \`ToolButton\` widget from scratch.
-   Examples: Added comprehensive demos (\`palette_example.py\`, \`palettegroup_example.py\`) to showcase every feature and edge case of the new system.

---

## Looking Ahead

With palettes and toolbuttons now on a solid GTK4 footing, the next weeks will focus on:

-   Finalizing the remaining widget infrastructure (\`widgets.py\`) and integrating it with the palettes.
-   Porting an actual Sugar activity to use the new toolkit, putting our work to a real-world test.

---

## Links

-   [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
-   [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
-   [New C Library (sugar-ext)](https://github.com/sugarlabs/sugar-ext)
-   [Game Demo Video](https://youtu.be/B517C_LTCns)

---

## Closing Thoughts

Next half of this GSoC going to be fun! And also we merged Sugar-AI ( _yay!_ thanks to Ibiam for taking out time to sit on a meet and go through this ) now we can deploy and test our LLMs and try to have more fun that way as well.

And YESS NOW YOU CAN PLAY THE GAME HEHE.

Until next week (on time, I promise!),
Krish
`,lr=Object.freeze(Object.defineProperty({__proto__:null,default:Zn},Symbol.toStringTag,{value:"Module"})),et=`---
title: "GSoC '25 Week 7 Update by Krish Pandya"
excerpt: "Bundling, Post MidTerm"
category: "DEVELOPER NEWS"
date: "2025-07-22"
slug: "2025-07-22-gsoc-25-mostlyk-week07"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week07,mostlyk"
image: "assets/Images/GSOC.webp"
---


# Week 7: Bundling , Post MidTerm, Sugar Envrionment and Profiles

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)
**Reporting Period:** July 15 2025 – July 22, 2025

---

## Flatpak and the need for Bundling

Let's start by explaining why we need to bundle in the first place, so we are porting, there will be inherent incompatibilities which will take a lot longer than just the span of GSoC and that shouldn't stop us from writing and shipping activities in GTK4 as GTK3 is regardless reaching its EOF soon.

We can begin by writing both existing and new activities in this way to ship them as Flatpaks. I’ll share the structure in this blog post (subject to change as we progress).

Here's the main start:

\`\`\`json
{
  "app-id": "org.sugarlabs.Gtk4BundleTest",
  "runtime": "org.gnome.Platform",
  "runtime-version": "45",
  "sdk": "org.gnome.Sdk",
  "command": "org.sugarlabs.Gtk4BundleTest",
  "finish-args": [
    "--share=network",
    "--socket=wayland",
    "--socket=x11",
    "--device=dri",
    "--filesystem=host"
  ],
  "modules": [
    {
      "name": "python-builddeps",
      "buildsystem": "simple",
      "build-commands": [
        "pip3 install --prefix=/app --no-build-isolation setuptools wheel pip"
      ],
      "sources": []
    },
    {
      "name": "sugar-toolkit-gtk4-py",
      "buildsystem": "simple",
      "build-commands": [
        "pip3 install --prefix=/app --no-build-isolation ."
      ],
      "sources": [
        { "type": "dir", "path": "../../", "dest": "." }
      ]
    },
    {
      "name": "gtk4-bundle-test",
      "buildsystem": "simple",
      "build-commands": [
        "install -Dm755 main.py /app/bin/org.sugarlabs.Gtk4BundleTest"
      ],
      "sources": [
        { "type": "file", "path": "main.py" }
      ]
    }
  ]
}
\`\`\`


## Hacks Explained:

As I’ve explained in the [README](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py/tree/main/examples/gtk4_bundle_test), the source code needs to be two directories above. The build command would change if we were installing from a \`pyproject\` or as a pip dependency.

After discussing this with Walter, I have a fun flatpak to bundle now for the few weeks as a proof of concept , It is [fractionbounce](https://github.com/sugarlabs/fractionbounce/)

Additional Notes: The main.py needs to be executable and needs to have the shebang of python at the start of file.

Apart from that there are no salient quirks one needs to know, just follow the README and you can generate the flatpak , install and run it!


## The Discussion with Juan Pablo and Ibiam

So this friday ( July 18 , 2025 ) I had a call with Juan Pablo and Ibiam and we discussed about the implications of changes and overall progress.
We talked about how Popover are a really nice alternative as discussed in the last blog as well.
I learnt about GTK_DEBUG=interactive flag and it changed a lot of things for me. A bit late to learn about that but better late than never they say.


## Looking Ahead

>  With palettes and toolbuttons now on a solid GTK4 footing, the next weeks will focus on:
>  -   Finalizing the remaining widget infrastructure (\`widgets.py\`) and integrating it with the palettes.
>  -   Porting an actual Sugar activity to use the new toolkit, putting our work to a real-world test.

As mentioned in the previous blog, I’ve started by adding the profile and environment required for the Sugar Labs profile for the \`widgets.py\` port. We also need to implement a few more radio and other types of buttons, which will be completed soon.

## Links

-   [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
-   [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
-   [New C Library (sugar-ext)](https://github.com/sugarlabs/sugar-ext)
-   [Game Demo Video](https://youtu.be/B517C_LTCns)
`,dr=Object.freeze(Object.defineProperty({__proto__:null,default:et},Symbol.toStringTag,{value:"Module"})),nt=`---
title: "GSoC '25 Week 05, 06 Update by Saumya Shahi"
excerpt: "This week, I focused on building drag-and-drop utilities for bricks, developed a reverse mapping utility for coordinate-to-brick/tower lookup, and integrated these with the new collision map. Next up: visual interactions and user feedback!"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-gsoc-25-saumya-shahi-week05"
author: "@/constants/MarkdownFiles/authors/saumya-shahi.md"
tags: "gsoc25,sugarlabs,week05,saumya-shahi"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 05 & 06 Progress Report by Saumya Shahi

**Project:** [Masonry Module - Music Blocks v4](https://github.com/sugarlabs/musicblocks-v4)  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-30 – 2025-07-06

---

## Goals for Weeks 05 & 06

- Build robust drag-and-drop utilities for bricks and palette
- Develop a reverse mapping utility to map coordinates to bricks/towers
- Integrate collision detection logic for interactive feedback
- Prepare for next week’s focus on visual feedback and user interactions

---

## This Week's Progress

### 1. **Drag-and-Drop Utilities for Bricks**

This week, I focused on refining the drag-and-drop experience across both the palette and the workspace.  
- **Unified Drag Logic:** The drag-and-drop system now works seamlessly, whether you’re moving bricks from the palette or rearranging them in the workspace.
- **Component Integration:** Real brick components are now fully draggable and interactable, making the workspace more dynamic.
- **Consistent State Management:** Drag state is now shared and updates are reflected instantly, ensuring a smooth user experience.

![Drag-and-Drop from Palette](assets/Images/dragFromPallette.webp)  
![Drag-and-Drop on Workspace](assets/Images/dragAroundWorkspace.webp)

---

### 2. **Reverse Mapping Utility**

I developed a utility that allows us to map any (x, y) coordinate to the corresponding brick and tower.  
- **Efficient Lookup:** The utility uses bounding box and layout data for fast, accurate results.
- **Foundation for Visual Interactions:** This mapping is essential for features like selection, highlighting, and collision detection post processing.

\`\`\`typescript
function getBrickAtCoordinate(x: number, y: number): { brickId: string, towerId: string } | null {
  // Uses bounding box/layout data to find the brick and tower at (x, y)
}
\`\`\`

---

### 3. **Collision Map Integration**

- **Collaboration:** I worked closely with another contributor who implemented the core collision detection logic.
- **Utility Integration:** The drag-and-drop and reverse mapping utilities are now integrated with the new collision map, enabling real-time interaction and hit-testing.

![Collision Map](assets/Images/collision.webp)

As a side project, I also built a visualizer for collision points on the workspace. While it’s not part of the final product, it was a valuable exercise in visualizing interactions.

![Drag-and-Drop on Workspace with collision detection](assets/Images/collisionVisual.webp)

---

## Technical Details

- **Component Reuse:** Brick components are reused across different parts of the app, reducing duplication.
- **Extensible Design:** The reverse mapping utility is designed to support future features like selection and tooltips.

---

## Key Takeaways

- **Component and State Reuse:** Reusing logic and state across the app improves maintainability and reliability.
- **Hit Testing:** Building efficient hit-testing utilities is crucial for interactive UIs.
- **Atomic Commits:** I continued to practice atomic commits for better codebase hygiene and easier reviews.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for your ongoing support and feedback.

---

<!-- markdownlint-enable -->`,cr=Object.freeze(Object.defineProperty({__proto__:null,default:nt},Symbol.toStringTag,{value:"Module"})),tt=`---
title: "GSoC ’25 Week 06 Update by Mebin J Thattil"
excerpt: "Optimizations and reading documentation"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-gsoc-25-mebinthattil-week6"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week06,midterm,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

# Week 06 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-07 - 2025-07-13

---

## Goals for This Week

- **Goal 1:** Improve dataset quality  
- **Goal 2:** Fine-tune the model again and evaluate performance  
- **Goal 3:** Work on mechanics for voice switching and personas inside Sugar  

---

## This Week’s Progress

### **1. Improving the dataset**

I fine-tuned the model using the dataset I had before, but it didn’t meet expectations. The model's responses were often repetitive and lacked the nuanced, encouraging tone of a teacher. For instance, it would give correct but blunt answers without any of the supportive dialogue we were aiming for. At times it gave answers that were completely irrelevant to the question. 

To address this, the next logical step was to significantly improve the dataset. I expanded it with more diverse conversation types and a wider range of questions that children might ask. To better simulate a real learning environment, I added examples where the teacher corrects a child's factual mistakes or spelling errors. Finally, to make the interactions feel more natural, I included general conversational snippets like “I love pizza” or “I just woke up.”

### **2. Fine-tune the model again and evaluate performance**

I proceeded to fine-tune the [Llama 135M model](https://huggingface.co/amd/AMD-Llama-135m) again, this time on the [updated dataset](https://github.com/mebinthattil/AMD_Llama_135M). After testing its performance, the results were still disappointing. While the tone improved slightly, the model struggled to maintain context in longer conversations and sometimes produced irrelevant responses, likely due to the inherent limitations of such a small model.

Wanting to give it one last shot, I generated an entirely new, higher-quality dataset using Gemini, focusing specifically on teacher-child conversational patterns(Next week I'll share a link to a repo where I aggregate all these different datasets and model outputs in different formats). After fine-tuning the model on this new dataset, it performed better than before but still fell short of my goals. The next step is to formally benchmark both fine-tuned versions against the 50 questions I used for [benchmarking earlier](https://llm-benchmarking-sugar.streamlit.app/) and add their results for a direct comparison.

### **3. Work on mechanics for voice switching and personas inside Sugar**

I began working on the mechanics for voice switching and persona selection within Sugar. Before diving into the UI, I decided to first optimize Kokoro's integration with the Speak activity. The current process, where Kokoro writes a WAV file that GStreamer then plays, introduces a delay of 2 - 4 seconds. My goal is to get Kokoro to stream audio data directly to GStreamer as a source, which can then be played out using dual sinks similar to Speak's current implementation. This part isn’t fully working yet, as it requires a deeper dive into GStreamer's internals. I've been studying the documentation and hope to have this optimization completed in a few days, after which I can resume implementing the voice switching and persona mechanics.

### **4. Size Optimization**

One of the hardest and most interesting parts of this project was to package the SLM, the TTS model, and all its required dependencies within very tight size constraints. Every single byte matters.

These are the sizes of the components as of now:
- **TTS**: 0.7MB Base + 0.5MB for each additional voice
- **SLM**: 82.6MB
- **Llama.cpp**:
  - if we choose to distribute binaries for llama-cpp that will be used for inference: 2MB
  - else, I would need to look into optimization (not done yet)

Main factors contributing to the small size of components were:
- **TTS**: Switching Kokoro's fallback to use espeak instead of espeak-ng, since espeak was already used by the Speak activity. It also helps that Kokoro is pretty lightweight with only 82M parameters.
- **SLM**: The biggest reason is the insanely small parameter count of the SLM. I'm using LLaMA-135M. Further quantization and converting to GGUF format helped.
- **llama-cpp** (local model inference): Compiling to binary helped reduce size. I did a specific compilation, so it did not build a binary for everything, only the inference binary for chat was built.

So overall, including the TTS, SLM, and llama-cpp, the size of additional components would be ~85–110MB (85MB if we distribute the binaries, 110MB if we don't). Do note that the dependencies for the LLM have not been included, but those are pretty lightweight, since it's just calling an API endpoint.

---

## Midterm Summary

*It feels great to sit back and reflect on what I’ve done so far. I’ve learned a lot and had a lot of fun building things.*
- The first week started off with a lot of [benchmarking](https://llm-benchmarking-sugar.streamlit.app/). This was essential, as we needed to choose a model to fine-tune.  
We tested various models on a standard set of questions, asking each model the same ones and comparing the responses.  
I also ensured I had a clear understanding of the project constraints, especially the limited client-side hardware. This directly influenced many of the design decisions later on.

- The second week was focused on setting up the AWS infrastructure.  
AWS was configured, and the LLaMA3-1B foundation model was fine-tuned on the [education dataset](https://github.com/mebinthattil/Education-Dialogue-Dataset).  
The dataset was cleaned and formatted for LLaMA, and after fine-tuning, it was deployed to AWS.  
I then tested the API endpoint with a Python script. This gave us a solid base to move forward.

- The third week was spent addressing a model behavior issue where it would generate long response chains instead of simple Q&A style outputs.  
To fix this, I restructured the [dataset](https://github.com/mebinthattil/Education-Dialogue-Dataset).  
That week also coincided with my exams, so progress was slower than usual.

- In Week 4, I worked on [integrating Kokoro into Speak](https://drive.google.com/file/d/1Z-zQrnH56CDVFJnEMmm6DflwpajwrLmI/view?usp=sharing).  
While I managed to integrate Kokoro TTS, it was a bit hacky. Kokoro saved WAV files, and GStreamer read from them.  
I also built a [model quantization pipeline](https://github.com/mebinthattil/Model_Quantize_Pipeline) that allowed me to quickly quantize chat-style models from 🤗, convert them to GGUF, and run [inference with plugin](https://github.com/mebinthattil/template_llama_chat_python) support.  
This significantly sped up testing and allowed me to observe the impact of quantization on output quality.

- And finally, last week was spent building a [Streamlit app](https://newstreamlit-frontend.blackpond-9921706d.eastus.azurecontainerapps.io/) for experimenting with different Kokoro voices. The app let you try differnt voices in kokoro with different languages, and also had an option to blend and mix different voices to create a unique voice.
This app made it easier to demo the new TTS to kids and collect feedback.  
I also integrated the SLM into Speak. I used \`llama-cpp-python\` during inference, which led to noticeable performance boosts.  
The model used was a fine-tuned and quantized version of [Llama-135M](https://huggingface.co/MebinThattil/Llama-135M-FT/tree/main).  
However, due to the model’s small size, the initial responses were underwhelming. Even with fine-tuning, the improvements were only slight.

---

## Next Week’s Roadmap

- Complete Kokoro streaming with GStreamer  
- Work on UI enhancements and group Kokoro voices by language  
- Add both variations of the SLM to the benchmark  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,ur=Object.freeze(Object.defineProperty({__proto__:null,default:tt},Symbol.toStringTag,{value:"Module"})),at=`---
title: "GSoC '25 Week 06 Update by Nikhil Bhatt"
excerpt: "Implemented commit history viewer and version loading system using Git CLI and new backend routes, enabling seamless time-travel across project states."
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-gsoc-25-nikhilbhatt-week06"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week06,nikhilbhatt,midterm"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-07-07 – 2025-07-13  

---

## Progress Summary 

The first 6 weeks of GSoC'25 have been a great learning experience. The project is progressing as planned with meaningful improvements every week. <br/>
Our primary focus during this phase was the backend, with some attention to enhancing the user experience. 
- Repository Creation with Ownership Tracking (using a Github app) - \`\`\`Github apps\`\`\` are safer, and scalable way of dealing with github directly, students can now create repositories directly into a centralised account, with ownership using a key, note that we do not save any user related information.
- Secure Editing Mechanism - even after publishing a project, students are able to edit their projects. Only those having a valid key can now edit their projects, in absence of that key, the project becomes \`\`\`read only\`\`\`.
- Forking with Metadata & History - Projects can be forked easily via the UI. Forked repositories retain original content and metadata,A later upgrade replaced basic copying with full Git CLI–based cloning, ensuring complete \`\`\`commit history is preserved\`\`\`.
- Commit History & Version Time Travel - Users can now select a commit from a UI modal and load the project state at that point. This feature introduces \`\`\`reflective-learning\`\`\` in students. 
- Pull Request Workflow - an interesting addition to our existing planet based system, students can now contribute back to original projects after forking. The backend logic for this is complete and tested. Frontend integration is currently underway and will allow students to \`\`\`submit PRs with minimal effort.\`\`\`

## A flow chart about the architecture of the project
![Flow chart](assets/Developers/Nikhil/project-flow.webp)

 
## This Week's Achievements

### Backend: Commit History & Version Retrieval

To support loading older versions of projects, I implemented two key backend routes using the Git CLI:

- \`GET /api/github/commitHistory/?repoName\`  
  → Returns a list of all commit SHAs and messages for a given repository.

- \`GET /api/github/getProjectDataAtCommit?repoName=""&sha=""\`  
  → Accepts a repo name and commit SHA, checks out the commit, and returns the \`projectData.json\` at that point in history.

Both routes use secure Git Rest API methods.

---

### 💡 Frontend: Modal Interface for Commit Viewer

- Added a modal component that displays when the user clicks **"Show Commits"** from the GitHub dropdown.
- Each commit is rendered as a card showing the commit message, SHA, and a **"Load this version"** button.
- On click, the selected commit is sent to the backend, and the returned \`projectData\` is loaded using:

---

## Challenges & How I Solved Them

- **Challenge:** GitHub API only returns the latest file in current branch
  **Solution:** Used GET /repos/:owner/:repo/contents/:path?ref=sha to fetch files at a specific commit.

- **Challenge:** Loading project data for specific commits
  **Solution:** Created an end point which takes the commit \`sha\` and returns the project data for that commit

---

## Key Learnings
- How to use GitHub's REST API to interact with historical commit data.
- How to extract blob data (projectData) from specific commits using SHA.
- Importance of UX when introducing power-user features like history viewing.

---

## Next Week's Roadmap
- Begin work on pull request functionality from forked projects.
- Enable students to raise PRs with metadata describing their changes.
- Explore preview diffs before PR submission.

---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [Octokit REST.js Library](https://github.com/octokit/rest.js)

---

## Acknowledgments

Thanks again to my mentors and the Sugar Labs community for feedback and support!  
Looking forward to next week’s frontend PR features. 

`,hr=Object.freeze(Object.defineProperty({__proto__:null,default:at},Symbol.toStringTag,{value:"Module"})),ot=`---
title: "GSoC '25 Week 6 Update by Safwan Sayeed"
excerpt: "Symbol Table Refinements, IR Instructions Design, and Interpreter Architecture"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-gsoc-25-sa-fw-an-week6"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week6,sa-fw-an,midterm"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 6 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-07 - 2025-07-13  

---

## A Blog-style Retrospective

This week marked a significant refinement phase in our Music Blocks program engine development as we focused on optimizing the Symbol Table design and laying the groundwork for the execution phase. The primary focus was on identifying and cataloging the IR (Intermediate Representation) instructions that will be implemented, followed by beginning the technical specification for the Interpreter module - the component that will bring our compiled IR code to life.

The Symbol Table modifications were crucial for improving variable resolution efficiency and ensuring proper scope management. Working through the IR instruction identification process helped clarify the execution model and provided a clear roadmap for the interpreter implementation.

---

## Six-Week Progress Summary

Over the past six weeks, we've built a comprehensive foundation for the Music Blocks 4 Program Engine:

**Weeks 1-2:** Established the core architecture with AST (Abstract Syntax Tree) framework and memory management system, implementing a three-scope hierarchy (Global, Thread, Local) with full CRUD operations.

![AST Representation](/assets/Developers/Safwan/AST.webp)

**Weeks 3-4:** Developed the AST-to-IR compilation logic, creating the crucial translation layer between abstract syntax trees and executable instructions using three-address code format.

**Week 5:** Implemented the Symbol Table and integrated it with the Memory Module for effective variable scope and dependency management.

![Memory Module Tests](/assets/Developers/Safwan/context-stack-test.webp)

**Week 6:** Refined the Symbol Table design, identified comprehensive IR instruction sets, and initiated the Interpreter architecture specification.

![Symbol Table Design](/assets/Developers/Safwan/symbol-table-test.webp)

This progression has taken us from initial planning to having a complete compilation pipeline ready for execution engine implementation.

---

## Goals for This Week

- Refine the Symbol Table design to improve variable resolution efficiency.
- Identify and catalog all IR instructions that will be implemented in the execution engine.
- Begin writing the technical specification for the Interpreter module.
- Define the interpreter's execution model and core implementation patterns.

---

## This Week's Highlights

1. **Symbol Table Design Modifications**  
   - Refined the Symbol Table implementation to improve variable resolution performance and scope management.

2. **IR Instructions Identification**  
   - Conducted comprehensive analysis to identify all IR instructions required for the execution engine.

3. **Interpreter Technical Specification**  
   - Started writing the technical specification for the Interpreter module architecture.

---

## Challenges & Solutions

- **IR Instruction Completeness:**  
  Ensuring we identified all necessary IR instructions for complete program execution support.  
  *Solution:* Systematically analyzed the AST compilation patterns and execution requirements to create a comprehensive instruction catalog.

---

## Key Learnings

- Gained deeper understanding of IR instruction design and Interpreter architecture.

---

## Next Week's Roadmap

- Complete the Interpreter technical specification with detailed implementation patterns.
- Begin implementing the first set of IR instructions in the execution engine.

---

## Resources & References

- **Tech Spec:** [Interpreter Architecture](https://docs.google.com/document/d/1_MCCgl-RqiEQH0UQ4EX-2O6G4iRxgHAY1rZpw3QPXT0/edit?tab=t.vexvgnhpt90v)  
- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their continued guidance on compiler design principles and execution engine architecture. Their emphasis on maintaining clean separation between compilation and execution phases was crucial for this week's successful progress.

---
`,gr=Object.freeze(Object.defineProperty({__proto__:null,default:ot},Symbol.toStringTag,{value:"Module"})),it=`---
title: "GSoC ’25 Week 06 Update by Diwangshu Kakoty"
excerpt: "Reflection Learning Widget in Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-gsoc-25-diwangshu-week06"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week06,AI,midterm"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-07-06 - 2025-07-13  

---

## Progress Summary

The first six weeks of GSoC'25 have been highly productive, with several key milestones already accomplished:

- Developed a Retrieval-Augmented Generation (RAG) pipeline.
- Built a fully functional Streamlit application for testing.
- Implemented a multi-agent chat model.
- Experimented with reasoning models and explored their integration.
- Created API endpoints for backend functionality.
- Developed a "reflection" widget in Music Blocks.
- Added save and upload capabilities to the Streamlit app.

## Goals for This Week

- **Goal 1:** Add upload and download of session state in Streamlit app.
- **Goal 2:** Add code conversion function in Streamlit app.
- **Goal 3:** Implement periodic summary generation.
- **Goal 4:** Fix bugs occured by these changes.

---

## This Week’s Achievements

1. **Add upload and download of session state in Streamlit app**  
   - Users can now conveniently save their conversations by downloading them. If they wish to resume at a later time, they can simply upload the saved session to continue where they left off.

   <a href="https://ibb.co/XZB7HJMG"><img src="https://i.ibb.co/zhcXdfDt/image.webp" alt="image" border="0"></a>

2. **Add code conversion function in Streamlit app**
   - Users can now copy their Music Blocks project code and paste it into the app. The app then uses a conversion algorithm developed by [Omsuneri](authors/om-santosh-suneri) to generate an equivalent flowchart, which is easier for the LLM to interpret.

   - This flowchart is sent to the reasoning_llm, which produces the algorithm, a summary, and the purpose of the code. These outputs are then utilized by lightweight models.

3. **Implement periodic summary generation**
   - Based on my mentor's suggestion, I am implementing automatic periodic summary generation instead of relying on a manual button. This approach keeps the conversation seamless and allows users to take notes as they go.

   - This feature is still a work in progress.

4. **Fix bugs occured by these changes**
   - This week's work focused primarily on debugging. There were issues with the download button and updating the session state after file uploads. Further details on these challenges will be covered in the next section.

---

## Challenges & How I Overcame Them

- **Challenge :** I encountered challenges in refreshing the session states upon file upload. The expected behavior includes updating the message history, selected mentor, and user interface, but these updates weren't occurring properly.

  **Solution :** Streamlit reruns the entire script each time a button is clicked — a core behavior of the framework. Many of the issues I faced were due to the improper ordering of session state declarations, which I have now resolved. Additionally, I enhanced the download functionality to include more comprehensive information in the saved file, such as the mentor's name, the message history, and the session title.

---

## Key Learnings

- I am becoming more experienced as a Streamlit developer. 

---

## Next Week’s Roadmap

- Implement a widget with functionality to save conversations, session summaries, and analytical insights.
- Finalize the auto-summary generation feature.
- Deploy the FastAPI server on AWS.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)
- **Streamlit App:** [Reflection App](https://reflectionapp-2yoxtvn6sknvktme2zorvq.streamlit.app/)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,mr=Object.freeze(Object.defineProperty({__proto__:null,default:it},Symbol.toStringTag,{value:"Module"})),st=`---
title: "GSoC '25 Week 06 Update by Shubham Singh"
excerpt: "Music Player + Mid Term Evaluation"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-gsoc-25-firepheonix-week06"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week06
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 6 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-07 – 2025-07-13

---


## Goals for This Week

- Printing the outputs detected by the color detector.
- Implementing the music player.

---

## This Week's Achievements

1. **The music notations and their durations are now logged to the console**  
   - I finally logged all the colors to the console in a systematic way, without affecting projectstorage.js.
        ![Musical Notations mapped to their corresponding times](https://i.ibb.co/yFLF1fSS/Music-Blocks-Google-Chrome-18-07-2025-14-23-07.webp)


2. **Implemented the music playing feature**  
   - For example, the music player plays X rows, and the music for those X rows is played simultaneously, just like in the PhraseMaker.
   - The system works on the principle: if green → no note played; if not green → note played.
   - All notes are started simultaneously, then played according to their mapped timings.
   - And here's a sample of the music generated.

    <iframe width="800" height="405" src="https://www.youtube.com/embed/ySjvYi936tg?si=FxZQn19AiLRixlpM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


---

## Challenges & How I Overcame Them

- **Challenge:** Wasn't able to figure out the next steps in development, and felt stuck while trying to find multiple ways of using the existing data.   
  **Solution:** I logged the data to the console and observed the PhraseMaker's approach to simultaneous playing.

---

## Key Learnings

- Sometimes logging the output to the console helps you take the next steps more effectively. For example, in API responses, you'll need to have the same type of UI as the type of response generated, so it's better to take care of that step beforehand.

---

## Next Week's Roadmap

- Build the action block output.
- Try to build a simple Do Re Mi Fa Sol La Ti sequence and its reverse, using exported action blocks in Music Blocks.

---

## Resources & References

- **Nothing much, just the Music Blocks documentation sufficed.**

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. 

---`,pr=Object.freeze(Object.defineProperty({__proto__:null,default:st},Symbol.toStringTag,{value:"Module"})),rt=`---
title: "GSoC’25 Week 06 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-gsoc-25-omsuneri-week06"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week06,Debugger,AI,Music Blocks,GSoC Midterm"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-07-06 - 2025-07-12

---

## Goal for This Week

**Build a tightly integrated debugging experience by embedding the JSON-to-Text converter into the main debugger Streamlit app and enabling users to export complete chat logs with the AI assistant**

---

## This Week’s Achievements

### Introduction

This week’s focus was two-fold:

1. **Merge and integrate** the Music Blocks JSON-to-Text converter directly into the existing Streamlit-based debugger UI.
2. **Enhance user experience** by introducing a "Chat Export" feature that allows users to download their complete AI-debugger conversation history in \`.txt\` format.

These updates mark a major usability milestone and make the debugging experience smoother and more developer-friendly.

### What I Did

#### 1. Embedded JSON-to-Text Converter in the Debugger Workflow

Previously, users had to first convert their Music Blocks JSON into readable text using a separate converter app and then copy that result into the debugger interface. This extra step caused friction in the user flow.

Now, I’ve **fully integrated the \`convert_music_blocks()\` function** (from our \`json_parser.py\` module) directly into the debugger pipeline. Here’s how it works:

* A user pastes raw Music Blocks JSON code into a text area inside the main debugger app.
* Upon clicking **"🚀 Launch My Music Blocks Project!"**, the code is parsed using \`json.loads()\` and fed into the \`convert_music_blocks()\` function.
* This recursive function translates the block structure into a clean, readable text representation using a tree-like format (\`├──\`, \`│\`, etc.), supporting clamp/stack logic and deeply nested project structures.
* The converted code is **stored in \`st.session_state.project_code\`** and becomes the foundational context for the entire debugging session.

**Key Enhancements**:

* Handles more block types like \`arc\`, \`incrementOne\`, \`pitch\`, and \`settransposition\`.
* Automatically redacts base64-encoded data like audio/image blobs by replacing them with \`"data"\` in output.
* Maintains formatting consistency to assist LLM comprehension and improve semantic chunk retrieval.

---

#### 2. Chat Export Functionality

To support documentation, sharing, and revisiting past sessions, I implemented a **chat export button**. The feature is context-aware and only appears when the user has interacted with the debugger.

**Implementation Details**:

* On each AI-user interaction, chat messages are appended to \`st.session_state.chat_history\` as a list of message dictionaries (\`{"role": ..., "content": ...}\`).
* The \`generate_chat_export()\` function:

  * Adds a timestamp using Python’s \`datetime.now()\`.
  * Includes both the original converted project code and the full chat history.
  * Formats everything into plain text.
* The Streamlit \`st.download_button()\` is used to render the export option, generating a downloadable \`.txt\` file named like \`music_blocks_chat_20250711_143512.txt\`.

This makes the tool much more practical for teachers or learners who want to **archive** AI insights, share results, or continue the session later.

---

### Why These Features Matter

**Improved UX**:
With the converter now inside the debugger, users no longer need to juggle multiple tools. They can paste once, click once, and begin debugging immediately.

**Smarter Debugging**:
The LLM uses the converted project code + relevant chunks from Music Blocks documentation (via \`retrieve_relevant_chunks()\`) to generate highly contextual, beginner-friendly replies.

**Educational Value**:
Students and educators can **save their interactions**, review solutions offline, or submit chat logs for peer or mentor feedback.

---

### Preview Features

<a href=""><img src="https://i.ibb.co/FbHymBYN/Screenshot-2025-07-11-at-2-16-30-PM.webp" alt="Music Blocks Debugger"></a>

* 🔁 One-click conversion of Music Blocks JSON to structured text.
* 💬 Chat-driven debugging using Music Blocks Bot + documentation chunks.
* 💾 "Export Chat" button for persistent chat history.
* 🧽 "Clear Chat" button to reset sessions easily.

---

## Midterm Evaluation Summary (Weeks 01–06)

The first six weeks of GSoC 2025 have been focused on architecting and implementing the core systems behind the **AI-powered Debugger for Music Blocks**. From block parsing and embedding generation to LLM integration and full-stack deployment, the project has steadily evolved into a functional, AI-assisted debugging tool optimized for kids and educators.

---

### Key Technical Achievements

* **JSON-to-Text Parser**: Migrated the logic-heavy JavaScript converter to Python, maintaining tree-structured formatting (\`├──\`, \`│\`) and supporting recursion for nested Music Blocks projects. This makes visual projects readable and interpretable as text.

* **Streamlit Interface**: Built a clean, user-friendly UI that enables users to paste JSON, parse it live, and interact with the AI debugger—all in one app. Integrated Gemini for generating responses tailored to kids.

* **Vector Search with Qdrant**: Generated semantic embeddings from 14 curated Music Blocks projects and stored them in a Qdrant vector DB. This enables chunk retrieval from documentation and real examples to enhance LLM understanding.

* **RAG Pipeline**: Combined user input + parsed project code + vector context to construct dynamic prompts for the LLM. Prompt behavior adapts based on session length to balance discovery and solution guidance.

* **Export + UX Enhancements**: Added \`.txt\` chat export, refined session state handling, and introduced autoscroll + dynamic prompt control for a polished user experience.

---

### Why It Matters

By allowing users to paste a Music Blocks JSON file and instantly receive both a clean text summary and interactive feedback from an AI assistant, the tool reduces the barrier to debugging and learning. It helps students understand project flow, educators explain logic, and kids explore possibilities in a guided, friendly way.

---

### Final Thoughts

Over the past six weeks, I’ve transitioned from building isolated components to integrating them into a cohesive, interactive debugger. This week’s merge of the JSON converter into the main app simplified the workflow and enabled richer, context-aware prompts for the LLM.

Technically, it deepened my understanding of state management, error handling, and modular design. Functions like convert_music_blocks() and retrieve_relevant_chunks() proved invaluable for maintaining clean, scalable code. The debugger is now not just functional — it’s ready to be embedded, deployed, and used meaningfully by kids and educators alike.

---

### Next Week’s Roadmap

* **Deploy the app to Sugar Labs’ AWS server** for long-term availability and community usage.
* **Develop a Music Blocks Widget** to embed the debugger directly into the Music Blocks environment for seamless integration and real-time support.

---

## Resources & References

- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)

---

### Acknowledgments

Thanks to my mentors Walter Bender for the consistent feedback and support, and to Devin Ulibarri for assisting with insights into Music Blocks educational usage. The Sugar Labs community continue to be an invaluable support system.

---
`,br=Object.freeze(Object.defineProperty({__proto__:null,default:rt},Symbol.toStringTag,{value:"Module"})),lt=`---
title: "SSoC ’25 Week 06 Update by Muhammad Haroon"
excerpt: "Find another open-source model that can generate sound samples from prompts."
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-ssoc-25-MuhammadHaroon-week06"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,midterm,sugarlabs,week06,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-07 - 2025-07-13  

---

## Progress Summary

The first half of my Sugar Summer of Code 2025 project has been both challenging and rewarding. My project focuses on generating sound samples from prompts. Over the past six weeks, I've made significant progress toward this goal, working closely with my mentors which is as follow:

- Researched state of art open-source models for generating sound samples from prompts, including [AudioGen](https://audiocraft.metademolab.com/audiogen.html) and [TangoFlux](https://huggingface.co/spaces/declare-lab/TangoFlux).

- Set up the models locally to enable hands on testing and integration.

- Tested the models using various prompts. (High quality sound of dog bark, A natural and rich sound of car horn etc). Saved the sounds samples into Google Drive which was then scored by both the mentors.

- Concluded that the generated sound samples cannot be used directly in Music Blocks, they need to be trimmed before integration.

---

## Goals for This Week

- **Goal 1:** Find another open-source model to generate high quality sound samples.

---

## This Week's Achievements

1. **Find another open-source model**  
   - I was sucessfully able to find another open-source model [TangoFlux](https://huggingface.co/spaces/declare-lab/TangoFlux). However, after testing several prompts, I realized that these models are unable to generate sound samples suitable for use in Music Blocks. After discussing this with the mentors, we decided that an additional tool is needed, one that can clip audio between specific timestamps. This trimmed audio can then be used in Music Blocks, similar to how it's done in Audacity software.

---

## Next Week's Roadmap

- Create sketches of user interfaces showing how students will interact with the GenAI and the audio trimming tool.

---

## Proof of Concept (POC)

Since current LLMs are not capable of generating audio that can be used directly in Music Blocks, the following workflow serves as an alternative approach:

- The user first generates an audio using a text-to-audio model such as TangoFlux.  
![TangoFlux - text to audio generation model](/assets/Developers/Muhammad_Haroon/TangoFlux-Text_to_Audio_Generation_Model.webp)

- The generated audio is then passed into an audio trimming tool, for demonstration purpose I am using an Audacity software.
![Trimming AI-generated audio in Audacity](/assets/Developers/Muhammad_Haroon/Trimming_AI_generated_audio_in_Audacity.webp)

![Trimmed audio in Audacity](/assets/Developers/Muhammad_Haroon/Trimmed_audio_in_Audacity.webp)

- Click on the video below to see how can we import the audio into Music Blocks:

[youtube: eR8hfvNzPTg]

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,fr=Object.freeze(Object.defineProperty({__proto__:null,default:lt},Symbol.toStringTag,{value:"Module"})),dt=`---
title: "DMP ’25 Week 06 Update by Harshit Verma"
excerpt: "I added a new step to help students understand their code’s intent before debugging begins. I also worked on improving the terminal’s formatting and finalized Mistral 7B as the debugging model to be integrated with Sugar AI"
category: "DEVELOPER NEWS"
date: "2025-07-14"
slug: "2025-07-14-dmp-25-therealharshit-week06"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week06,midterm,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-07 - 2025-07-13   

---

## Goals for This Week

- **Goal 1:** Work on contextualization before debugging.
- **Goal 2:** Add CSS-style formatting to the debugging terminal.
- **Goal 3:** Finalize model decision for debugging.

---

## This Week’s Achievements

1. **Implemented Code Context Display for Learners**  
   - As discussed in the debugging meeting, added a step that shows the context or purpose of the code to the student, helping them understand what the code is trying to do before showing debug suggestions.
   - This helps children first grasp what the code is meant to do, which builds confidence and improves the effectiveness of the debugging tips that follow.
   - Introduced a new step in the debugging flow: before showing any suggestions, the interface displays a brief summary of the code’s intent or functionality.

2. **Worked on Debug Terminal Formatting**  
   - Tried to apply CSS-like styles to make debug output more structured and visually appealing.
   - GTK limitations posed challenges, continued work on enhancing the Markdown parser instead.

3. **Finalize model decision for debugging**  
   - Decided to use **Mistral 7B**, which will be integrated with Sugar AI for better compatibility and performance.
   - Based on performance tests and Sugar AI's deployment pipeline, It offers a good balance of output quality and resource efficiency for server-side use.

---

## Challenges & How I Overcame Them

- **Challenge:** Styling Virtual Terminal Emulator (VTE) output with CSS.  
  **Solution:** Learned that we can't apply CSS to the VTE terminal output as they are not GTK widget, so I decided to work on further improving the markdown parser.

---

## Key Learnings

- Learned how code contextualization can help beginner coders by giving them an idea of what the code should do, and it also improves their ability to understand and fix problems.
- Developed a design-focused mindset for user-centric debugging tools.

---

## Next Week’s Roadmap

- Start working on replacing pippy-debugger-server with sugar-ai.
- Start working on saving debug history to Sugar Journal.
- Work on preparing a presentation as part of DMP midterm evaluation.

---

# Midterm Progress Report (6 Week Summary)

## Project Objective

The goal of this project is to enhance the Pippy learning environment by integrating an LLM-powered debugger. The debugger uses LLMs to provide readable, friendly suggestions for fixing broken code, helping young learners understand and improve their programs.

---

## Technical Implementation

- Set up a **FastAPI backend** (\`/debug\`) to handle Python code input.

- Integrated **Hugging Face model** for generating debugging tips.

- Created **Run & Debug** buttons in Pippy’s GTK interface.

- Connected **Pippy**  with the backend server via API.

- Implemented a **Debug terminal** in the UI to display suggestions.

- Developed a **basic Markdown parser** for formatted output in VTE.

- Added a **Contextualization step** to show students what the code intends to do before debugging begins.

---

## Research & Design

- Explored multiple **UI layouts** for debug output.

- Tested different **LLM prompts** for clarity and simplicity.

- Held discussions on **Debugging best practices for children**.

- Evaluated models and selected **Mistral 7B** for deployment via Sugar AI.

---

## Project Demo
 
Please watch the project demo to see the progress I've made so far.  
[Watch here](https://drive.google.com/file/d/1-FHfsd0YiOZ2Fb7V7HeSswcga89jEvos/view?usp=drive_link)

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,wr=Object.freeze(Object.defineProperty({__proto__:null,default:dt},Symbol.toStringTag,{value:"Module"})),ct=`---
title: "GSoC ’25 Week 06 Update by Bishoy Wadea"
excerpt: "Mid term evaluation reflection"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "gsoc-25-BishoyWadea-week06"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week06,midterm,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Bishoy Wadea

**Project:** [Euclid’s Game](https://github.com/Bishoywadea/Euclid-s-Game)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-06-07 - 2025-07-14 

---

## Goals for This Week

- **Goal 1:** Start implementing Euclid’s Game
---

## This Week’s Achievements

### *Goal 1: add helpful video tutorial in Soma Cube Game*

1. **add video in help button**  
   - commit: [modify code to handle help videos](https://github.com/Bishoywadea/Soma-Cube/commit/63a7daaa8009f5f54791cdf9081e765846135f70)

Soma Cube as Sugar activity [youtube: Q4BKp3Yo3Uw]

---

### *Goal 2: Start implementing Euclid’s Game*

**description of the game:**
The game inspired by Euclid’s game is a two-player mathematical strategy game
that illustrates the principles of the Euclidean algorithm, particularly in finding the
greatest common divisor (GCD) of two numbers. The game begins with two unequal
positive integers written on a board. Players alternate turns, and on each turn, a
player writes a new number on the board, which is the positive difference of any two
numbers already present. The new number must be distinct from all numbers
previously written. The game continues until a player cannot make a valid move; this
player loses the game.

**Menu Light Theme:**

This shows the main menu screen of Euclid’s Game in light mode. You can see the toolbar at the top with buttons like New Game and Help, along with options to switch between light and dark themes. Below that, there are buttons for selecting difficulty levels and choosing game modes, such as 2‑player or vs AI.

![menu light theme](https://github.com/Bishoywadea/Euclid-s-Game/blob/main/screenshots/01.webp?raw=true)

**Menu Dark Theme:**

This shows the main menu screen of Euclid’s Game in Dark theme

![menu dark theme](https://github.com/Bishoywadea/Euclid-s-Game/blob/main/screenshots/02.webp?raw=true)

**Gameplay Dark Theme:**

Here you’re looking at the core game screen in dark mode. There's a board displaying numbers—the starting pair and any differences added. You can also see the current player’s turn and the move counter.

![game play dark theme](https://github.com/Bishoywadea/Euclid-s-Game/blob/main/screenshots/05.webp?raw=true)

**Gameplay Dark Theme:**

![game play light theme](https://github.com/Bishoywadea/Euclid-s-Game/blob/main/screenshots/04.webp?raw=true)

**Gameplay Light Theme**

This is the same gameplay view but in light theme. 

**Help Panel**

This overlay provides instructions or guidance on how to play the game. It likely appears when you click the “Help” button from the toolbar, offering context and tips for first-time users.

![help panel](https://github.com/Bishoywadea/Euclid-s-Game/blob/main/screenshots/06.webp?raw=true)
---

## Challenges & Solutions

- **Challenge:** Creating a responsive and user-friendly .  
  **Solution:** Implemented smooth game play logic to ensure accuracy and a satisfying user experience.
---

## Midterm Evaluation Reflection

As I reach the halfway point of my GSoC journey, I’ve had the chance to reflect on the past six weeks—both the technical milestones and personal growth that came with them.

### Progress So Far
Over the first phase of GSoC, I successfully developed and shipped five fully functional Sugar activities:
- [**Four Color Map Puzzle**](https://github.com/Bishoywadea/Four-Color-Map) – Core gameplay, UI enhancements, region data integration.
- [**Broken Calculator**](https://github.com/Bishoywadea/Broken-Calculator) – Restrictive math puzzle with scoring, themes, and child-friendly UX.
- [**Soma Cube**](https://github.com/Bishoywadea/Soma-Cube) – A 3D spatial reasoning puzzle featuring piece manipulation, textures, collision, and video tutorials.
- [**Fifteen Puzzle**](https://github.com/Bishoywadea/FifteenPuzzle) – Classic sliding puzzle with smooth animations and responsive layout.
- [**Euclid’s Game**](https://github.com/Bishoywadea/Euclid-s-Game) – Strategic math game with theme switching, help overlays, and polished UI.


Each activity was built from scratch or significantly improved, covering diverse gameplay styles—from logic puzzles to real-time spatial challenges—all designed with **educational value and child accessibility** in mind.

### What I’ve Learned
- **Technical Mastery:** Strengthened my experience with **Pygame**, **Three.js**, and **GTK**, along with concepts like game loops, animation, and real-time input handling.
- **UI/UX Design:** Built interfaces tailored for young learners, focusing on clarity, feedback, and accessibility.
- **Open Source Discipline:** Embraced good development practices—clean commits, documentation, issue tracking, and community feedback cycles.

### cknowledgments
This progress would not have been possible without the patient guidance of my mentors, Ibiam. Their feedback has helped me think more deeply about software design, education, and the impact of simplicity. The Sugar Labs community’s encouragement has also been motivating and insightful.


---

## Next Week’s Roadmap

- Fix any feedback provided by members of the organization.  
- Start implementing the Magic moving game.
---
`,yr=Object.freeze(Object.defineProperty({__proto__:null,default:ct},Symbol.toStringTag,{value:"Module"})),ut=`---
title: "GSoC ’25 Week 09 Update by Aditya Kumar Singh and Midterm Summary"
excerpt: "Enhanced collaboration in Human Body activity by refining Paint and Tour interactions, improved UX in Doctor mode, and launched key features in Stickman like frame handling and animation controls."
category: "DEVELOPER NEWS"
date: "2025-07-15"
slug: "2025-07-15-gsoc-25-AdityaKrSingh26-week09"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week09,AdityaKrSingh26,midterm"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Aditya Kumar Singh and Midterm Summary

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-07-10 – 2025-07-16

---

## Goals for This Week

- **Goal 1:** Fix key UX and sync issues in the Human Body activity for Paint and Tour modes.
- **Goal 2:** Improve interactivity and usability in Doctor mode.
- **Goal 3:** Add shared leaderboard functionality for Doctor participants.
- **Goal 4:** Begin dashboard and animation logic in Stickman activity.

---

## This Week’s Achievements

1. **Human Body Paint & Tour Interaction Fixes**  
    - **Issue:** When switching from Tour to Paint, highlighted parts remained visually active across users.  
        - **Fix:** Restored original mesh material on mode switch using \`restoreMeshColor()\` and synced the update with a new \`restoreMaterials\` action.  
    - **Issue:** Unnecessary part-name popup showed for everyone when anyone painted.
        - **Fix:** Restricted the popup to only the user who performed the action, enhancing clarity in shared sessions.
    - **Issue:** Doctor mode lacked reminders of the current target part after failed guesses.
        - **Fix:** Implemented a reminder popup after every 3 failed attempts to display:  \`"Remind you, we're looking for [Part Name]"\`.
    \`\`\`javascript
        // restore material
        if (msg.action = = "modeChange") {
            if (msg.content != 0) return;
            if (currentModel) {
                currentModel.traverse((node) => {
                    if (node.isMesh && node.userData.originalMaterial) {
                        node.material = node.userData.originalMaterial.clone();
                    }
                });
            }
        }
        // Reminder popup
        if (failedAttempts % 3 === 0 && failedAttempts > 0) {
            showModal("Remind you, we're looking for " + l10n.get(bodyParts[presenceCorrectIndex].name));
        }
    \`\`\`
    - Links : PR [#1800](https://github.com/llaske/sugarizer/pull/1800) 
    > Failed Attempt Popup  
    ![Leaderboard](https://i.ibb.co/TxWvQShK/image.webp)


2. **Shared Doctor Mode Leaderboard Enhancements**  
    - Reworked the leaderboard to show users with the **highest score on top** in real-time.
    - Implemented logic to sort and re-render the leaderboard HTML dynamically after each answer.
    - Ensured that scores are updated and synchronized across all participants using the \`scoreUpdate\` action.
    \`\`\`javascript
        playerScores.sort((a, b) => b[1] - a[1]);
    \`\`\`
    - XO icons rendered dynamically using user colors:
     \`\`\`javascript
        iconElement.style.backgroundImage = \`url(\${generateXOLogoWithColor(playerColor)})\`;
     \`\`\`
    > Real-time XO Leaderboard during Shared Doctor Mode  
    ![Leaderboard](https://i.ibb.co/jkLPqWDP/image.webp)


3. **Stickman Activity – Dashboard Features Bootstrap**  
    - **Launched key drawing infrastructure**:
        - Users can now **create stickman**, **drag**, and **move** the whole figure.
        - Proper **distance constraints** between joints maintain anatomical correctness.
    - Integrated real-time canvas rendering loop to support:
        - Drawing joint previews.
    - Added mouse interaction listeners to support **joint selection and dragging**.


4. **Stickman Frame Handling + Animation Tools**
    - Added **Add Frame**, **Preview Frame**, and **Remove Frame** options via UI.
    - Integrated **Play / Pause** logic controlled via speed slider (\`speedpalette.js\`) to control animation playback.
    - Introduced **Onion Skinning**—each frame preview shows a translucent version of adjacent frames for better motion consistency.
    - Enabled **Template Palette** with selectable pre-built poses (run, dance).
    - **Export as Video** and playback scaffold in progress using HTML5 Canvas.
    - Links : PR [#1799](https://github.com/llaske/sugarizer/pull/1799)
    > Stickman Dashboard UI with Toolbar and Timeline  
    ![Stickman UI](https://i.ibb.co/H86RT1Z/image.webp)


---

## Challenges & How I Overcame Them

- **Challenge:** Popup messages overloaded users in shared mode.  
  **Solution:** Added \`networkId\` checks to restrict popup visibility only to the sender.

---

## Key Learnings

- Gained deeper understanding of **presence synchronization patterns** in collaborative activities.
- Learned best practices for **frame-by-frame animation** and **canvas optimization**.
- Improved on creating **real-time UI updates** and dynamic SVG rendering using data-driven design.

---

## Midterm Summary

Over the past nine weeks, my journey with Sugar Labs through GSoC has been incredibly rewarding, both technically and personally. Here's a quick recap of my key milestones:

- **Weeks 01–03:** I dove deep into the world of 3D anatomy, cleaning and merging segmented organ models, improving mesh clarity, and laying the foundation for the interactive Paint Mode in the Human Body activity.
- **Weeks 04–05:** I introduced internationalization with \`i18next.js\`, created a palette system to switch between anatomical models, and improved educational clarity through accurate labeling and skeletal refactoring.
- **Week 06:** I implemented onboarding tutorials, optimized models for performance, and started building shared logic for collaborative Paint Mode.
- **Weeks 07–08:** I built synchronization features for Tour and Doctor modes, including real-time scoring, shared camera states, and adaptive mesh highlighting. I also bootstrapped the new Stickman activity with animation tools and scaffolding.
- **Week 09 (this week):** I improved user experience by fixing shared mode bugs, added a real-time XO leaderboard in Doctor mode, and implemented critical frame-based animation controls like onion skinning and play/pause for Stickman.

Throughout this phase, I’ve gained:

- A much deeper understanding of **Three.js**, especially around camera controls, mesh interactions, and rendering pipelines.
- Hands-on experience in designing **real-time collaborative environments**, ensuring consistent state across clients.
- Confidence in writing **modular, scalable JavaScript**, integrating localization, and building UI that’s both intuitive and accessible.
- Awareness of **educational UX design**, where clarity and simplicity matter just as much as functionality.


I’m sincerely **grateful to my mentors** Lionel and Samarth for their patient guidance, critical feedback, and unwavering support. I’ve also grown by engaging with the Sugar Labs community, learning from discussions, and reading others’ code.

This journey so far has not only improved my technical depth but also taught me how to think like an open-source contributor—collaborative, responsible, and focused on impact. I'm excited for the second half of GSoC and all the challenges and learning it will bring.

Thank you again to everyone who's been part of this experience so far!

## Next Week’s Roadmap

- Fix remaining issue on Human Body
- Fix issues on dashboard and frame for Stickman activity
- Handle the adding a new stickman feature
- Handle Journal storage for stickman activity

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,kr=Object.freeze(Object.defineProperty({__proto__:null,default:ut},Symbol.toStringTag,{value:"Module"})),ht=`---
title: "DMP ’25 Week 7 Update by Aman Naik"
excerpt: "This week focused on UI enhancements for toggling the chat sidebar and setting up an AWS SageMaker endpoint for LLM inferencing."
category: "DEVELOPER NEWS"
date: "2025-07-19"
slug: "2025-07-19-dmp-25-AmanNaik-week07"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week07,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 7 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-07-13 – 2025-07-19  

---

## Goals for This Week

- Create an icon on the toolbar to toggle the chat sidebar  
- Set up and test an AWS endpoint for LLM inferencing using Amazon SageMaker  

---

## This Week’s Achievements

1. **Toolbar Button for Chat Sidebar Toggle**  
   - Added a new icon on the Sugar toolbar using GTK's \`ToolButton\` class.
   - Connected the button to toggle the visibility of the chat sidebar dynamically using GTK container methods.
   - Ensured the sidebar is hidden by default and only becomes visible upon user interaction.
   - This feature allows users to keep their workspace distraction-free and access the AI assistant only when needed.
   - [Toggle button demo](assets/Images/aman-naik-week7-vid1.mp4). The icon is just a placeholder for now.

2. **AWS SageMaker Endpoint for LLM Inferencing**  
   - Created an AWS endpoint using Amazon SageMaker and deployed the Hugging Face model \`Qwen/Qwen3-235B-A22B-Instruct-2507\`.
   - Observed that the initial outputs from the model were overly verbose and hallucinated unrelated content.
   ![Prompt and the response it generated](assets/Images/aman-naik-week7-img1.webp)
   - Identified that a better prompt template could significantly improve output quality, which will be explored further.

---

## Challenges & How I Overcame Them

- **Challenge:** Chat sidebar was visible at activity startup  
  **Solution:** Initially, the sidebar was showing up by default due to its presence as a child widget in the main container. By explicitly setting its visibility to \`.hide()\` after the \`content_box.show.all()\` trigger at initialization and linking the toggle behavior to the toolbar button, the issue was resolved. Now, the sidebar behaves as intended—hidden until toggled.

- **Challenge:** Limited experience with AWS SageMaker made endpoint deployment complex  
  **Solution:** Referred to AWS and Hugging Face documentation along with video tutorials to learn how to prepare the model, create an endpoint, and configure permissions. This process enhanced my understanding of AWS instance types, inference containers, and IAM roles.

---

## Key Learnings

**GTK UI Customization and Conditional Widget Rendering**  
   - Gained hands-on experience in dynamically managing widget visibility in GTK.
   - Learned how to cleanly modify the toolbar and use callback functions to control the state of sidebar components.

**Improved Understanding of AWS SageMaker Deployment**  
   - Developed an end-to-end workflow to deploy and test a large language model using Hugging Face’s inference containers on AWS SageMaker.
   - Learned about inference pipelines, endpoint scaling, and best practices for managing response lengths and hallucinations.

---

## Next Week’s Roadmap

- Implement mentor feedback on improving the UI/UX of the story framework section  
- Experiment with improved prompt engineering  
- Explore smaller or more instruction-aligned models for improved response reliability  

---

## References

_Model deployed using Hugging Face: [Qwen/Qwen3-235B-A22B-Instruct-250](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507)_  
_AWS SageMaker Deployment Guide: [Amazon SageMaker documentation](https://docs.aws.amazon.com/sagemaker/)_

---

## Acknowledgments

Thank you to my mentors for their consistent guidance. Special thanks to the open-source contributors and AWS documentation community whose detailed resources helped me overcome deployment challenges.

---
`,vr=Object.freeze(Object.defineProperty({__proto__:null,default:ht},Symbol.toStringTag,{value:"Module"})),gt=`---
title: "GSoC '25 Week 7 Update by Elwin Li"
excerpt: "MusicBlocks generation model"
category: "DEVELOPER NEWS"
date: "2025-07-19"
slug: "2025-07-19-gsoc-25-Elwin-Li-week07"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week7,javaScript editor,debugger,syntax highlighting"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 7 Progress Report by Elwin Li

**Project:** MusicBlocks Generation Model

**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-07-12 - 2025-07-19

---

## Goals for This Week

- **Goal:** Work on obtaining a dataset for MusicBlocks generation model

---

## This Week’s Achievements

Before diving into the technical work, I want to share some context on the direction of my project. Last week, I experimented with a prompt-engineered Gemini API call to generate MusicBlocks code from natural language prompts. However, I found that this approach did not work well for examples more complex than simple nursery rhymes. As a result, I decided to explore the possibility of fine-tuning a model specifically for MusicBlocks code generation.

I spent a significant amount of time this week learning about the process of fine-tuning large language models. Through this research, I discovered that a high-quality dataset is essential for effective fine-tuning. This realization shaped the rest of my week's work, as I shifted my focus toward obtaining and preparing such a dataset.

This week, I mainly focused on gathering data for the MusicBlocks generation model. I used the example projects in the examples folder as my data source. Since these projects were in blocklist format, I needed to find a way to convert all of them to JavaScript code.

To accomplish this, I developed a widget that can load projects directly from the examples folder, generate the corresponding JavaScript code, and download it. This streamlined the process of extracting code from a large number of example projects.

<a href="https://ibb.co/7NTw72yd"><img src="https://i.ibb.co/HpMWmngf/Screenshot-2025-07-20-at-1-04-37-AM.webp" alt="Examples Loader Widget"></a>


However, I found that only about half of the projects could be successfully converted to JavaScript. Many of the example projects contained blocks that are not currently supported for block-to-code conversion, which limited the amount of usable data I could extract for the model.

After completing these achievements, I realized that since I didn't have much data available, fine-tuning might not be the most effective approach. Instead, I decided to shift my focus towards Retrieval-Augmented Generation (RAG) as an alternative. I have now started learning about the RAG process and how it could be applied to the MusicBlocks generation task.

---

## Challenges & How I Overcame Them

- **Challenge:** The Gemini API prompt engineering approach only worked for very simple examples and failed on more complex MusicBlocks projects.
  
  **Solution:** Decided to explore fine-tuning a model for MusicBlocks code generation, which required learning about the fine-tuning process and dataset requirements.

- **Challenge:** Many example projects could not be converted from blocklist to JavaScript due to unsupported blocks in the block-to-code conversion process.
  
  **Solution:** Built a widget to automate the conversion and identify which projects could be used, maximizing the amount of usable data.

- **Challenge:** Realized that the available dataset was too small for effective fine-tuning.
  
  **Solution:** Shifted focus to learning about Retrieval-Augmented Generation (RAG) as an alternative approach.

---

## Key Learnings

- Gained hands-on experience with prompt engineering for LLMs and its limitations for domain-specific code generation.
- Learned about the requirements and process for fine-tuning large language models, including the importance of dataset size and quality.
- Improved skills in automating data extraction and conversion workflows using custom widgets.
- Discovered the potential of Retrieval-Augmented Generation (RAG) as a practical alternative to fine-tuning when data is limited.

---

## Next Week’s Roadmap

- Continue learning about and experimenting with Retrieval-Augmented Generation (RAG) for MusicBlocks code generation.
- Investigate tools and frameworks for implementing RAG in the context of MusicBlocks.
- Explore ways to further expand or enhance the dataset, if possible.
- Begin prototyping a basic RAG pipeline using the data collected so far.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

--- `,Sr=Object.freeze(Object.defineProperty({__proto__:null,default:gt},Symbol.toStringTag,{value:"Module"})),mt=`---
title: "DMP’25 Week 07 Update by Justin Charles"
excerpt: "Implemented tower-level dragging in the workspace, enabling grouped brick movement and refining state synchronization across collisions"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-dmp-25-justin212407-week07"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week7,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 7 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-12 - 2025-07-20   

---

## Goals for This Week

- Implement tower-level dragging for grouped bricks in the workspace  
- Ensure consistent updates to brick positions during drag  
- Synchronize tower state with collision maps in real-time  

---

## This Week’s Highlights

### 1. **Tower Dragging Implementation**

Worked on [PR #450](https://github.com/sugarlabs/musicblocks-v4/pull/450) to add tower-level dragging:
- Enabled movement of entire towers (root brick + children) as a single unit  
- Preserved parent-child hierarchy when updating positions  
- Improved drag responsiveness by recalculating bounding boxes during movement  

### 2. **State Synchronization Across Towers**

- Updated \`TowerModel\` to handle bulk position updates for all bricks within a tower  
- Integrated with collision maps so towers temporarily unregister during drag and re-register on drop  
- Enhanced React state management for smoother rendering of large tower movements  

### 3. **User Interaction Improvements**

- Introduced proper offset handling to keep drag anchor consistent regardless of tower size  
- Added visual feedback for tower movement, ensuring alignment with cursor  
- Prepared groundwork for snapping logic to align towers when dropped near others  

---

## Challenges & Solutions

**Challenge:** Dragging large towers caused lag due to repeated state updates  
**Solution:** Batched updates at the tower level and minimized per-brick re-renders  

**Challenge:** Maintaining relative brick positions while dragging  
**Solution:** Used stored subtree offsets to apply uniform translation during movement  

---

## Key Learnings

- **Tower-Level Abstractions**  
  Learned how to extend single-brick drag logic to tower hierarchies without breaking child alignment  

- **Batching Updates**  
  Saw the importance of batching atom updates in Recoil to avoid UI jank in React  

- **Collision Integration**  
  Understood how temporary removal from collision maps avoids false positives during active drag  

---

## Next Week’s Roadmap

- Implement snapping between towers using collision hints  
- Add shadow previews during drag for better visual guidance  
- Begin refining detach/attach logic for bricks when splitting or merging towers  

---

## Resources & References

- [musicblocks-v4 PR #450](https://github.com/sugarlabs/musicblocks-v4/pull/450)  
- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  
---

## Acknowledgments

Thanks to my mentors for guiding me through scaling drag logic from bricks to full towers.
`,Ir=Object.freeze(Object.defineProperty({__proto__:null,default:mt},Symbol.toStringTag,{value:"Module"})),pt=`---
title: "GSoC ’25 Week 10 Update by Aditya Kumar Singh"
excerpt: "Improved UX and syncing in Human Body activity, enhanced Stickman dashboard visuals, redesigned proportions, and implemented Journal save & multi-stickman support."
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-gsoc-25-AdityaKrSingh26-week010"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week10,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Aditya Kumar Singh and Midterm Summary

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-07-16 - 2025-07-23

---

## Goals for This Week

- **Goal 1:** Improve Human Body UX (Tour/Doctor mode randomization, camera reset, leaderboard toggle).
- **Goal 2:** Polish Stickman activity dashboard and frame preview behavior.
- **Goal 3:** Improve stickman appearance and proportions.
- **Goal 4:** Enable multi-stickman support and journal storage.

---

## This Week’s Achievements

1. **Random Part Selection in Doctor/Tour Modes**  
   - Ensured every new session randomly selects a body part to focus on.
   - The selection is now host-driven and synced to all participants.
   \`\`\`javascript
        function selectRandomPartForDoctor() {
            presenceCorrectIndex = Math.floor(Math.random() * bodyParts.length);
            document.dispatchEvent(new CustomEvent("target-updated", {
                detail: { part: presenceCorrectIndex }
            }));
        }
    \`\`\`


2. **Camera Reset and Leaderboard Cleanup on Exit**  
    - Fixed host → client camera sync when exiting Tour mode.
    - Leaderboard UI now clears correctly when Doctor mode ends.
    \`\`\`javascript
        function resetTourState() {
            if (!window.isHost) {
                camera.position.set(defaultX, defaultY, defaultZ);
                controls.target.set(0, 1, 0);
                controls.update();
            }
            hideLeaderboard();
        }
    \`\`\`


3. **Frame Preview Enhancement in Stickman Activity**  
   - Previously, users had to add a new frame for the thumbnail preview to refresh.
   - Now, any movement or change in the canvas auto-updates the preview.
   - **Approach:**
     - Detect changes in the canvas (e.g., drag end or part movement).
     - Clone the updated canvas to the current frame’s preview.
     - This ensures instant visual feedback while animating.


4. **Stickman Design Overhaul**  
   - Revisited the drawing logic and proportions:
     - Shorter neck
     - Thicker limbs
     - Solid, filled circular head
   - Inspired by Pivot Animator to offer a more professional, relatable look.
    > Updated Stickman Design  
    ![Stickman UI](https://i.ibb.co/60VymQhm/image.webp)


5. **Multi-Stickman Canvas Support**  
   - Users can now add more than one stickman in the scene.
   - Each stickman is an isolated object with its own:
     - Position and joint data
     - Frame history
     - Selectable state
   - **Algorithm:**
     - Maintain a list of stickman instances.
     - On user interaction, determine which stickman is targeted.
     - Only that stickman responds to move, draw, and animate actions.
    > Multiple Stickman preview in acitvity  
    ![Multiple Stickman](https://i.ibb.co/s9VJBctL/image.webp)


6. **Journal Integration for Stickman**  
   - Implemented save/load logic to persist stickman data (frames, templates, active character).
   - **Approach:**
     - On save: Serialize all current stickmen, their frame sequences, and selected templates into a JSON blob.
     - On load: Deserialize and reconstruct all visual data, restoring the full session.
   - This allows users to save their progress and resume where they left.


---

## Challenges & How I Overcame Them

- **Challenge:** Preventing multiple stickmen from interfering with each other’s states.  
  **Solution:** Scoped interaction events to only apply to the selected stickman instance.

- **Challenge:** Updating previews without triggering unnecessary rendering overhead.  
  **Solution:** Triggered preview redraws only on meaningful events like drag-end or transformation complete.

---

## Key Learnings

- Learned how to architect multi-actor systems on a single canvas while maintaining performance.
- Strengthened my understanding of event-driven synchronization in real-time collaborative applications.

---

## Next Week’s Roadmap

- Fix remaining issue on Human Body
- Increase the size of Stickman
- Show frames only for selected stickman for multiple stickman
- Show joints only for selected stickman for multiple stickman
- Add popup when removing stickman with frames count >1

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,Ar=Object.freeze(Object.defineProperty({__proto__:null,default:pt},Symbol.toStringTag,{value:"Module"})),bt=`---
title: "GSoC ’25 Week 07 Update by Mebin J Thattil"
excerpt: "Benchmarking and community feedback"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-gsoc-25-mebinthattil-week7"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week07,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-14 - 2025-07-20

---

## Goals for This Week

- Add both variations of the SLM to the benchmark  
- Complete Kokoro streaming with GStreamer  
- Work on UI enhancements and group Kokoro voices by language  

---

## This Week’s Progress

### **1. Benchmark for the SLM**

For the past few weeks, I've been working on fine-tuning different SLMs. I would always try to have a conversation with the model to see how it responds, but I often found the responses unsatisfactory. The problem was that only I could see the responses. So, I was advised to create a benchmark comparing responses across all the different fine-tuned versions of the SLM. This way, the community can evaluate how each model performs in various scenarios and collectively decide which one suits our use case best.

My first step was to clean up all the different fine-tuned versions I had and segregate them based on the formats I had converted them to (GGUF, GGUF with Q4_0). I then uploaded all the [models to my 🤗 profile](https://huggingface.co/MebinThattil/models). I also created a [GitHub repo](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135) to categorize these models for easier viewing. This [repo](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135) also includes all the [training scripts](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135/blob/main/Training_Script.py), [model conversion scripts](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135/blob/main/gguf.sh), [inference scripts](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135/blob/main/Batch_Inference_Script.py), the [benchmarking app source code](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135/blob/main/slm_benchmark_app.py), as well as the [benchmark questions](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135/blob/main/Benchmarking_Questions.json) and [results](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135/tree/main/Distill_Claude_RUN1/Benchmarking%20Answers).

I then built a benchmarking [Streamlit app](https://slm-benchmark.streamlit.app/) to compare the different models. This app lets users view and compare the responses of all 16 fine-tuned models. Each model is asked five sets of 50 questions, with parameters like \`temperature\` and \`do_sample\` tweaked to observe their impact.

This benchmarking process was very time-consuming because:
- Each model has a very limited context window, so I had to generate responses for each question one at a time.
- The number of questions per model was high - 250 questions per model across 16 models.

### **2. SugarAI Deployment and AWS Struggles**

A big part of my project is to use an LLM hosted on AWS. We aim to streamline how AI-powered activities use LLMs in the cloud; and that’s through SugarAI. The issue so far was that we needed an EC2 instance with a G-series GPU to run and host SugarAI. However, our previous AWS service limit requests were denied.

After several back-and-forths with the AWS support team, we finally managed to get access to 16 spot and on-demand instances with G-series GPUs. This means we now have the necessary resources to host SugarAI.

### **3. Reading GStreamer Internals for Optimizations**

I've been digging into the [GStreamer documentation](https://gstreamer.freedesktop.org/documentation/tutorials/basic/index.html) to understand how it works in greater detail. The goal is to stream audio data directly from Kokoro into GStreamer's source and pipe it into the existing two-sink setup that Speak currently uses. This lets us reuse the robust and already optimized pipeline, we just need to plug Kokoro into it. I’ll need a bit more time to get this fully functional.

### **4. Community Feedback and Opinions**

For this AI revamp of Speak, there are two critical components - the TTS model and the SLM.

- For TTS, we plan to include only 5-6 default voices to reduce the activity's size. Users can download the rest later as needed. The key question is: **Which voices should be included by default?**  
  To decide, I sent out a [community survey](https://forms.gle/axhDhBKX9n8pZJTo9) to gather input.

- I did the same for the SLM. A separate [community survey](https://forms.gle/ZNHyh4VRC67nnEzHA) was shared to get feedback on the preferred default model.

Both surveys include links to test out the TTS voices and view the SLM responses.

---

## Next Week’s Roadmap

- Optimize Kokoro + GStreamer  
- SLM inference without using compiled binaries for Llama.cpp and avoid client side binary build processes
- Begin dataset collection for the SugarAI-hosted LLM and gear up for fine-tuning  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,Tr=Object.freeze(Object.defineProperty({__proto__:null,default:bt},Symbol.toStringTag,{value:"Module"})),ft=`---
title: "GSoC '25 Week 07 Update by Nikhil Bhatt"
excerpt: "Implemented forking of projects in the frontend, backend route for returning project data only, and student descriptions for projects"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-gsoc-25-nikhilbhatt-week07"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week07,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-07-13 – 2025-07-20 

---
 
## This Week's Achievements

### Backend: Project data end point

- Created a new backend route that returns project data of projects without forking them \`GET/api/github/getProjectData\`.   
Earlier, when we used to click "Open in Music blocks" in the projects page, a shallow fork of the project (without all the project history) 
used to get created, the route helps in only returning the projectData which is loaded to musicblocks allowing students to see first and then 
decide whether to fork or not. 

- Custom description for the project - This change allows student to add descriptions to their projects, similar to what they did in the planet page.  

---

###  Frontend: Forking projects & Student written Description for Projects

- Fork Button in UI: Users now see a "Fork This Project" button while inside any project.
- It also retains all commit history from the original repository in the fork.
- Allows student to edit the forked projects in their own repo to work further on others projects.
- Students can also enter the description for their projects when creating their projects, also visible in the projects page.
---

## Challenges & How I Solved Them

- **Challenge:** Handling local saved states for identifying projects with their keys.  
  **Solution:** We are replacing the repoName and its key when a project is forked, discussion on this approach is still in progress. 

- **Challenge:** Managing clear separation between forking and opening a project in Music Blocks.  
  **Solution:** Created a separate end point which only returns the projectData, no forking initially, will save loading time as well as un-necessary repository creation.

---

## Key Learnings
- Understanding the importance of UX clarity when introducing forking systems.
- How forks inherit full Git commit histories and the implications for educational use-cases, reflective journey in particular.
- Value of allowing students to describe their projects for documentation and self-reflection.

---

## Next Week's Roadmap
- Begin work on downloading and sharing of projects.
- Conceptualise creating pull requests and an option to see them Music Blocks.  
- Discuss on working on multiple projects simultaneously.  


---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [Octokit REST.js Library](https://github.com/octokit/rest.js)

---

## Acknowledgments

Thanks again to my mentors and the Sugar Labs community for feedback and support!  
Looking forward to next week’s frontend PR features. 

`,Pr=Object.freeze(Object.defineProperty({__proto__:null,default:ft},Symbol.toStringTag,{value:"Module"})),wt=`---
title: "GSoC '25 Week 7 Update by Safwan Sayeed"
excerpt: "Implementing the Symbol Table and Memory Module Integration"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-gsoc-25-sa-fw-an-week7"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week7,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 7 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-14 - 2025-07-20  

---

## A Blog-style Retrospective

This week I worked on creating a TechSpec for the Interpreter and then Created a Data Flow Diagram (DFD) to visualize the data movement within the system.

---

## Goals for This Week

- Create a TechSpec for the Interpreter.  
- Create a Data Flow Diagram (DFD) for the Interpreter.  
---

## This Week's Highlights

1. **TechSpec Creation**  
   - Developed a comprehensive TechSpec for the Interpreter, detailing its architecture, components, and interaction with the Symbol Table and Memory Module.
   - The TechSpec serves as a blueprint for the implementation of the Interpreter, ensuring clarity in design and functionality.

2. **Data Flow Diagram (DFD) Creation**  
   - Created a Data Flow Diagram (DFD) to visualize the data movement within the Interpreter.
   - The DFD highlights key processes, data stores, and data flows, providing a clear overview of the system's operation.

![Data Flow Diagram](/assets/Developers/Safwan/dfd.webp)

---

## Challenges & Solutions

- **Defining the Interpreter's Architecture:**  
  Faced challenges in clearly defining the architecture and components of the Interpreter.  
  *Solution:* Collaborated with mentors to refine the TechSpec, ensuring it accurately reflects the intended design and functionality of the Interpreter.


---

## Key Learnings

- Gained insights into the process of creating a TechSpec for complex systems, focusing on clarity and detail.  
- Learned how to create a Data Flow Diagram (DFD) to visualize data movement and interactions within the system, enhancing understanding of the Interpreter's operation.

---

## Next Week's Roadmap

- Start working on the implementation of the Interpreter based on the TechSpec and DFD.  
- Begin coding the first components of the Interpreter, focusing on integrating it with the Symbol Table and Memory Module.  
---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their crucial guidance on compiler design principles and static compilation concepts. Their clarification on the AST-to-IR translation approach and emphasis on maintaining clean instruction generation patterns was essential for this week's successful progress.

---`,Mr=Object.freeze(Object.defineProperty({__proto__:null,default:wt},Symbol.toStringTag,{value:"Module"})),yt=`---
title: "GSoC ’25 Week 07 Update by Diwangshu Kakoty"
excerpt: "Reflection Learning Widget in Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-gsoc-25-diwangshu-week07"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week06,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-07-14 - 2025-07-19  

---

## Goals for This Week

- **Goal 1:** Implement periodic summary generation.
- **Goal 2:** Upgrading the 'reflection' widget.
- **Goal 3:** Fix bugs occured by these changes.

---

## This Week’s Achievements

1. **Implement periodic summary generation**  
   - As mentioned in the previous blog, I’ve now implemented periodic summary generation. Currently, it uses a straightforward prompt that requests a summary after every five bot messages. While this is a simple and somewhat detailed approach, it’s still basic and may not consistently produce accurate results. I’m in the process of testing it. 
   
   - If it proves unreliable, I’ll switch to invoking the LLM with a dedicated prompt template after every five bot messages. This will ensure a structured and consistent summary each time.

2. **Upgrading the 'reflection' widget**

   - The widget now allows users to interact with all available AI mentors directly within the interface. When a user initiates a conversation, their project code is automatically sent to the server, enabling mentors to provide more context-aware guidance and feedback. For this I developed a '/code' endpoint. This is the flow:

        - Music Blocks sends the project code to the server as a POST request in JSON format.

        - The server processes this data by running a conversion module and then calls the reasoning LLM to generate the corresponding algorithm.

        - It then responds with both the flowchart and the algorithm.

        - The client is responsible for storing this information and including it in requests sent to the /chat endpoint.


   - I have also enhanced the save functionality. Users can now choose to save their entire conversation history at any point. In addition, the system automatically stores generated summaries and analytical insights, ensuring that important information and progress are preserved for future reference.

---

## Challenges & How I Overcame Them

- **Challenge :** I faced a minor challenge while implementing the periodic summary. My approach is to start simple and build up as needed, so I initially relied on prompting. However, the LLM wasn’t following the instruction. After some brainstorming, I realized that other instructions like 'Limit your response to 30 words' might have been conflicting with it 

  **Solution :** I modified the conflicting prompts and experimented with few-shot prompting, which resolved the issue.
---

## Key Learnings

- Adjusting or refining conflicting prompts, combined with the use of few-shot prompting, can significantly improve an LLM’s output. This highlights the importance of prompt engineering in guiding model behavior and achieving desired results.
---

## Next Week’s Roadmap

- I need to finish building the widget to store user data, such as messages, summaries, and analysis reports using IndexedDB.
- Once that’s completed, I’ll move on to the 'analysis generation' phase.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)
- **Streamlit App:** [Reflection App](https://reflectionapp-2yoxtvn6sknvktme2zorvq.streamlit.app/)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Cr=Object.freeze(Object.defineProperty({__proto__:null,default:yt},Symbol.toStringTag,{value:"Module"})),kt=`---
title: "GSoC’25 Week 07 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-gsoc-25-omsuneri-week07"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week07,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-06-13 - 2025-07-20

---

## Goal for This Week

**Build the backend API for the AI Debugger and enrich the LLM using Music Blocks lesson plans**

---

## This Week’s Achievements

### Introduction

This week was focused on two critical and foundational systems that expand the functionality, scalability, and intelligence of the debugger:

1. I developed the core **FastAPI backend** (\`api.py\`) for handling LLM interactions with contextual awareness.
2. I scraped and parsed all **Music Blocks lesson plans** from the MAP FLC site and created **embeddings** for retrieval augmentation.

Together, these components make the AI-powered debugger more conversational, contextually smart, and aligned with the Music Blocks pedagogy.

### What I Did

#### 1. FastAPI Backend for Conversational Debugging

To move beyond a local Streamlit prototype and toward a production-ready debugger, I created a structured backend API using **FastAPI**. The key route is a \`POST /analyze\` endpoint that handles user input, retrieves context, formats prompts, and returns LLM responses.

**Key Features of the API:**

* **CORS Support**: Enabled via \`CORSMiddleware\` to allow frontend access from any origin.
* **User Prompt + History**: Accepts user queries, chat history, and the converted Music Blocks code.
* **Dynamic Prompting**: Varies the LLM’s response style based on \`prompt_count\`, guiding the bot to be playful early and more helpful later.
* **System Personality**: A carefully designed system instruction makes the LLM act like a fun, patient music teacher  using emojis, stories, and simple words.
* **Contextual Awareness**: The input code is parsed from JSON into text (via \`convert_music_blocks()\`), and semantic context is retrieved from documentation using the \`retrieve_relevant_chunks()\` method.
* **LLM Integration**: The constructed prompt is sent to Gemini (via \`ask_gemini()\`), and the response is returned as JSON.

This modular architecture is easy to integrate with Music Blocks UI, scalable across users, and makes the debugger interactive in real-time.

---


#### 2. Embedding Music Blocks Lesson Plans

To make the LLM better at understanding educational goals, I wrote a full scraping pipeline to collect and embed **lesson plans from the [MAPFLC](https://mapflc.com/lesson-plans/) site**.

**What the Script Does:**

* Crawls all \`https://mapflc.com/lesson-plans/\` URLs using BeautifulSoup.
* Extracts key metadata: title, duration, age range.
* Parses sections such as Objectives, Materials, Steps, and Vocabulary.
* Cleans up and flattens the text into structured JSON.
* Saves all data into a single JSON file: \`music_blocks_lessons.json\`.

Once the data was collected, I passed the documents through our embedding pipeline to store them as vector chunks. This allows the LLM to retrieve lesson-specific context (e.g., "loop rhythm exercises" or "pitch experiments") when analyzing a project or answering a student’s question.

---

### Why It Matters

Both of these systems expand the AI debugger’s capabilities beyond prototype-level tooling.

#### The Backend API:

* **Decouples frontend from logic** — allowing future deployment on Music Blocks.
* **Improves UX** — conversations can now be smooth, asynchronous, and stateful.
* **Encodes domain-specific tone and guidance** — the bot behaves like a kid-friendly tutor with every response.

#### Lesson Plan Embeddings:

* **Bring pedagogical context into the loop** — aligning AI suggestions with real-world music education.
* **Enable smarter retrieval** — the LLM doesn’t just guess; it recalls relevant activities.
* **Support curriculum-based learning** — ideal for educators using Music Blocks in structured settings.

These tools pave the way for a smarter, kinder, and more helpful AI debugger tailored for kids and teachers.

---

### Final Thoughts

This week marked a turning point in the architecture of the debugger. With a clean, modular backend and embedded educational context, the foundation is now strong enough to scale and personalize the debugging experience.

---

## Next Week’s Roadmap

**Create a Music Blocks Widget and basic integration of the debugger backend with the widget**

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)


## Acknowledgments

Huge thanks to my mentors and the Sugar Labs community for always guiding me to think pedagogically, build modularly, and focus on what helps learners most.

---
`,Lr=Object.freeze(Object.defineProperty({__proto__:null,default:kt},Symbol.toStringTag,{value:"Module"})),vt=`---
title: "SSoC ’25 Week 07 Update by Muhammad Haroon"
excerpt: "Create sketches of user interface showing how students will interact with the GenAI and the audio trimming tool."
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-ssoc-25-MuhammadHaroon-week07"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week07,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-14 - 2025-07-20

---

## Goals for This Week

- **Goal 1:** Create sketches of user interface showing how students will interact with the GenAI and the audio trimming tool.

---

## This Week's Achievements

1. **Created sketches of user interface**  
   - I created sketches of the user interface, keeping children in mind to ensure it is easy for them to interact with. Below are the sketches of the user interface.

   - I added two buttons to the sampler widget, upon clicking those users can access AI sample generation tool and audio trimming functionality.

   ![User Inerface 1](/assets/Developers/Muhammad_Haroon/user_interface_1.webp)

   - Upon clicking the Prompt button (which has an icon resembling a code editor), the AI sample generation tool will open. It includes an input box where users can enter a prompt and press the Submit button. Users can preview the generated audio by pressing the Preview button. If the audio doesn't sound good, they can modify the prompt and preview the audio again before saving it by pressing the Save button.

   ![User Inerface 1](/assets/Developers/Muhammad_Haroon/user_interface_2.webp)

   - Once the audio is downloaded, users may need to trim it to extract the desired portion. For this, I designed an Audio Trimming Tool, it can be opened by clicking on an icon of a scissor. Users can select the downloaded audio file by clicking the file chooser button. After selecting a file, the file chooser is replaced with an HTML audio player that loads the selected audio (as shown in User Interface 4). This allows users to listen and identify the timestamps of the segment they want to keep. Two input boxes are provided where users can enter the start time and end time of the desired audio segment. A Preview button lets users listen to the trimmed portion before finalizing it. Once satisfied, they can click the Save button to download the trimmed audio.

   ![User Inerface 1](/assets/Developers/Muhammad_Haroon/user_interface_3.webp)

   ![User Inerface 1](/assets/Developers/Muhammad_Haroon/user_interface_4.webp)

---

## Next Week's Roadmap

- Code the sketches of the user interface in Music Blocks.
- Create a FastAPI for connecting frontend with backend.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,xr=Object.freeze(Object.defineProperty({__proto__:null,default:vt},Symbol.toStringTag,{value:"Module"})),St=`---
title: "DMP ’25 Week 07 Update by Harshit Verma"
excerpt: "Presented my work on Pippy Debugger to mentors and also started working on developing API endpoint in Sugar-AI."
category: "DEVELOPER NEWS"
date: "2025-07-21"
slug: "2025-07-21-dmp-25-therealharshit-week07"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week07,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-14 - 2025-07-20   

---

## Goals for This Week

- **Goal 1:** Prepare a presentation for the DMP Midterm Evaluation.
- **Goal 2:** Start working on the \`/debug\` endpoint in Sugar-AI.

---

## This Week’s Achievements

1. **Prepared a presentation for the DMP Midterm Evaluation.**  
   - I prepared a comprehensive presentation to showcase the progress of the **Pippy Debugger** at the DMP midterm review. The presentation covered everything from project objectives and methods to current results, challenges, and future plans.
   - Additionaly, I also gave a mock presentation of my work to the Sugar Labs mentors.
   - [DMP Midterm Presentation](https://docs.google.com/presentation/d/13bAMCpKi6ezlhBEQ7NGR7eszumwpYZnL8dGFLNlnBF8/edit?usp=sharing)

2. **Started working on developing API endpoint in Sugar-AI**  
   - Began development of a new \`/debug\` endpoint in Sugar-AI. This endpoint will handle code input and return structured debug suggestions from the LLM.
   - I have also started the process of integrating Sugar-AI with Pippy.

---

## Challenges & How I Overcame Them

- **Challenge:** Understaing Sugar-AI’s existing API structure.  
  **Solution:** I followed the documentaion and my mentors guidance.

---

## Key Learnings

- How to design and deliver a structured presentation.
- Introduction to Sugar-AI’s internal API design and how to extend it.

---

## Next Week’s Roadmap

- Finalize the work of \`/debug\` endpoint in Sugar-AI.
- Work on making the LLM response more kids friendly.
- Start working on saving debug history to Sugar Journal.

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,Gr=Object.freeze(Object.defineProperty({__proto__:null,default:St},Symbol.toStringTag,{value:"Module"})),It=`---
title: "GSoC '25 Week 07 Update by Shubham Singh"
excerpt: "Method to simplify musical notes and export as action block."
category: "DEVELOPER NEWS"
date: "2025-07-21"
slug: "2025-07-21-gsoc-25-firepheonix-week07"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week07
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 7 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-13 – 2025-07-20

---

## Goals for This Week

- Figure out a method to export Lego Patterns as musical action blocks.
- Consult mentors regarding the issue of action blocks.

---

## This Week's Achievements

1. **Researched how the Phrase Maker's action block export actually works.**  
   - The Music Blocks Phrase Maker exports in the form of action blocks, organized by rows:
        ![How the format of the Phrase Maker's vertical rows looks.](https://i.ibb.co/bRgqgHBL/Music-Blocks-Google-Chrome-22-07-2025-21-54-18.png)

        ![How the format of the Phrase Maker's action output looks, corresponding to its rows.](https://i.ibb.co/fYnwD9qw/Music-Blocks-Google-Chrome-22-07-2025-21-55-27.png)

2. **After talking with my mentors**  
   - My mentor, Devin, suggested a completely new method—a complete pivot.
   - Basically, instead of the current method of placing blocks and playing them horizontally and simultaneously, the user should place the blocks in vertical rows, just like the PHRASE Maker block.
   - Next week, I'll apply this methodology and present an actual deliverable.

---

## Challenges & How I Overcame Them

- **Challenge:** The week itself was very unproductive. Action blocks don't work with the way we have designed the current system.   
  **Solution:** I talked to my mentors and figured out a completely new method.

---

## Key Learnings

- Sometimes you'll be forced to pivot. Be sure to consult others beforehand.
- People may use different different widths and heights of monitors, when doing computer vision things related to shapes and sizes, use both x and y-axis to standardize across all monitors.

---

## Next Week's Roadmap

- Complete the first actual prototype, with the action block export.
- Add vertical lines as a grid, to standardize detection time accross all widths of monitors.
- Find out a method to divide the the entire musical pattern into standard column like sections, like in phrase maker.

---

## Resources & References

- **You can refer to music blocks documentation: https://github.com/sugarlabs/musicblocks/tree/master/documentation** 
- **You may refer to the Lego Blocks Notation system video: https://youtu.be/LOfrCPf3XJU?feature=shared**
- **Devin's CMK'24 blog: https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c**

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Thanks to Devin and Walter for suggesting methods to make this process easy.

---`,Wr=Object.freeze(Object.defineProperty({__proto__:null,default:It},Symbol.toStringTag,{value:"Module"})),At=`---
title: "DMP ’25 Week 8 Update by Aman Naik"
excerpt: "This week focused on improving model response quality, optimizing inference costs, and enhancing the UX logic of the story framework display."
category: "DEVELOPER NEWS"
date: "2025-07-26"
slug: "2025-07-26-dmp-25-AmanNaik-week08"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week08,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 8 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-07-20 – 2025-07-26  

---

## Goals for This Week

- Improve the accuracy and coherence of LLM model responses  
- Enhance user experience by reordering framework display elements  

---

## This Week’s Achievements

1. **Deployed a Smaller Qwen Model and improved configuration for accurate response generation**  
   - Switched to a smaller version of the Qwen model from Hugging Face to reduce GPU memory usage and cost.  
   - Used the \`.predict()\` method to generate responses and validate output.  
   - Configured the the prompt and text_generation function to generate controlled responses which contain only the required information
   \`\`\`model-deployment.py
    import json
    from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri

    # Hub Model configuration. https://huggingface.co/models
    hub = {
      'HF_MODEL_ID':'Qwen/Qwen2-7B-Instruct',
      'SM_NUM_GPUS': json.dumps(1)
    }

    # create Hugging Face Model Class
    huggingface_model = HuggingFaceModel(
      image_uri=get_huggingface_llm_image_uri("huggingface",version="3.2.3"),
      env=hub,
      role=role, 
    )

    # deploy model to SageMaker Inference
    predictor =  huggingface_model.deploy(
      initial_instance_count=1,
      instance_type="ml.g5.2xlarge",
      container_startup_health_check_timeout=300,
      )	
   \`\`\`

2. **Improved UX by Reordering Story Framework Output**  
   - Previously, the story framework UI displayed elements in a fixed order, resulting in scattered empty and filled sections.  
   - Now, the application prioritizes displaying filled sections first, followed by the empty ones.  
   - This change improves readability and helps students better focus on the generated content.

---

## Challenges & How I Overcame Them

- **Challenge:** \`.predict()\` method returned prompt + raw model output  
  The raw output from the model included the prompt text followed by a generic continuation, making it difficult to isolate meaningful responses.  
  **Solution:**  
    - Discovered through documentation that structured prompting and post-processing are essential.  
    - Now slicing the model's response by measuring the prompt length and trimming everything before it.  
    - This ensures only the meaningful, post-inference content is displayed.  
    \`\`\`python
    system_prompt = (
        "<|im_start|>system\\n"
        "You are a helpful assistant named Mary Tales. You are a guide to the students to help them in story telling. "
        "Your responses should be concise and simple for young learners, one line only.<|im_end|>\\n"
    )
    user_prompt = (
        "<|im_start|>user\\n"
        "My story is about a big business man! And he wants to rule the whole world.How is my idea?<|im_end|>\\n"
        "<|im_start|>assistant\\n"
    )
    full_prompt = f"{system_prompt}{user_prompt}"

    # send request
    response = predictor.predict(
        {
        "inputs": full_prompt,
        "parameters": {
            "do_sample": True,
            "max_new_tokens": 128,
            "temperature": 0.7,
            "top_k": 50,
            "top_p": 0.95,
            }
        }
    )
    generated_text = response[0]['generated_text']
    print(generated_text[len(full_prompt):])
    \`\`\`
    - This made the output from the model more consistent.


---

## An interesting gamification idea for the future
   - A progress bar to indicate the compeleteness of the story.  
   - As the student writes the story using the framework after certain number of words if they implement each element of the story framework, the progress bar will move ahead and a message of encouragement will pop up.  
   - I havent discussed this with the mentors. But this seems like a fun gamification for students. A bit outside the scope of this project but will be an addition once the scope of this project are finalised.  

   ![Rough idea of UI](assets/Images/aman-naik-week8-img1.webp)

---

## Key Learnings

**Model-Specific Prompt Engineering**  
   - Understood the difference between raw token streaming and structured prompting when using large language models in production.  
   - Learned how to manipulate string slices and structure prompts to get clean, contextually relevant outputs.

**Inference Cost Optimization with Smaller Models**  
   - Learned the importance of model size on inference speed and cost, especially when working within AWS SageMaker constraints.  
   - Successfully deployed and tested a smaller instruction-tuned variant of the Qwen model, improving both performance and affordability.

**Better UX Through Dynamic Element Sorting**  
   - Enhancing the layout logic in GTK led to a cleaner interface where students now see their generated content prioritized over empty templates.

---

## Next Week’s Roadmap

- Continue testing alternate prompt templates for more creative and friendly conversation 
- Explore other compact instruction-tuned models for better performance  
- Implement UI improvements:  
  - Framework section should display meaning of each story element(Enables students to learn more about each element)
  - Remove the \`back\` button and make the \`Create Framework\` button change state, to become the back button.

---

## Acknowledgments

Thanks to my mentors and the Sugar Labs community. Special thanks to the open-source contributors whose documentation around Qwen models and SageMaker integration helped resolve key technical issues this week.

---
`,Dr=Object.freeze(Object.defineProperty({__proto__:null,default:At},Symbol.toStringTag,{value:"Module"})),Tt=`---
title: "GSoC '25 Week 8 Update by Elwin Li"
excerpt: "MusicBlocks generation model"
category: "DEVELOPER NEWS"
date: "2025-07-26"
slug: "2025-07-26-gsoc-25-Elwin-Li-week08"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week8,music generation,RAG"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 8 Progress Report by Elwin Li

**Project:** MusicBlocks Generation Model

**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-07-19 - 2025-07-26

---

## Goals for This Week

- **Goal:** Generate MIDI from prompt for MusicBlocks generation model

---

## This Week’s Achievements

Last week, I made the pivot from trying to fine tune a model to building a RAG pipeline. This week, I have completed building a RAG pipeline that takes in a prompt in the form of a song, artist, or music style, and generates a MIDI note sequence in a similar style.

This was done by the following:
1. **Data Collection & Cleaning**: Found and cleaned a large dataset of MIDI files to use as the foundation for the generation model.

2. **Metadata Extraction**: Extracted important metadata from each MIDI file including:
   - Artist name
   - Song title 
   - Musical style/genre
   - BPM (Beats Per Minute)
   - Additional musical characteristics
   This step proved crucial for improving the retrieval accuracy of the RAG pipeline.

3. **Vector Embedding**: Used Langchain to:
   - Create embeddings of the MIDI data and metadata
   - Store the embeddings in a vector database
   This forms the "Retrieval" component of the RAG system.

4. **Similarity Search**: When a user inputs a prompt (e.g., "hotel california"):
   - The system performs a similarity search between the query and vector database
   - Returns either the exact matching song (if present in dataset)
   - Or returns similar songs based on musical characteristics

5. **Generation Pipeline**: Using the retrieved MIDI representation:
   - Leveraged Gemini API with carefully engineered prompts
   - Generated new melodies that maintain similar musical characteristics
   - Output new MIDI files that capture the style of the requested song

---

## Challenges & How I Overcame Them

- **Challenge:** Realized that the available dataset was too small for effective fine-tuning.
  
  **Solution:** Shifted focus to learning about Retrieval-Augmented Generation (RAG) as an alternative approach.

- **Challenge:** Some MIDI files in the dataset had formatting issues and corruption.
  
  **Solution:** Implemented thorough data cleaning and validation:
  - Checked for proper MIDI file structure
  - Removed corrupted or malformed files
  - Validated tempo and time signature information
  - Ensured consistent formatting across the dataset

- **Challenge:** Initial attempts at embedding raw MIDI data resulted in poor retrieval accuracy.
  
  **Solution:** Enhanced the embedding process by:
  - Including rich metadata alongside MIDI data
  - Adding musical characteristics like genre, tempo, and key
  - Incorporating artist and song information
  - This significantly improved the relevance of retrieved results

---

## Key Learnings

- **RAG as an Alternative to Fine-tuning**: Learned that RAG can be an effective approach when dealing with limited training data, as it leverages existing knowledge rather than requiring extensive fine-tuning.

- **Data Quality is Critical**: Discovered the importance of thorough data preprocessing and validation in building robust ML systems. Poor quality data can significantly impact system performance.

- **Embedding Strategy Matters**: Realized that the choice of what information to include in embeddings greatly affects retrieval accuracy. Including rich metadata alongside raw data can substantially improve results.

- **MIDI Data Handling**: Gained practical experience in:
   - Working with MIDI file formats
   - Handling corrupted files
   - Extracting musical characteristics

---

## Next Week’s Roadmap

- Improve Output Quality
- Documentation & Testing
- Use gemini embedding model

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

--- `,_r=Object.freeze(Object.defineProperty({__proto__:null,default:Tt},Symbol.toStringTag,{value:"Module"})),Pt=`---
title: "GSoC '25 Week 8 Update by Krish Pandya"
excerpt: "Palettes, Groups, and GTK4 Decisions "
category: "DEVELOPER NEWS"
date: "2025-07-26"
slug: "2025-07-26-gsoc-25-mostlyk-week08"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week08,mostlyk"
image: "assets/Images/GSOC.webp"
---


# Week 8: ToolBarBox , Radio-Palette and RadioToolButton

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)  
**Reporting Period:** July 22, 2025 – July 29, 2025

---

## In Summary

Focused on palette positioning, finished graphics for widgets.py and prepared for activity porting.

> ## The Palette Rewrite of '25
>
> The palette system was one of the most challenging and complex rewrites till now, it wasn't a find and replace, original implementation was tied to our own gestures. And event model and widget hierarchy which has been changed significantly in GTK4.

This was there in week 6 blog and oooo boi it really was, I keep coming back to this because of errors.
There seems to be a lot of bugs here and there and the timing for this has affected my own timeline on working on the next components because the following components are kind of dependent on the palettes themselves.

Every time I think I’ve solved one part, another subtle bug or incompatibility pops up, often related to how GTK4 expects widgets to interact or how events are propagated.


![Week-08-Commit](public/assets/Images/week08-mostly-commit.webp)

I’ve been itching to record a demo of palettes in action, but there’s a major technical hurdle: on Wayland, widgets don’t have absolute screen coordinates, so palettes can’t reliably appear at the cursor or next to the invoking widget. This is a big departure from X11, where absolute positioning was straightforward. As a result, palettes sometimes pop up in unexpected places, which isn’t ideal for usability or demos. I’ve documented this as a TODO in the code and am actively looking for workarounds, but for now, the ToolbarBox example is at least functional.

I’m still planning to make a video walkthrough of the new palette system, but I want to make sure the positioning bug is fixed first so the demo truly reflects the intended user experience.

On a brighter note, finishing the graphics for widgets.py is a huge step forward. This file is one of the most important file for building and porting classic Sugar activities, so having it ready means I can finally shift my focus from infrastructure to actual porting of activities as well. There are still a few minor files left to port, but the bulk of the graphics work is behind me. Looking back, it’s satisfying to see how much of the library is now GTK4-ready.

A lot of decisions make sense now after one writes on the same system and builds it for 8 weeks, one starts understanding the GTK4 way of doing things and also why the older decisions were made.

## Looking Ahead

- Continue investigating and (hopefully) resolving the palette positioning issue, since it’s a major blocker for UI polish and usability.
- Finish the palette originating position issue, this is a blocker for the next steps.
- Porting <https://github.com/sugarlabs/fractionbounce/> activity after widgets.py being ported.

---

## Links

- [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [New C Library (sugar-ext)](https://github.com/sugarlabs/sugar-ext)
- [Game Demo Video](https://youtu.be/B517C_LTCns)
`,Er=Object.freeze(Object.defineProperty({__proto__:null,default:Pt},Symbol.toStringTag,{value:"Module"})),Mt=`---
title: "DMP’25 Week 08 Update by Justin Charles"
excerpt: "Implemented brick disconnection logic for towers, enabling subtree detachment and independent movement of child groups"
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-dmp-25-justin212407-week08"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week8,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 8 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-21 - 2025-07-27   

---

## Goals for This Week

- Extend tower drag logic by implementing brick disconnection  
- Allow subtree detachment from parent towers when dragging out child bricks  
- Maintain consistent state updates for both the parent and the detached subtree  

---

## This Week’s Highlights

### 1. **Brick Disconnection Implementation**

Expanded [PR #450](https://github.com/sugarlabs/musicblocks-v4/pull/450) to support brick disconnection:
- Enabled dragging of a child brick (and its subtree) out of a parent tower  
- Ensured detached bricks retain hierarchy and become a new independent tower  
- Updated \`TowerModel\` to support \`detachSubtree\` operation with proper ID remapping  

### 2. **State Management for Disconnected Bricks**

- Synced Recoil state so detached subtrees re-register as new towers  
- Updated reverse mapping utility to correctly track parent/child relations after split  
- Maintained integrity of collision maps by removing and re-adding affected nodes  

### 3. **Improved Workspace Interactivity**

- Added consistent cursor anchoring when pulling bricks from towers  
- Ensured visual feedback during disconnection (brick shadows and offset updates)  
- Prevented invalid states by blocking disconnection of non-draggable root nodes  

---

## Challenges & Solutions

**Challenge:** Preventing partial subtree corruption during disconnection  
**Solution:** Built a dedicated \`detachSubtree()\` method that clones and relocates the full hierarchy safely  

**Challenge:** Collision map desync when multiple towers updated at once  
**Solution:** Batched tower re-registration to ensure atomic updates across maps  

---

## Key Learnings

- **Subtree Logic**  
  Learned how to safely extract and reinitialize hierarchical structures without breaking references  

- **Tower Model Flexibility**  
  Deepened understanding of extending core tower APIs (\`add\`, \`merge\`, \`detach\`) for scalable interactions  

- **Collision Map Resilience**  
  Saw how batching state updates helps avoid flickers and false collisions in real-time rendering  

---

## Next Week’s Roadmap

- Implement snapping of detached towers onto valid drop zones  
- Introduce shadow previews for disconnection to guide user interaction  
- Begin refining attach logic for merging detached towers back together  

---

## Resources & References

- [musicblocks-v4 PR #450](https://github.com/sugarlabs/musicblocks-v4/pull/450)  
- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  

---

## Acknowledgments

Thanks to my mentors for helping validate the disconnection workflow and ensuring robustness of the tower model.
`,jr=Object.freeze(Object.defineProperty({__proto__:null,default:Mt},Symbol.toStringTag,{value:"Module"})),Ct=`---
title: "GSoC ’25 Week 11 Update by Aditya Kumar Singh"
excerpt: "Polished multi-stickman support with per-frame rendering, single-shadow enforcement, per-joint visibility, and safe delete flow. Also increased stickman size for better canvas presence."
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-gsoc-25-AdityaKrSingh26-week011"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week11,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-07-24 - 2025-07-30

---

## Goals for This Week

- **Goal 1:** Increase visual scale of the stickman for better visibility.
- **Goal 2:** Show frame previews only for the selected stickman.
- **Goal 3:** Limit shadow visibility to just the selected stickman and ensure new stickmen begin with exactly one frame.
- **Goal 4:** Display joints only for the selected stickman to reduce UI clutter.
- **Goal 5:** Add confirmation popup when removing a stickman with more than one frame.
- **Goal 6:** Implement Pivot Animator-style parent-child joint logic.

---

## This Week’s Achievements

1. **Increased Stickman Size**  
   - Enlarged the base rendering scale of stickman joints and limbs to make animation more visible and intuitive on canvas.
   - **Why it matters:** It improves accessibility, especially on high-resolution screens or dense animations.
   - This was done by:
        - Scaling the joint radii
        - Adjusting connection line thickness
        - Offsetting coordinates to preserve proportions
    > Updated Stickman Design  
    ![Earlier](https://i.ibb.co/4ZkrMBYm/image.png)
    ![Now](https://i.ibb.co/YFRRH2Ys/image.png)


2. **Show Frames Only for Selected Stickman**  
   - Previously, all stickmen shared the same frame thumbnails, which led to visual confusion.
   - Now, each stickman has an isolated frame timeline that only shows when it is selected.
    - This creates an intuitive editing experience similar to video editing software with multiple tracks.
   - **Algorithm:**
        - Store \`frames[]\` per stickman instance.
        - When a stickman is selected:
            - Load its \`frames[]\` to the UI bar.
            - Render only the active stickman’s previews.
            - Hide all others.



3. **Single Shadow Enforcement + Initial Frame Guarantee**  
   - **Problem:** All stickmen had shadows simultaneously and new ones could lack animation history.
   - **Fix:** When a stickman is selected:
        - Show only its onion-skin shadow (ghost of previous frame).
        - Hide shadows of others.
        - Ensure any newly created stickman is initialized with a default frame.




4. **Only Selected Stickman Shows Joints**  
    - Added visual filtering so that: Joints (circles for draggable points) are drawn **only** for the currently selected stickman.
    - **Approach:**
        - Loop through all stickmen.
        - For each stickman, set: \`showJoints = (stickman.id === selectedStickman.id);\`
        - Then draw joints conditionally inside the rendering function.


5. **Safe Deletion with Popup for Multi-Frame Stickmen**  
    - When a user attempts to delete a stickman with more than one frame, a confirmation popup is shown.
    - **Why it's important:** Prevents accidental loss of complex animation timelines.
    - Ensures clarity and gives users a chance to cancel destructive actions.
    > Remove Popup UI  
    ![](https://i.ibb.co/vCHLQ67t/image.png)


## Pivot Animator Style Joint Hierarchy in Stickman Animator

One of the core architectural challenges in building a stickman animation tool is designing an effective **joint hierarchy system** a system where moving or rotating a parent joint automatically affects all of its child joints. This feature mimics the functionality of tools like Pivot Animator and is essential for creating realistic, controllable animations.

In this section, I will explain how I implemented this hierarchical joint system from scratch, including how joints are defined, how relationships are structured, and how recursive transformations are performed.

### 1. Understanding Joints

Each stickman is defined as a collection of joints. A joint represents a specific body part such as the head, torso, elbow, knee, or foot. Every joint is represented as a 2D coordinate point:
\`\`\`javascript
    joints: [
        { x: ..., y: ..., name: 'head' },    // index 0
        { x: ..., y: ..., name: 'body' },    // index 1
        { x: ..., y: ..., name: 'hips' },    // index 2
        ...
        { x: ..., y: ..., name: 'middle' }   // index 11
    ]
\`\`\`

### 2. Defining Joint Relationships

Joints are connected in two meaningful ways:

**A. Distance-Based Constraints**  
These constraints ensure that limbs maintain a fixed length and structure during animation:
\`\`\`javascript
const jointConnections = [
    { from: 0, to: 1, length: 20 },    // head to body
    { from: 1, to: 11, length: 30 },   // body to middle
    { from: 11, to: 2, length: 30 },   // middle to hips
    { from: 2, to: 3, length: 25 },    // hips to left knee
    { from: 2, to: 5, length: 25 },    // hips to right knee
    { from: 3, to: 4, length: 25 },    // left knee to left foot
    { from: 5, to: 6, length: 25 },    // right knee to right foot
    { from: 1, to: 7, length: 25 },    // body to left elbow
    { from: 1, to: 9, length: 25 },    // body to right elbow
    { from: 7, to: 8, length: 25 },    // left elbow to left hand
    { from: 9, to: 10, length: 25 }    // right elbow to right hand
];
\`\`\`

**B. Hierarchical Parent-Child Structure**  
To model recursive movement, a joint hierarchy tree is used. This structure defines how movement in one joint affects its descendants:
\`\`\`javascript
const jointHierarchy = {
    2: [11],         // hips → middle
    11: [1],         // middle → body
    1: [0, 7, 9],    // body → head, left elbow, right elbow
    7: [8],          // left elbow → left hand
    9: [10],         // right elbow → right hand
    3: [4],          // left knee → left foot
    5: [6]           // right knee → right foot
};
\`\`\`

### 3. Recursive Joint Rotation Algorithm

To propagate transformations across the hierarchy, we use a recursive rotation algorithm. Below is a pseudocode description of the logic:

**Algorithm: RotateJointHierarchy**  
**Input:**
- \`stickmanIndex\`: the index of the stickman in the array  
- \`pivotJointIndex\`: the joint to rotate  
- \`angle\`: the angle in radians  

**Steps:**
1. Get the list of joints for the given stickman.  
2. Determine the correct pivot point based on the joint being rotated.  
3. Fix the pivot coordinates to prevent them from changing.  
4. If the selected joint is not the pivot, rotate it around the pivot point.  
5. Recursively do the following for each child in \`jointHierarchy\`:  
    - Rotate the child joint around the pivot.  
    - Call \`RotateJointHierarchy\` recursively on each child.  
6. Restore the pivot joint’s original position.  

**Algorithm: RotatePointAroundPivot**  
**Input:**
- \`point\`: coordinates of the joint to rotate  
- \`pivot\`: coordinates of the pivot  
- \`angle\`: rotation angle in radians  

**Steps:**
1. Translate the point relative to the pivot:  
    - \`dx = point.x - pivot.x\`  
    - \`dy = point.y - pivot.y\`  
2. Apply rotation transformation:  
    - \`rotatedX = pivot.x + (dx * cos(angle) - dy * sin(angle))\`  
    - \`rotatedY = pivot.y + (dx * sin(angle) + dy * cos(angle))\`  
3. Return the new coordinates \`(rotatedX, rotatedY)\`

### 4. Pivot Assignment Rules

Different joints rotate around different pivots depending on their anatomical location. The implementation uses a sophisticated mapping system:

**Algorithm: GetRotationPivot**  
**Input:**
- \`stickmanIndex\`: the stickman to operate on
- \`jointIndex\`: the joint being rotated

**Implementation Logic:**
\`\`\`javascript
function getRotationPivot(stickmanIndex, jointIndex) {
    const joints = stickmen[stickmanIndex].joints;
    
    const pivotMap = {
        11: joints[2],  // middle joint rotates around hip
        1: { x: joints[11].x, y: joints[11].y },  // body rotates around middle
        7: joints[1],   // left elbow rotates around body
        9: joints[1],   // right elbow rotates around body
        3: joints[2],   // left knee rotates around hip
        5: joints[2]    // right knee rotates around hip
    };
    
    return pivotMap[jointIndex] || joints[jointIndex];
}
\`\`\`

**Anatomical Rules:**
1. **Torso joints (middle, body):** Rotate around their parent in the spine chain
2. **Arms (elbows, hands):** Rotate around the body/shoulder connection
3. **Legs (knees, feet):** Rotate around the hip joint
4. **Extremities (head, hands, feet):** Can rotate independently when directly manipulated

### 5. Resulting Behavior

With this system, several realistic behaviors are supported:

- **Whole-body movement:** Dragging the hips moves the entire stickman.  
- **Upper-body rotation:** Rotating the torso moves the head and arms.  
- **Limb articulation:** Rotating an elbow causes the hand to follow.  
- **Independent motion:** Feet, hands, and head can still be individually adjusted when needed.

> Final Result
![](https://i.ibb.co/fzWLMJWr/Screenshot-2025-07-29-004041.png)

---


## Key Learnings

- Developed a better grasp of selective rendering techniques to keep canvas visuals clean and relevant.
- Improved user experience by prioritizing safe defaults (e.g., confirmation popups, visual scoping, first-frame logic).
---

## Next Week’s Roadmap

- Add feature to export human body instance as image
- Add Localisation support in Stickman activity
- Update codebase to keep relative positioning, instead of absolute positioning of stickman.
- Look into pivot animator templates

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,Br=Object.freeze(Object.defineProperty({__proto__:null,default:Ct},Symbol.toStringTag,{value:"Module"})),Lt=`---
title: "GSoC ’25 Week 08 Update by Mebin J Thattil"
excerpt: "Platform Agnostic Inference, Profanity Filters and Kokoro Optimizations"
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-gsoc-25-mebinthattil-week8"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week08,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

# Week 08 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-20 - 2025-07-27

---

## Goals for This Week

- Optimize Kokoro + GStreamer  
- Enable SLM inference without using compiled binaries for Llama.cpp and avoid client side binary build processes  
- Begin dataset collection for the SugarAI-hosted LLM and gear up for fine-tuning  

---

## This Week’s Progress

### **1. Audio Pipeline Optimizations (Kokoro & GStreamer)**

After reading through the GStreamer documentation, I finally got Kokoro to stream audio directly to GStreamer, avoiding the intermediate step of writing a WAV file. This not only reduces latency, since writing to a WAV file requires the entire text to be processed, saved, and then read. While streaming we can break up the input into multiple different chunks. These chunks can be sent to Kokoro's engine for processing and then output into GStreamer’s source. This significantly reduces latency and removes the need to write to a file.

I was able to get the streaming to work using the \`appsrc\` element. \`appsrc\` is a GStreamer element that lets external applications insert data into a GStreamer pipeline. The best part is that it provides external API functions.

Currently, the command to construct the pipeline looks like:
\`\`\`python
cmd =   'appsrc name=kokoro_src' \\
        ' ! audioconvert' \\
        ' ! audio/x-raw,channels=(int)1,format=F32LE,rate=24000' \\
        ' ! tee name=me' \\
        ' me.! queue ! autoaudiosink name=ears' \\
        ' me.! queue ! audioconvert ! audioresample ! audio/x-raw,format=S16LE,channels=1,rate=16000 ! fakesink name=sink'
\`\`\`

And the fallback pipeline if Kokoro is not available (using espeak) looks like:
\`\`\`python
cmd = 'espeak name=espeak' \\
      ' ! capsfilter name=caps' \\
      ' ! tee name=me' \\
      ' me.! queue ! autoaudiosink name=ears' \\
      ' me.! queue ! fakesink name=sink'
\`\`\`

You’ll notice that in the Kokoro pipeline, we use \`audioconvert\` to convert Kokoro's audio input into F32LE, 24kHz audio. This ensures the audio is in the correct format for the pipeline. Kokoro, by default, outputs audio in F32LE, 24kHz, so this is actually a redundant step made to enforce that the audio is infact in that format. 
It’s important to note that the logic written for the mouth movements assumes the audio is in 16kHz, 16-bit, signed integer format. So for the \`fakesink\` sink, we convert it into S16LE, 16kHz, while the \`ears\` sink (the speaker/audio device) remains in F32LE, 24kHz.

However, there’s still one issue - the mouth movements are not working. I initially thought it was because the logic assumes 16kHz, 16-bit signed integer audio, but even after converting the audio to that format, the mouth movements still didn't work. I’ll be debugging this further to identify the root cause.

But for now, streaming works perfectly, but the mouth movements don’t work.

### **2. OS-Agnostic GGUF Inference**

The most performant and lightweight inference binary provided by llama.cpp is only around 2MB in size. With this compiled binary, we can run inference on the local SLM. However, this poses a problem - we either need to build and distribute binaries for every platform we want to support, or build them on the client side.

Since we aim to support most OLPC laptops (which are quite limited in terms of hardware) it’s wise to avoid client-side builds. So we decided to use \`llama-cpp-python\`. This allows us to run inference on a local SLM without worrying about building binaries for different platforms. Sure, if you dive into the nitty-gritty, there’s still a small build that happens client-side, but it's handled by pip and we don’t need to manage the distributions ourselves. This increases our dependencies, but it’s a worthwhile tradeoff.

### **3. Profanity Filters**

While working on the inference script, I realized it made sense to add profanity filters as part of this module itself. To set this up, I scoured the internet for a list of curse words and compiled a comprehensive list. I then encoded each bad word into base64 and added them to a \`.txt\` file.

The reason for encoding the words is to prevent children from understanding the list if they stumble upon the file, since it just looks like gibberish. Of course, during processing in code, we decode the words and use them.

Right now, the profanity checks happen at two points:
- **First**, when the user submits a question to the chatbot. If the input contains a bad word, the filter intercepts the request and doesn't send it to the SLM. Instead, it informs the user that their input contains a blacklisted word.
- **Second**, after the SLM generates a response. If the output contains a bad word, we inform the user that the response cannot be processed and don't show the user the SLM response.

When working with SLMs, it’s crucial to put these strong guardrails in place, because these models are still limited in their capabilities and can sometimes blurt out random or inappropriate responses.

---

## Next Week’s Roadmap

- Fix the mouth movements in Speak  
- Integrate everything into Speak  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,Rr=Object.freeze(Object.defineProperty({__proto__:null,default:Lt},Symbol.toStringTag,{value:"Module"})),xt=`---
title: "GSoC '25 Week 08 Update by Nikhil Bhatt"
excerpt: "Implemented Local Projects display enabling students to switch between different projects they created "
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-gsoc-25-nikhilbhatt-week08"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week08,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-07-21 – 2025-07-27  

---
## This Week's Achievements

### Frontend : Added a Local Projects page

Till last week, students were able to create a new project and view its history, and edit it, but they were not able to keep a track of the projects they made. Now, they are able to switch between projects they created (or forked) and even edit them. This allows students to work with different projects and even update them in future. A couple of techniques were used to implement this functionality. 

- Storing \`allProjects\` in Local Storage 
  → We store the name, description and key (to uniquely identify a project) in the allProjects array inside the local storage. This array is rendered at the localProjects.html page allowing students to see all the projects they have created. 

- Current Project and current key 
  → Anytime a student change a project, currentProject and currentKey updates inside the local storage, allowing them to work inside the project they chose to. This helps them edit the project even in future, edit them, view it's commit history. This feature acts as an addition to what we have in the Planet currently. 

---


## Challenges & How I Solved Them

- **Challenge:** Allowing students to work with multiple projects.   
  **Solution:** Saving the projects of students they have created or forked, inside a persistent local storage, which is also co-incidentally similar to the current Planet implementation. 

- **Challenge:** Switching and editing multiple projects.  
  **Solution:** Storing current project and the key associated with the project allows students to work with different projects. 

---

## Key Learnings
- Creating an effective User experience, to provide a smooth transition from the existing system without much learning curve.
- Identification of the problem, designing a simple architecture of the solution and its implementatiion. 

---

## Next Week's Roadmap
- Demo the current setup. 
- Discuss about deployment, integration and error handling/fallbacks. 

---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [Octokit REST.js Library](https://github.com/octokit/rest.js)

---

## Acknowledgments

Thanks again to my mentors and the Sugar Labs community for feedback and support!  
Looking forward to next week’s frontend PR features. 

`,Or=Object.freeze(Object.defineProperty({__proto__:null,default:xt},Symbol.toStringTag,{value:"Module"})),Gt=`---
title: "GSoC '25 Week 8 Update by Safwan Sayeed"
excerpt: "Implementing the Interpreter and Symbol Table Integration"
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-gsoc-25-sa-fw-an-week8"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week8,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 8 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-21 - 2025-07-27

---

## A Blog-style Retrospective

This week I implemented the Interpreter and integrated it with the Symbol Table and Memory Module.

---

## Goals for This Week

- Start working on the implementation of the Interpreter based on the TechSpec and DFD.  
- Begin coding the first components of the Interpreter, focusing on integrating it with the Symbol Table and Memory Module.  
---

## This Week's Highlights

1. **Interpreter Implementation**  
   - Successfully implemented the core components of the Interpreter, including the execution logic.
   - Integrated the Interpreter with the Symbol Table and Memory Module, allowing for dynamic variable management and memory allocation.

![Interpreter Implementation](/assets/Developers/Safwan/IR-Test2.png)

2. **Symbol Table Integration**  
   - Developed the Symbol Table to manage variable declarations and scope.
   - Ensured that the Interpreter can access and manipulate variables defined in the Symbol Table, enabling dynamic variable handling during program execution.

![Symbol Table Integration](/assets/Developers/Safwan/IR-Test.png)

3. **IR-Instruction Classes Implemented**
   - There were 6 identified IR-Instruction classes that were implemented this week:
     - \`sym_declare\`
     - \`sym_assign\`
     - \`sym_query\`
     - \`call\`
     - \`compare_jump\`
     - \`jump\`


![IR-Instruction Classes](/assets/Developers/Safwan/IR-Test1.png)

---

## Challenges & Solutions

- **Integrating the Interpreter with the Symbol Table:**  
  Faced challenges in ensuring seamless interaction between the Interpreter and the Symbol Table.  
  *Solution:* Collaborated closely with mentors to refine the integration process, ensuring that variable management is efficient and error-free.


---

## Key Learnings

- Gained practical experience in implementing an Interpreter and integrating it with a Symbol Table and Memory Module.
- Learned about the complexities of dynamic variable management and memory allocation in programming languages.

---

## Next Week's Roadmap

- Start with the TechSpec for the Compiler, focusing on the architecture and components needed for the static compilation process.
- Begin drafting the Data Flow Diagram (DFD) for the Compiler to visualize data movement and interactions within the system.
---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their crucial guidance on compiler design principles and static compilation concepts. Their clarification on the AST-to-IR translation approach and emphasis on maintaining clean instruction generation patterns was essential for this week's successful progress.

---`,zr=Object.freeze(Object.defineProperty({__proto__:null,default:Gt},Symbol.toStringTag,{value:"Module"})),Wt=`---
title: "GSoC’25 Week 08 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-gsoc-25-omsuneri-week08"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week08,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-07-21 - 2025-07-27

---

## Goal for This Week

**Implement a Music Blocks-compatible UI widget for the AI Debugger with proper session tracking, error handling, and user interaction controls.**

---

## This Week’s Achievements

### Introduction

This week, I focused on integrating a clean and interactive **chat-based UI debugger widget** into the Music Blocks environment. The UI is designed to give learners a smooth experience interacting with the AI assistant while also maintaining session context, error visibility, and chat history.

### What I Did

#### Built a fully functional AI Debugger Widget UI:
- A resizable, centralized widget rendered directly within Music Blocks.
- Uses a flexbox-based layout to separate the **sidebar** and **chat area**.
- Styled consistently with Music Blocks' aesthetics.

#### Added an intelligent Chat Interface:
- Live chat log with user/system/assistant message types.
- Timestamped message bubbles with color-coded roles.
- Smooth scroll and message history tracking.

#### Built Conversation Controls:
- **Reset Conversation**: Starts a new session with a fresh \`conversationId\`, clears history, and reloads the project context.
- **Clear Chat**: Simply clears the visible chat log while keeping session data intact.

#### Sidebar with Context Info:
- Shows a shortened **conversation ID**.
- Live **message count** display.
- Clearly labeled "Debugger Controls" with contextual buttons.

#### Session Management:
- Each session generates a unique \`conversationId\` using timestamp and random string logic.
- Message history (\`chatHistory\`) and prompt count (\`promptCount\`) tracked across interactions.

---

### Preview

Here’s a quick preview of the widget:

<a href=""><img src="https://i.ibb.co/k6MCM1M6/Screenshot-2025-08-02-at-3-02-23-PM.png" alt="Music Blocks Debugger Widget"></a>

### Why It Matters

An AI debugger UI integrated into Music Blocks allows learners—especially kids and beginners—to:
- Ask natural-language questions about their projects.
- Receive helpful feedback in an intuitive format.
- See error messages and solutions as part of a conversation.
- Restart or reset when they feel stuck.

This brings us a big step closer to making **Music Blocks truly interactive, intelligent, and kids-friendly.**

---

### Final Thoughts

Working on the UI this week was both **technically enriching** and **pedagogically important**. The focus wasn't just styling but thinking deeply about how to build a **debugging experience** that feels responsive, informative, and simple for learners.

---

## Next Week’s Roadmap

- Add streaming response support from the backend (type-as-you-go for AI).
- Improve UI polish, add avatars or icons to message bubbles.
- Begin user testing with kids and teachers.

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)


## Acknowledgments

Grateful as always to my mentors and the Sugar Labs community for their thoughtful feedback, patience, and encouragement as I shape this into a usable tool for learners.

---
`,Fr=Object.freeze(Object.defineProperty({__proto__:null,default:Wt},Symbol.toStringTag,{value:"Module"})),Dt=`---
title: "SSoC ’25 Week 08 Update by Muhammad Haroon"
excerpt: "Code the sketches of the user interface in Music Blocks."
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-ssoc-25-MuhammadHaroon-week08"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week08,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-21 - 2025-07-27

---

## Goals for This Week

- **Goal 1:** Code the sketches of the user interface in Music Blocks.
- **Goal 2:** Create a FastAPI for connecting frontend with backend.

---

## This Week's Achievements

1. **Code the sketches of the user interface in Music Blocks.**  
   - I was succefully able to code the user interfaces in Music Blocks. Following are the screenshots of it.

   ![User Inerface 1](/assets/Developers/Muhammad_Haroon/MB_user_interface_1.png)

   - At the moment, I have used placeholders like a, b, c, d, e, f, g, h, i, j, which will later be replaced with actual prompts that users can type. Each time the user clicks on the prompt icon in the toolbar, a new prompt will appear as the placeholder, giving them an idea of what they can type.

   ![User Inerface 2](/assets/Developers/Muhammad_Haroon/MB_user_interface_2.png)

   ![User Inerface 3](/assets/Developers/Muhammad_Haroon/MB_user_interface_3.png)

   - Below is the video demonstrating the UI in Music Blocks.

   [youtube: woTpsiBh2O8]

---

## Challenges & How I Overcame Them

- **Challenge:** The actual challenge I faced was ensuring that when a user selects an audio file to trim, the file chooser should be replaced with an audio player so the user can get the timestamps of the segment to be trimmed. Initially, I tried hiding the file chooser using display: none after the file was selected. However, this caused the audio player to appear after the "Preview" and "Save" buttons, because the DOM was being modified in a way that shifted elements upwards.
- **Solution:** After researching online, I discovered the "replaceChild" function, which replaces one child element with another within the same parent, maintaining the layout structure correctly.

---

## Key Learnings

- Understood about "replaceChild" function.

---

## Next Week's Roadmap

- Create a FastAPI for connecting frontend with backend.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Ur=Object.freeze(Object.defineProperty({__proto__:null,default:Dt},Symbol.toStringTag,{value:"Module"})),_t=`---
title: "GSoC '25 Week 08 Update by Shubham Singh"
excerpt: ""
category: "DEVELOPER NEWS"
date: "2025-07-28"
slug: "2025-07-28-gsoc-25-firepheonix-week08"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week08
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 8 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-21 – 2025-07-28

---


## Goals for This Week

- Complete the first actual prototype, with the action block export.
- Add vertical lines as a grid, to standardize detection time accross all widths of monitors.
- Find out a method to divide the entire musical pattern into standard column like sections, like in phrase maker.

---

## This Week's Achievements

1. **Implemented the standardization method of vertical(y) axis**  
   - Earlier, the method of having the lego blocks just across the horizontal axis. Now, the number of pixels across 2 points on any monitor may vary, so we switched to time. But the length of DISPLAY of blocks might also vary.
   - So now, we're using three things: 1. X-axis 2. Y-axis 3. Time
   - Now, the time across any two columns will be the same. Hence keeping it the same across all types of monitors.

        ![Y-axis lines are now made](/assets/Developers/Shubham_Singh/gsoc-blog-week08-img2.png)


2. **Implemented the dynamic dividing of Lego Block images into different shaped columns**  
   - Now, the image detection also automatically detects the column division.
   - This will help significantly in exporting the audio as an action block.

    ![Detects column's left and right edges.](/assets/Developers/Shubham_Singh/gsoc-blog-week08-img-1.png)


---

## Challenges & How I Overcame Them

- **Challenge:** The most difficult challenge was figuring out a function that would divide the entire image into different different columns, so that they can be exported as an action block.
  **Solution:** Multiple trials and errors, some mathematical logic, and searched some other resources.
- **Challenge** I was busy with college the entire week.
  **Solution:** Managed my time better, gave more time to gsoc project at weekends.

---

## Key Learnings

- Break the entire pivot into multiple parts. And then solve step by step. You'll end with a pipeline that gives a LOT more clarity on things.
- Different monitor sizes mean different numbers of pixels between two points. But that difference doesn’t matter if a parameter is hardcoded in pixels (e.g., px) rather than in relative units like vh, vw, %, or em.
- Since different screens have different pixel densities and resolutions, the visual width of the same number of pixels could differ.

---

## Next Week's Roadmap

- Build the action block output.
- Generate note blocks with their corresponding note values and pitches for a given phrase, based on the LEGO brick input.

---

## Resources & References

- **You can refer to music blocks documentation: https://github.com/sugarlabs/musicblocks/tree/master/documentation** 
- **You may refer to the Lego Blocks Notation system video: https://youtu.be/LOfrCPf3XJU?feature=shared**
- **Devin's CMK'24 blog: https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c**

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. 

---`,Nr=Object.freeze(Object.defineProperty({__proto__:null,default:_t},Symbol.toStringTag,{value:"Module"})),Et=`---
title: "GSoC ’25 Week 08 Update by Diwangshu Kakoty"
excerpt: "Reflection Learning Widget in Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-30"
slug: "2025-07-30-gsoc-25-diwangshu-week08"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week08,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-07-19 - 2025-07-27  

---

## Goals for This Week

- **Goal 1:** Improved 'reflection' widget UI.
- **Goal 2:** Implement IndexedDB for storing user data.
- **Goal 3:** Fix bugs caused by these changes.

---

## This Week’s Achievements

1. **Improved the widget's User Interface**  
   - I have made improvements to the 'reflection' widget's user interface. The new design is more intuitive and user-friendly, enhancing the overall user experience. On opening the widget window, users can initialize a new session by clicking the 'Start New Session' button. This action sends the project code to the server, which then responds with a flowchart and algorithm.

2. **Storing User Data**
    - I have implemented IndexedDB to store user data, including summaries and analysis reports. IndexedDB is a low-level API for client-side storage of significant amounts of structured data, including files/blobs.  Now the LLM can take reference from the stored data to generate more accurate analysis.

---

## Challenges & How I Overcame Them

- **Challenge 01:** Working with vanilla JavaScript is really time-consuming. Although my fundamentals about this language are getting stronger, I still find it challenging to make dynamic UI components using it.

  **Solution :** I am using existing CSS styling to make the UI components a little bit faster.

- **Challenge 02:** The 'reflection' widget block comes in the project code. So, the LLM also describes the block in the algorithm that is not needed.

  **Solution :** I have not figured out a solution for this yet. I am thinking of using a regex to remove the block from the code before sending it to the LLM.
---

## Key Learnings

- I have learned how to use IndexedDB for storing user data in a structured way. This will be beneficial for future projects that require client-side storage.
---

## Next Week’s Roadmap

- From recent discussions with my mentor, I will be assigning persona-like names to the AI agents.
- I will be implementing the 'analysis' feature in the 'reflection' widget. Therefore, it has to read the previous summaries and analysis reports from the IndexedDB.
---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)
- **Streamlit App:** [Reflection App](https://reflectionapp-2yoxtvn6sknvktme2zorvq.streamlit.app/)
- **IndexedDB Documentation:** [MDN Web Docs - IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Hr=Object.freeze(Object.defineProperty({__proto__:null,default:Et},Symbol.toStringTag,{value:"Module"})),jt=`---
title: "DMP ’25 Week 9 Update by Aman Naik"
excerpt: "This week focused on improving the clarity and intuitiveness of the UI, refining UX elements, and aligning LLM integration plans with Sugar AI's upcoming deployment."
category: "DEVELOPER NEWS"
date: "2025-08-02"
slug: "2025-08-02-dmp-25-AmanNaik-week09"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week09,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 9 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-07-27 – 2025-08-02  

---

## Goals for This Week

- Display default explanatory text for empty story elements when creating a framework  
- Remove unintuitive UI elements for improved usability  
- Align LLM deployment strategy with the upcoming Sugar AI central inference system  

---

## This Week’s Achievements

1. **Default Text for Empty Story Elements**  
   - Enhanced the "Create Framework" functionality so that unfilled story elements now display a short description explaining their meaning.  
   - Helps guide users, especially students, to better understand what each section represents before filling it in.

   ![Default text for empty story elements](assets/Images/aman-naik-week9-img1.png)

2. **Removed Unintuitive Chat Section Back Button**  
   - The back button in the chat section had unclear functionality and caused confusion.  
   - Removed it entirely, simplifying the chat interface.

3. **Shift in Focus Toward UI/UX Improvements**  
   - Instead of deploying the model directly within the Write Activity, the plan is now to integrate with the upcoming Sugar AI system once deployed.  
   - This ensures a consistent inference backend shared across activities and avoids duplicate deployment work.

---

## Challenges & How I Overcame Them

- **Challenge:** Identifying unintuitive UX elements from a fresh perspective  
  **Solution:** Having been deeply involved in development, I found it challenging to view the interface as a new user would. Regular mentor meetings provided valuable feedback and helped me spot usability issues I had overlooked. This led to changes such as removing the unclear back button and improving guidance within the framework.

---

## Key Learnings

**Importance of Guided Placeholders in UI**  
   - Providing default explanatory text in empty fields helps users understand intended content without external guidance.

**Value of External Perspective in UX Design**  
   - Frequent mentor feedback sessions helped uncover usability issues that were invisible from a developer’s point of view.

**Strategic Planning for LLM Integration**  
   - Decided to align Write Activity’s LLM features with the centralized Sugar AI deployment, ensuring consistency and maintainability.

---

## Next Week’s Roadmap

- Add an advice button to get AI-generated suggestions during the writing of the story.
- Fix a critical UI bug I encountered while testing the sidebar toggle button.

---

## Acknowledgments

Thanks to my mentors for their honest feedback during meetings, which helped me identify and correct unintuitive UI elements.

---
`,qr=Object.freeze(Object.defineProperty({__proto__:null,default:jt},Symbol.toStringTag,{value:"Module"})),Bt=`---
title: "DMP ’25 Week 08 Update by Harshit Verma"
excerpt: "This week I was focused on backend integration for the Pippy Debugger. I developed and refined the /debug endpoint in Sugar-AI, this work is key to making the debugger responsive, modular, and ready for full integration."
category: "DEVELOPER NEWS"
date: "2025-08-02"
slug: "2025-08-02-dmp-25-therealharshit-week08"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week08,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-21 - 2025-07-27   

---

## Goals for This Week

- **Goal 1:** Continue developing the \`/debug\` endpoint in Sugar-AI.
- **Goal 2:** Align backend structure to support clean communication between Pippy and Sugar-AI.

---

## This Week’s Achievements

This week focused on backend development, particularly building and refining the \`/debug\` endpoint in Sugar-AI. This endpoint serves as the core communication bridge between the Pippy interface and the Sugar's AI inference.

**Key tasks accomplished:**
- Implemented structured request parsing for incoming code and context.
- Designed a response schema that aligns with frontend rendering expectations.
- Added basic error handling and response validation.
- Conducted initial tests to simulate real-time usage from the Pippy Debugger.

Although this week involved less visible UI development, the backend enhancements are vital to delivering a seamless debugging experience.

---

## Challenges & How I Overcame Them

- **Challenge:** Understaing Sugar-AI’s existing API structure.  
  **Solution:** I followed the documentaion and my mentors guidance.

---

## Key Learnings

- Deepened understanding of API endpoint design.
- Ensuring the \`/debug\` endpoint remains general enough to support various use cases, while still delivering responses formatted for children.

---

## Next Week’s Roadmap

- Fully connect the new \`/debug\` endpoint with Pippy.
- Refine the response output to improve readability and flow for children.
- Start working on saving debug history to Sugar Journal.

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,Kr=Object.freeze(Object.defineProperty({__proto__:null,default:Bt},Symbol.toStringTag,{value:"Module"})),Rt=`---
title: "GSoC '25 Week 9 Update by Elwin Li"
excerpt: "Improvements on the musicblocks generation RAG pipeline and a new MIDI file uploading widget"
category: "DEVELOPER NEWS"
date: "2025-08-02"
slug: "2025-08-02-gsoc-25-Elwin-Li-week09"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week9,RAG pipeline,MIDI widget"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 9 Progress Report by Elwin Li

**Project:** MusicBlocks Generation Model

**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-07-27 - 2025-08-02

---

## Goals for This Week

- **Goal:** Complete the MIDI generation RAG pipeline

---

## This Week's Achievements

This week I upgraded the RAG pipeline with the Gemini embedding model, which resulted in very accurate retrieval. I also used Gemini for the generation component, which also showed much better results compared to previous approaches.

The biggest update for this week is the creation of a MIDI upload widget. This widget allows users to upload any MIDI file and it will automatically generate the corresponding MusicBlocks. In the video demo below, I demonstrate using the widget to upload a MIDI file that was generated using the RAG pipeline with the query "guitar solo with similar style to hotel california". The widget also includes the option to directly generate a MIDI file and convert through a prompt, but it currently does not work, and will be next weeks plan.

[youtube: B0lPJwHc4pI]

---

## Challenges & How I Overcame Them

- **Challenge:** The RAG pipeline was not able to generate music directly to MusicBlocks format.
  
  **Solution:** Used MIDI as an intermediate format, creating a MIDI upload widget that converts MIDI files to MusicBlocks, effectively bridging the gap between the generation pipeline and the MusicBlocks format.

---

## Key Learnings

- Gained deep understanding of RAG (Retrieval-Augmented Generation) systems and their application to music generation.
- Learned about the importance of better embedding models (Gemini) for improved retrieval accuracy.

---

## Next Week's Roadmap

Connect the MIDI generation pipeline with the MIDI upload widget, so that the generated music will automatically be in MusicBlocks format.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Vr=Object.freeze(Object.defineProperty({__proto__:null,default:Rt},Symbol.toStringTag,{value:"Module"})),Ot=`---
title: "GSoC '25 Week 9 Update by Krish Pandya"
excerpt: "Hello-World, Radio Palettes, and PyPI Release!"
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-gsoc-25-mostlyk-week09"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week09,mostlyk"
image: "assets/Images/GSOC.webp"
---

# Week 9: Hello-World, Radio Palettes, and PyPI Release

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)  
**Reporting Period:** July 29, 2025 – August 3, 2025

---

## The Week of Debugging, Demos, and Downloads

This week was a classic GSoC roller coaster: the codebase is now big enough that tiny bugs become huge blockers, and huge features sometimes just work. I spent hours chasing down a path bug that turned out to be a config detail and later on hard coded the paths for a workaround for now , radio tool buttons, palettes, and the first working Hello World activity are all live!

_Hello-World isn't pushed yet, will push it with bundle itself_

## Debugging

Early in the project, writing code was fast, just a few graphical interfaces, no integration headaches. Now, every little bug can block the whole flow. This week, I spent hours just figuring out why I couldn't get the art icons working properly, the button signals not ending like I wanted. Turns out, hardcoding the path was the way I have made it work, not elegant, but it works!

_A special shoutout to the [Stack Overflow](https://stackoverflow.com/questions/72303475/gtk4-gestureclick-no-released-signal-emitted) and [GNOME Discourse](https://discourse.gnome.org/t/gtk4-need-button-pressed-and-released-signals/8506) threads that helped me fix signaling in Palettes._

## Radio Tool Buttons & Palettes: The Big Reveal

Let’s start with the fun stuff: radio tool buttons and radio palettes. After a lot of toolkit upgrades and some annoying GTK integration quirks, I finally got radio tool buttons working with their palettes. You can now select between states (eraser, pencil, etc.), and the palette stays in sync with the tool button.

Also do note: The color scheme is fully customizable via my config, sooo the rainbowish borders you see in the demo is all me, not GTK4 defaults.

Here’s a quick breakdown of what’s working:
( This is shown in the video which I have been delaying since the past few weeks! )

[youtube: gbaG9CaJJ-U]

- Radio Tool Buttons: Integrated with radio palettes, stateful selection (eraser, pencil, pen, etc.)

- Palette Groups: Grouped palettes now show and hide correctly, with proper event handling

- Menu Palettes: Custom content, icons, and actions all working

- ToolbarBox Example: Classic Sugar toolbar replicated, icons and colors working (though I need to fix icon sizes)

- Buffer Loading in Icon: Fixed buffer loading for icons, so custom SVGs and PNGs now render as expected

---

## Hello-World Activity: Actually Live

The big milestone this week: the Hello-World activity is up and running. I spent a lot of time emulating desktop environments (GNOME, KDE, Hyprland etc.) to make sure the UI looks right, even if some backend arguments are a bit hacky for now. The circular CSS isn’t perfect yet, but the basics are solid. This is the first real step toward porting and bundling activities for Sugar GTK4.

## PyPI Release

You can now download and install the toolkit directly from PyPI:  

[https://pypi.org/project/sugar-toolkit-gtk4/#description](https://pypi.org/project/sugar-toolkit-gtk4/#description)  

\`\`\`
pip install sugar-toolkit-gtk4
\`\`\`

We will change the authors and maintainers as GSoC comes to an end to Sugar Labs.
This makes it much easier for others to try out the toolkit and start porting their own activities. Publishing is now automated via GitHub Actions—so every new release is just a push away.

---

## Reflection & Next Steps

After nine weeks of building, breaking, and rebuilding, I’m starting to appreciate how much the little details matter. Debugging path issues, integrating palettes, and getting activities to actually launch has taught me a ton about GTK4’s quirks and strengths. The toolkit is finally at a point where I can start porting real activities.

Next up:

- Polish Hello-World and fix icon sizing
- Clean up debug statements and hardcoded paths
- Continue porting and refining the toolkit
- Add widgets example, presence and datastore from old library.

---

## Links

- [(sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [Game Demo Video](https://youtu.be/gbaG9CaJJ-U)
- [PyPI Release](https://pypi.org/project/sugar-toolkit-gtk4/#description)
- [Stack Overflow: GTK4 GestureClick](https://stackoverflow.com/questions/72303475/gtk4-gestureclick-no-released-signal-emitted)
- [GNOME Discourse: GTK4 Button Signals](https://discourse.gnome.org/t/gtk4-need-button-pressed-and-released-signals/8506)
`,Jr=Object.freeze(Object.defineProperty({__proto__:null,default:Ot},Symbol.toStringTag,{value:"Module"})),zt=`---
title: "DMP’25 Week 09 Update by Justin Charles"
excerpt: "Mapped out the integration plan for brick connections in Music Blocks 4, including collision maps, detection workflow, and tower merge/stale strategies"
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-dmp-25-justin212407-week09"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week9,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 9 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-28 - 2025-08-03   

---

## Goals for This Week

- Map out a concrete plan for integrating **brick-to-brick connections**  
- Define data structures and maps for efficient collision queries  
- Document full lifecycle of connection events: drag start → collision → drop → merge/stale  

---

## This Week’s Highlights

### 1. **Workspace Presentation Design**

- On adding a tower (or the very first brick) to the workspace, we compute **absolute coordinates** of all *incoming* connection points:
  - Expression right-side notches  
  - Statement bottom notches  
  - Compound brick inner-top notches  

- These coordinates are registered into quadtree-based data structures for performance.  
- Reverse mapping utility (\`notchId → {BrickId, TowerId}\`) ensures we can quickly trace which tower/brick owns a given notch.  
- For efficiency, only the towers/bricks that change are recomputed.  

---

### 2. **Collision Maps**

Created a two-map design for separating brick connection points:  
- **Expression Map** → Holds all expression brick notches  
- **Statement Map** → Holds all statement brick notches  

Each entry is indexed by a unique **Notch ID**, which reverse maps to \`{BrickId, TowerId}\`.  
This allows collision queries to resolve directly into the correct brick and tower model.  

---

### 3. **Collision Detection Workflow**

- On **drag start**, all notch coordinates belonging to the dragged brick/tower are removed from the maps (to avoid self-matching).  
- During drag, we continuously check outgoing notch coordinates against the target map (expression or statement).  
- On **each mouse move**, detect overlapping notch pairs:
  - When overlap occurs → log \`{BrickId, TowerId}\` from the map as a *potential connection*.  
  - Reverse mapping utility helps locate the parent brick within its tower for precise attachment.  

---

### 4. **Merge & Stale Tower Logic**

- **Merge:**  
  If drag ends on a collision, fetch the target tower via reverse mapping. Merge dragged tower into it, attaching at the correct brick notch.  

- **Shadow Feedback:**  
  During drag, show a shadow element preview of where the connection will happen.  

- **Stale:**  
  - If no collision occurs and drag ends → tower remains standalone.  
  - Its incoming connection coordinates are re-registered into the collision maps.  
  - If no collision occurs and drag continues → shadow disappears.  

---

## Challenges & Considerations

- **Efficient Updates:** Needed a strategy to update only changed towers instead of recomputing the entire map.  
- **Shadow Feedback:** Designing the UI to show previews without interfering with state was tricky.  
- **Tower Integrity:** Ensured merge/disconnection logic didn’t break brick hierarchies when recomputed.  

---

## Key Learnings

- Importance of **reverse mapping utilities** for bridging geometry (notch coords) with logical models (brick/tower).  
- How **separating expression vs statement maps** simplifies collision lookups and prevents false positives.  
- Designing clear **merge vs stale outcomes** ensures intuitive user interactions in the workspace.  

---

## Next Week’s Roadmap

- Begin implementing the **connection merge logic** in the workspace manager  
- Add real-time shadow previews for possible brick connections  
- Start writing utility tests for collision detection and merge scenarios  

---

## Resources & References

- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  
- [Document for brick connection](https://docs.google.com/document/d/1C0t4iSze2eDEv6lWbloK3MnvJgAa6HvmXmk2sQ0lCZs/edit?tab=t.wc31i1lo6mgp) 
- [Quadtree Algorithm Notes](https://en.wikipedia.org/wiki/Quadtree)  

---

## Acknowledgments

Thanks to my mentor Anindya Kundu on revisiting the basic of brick connections and helping me refine the connection lifecycle and reviewing the mapping approach. 
`,Xr=Object.freeze(Object.defineProperty({__proto__:null,default:zt},Symbol.toStringTag,{value:"Module"})),Ft=`---
title: "GSoC ’25 Week 08 Update by Bishoy Wadea"
excerpt: "Fixing Sugar OS compatibility and enhancing Euclid’s Game"
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "gsoc-25-BishoyWadea-week08"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week08,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Bishoy Wadea

**Project:** [Euclid’s Game](https://github.com/Bishoywadea/Euclid-s-Game)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-07-13 – 2025-08-03  

---

## Goals for This Week

- **Make all games developed before the midterm fully compatible with Sugar OS.**

---

## Achievements

### Fixed compatibility issues in Sugar OS

- **Four Color Map**  
  Resolved launch issue under Sugar environment  
  [Commit](https://github.com/Bishoywadea/Four-Color-Map/commit/7c7135b0234e81ebe27247383230ac824a4908c9)

- **Euclid’s Game**  
  Corrected Sugar-specific loading error and startup crash  
  [Commit](https://github.com/Bishoywadea/Euclid-s-Game/commit/f18dcec942b0063d4763100245ce501649289718)

---

### Added New Features to Euclid’s Game

- **Journaling Integration**  
  Games are now saved in the Journal with metadata and can be restored later  
  [Commit](https://github.com/Bishoywadea/Euclid-s-Game/commit/0e67b7df641c0ff89faac3206ad1cc45929081f1)

- **Multiplayer Support Across Devices**  
  Enabled players on different machines to join a shared Euclid game session  
  [Commit](https://github.com/Bishoywadea/Euclid-s-Game/commit/b3cd9de10159a67422f46f9fba4d54912b42a81e)

Multiplayer Support Across Devices [youtube: 42-uk2LwToo]

---

## Challenges & Solutions

- **Challenge:** Implementing reliable multiplayer functionality across devices within the Sugar OS ecosystem using \`collabwrapper\`, while ensuring compatibility with the unique networking and activity-sharing model in Sugar.

- **Solution:** Integrated Sugar’s \`collabwrapper\` API to manage session joining, data synchronization, and peer discovery. Adjusted the game’s state handling logic to respond to collaboration events, ensuring consistent gameplay across machines. Also performed extensive testing in simulated multi-user Sugar environments to fine-tune message broadcasting and activity resumption.


---

## Key Learnings

- Gained deeper understanding particularly how GTK, Journal, and Activity toolbars interact.

---

## Next Week’s Roadmap

- Fix any feedback provided by members of the organization.  
- Start implementing the Magic moving game.
---
`,$r=Object.freeze(Object.defineProperty({__proto__:null,default:Ft},Symbol.toStringTag,{value:"Module"})),Ut=`---
title: "GSoC ’25 Week 09 Update by Mebin J Thattil"
excerpt: "Critical fixes and breathing life back into Speak"
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-gsoc-25-mebinthattil-week9"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week09,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-27 - 2025-08-03

---

## Goals for This Week

- Fix the mouth movements in Speak  
- Integrate everything into Speak 

---

## This Week’s Progress

### **1. Fix the mouth movements in Speak**

I got the mouth movements working after three iterations. The outcomes of the three iterations were:
- Initially, the mouth movements would occur **after** the TTS model spoke the text.
- Then I got them to start exactly **when** the TTS model began speaking. But another issue came up - the movements were too fast and ended **before** the entire text was spoken.
- Finally, I got the mouth movements to start at the right time, behave as expected, and end precisely when the voice stopped.

The issues were caused by a few conditions:
1. There were cases where the TTS model didn't get enough time to process a chunk, which was still passed into the pipeline. The mouth movement logic didn’t account for this empty data - I had to handle that.
2. In some instances, chunking failed or didn't work properly, so I had to manually set a few defaults like chunk size and explicitly split the data.
3. The reason mouth movements started late was simply because they were triggered **after** the full text was converted. I just had to trigger them **at the start** instead.
4. The reason for the mouth movements finishing too early (sped up) was because each mouth frame was, by default, rendered every 25ms. Since we're streaming, it’s important **not** to keep a fixed delay. I had to dynamically adjust based on how long the audio actually takes. So I updated the logic accordingly.

### **2. UI enhancements to accommodate Kokoro**

The UI had to be updated to provide options to select from different Kokoro voices and group them into languages and categories - such as default voices and add-on voices. Waiting indicators have also been added to let the user know they need to wait a few seconds when switching voices.

The setup also handles cases where the user can download a voice model if it’s not part of Speak’s default list. These are pulled via the Hugging Face hub, so it adds an extra dependency for users who want to access add-on voices.

Currently, I haven’t added new icons - I reused the old world map icon as a placeholder. I’ll replace this with something more appropriate later.

### **3. Integrate SLM + TTS into Speak**

I got Kokoro to stream into the existing GStreamer pipeline. I also made UI accommodations to allow voice selection. My SLM inference script and profanity filters were ready, so I was finally able to stitch everything together.

Here’s a demo of the new Speak activity (excluding LLM and LLM-exclusive features like personas):

<iframe src="https://drive.google.com/file/d/141iU7v0zw9cKyynaz3BN83kMA783OoEB/preview" width="740" height="480" allow="autoplay"></iframe>

---

## Next Week’s Roadmap

- Set up AWS for LLM deployment along with [Krish](https://www.sugarlabs.org/authors/krish-pandya)  
- Build the foundations for personas and LLM integration

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,Yr=Object.freeze(Object.defineProperty({__proto__:null,default:Ut},Symbol.toStringTag,{value:"Module"})),Nt=`---
title: "GSoC '25 Week 09 Update by Nikhil Bhatt"
excerpt: "Implemented theme selection via GitHub topics, added fetch-all-repositories route, and introduced download project as ZIP functionality."
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-gsoc-25-nikhilbhatt-week09"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week09,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-07-28 – 2025-08-03  

---
## This Week's Achievements

###  Added Theme Feature (GitHub Topics)
This week, I implemented the functionality to allow users to **add a theme** to their repositories, in the backend it is what we see on GitHub’s “About” section using \`topics\`.

- Themes like \`music\`, \`education\`, \`learning\` can now be added directly through our UI, and they will reflect in the GitHub repository’s topic list.
- This helps with **categorization**, **searchability**, and **better discovery** of projects.


###  Added Route to Get All Repositories (Authenticated)

To overcome the GitHub API rate-limiting issue, I implemented a **new route** that fetches all repositories using **authenticated access** through our GitHub app. 

- This ensures users can list all their repositories reliably without hitting the public API rate limit.
- The route fetches repositories the app has access to, respecting GitHub permissions. 

## Updated Projects page (with themes and updated route)

After integrating the new theme feature and the authenticated repository fetch route, I updated the Projects page to showcase these enhancements in action. You can now see repository themes displayed alongside project descriptions, making it easier for users to visually identify and filter projects.

![Projects page](assets/Developers/Nikhil/projectPage.webp)

## Actual GitHub repository created in Music Blocks project account 

Here's an example of a repository actually created in the Music Blocks GitHub organization using the new backend functionality. The topics we added (themes) are visible directly in GitHub's About section, showcasing that the integration works end-to-end.

![GitHub repo](assets/Developers/Nikhil/github-repo.webp)

---


## Challenges & How I Solved Them

- **Challenge:** Rate limits with unauthenticated API calls.  
  **Solution:** Switched to authenticated GitHub App API routes to ensure seamless access without throttling.

- **Challenge:** Adding topics to a repository programmatically.  
  **Solution:** Used Octokit to update the \`topics\` field via PATCH request to the GitHub REST API.

- **Challenge:** Handling ZIP file downloads in a seamless way.  
  **Solution:** Wrapped GitHub’s archive download API and added front-end UI to allow one-click downloads. 

---

## Key Learnings

- Deeper understanding of GitHub's REST API and how authenticated apps can bypass public API limits.
- Clean separation between frontend controls and backend functionality to make features more extensible.
- Designing features with fallbacks for future flexibility. 

---

## Next Week's Roadmap

- Finalize the ZIP download structure and filename pattern.
- Improve UI/UX of repository listing with themes.
- Write some tests for the backend. 

---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [Octokit REST.js Library](https://github.com/octokit/rest.js)

---

## Acknowledgments

Thanks again to my mentors and the Sugar Labs community for feedback and support!  
Looking forward to next week.  

`,Qr=Object.freeze(Object.defineProperty({__proto__:null,default:Nt},Symbol.toStringTag,{value:"Module"})),Ht=`---
title: "GSoC '25 Week 9 Update by Safwan Sayeed"
excerpt: "Design and Implementation of Compiler for Music Blocks 4"
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-gsoc-25-sa-fw-an-week9"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week9,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 9 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-28 - 2025-08-03

---

## A Blog-style Retrospective

This week I Designed and Implemented the Compiler. The work involved translating the Abstract Syntax Tree (AST) into Intermediate Representation (IR) instructions, which are essential for executing programs in Music Blocks 4.

---

## Goals for This Week

- Write a TechSpec for the Compiler, outlining its architecture and components.
- Implement the Compiler's core functionality, focusing on the translation from AST to IR.
- Develop the Data Flow Diagram (DFD) for the Compiler to visualize data movement and interactions within the system.
---

## This Week's Highlights

- **TechSpec for Compiler:**  
  Created a detailed TechSpec document that outlines the architecture and components of the Compiler, including the translation process from AST to IR.
- **Implementation of Compiler:**  
  Successfully implemented the core functionality of the Compiler, focusing on the translation from AST to IR.

![AST Converted to IR](/assets/Developers/Safwan/AST-IR.png)
- **Data Flow Diagram (DFD):**  
  Developed a Data Flow Diagram (DFD) to visualize the data movement and interactions within the Compiler system, providing a clear overview of how data flows through the various components.

![Data Flow Diagram](/assets/Developers/Safwan/compiler-dfd.png)

![Comprehensive Tests](/assets/Developers/Safwan/Compiler-test.png)

---

## Challenges & Solutions

- **Dynamic Variable Management:**  
  Encountered challenges in managing dynamic variables and memory allocation during the translation process. To address this, I implemented a robust memory management system that ensures efficient allocation and deallocation of resources.
- **Complexity of AST to IR Translation:**  
  The translation from AST to IR was complex due to the need to maintain the integrity of the original program while optimizing for performance. I tackled this by breaking down the translation process into smaller, manageable components, allowing for easier debugging and testing.


---

## Key Learnings

- Gained a deeper understanding of compiler design principles, particularly in the context of static compilation.
- Learned about the intricacies of translating an Abstract Syntax Tree (AST) into Intermediate Representation (IR) instructions, including the challenges of maintaining program semantics while optimizing for performance.
---

## Next Week's Roadmap

- **Think about the Scheduler:**  
  Explore how the Scheduler can be integrated into the Compiler to manage the execution of programs more effectively, including task prioritization and resource allocation.

---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their crucial guidance on compiler design principles and static compilation concepts. Their clarification on the AST-to-IR translation approach and emphasis on maintaining clean instruction generation patterns was essential for this week's successful progress.

---`,Zr=Object.freeze(Object.defineProperty({__proto__:null,default:Ht},Symbol.toStringTag,{value:"Module"})),qt=`---
title: "SSoC ’25 Week 09 Update by Muhammad Haroon"
excerpt: "Create a FastAPI for connecting frontend with backend for AI Sample Generation."
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-ssoc-25-MuhammadHaroon-week09"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week09,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-28 - 2025-08-03

---

## Goals for This Week

- **Goal 1:** Create a FastAPI for connecting frontend with backend for AI Sample Generation.

---

## This Week's Achievements

1. **Create a FastAPI for connecting frontend with backend for AI Sample Generation.**  
   - I successfully created a FastAPI for connecting the frontend with the backend for AI Sample Generation.

   - Users can now enter a prompt in the Music Blocks Sampler widget. Initially, only the Submit button will be enabled. The prompt will be sent to the backend server, and audio generation will begin. While the audio is being generated, a text message will repeatedly appear on the screen at regular intervals to inform the users. Once the audio is ready, another message will be displayed to let them know that the audio has been generated. After this, the Preview and Save buttons will become enabled, allowing users to listen to the generated audio and, if satisfied, save it.

   - Below is the video demonstrating the AI Sample Generation in Music Blocks.

   [youtube: 7e6454_j74g]

---

## Challenges & How I Overcame Them

- **Challenge:** I had no experience with FastAPI before.
- **Solution:** Learned it along the way, followed the docs of FastAPI and some Youtube tutorials for it.

---

## Key Learnings

- Learned about CORSMiddleware in FastAPI, which allows your frontend (running on a different port) to communicate with your backend by relaxing the browser’s cross-origin restrictions. Without it, browsers block such requests for security reasons.

- Discovered that FastAPI can also send file and JSON responses to the browser.

---

## Next Week's Roadmap

- Create a FastAPI for connecting frontend with backend for Audio Trimmer.

---

## Resources & References
- **Frontend Code** https://github.com/sugarlabs/musicblocks/pull/4740
- **Backend Code** https://github.com/haroon10725/AI-Sample-Generation-Backend

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,el=Object.freeze(Object.defineProperty({__proto__:null,default:qt},Symbol.toStringTag,{value:"Module"})),Kt=`---
title: "DMP ’25 Week 09 Update by Harshit Verma"
excerpt: "Finalized the /debug endpoint in Sugar-AI and tested its performance using buggy Python code. I also plan to experimented with a larger model to evaluate debugging responses and began refining them to be more age-appropriate."
category: "DEVELOPER NEWS"
date: "2025-08-09"
slug: "2025-08-09-dmp-25-therealharshit-week09"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week08,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-28 - 2025-08-03   

---

## Goals for This Week

- **Goal 1:** Complete work on the \`/debug\` endpoint in Sugar-AI.  
- **Goal 2:** Test the debugging response using Sugar-AI on various buggy Python code samples.

---

## This Week’s Achievements

1. **Enhanced \`/debug\` Endpoint in Sugar-AI**  
  - Finalized the logic for better parsing and structured debugging feedback.  
  - Ensured the endpoint outputs clear, concise, and kid-friendly messages.  

2. **Testing with Real Buggy Python Code**  
  - Curated multiple buggy Python scripts ranging from beginner-level mistakes to more advanced logical errors.  
  - Verified that Sugar-AI correctly identifies, explains, and suggests fixes for each case.  
  - Helped improve prompt handling to maintain age-appropriate explanations for kids.
  - Document: [LLM response](https://docs.google.com/document/d/1a8GgsccWm9lSuFCWc7yStXzZ3dZW_EIigLyGXseOfjs/edit?usp=sharing)  

---

## Challenges & How I Overcame Them

- **Challenge:** Initial debugging responses were too technical for the target audience.  
  **Solution:** Iterated the prompt design and response formatting to make them simpler and more engaging.

---

## Key Learnings

- Deepened understanding of API endpoint design.
- Improved prompt engineering for educational AI tools.  

---

## Next Week’s Roadmap

- Observed that the current responses were too technical, so worked on making them more age-appropriate.
- Tested the debugging responses using a larger language model for improved accuracy.

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,nl=Object.freeze(Object.defineProperty({__proto__:null,default:Kt},Symbol.toStringTag,{value:"Module"})),Vt=`---
title: "GSoC '25 Week 12 Update by Aditya Kumar Singh"
excerpt: "Enhanced user experience with image export functionality for Human Body activity, improved stickman visual design, comprehensive localization support, and interactive tutorial system implementation."
category: "DEVELOPER NEWS"
date: "2025-08-04"
slug: "2025-08-04-gsoc-25-AdityaKrSingh26-week12"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week12,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-07-31 - 2025-08-06

---

## Goals for This Week

- **Goal 1:** Implement image export functionality for Human Body activity instances.
- **Goal 2:** Enhance stickman visual design by increasing overall size and improving visibility.
- **Goal 3:** Add comprehensive localization support for Stickman activity interface and toolbar elements.
- **Goal 4:** Design and implement an interactive tutorial system for new users.

---

## This Week's Achievements

1. **Human Body Image Export Feature**  
    - **Feature Overview:** 
        - Implemented a image export system that allows users to capture and save their painted human body models as high-quality images, making it easy to share and resuse their creative work in other activities.
        - Image export feature that lets users save their painted human body models as PNG images. When you click the export button, the system captures whatever is currently displayed on the 3D canvas and converts it to a downloadable image file.
    > Export Image in Human Body Activity  
    ![Export Button](https://res.cloudinary.com/djhshvtwo/image/upload/v1754489461/GSoC%2725%20Blog%20Images/image1_jlswus.webp)
    ![Use Image in Fototoon](https://res.cloudinary.com/djhshvtwo/image/upload/v1754489568/GSoC%2725%20Blog%20Images/image2_lit8zq.webp)



2. **Enhanced Stickman Visual Design**  
    - The original stickman figures were way too small and hard to see, especially on high-resolution screens. I spent time making everything bigger and more visible:
        - **Increased joint circles** from tiny 8px radius to a much more clickable 12px
        - **Made limb lines thicker** - bumped them up from 2px to 4px so you can actually see the stick figure clearly
        - **Improved the head circle** to be more prominent and easier to grab
        - **Enhanced selection highlighting** so you know exactly which stickman you're working on
    - The changes make a huge difference when you're trying to precisely position joints or work with multiple characters on screen. Everything feels much more responsive and easier to manipulate, especially on tablets where precise finger taps matter.




3. **Localization Support (i18n) in Stickman Activity**  
    - Added multilingual support for Stickman activity using Sugarizer’s \`l10n.js\`.
    - Strings like "Add Frame", "Remove", "Undo" are now wrapped in _() function.
    - Created a locales folder with example translations for \`en\` and \`fr\`.
    - Created a \`translateToolbarButtons()\` function that maps each button to its translation key, and set up event listeners to update everything when the localized event fires.
    - This allows the activity to automatically switch languages based on user preferences or system settings.
    - This is crucial for making the activity accessible to non-English speakers, especially in educational contexts where students may not be fluent in English. The i18n support allows us to easily add more languages in the future as needed.
    > Localization in Stickman Activity  
    ![French](https://res.cloudinary.com/djhshvtwo/image/upload/v1754489639/GSoC%2725%20Blog%20Images/localisatio_inok3u.webp)




4. **Interactive Tutorial System**
    - Added a tutorial system that actually helps new users was challenging because I needed to integrate it smoothly with the existing activity without breaking anything. I used the IntroJS library to create a step-by-step guided tour that highlights each UI element and explains what it does. The tutorial walks users through all the main features:
        - **Network button** for sharing animations with others
        - **Play/pause controls** for testing your animations
        - **Speed settings** to control animation playback
        - **Add/remove stickman tools** for managing characters
        - **Template system** for loading pre-made poses
        - **Import/export functionality** for saving work
        - **Timeline interface** for frame management
        - **Add frame button** for creating new keyframes
    - What's nice about the IntroJS approach is that it automatically positions tooltips around the actual UI elements and handles all the overlay and highlighting effects.
    - Users can navigate through steps at their own pace, and all the tutorial text is fully localized so it works in any supported language.
    > Tutorial System in Action  
    ![](https://res.cloudinary.com/djhshvtwo/image/upload/v1754489701/GSoC%2725%20Blog%20Images/14a726e1-ee5c-4f7c-8553-48253b628908.png)



---

## Technical Challenges Overcome

- **Challenge:** Making the stickman figures scale properly across different screen sizes.  
  **Solution:** Rewrote the scaling system to use relative units based on viewport dimensions. Took some trial and error to get the proportions right, but now it looks crisp on everything.

---

## Next Week's Roadmap

- **Goal 1:** Finalize the Human Body activity.
- **Goal 2:** Implement individual frame management.
- **Goal 3:** Transition from absolute to relative positioning for stickman coordinates.
- **Goal 4:** Begin implementing shared mode functionality for the Stickman activity.

---

## Acknowledgments

Special thanks to my mentors for their guidance on user experience design and internationalization best practices. Gratitude to the Sugar Labs community for testing the localization features and providing valuable feedback on the tutorial system effectiveness.

---`,tl=Object.freeze(Object.defineProperty({__proto__:null,default:Vt},Symbol.toStringTag,{value:"Module"})),Jt=`---
title: "GSoC’25 Week 09 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-04"
slug: "2025-08-04-gsoc-25-omsuneri-week09"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week09,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-07-28 - 2025-08-03

---

## Goal for This Week

The primary goal for this Week was to **embed the AI-powered Debugger directly into the Music Blocks UI** so that users, especially kids, could debug their projects *without leaving the app*. This meant replacing the previously external Streamlit interface with a fully functional, session-aware UI widget inside the Music Blocks canvas, connected to the FastAPI backend.

---

## This Week’s Achievements

### Introduction

Until now, users had to export their Music Blocks project and visit an external site to use the AI Debugger. This week marks a key turning point: **the debugger is now available as a draggable widget inside the Music Blocks interface**. With a fully integrated chat UI, live connection to the backend, and context-rich messaging, the experience has become smoother and more educational.

This change not only improves usability but also opens the door for better debugging workflows, especially for children and educators.

### What I Did

Here’s a breakdown of what was implemented and how:

#### 1. **Custom Music Blocks Widget**

* Developed a new **UI widget** inside Music Blocks.
* The widget supports a **session-aware chat interface**: users can ask the AI for help, and the assistant retains context across messages.
* Integrated controls like:

  * Reset conversation
  * Download session history
  * Minimize/maximize
  * Re-analyze current code

#### 2. **Connected to FastAPI Backend**

* The widget sends the current project’s JSON representation to the FastAPI backend.
* Backend runs a custom module (\`convert_music_blocks\`) that:

  * Extracts block types, structure, and key events from the Music Blocks JSON.
  * Converts that into a **natural-language program summary**.
* Context (code + prompt history) is passed to Gemini via a modular prompt manager.
* Gemini responds in a **teacher-like tone** based on prompt count:

  * First prompt: Friendly, curious, Socratic
  * Later prompts: More directive and explicit

#### 3. **Conversation Session Management**

* Sessions are now **stateless in the frontend but tracked via conversation ID**.
* Every prompt includes metadata:

  * \`prompt_number\`
  * \`history\` (with speaker names and timestamps)
  * System prompt fingerprint
* This ensures that users get progressive help and avoids repeated suggestions.

#### 4. **CORS + JSON Fixes + Robust API Calls**

* Added full CORS support for local and production deployment.
* Built fallback messages and UI alerts for:

  * Invalid JSON export
  * Backend timeout
  * Gemini failure

--- 

### Preview

<a href=""><img src="https://i.ibb.co/VYhCQzjL/Screenshot-2025-07-29-at-9-45-19-PM.png" alt="Music Blocks Debugger"/></a>

Here’s what the new AI Debugger UI inside Music Blocks includes:

* A draggable debugger block in the block palette
* Chat interface with:

  * Conversation bubbles
  * Reset options
* One-click analysis of current project (auto-export + backend call)
* System prompt: Designed for kids, friendly, and context-aware

Here’s a sample flow:

1. User opens the AI Debugger widget.
2. The debugger auto-loads current project code.
3. Debugger types out a friendly greeting and a first view of the project.
4. User types: “Why is the melody not playing after this repeat block?”
5. Gemini (via FastAPI) responds: “It seems you’ve placed the melody inside a block that never runs. Try moving it outside the repeat loop.”

And it all happens **without leaving Music Blocks**.

---

### Why It Matters

This integration transforms the debugging experience:

* **No context switching** → learners stay inside Music Blocks.
* **Seamless feedback loop** → real-time guidance as they build music.
* **Age-appropriate design** → kids get hints, not just fixes.
* **Educator-friendly** → can be used in classrooms without external tools.

From an architectural point of view:

* The modular backend and frontend now follow a **clean interface contract** (\`/analyze\` API).
* The design is future-proof — e.g., can support multiple LLMs, save sessions to the cloud, or run offline with local models.

---

### Final Thoughts

This week’s milestone is a big leap towards **making Music Blocks truly AI-augmented**. Embedding the debugger inside the platform not only enhances the UX but also lays the groundwork for advanced features like Intelligent code suggestions.

As a developer, this week helped me deeply understand:

* How to write modular UI widgets in Music Blocks
* How to structure backend APIs for interactive apps
* How to balance UX for kids with technical depth in LLM prompts

---

## Next Week’s Roadmap

**Refining the debugger widget based on feedback from the community and mentors, and deploying the backend for seamless integration.**

## Resources & References

- **Repository:** [JSON to Text representation](https://github.com/omsuneri/JSON-to-Text-representation)
- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)
- **Directory for Projects:** [Embedding Project Set](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/tree/main/data/docs)


## Acknowledgments

Grateful as always to my mentors and the Sugar Labs community for their thoughtful feedback, patience, and encouragement as I shape this into a usable tool for learners.

---
`,al=Object.freeze(Object.defineProperty({__proto__:null,default:Jt},Symbol.toStringTag,{value:"Module"})),Xt=`---
title: "GSoC '25 Week 09 Update by Shubham Singh"
excerpt: "Successfully implemented action block export functionality."
category: "DEVELOPER NEWS"
date: "2025-08-05"
slug: "2025-08-05-gsoc-25-firepheonix-week09"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week09
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 9 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-28 – 2025-08-05

---

## Goals for This Week

- Build the action block output.
- Generate note blocks with their corresponding note values and pitches for a given phrase, based on the LEGO brick input.

---

## This Week's Achievements

1. **Implemented the correct audio output when LEGO bricks pattern was played.**  
   - Successfully integrated the LEGO brick pattern recognition with Music Blocks' audio engine.
   - The LegoBricks widget now accurately reads brick patterns and translates them into musical sequences.
   - Implemented proper timing synchronization to ensure notes play at the correct intervals based on brick positioning.
   - Added support for multiple note types (quarter notes, half notes, whole notes) based on brick spacing and arrangement.
   - Tested the audio output with various brick configurations to ensure consistent musical interpretation.

2. **Export as action blocks now working**  
   - Developed a complete export mechanism that converts LEGO brick patterns into Music Blocks action blocks.
   - The system now mimics the phrase maker's column-based approach, where each column represents a specific duration.
   - Implemented column width detection to accurately determine note durations from brick spacing.
   - Added proper metadata handling to ensure exported action blocks maintain all necessary musical information.
   - Created a seamless integration between the visual brick interface and Music Blocks' internal action block structure.
   - The exported action blocks can now be imported and used in other Music Blocks projects, maintaining full compatibility.

   ![Action block export](/assets/Developers/Shubham_Singh/action-block-export-lego.webp)

3. **Attended and demonstrated with webcam on live meet**  
   - Participated in the weekly GSoC/DMP/SSoC progress showcase meeting with all participating students.
   - Successfully demonstrated the LEGO blocks project using a live 4K webcam feed, showing real-time brick detection and music generation.
   - Received positive feedback from mentors and fellow students on the project's innovative approach to music education.
   - Showcased the system's ability to detect different colored bricks and translate them into musical notes in real-time.

---

## Challenges & How I Overcame Them

- **Challenge:** Implementing accurate column division for action block export was extremely complex. The system needed to divide the entire image into precise columns that would correctly map to musical durations, similar to how the phrase maker operates.
  **Solution:** Developed a mathematical algorithm that analyzes brick spacing and calculates optimal column boundaries. Used multiple iterations of testing with different brick arrangements to refine the column detection logic. Researched Music Blocks' phrase maker source code to understand the exact formatting requirements for action blocks.

- **Challenge:** Ensuring cross-platform compatibility for webcam integration and real-time brick detection across different operating systems and camera specifications.
  **Solution:** Implemented adaptive camera settings that automatically adjust to different webcam capabilities. Added fallback mechanisms for lower-resolution cameras and tested extensively on various hardware configurations.

---

## Key Learnings

- **Modular Problem-Solving Approach:** Breaking complex problems into smaller, manageable components creates a clear development pipeline. This approach provided much better clarity when implementing the action block export functionality, as each module could be tested and refined independently.
- **Cross-Platform Pixel Density Considerations:** Different monitor sizes and resolutions significantly impact pixel-based calculations. However, this variance becomes negligible when using relative units (vh, vw, %, em) instead of hardcoded pixel values. This insight was crucial for ensuring consistent brick detection across different devices.

---

## Next Week's Roadmap

- Make the color detection and output more accurate.
- Deal with issue related to block length detection errors.
- Develop user documentation and tutorial materials for the LEGO blocks widget.

---

## Resources & References

- **Music Blocks Documentation:** https://github.com/sugarlabs/musicblocks/tree/master/documentation
- **LEGO Blocks Notation System Video:** https://youtu.be/LOfrCPf3XJU?feature=shared
- **Devin's CMK'24 Blog:** https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c
- **Music Blocks Phrase Maker Source Code:** Referenced for action block formatting standards

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Special appreciation for their feedback during the live demonstration and their continued support in refining the project's technical implementation.

---`,ol=Object.freeze(Object.defineProperty({__proto__:null,default:Xt},Symbol.toStringTag,{value:"Module"})),$t=`---
title: "GSoC '25 Week 08 Update by Shubham Singh"
excerpt: ""
category: "DEVELOPER NEWS"
date: "2025-07-28"
slug: "2025-07-28-gsoc-25-firepheonix-week08"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week08
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 7 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-21 – 2025-07-28

---


## Goals for This Week

- Complete the first actual prototype, with the action block export.
- Add vertical lines as a grid, to standardize detection time accross all widths of monitors.
- Find out a method to divide the entire musical pattern into standard column like sections, like in phrase maker.

---

## This Week's Achievements

1. **Implemented the standardization method of vertical(y) axis**  
   - Earlier, the method of having the lego blocks just across the horizontal axis. Now, the number of pixels across 2 points on any monitor may vary, so we switched to time. But the length of DISPLAY of blocks might also vary.
   - So now, we're using three things: 1. X-axis 2. Y-axis 3. Time
   - Now, the time across any two columns will be the same. Hence keeping it the same across all types of monitors.

        ![Y-axis lines are now made](/assets/Developers/Shubham_Singh/gsoc-blog-week08-img2.png)


2. **Implemented the dynamic dividing of Lego Block images into different shaped columns**  
   - Now, the image detection also automatically detects the column division.
   - This will help significantly in exporting the audio as an action block.

    ![Detects column's left and right edges.](/assets/Developers/Shubham_Singh/gsoc-blog-week08-img-1.png)


---

## Challenges & How I Overcame Them

- **Challenge:** The most difficult challenge was figuring out a function that would divide the entire image into different different columns, so that they can be exported as an action block.
  **Solution:** Multiple trials and errors, some mathematical logic, and searched some other resources.
- **Challenge** I was busy with college the entire week.
  **Solution:** Managed my time better, gave more time to gsoc project at weekends.

---

## Key Learnings

- Break the entire pivot into multiple parts. And then solve step by step. You'll end with a pipeline that gives a LOT more clarity on things.
- Different monitor sizes mean different numbers of pixels between two points. But that difference doesn’t matter if a parameter is hardcoded in pixels (e.g., px) rather than in relative units like vh, vw, %, or em.
- Since different screens have different pixel densities and resolutions, the visual width of the same number of pixels could differ.

---

## Next Week's Roadmap

- Build the action block output.
- Generate note blocks with their corresponding note values and pitches for a given phrase, based on the LEGO brick input.

---

## Resources & References

- **You can refer to music blocks documentation: https://github.com/sugarlabs/musicblocks/tree/master/documentation** 
- **You may refer to the Lego Blocks Notation system video: https://youtu.be/LOfrCPf3XJU?feature=shared**
- **Devin's CMK'24 blog: https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c**

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. 

---`,il=Object.freeze(Object.defineProperty({__proto__:null,default:$t},Symbol.toStringTag,{value:"Module"})),Yt=`---
title: "GSoC '25 Week 13 Update by Aditya Kumar Singh"
excerpt: "Fixed critical model switching bugs in Human Body activity, enhanced Stickman animation with individual frame management, transitioned to relative positioning, and began implementing shared mode functionality."
category: "DEVELOPER NEWS"
date: "2025-08-07"
slug: "2025-08-07-gsoc-25-AdityaKrSingh26-week13"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week13,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 13 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-08-07 - 2025-08-13  

---

## Goals for This Week

- **Goal 1:** Finalize the Human Body activity by resolving the critical model switching bug in shared mode.
- **Goal 2:** Implement individual frazme management for each stickman in the Stickman activity.
- **Goal 3:** Transition from absolute to relative positioning for stickman coordinates.
- **Goal 4:** Begin implementing shared mode functionality for the Stickman activity.

---

## This Week’s Achievements

1. **Fixed Critical Model Switching Bug in Human Body Activity**  
    - **Problem Identified:** In shared mode, when User A switched to a non-default model (e.g., skeleton) and User B joined the shared session, the application would incorrectly display both the default body model and the current model overlapped, creating visual confusion. 
    - **Root Cause Analysis:** The issue occurred in the model synchronization logic where:
        - New users joining a shared session would load the default "body" model first
        - The host's current model state wasn't properly communicated to new joiners
        - Model switching messages weren't prioritized during the initial sync process.

2. **Individual Frame Management for Stickman Animation**  
    - **Enhancement Overview:** Previously, all stickmen shared a common frame timeline, which created confusion during multi-character animation. Now each stickman maintains its own independent frame sequence.
    - **Memory Optimization Approach:**
        - Used JSON deep copying to prevent reference sharing
        - Added timestamp tracking for frame management and debugging
    - **Benefits Achieved:**  
        - Each stickman can have different numbers of frames (1-100+ frames per character)
        - Independent timeline scrubbing for complex multi-character scenes
        - Memory-efficient frame storage with delta compression

3. **Transition to Relative Positioning System**  
    - **Previous System Limitation:** Stickmen were positioned using absolute canvas coordinates, making it difficult to:
        - Move entire characters as units
        - Scale animations proportionally
        - Implement consistent character spacing
    - **Solution Architecture:**
        **Data Structure Redesign:**
        1. **Anchor Point System:** Each stickman has a base anchor coordinate (x, y)
        2. **Relative Joint Positions:** All joints stored as offsets from anchor
        3. **Transformation Matrix:** Anchor acts as transformation origin

        - **Algorithm: Relative to Absolute Conversion**
            1. **Input:** Stickman index for processing
            2. **Anchor Retrieval:** Get stickman's anchor coordinates
            3. **Joint Iteration:** Loop through all joints in the stickman
            4. **Coordinate Calculation:** For each joint, compute absolute position = anchor + joint.offset
            5. **Rendering Preparation:** Pass absolute coordinates to drawing functions

        - **Algorithm: Character Movement**
            1. **Input:** Stickman index and new position delta
            2. **Anchor Update:** Modify only the anchor coordinates
            3. **Automatic Propagation:** All joints automatically move with anchor
            4. **Single Operation:** Entire character moves with one coordinate change

        **Benefits of Implementation:**
        - Character movement: O(1) operation instead of O(n) where n = number of joints
        - Proportional scaling becomes simple multiplication of offset values
        - Template system can store relative coordinates for reusability
        - Collision detection simplified to anchor point + bounding box calculations

        **Advantages Gained:**  
        - Easy character repositioning by moving anchor point
        - Proportional scaling of entire characters
        - Simplified collision detection between characters
        - Better support for character templates and presets

3. **Shared Mode Implementation**  
    - **Architecture Design:** Built the groundwork for real-time collaborative stickman animation using Sugar's presence system.
    - **How Shared mode works:**  
        - Each stickman is represented as a presence object with unique ID
        - Host can create, update, and delete stickmen in the shared session
        - Presence updates are broadcasted to all connected users
        - Users can see real-time changes made by others
        - Users can edit their own stickmen independently while syncing changes
        - Conflict resolution via timestamp comparison to handle simultaneous edits
    - **Optimization Strategies:**
        - Delta compression for joint updates (only send changed coordinates)
        - Throttling mechanism to prevent message flooding during rapid movements
    > Shared Mode Implementation  
    ![Shared Mode](https://res.cloudinary.com/djhshvtwo/image/upload/v1754553152/GSoC%2725%20Blog%20Images/ee3d7398-c986-4565-8e09-f5fef3387271.png)

---


## Challenges & How I Overcame Them

- **Challenge:** Model switching bug in Human Body activity caused visual overlap when users joined shared sessions.  
  **Solution:** Analyzed THREE.js scene graph structure and implemented proper model cleanup sequences. Added state synchronization logic to ensure new users receive the correct current model instead of defaulting to body model first.

- **Challenge:** Converting from shared frame timeline to individual frame management for each stickman without breaking existing animations.  
  **Solution:** Refactored animation UI architecture using JSON deep copying and implemented memory optimization with frame limits. Maintained backward compatibility by converting old shared frames to individual sequences during load.

- **Challenge:** Migrating coordinate system from absolute to relative positioning while maintaining visual consistency.  
  **Solution:** Implemented anchor point system with mathematical transformations. Updated all rendering logic to convert relative coordinates to absolute for drawing, allowing O(1) character movement

---

## Next Week’s Roadmap

- Improve shared mode implementation.
- Add Journal import functionality for Stickman.
- Begin work on export to video feature and save the video in journal.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,sl=Object.freeze(Object.defineProperty({__proto__:null,default:Yt},Symbol.toStringTag,{value:"Module"})),Qt=`---
title: "DMP ’25 Week 10 Update by Aman Naik"
excerpt: "This week focused on adding an advice feature powered by the LLM, and refactoring the ChatSidebar using Gtk.Stack to resolve UI toggling issues."
category: "DEVELOPER NEWS"
date: "2025-08-09"
slug: "2025-08-09-dmp-25-AmanNaik-week10"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week10,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-08-03 – 2025-08-09  

---

## Goals for This Week

- Add a "Get Advice" button to provide students with feedback on their stories  
- Refactor ChatSidebar to properly manage chat and framework views using \`Gtk.Stack\`  

---

## This Week’s Achievements

1. **Added “Get Advice” Feature**  
   - Introduced a new button labeled **Get Advice** in the toolbar.  
   - When clicked, the application retrieves all text written in the document using the \`'get_content'\` method.  
   - The full story is then sent to an LLM along with a carefully designed prompt template.  
   - The model responds with both advice and encouragement, written in simple, child-friendly language, attributed to a fictional guide named *Mary Tales*.  
   - For now, the advice gets displayed on the console to quickly test out the LLM response quality.  

    ![Advice being displayed in the console based on the written story](assets/Images/aman-naik-week10-img1.png)
    ![Story that was written on the document](assets/Images/aman-naik-week10-img2.png)

2. **Refactored ChatSidebar with Gtk.Stack**  
   - Migrated the sidebar view management from manual hiding/showing to \`Gtk.Stack\`, which allows switching between the chat and framework sections without rendering conflicts.  
   - Fixed an issue where toggling the sidebar on/off caused **both** the chat and framework to appear simultaneously.  
   - Now, the sidebar correctly restores the last active view when reopened, ensuring a smoother and more predictable user experience.
   \`\`\`chatbox.py
        # Create a Gtk.Stack to manage different views (chat, framework)
        self.main_stack = Gtk.Stack()
        self.main_stack.set_transition_type(Gtk.StackTransitionType.SLIDE_LEFT_RIGHT)
        self.main_stack.set_transition_duration(300)
    \`\`\`

---

## Challenges & How I Overcame Them

- **Challenge:** Old toggle logic caused multiple framework instances to stack below the chat  
  **Cause:** Earlier implementation relied on \`'show_all()'\`, which rendered every child widget in the container. This resulted in vertically stacked duplicates when switching views.  

  ![Old toggle logic causing multiple framework instances to stack below the chat](assets/Images/aman-naik-week10-img3.png)

  **Solution:** Completely refactored the code so the chat section and framework section are independent widgets. They are now managed exclusively via \`Gtk.Stack\`, and navigation between them is handled by the **Create Framework** and **Back to Chat** buttons. This eliminated duplicate rendering and made state management far cleaner.

---

## Key Learnings

**Integrating Context-Aware LLM Feedback**  
   - Learned how to combine user-generated content with structured prompt templates to produce relevant, age-appropriate feedback.

**Using Gtk.Stack for Multi-View UI Management**  
   - \`Gtk.Stack\` provides a more robust method for switching views compared to manual widget hiding, preventing unwanted re-rendering issues.

**Refactoring for Maintainability**  
   - Separating chat and framework into standalone widgets improved both readability of the code and maintainability for future UI changes.

---

## Next Week’s Roadmap

- Continue refining the “Get Advice” feature to make the advice visible within the activity instead of the console.
- Contribute to the recent developments happening with Sugar-AI so we can quickly implement it within the write-activity.
- Add proper icons to the chat and advice buttons.

---

## Acknowledgments

Thank you to my mentors for helping me validate the UX flow for the new advice feature and suggesting improvements for sidebar state management.

---
`,rl=Object.freeze(Object.defineProperty({__proto__:null,default:Qt},Symbol.toStringTag,{value:"Module"})),Zt=`---
title: "GSoC '25 Week 10 Update by Elwin Li"
excerpt: "Weekly progress report for JSEditor updates - Continuing work on the RAG pipeline and MIDI widget improvements"
category: "DEVELOPER NEWS"
date: "2025-08-09"
slug: "2025-08-09-gsoc-25-Elwin-Li-week10"
author: "@/constants/MarkdownFiles/authors/elwin-li.md"
tags: "gsoc25,sugarlabs,week10,RAG pipeline,MIDI widget"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Elwin Li

**Project:** MusicBlocks Generation Model

**Mentors:** [Walter Bender](https://github.com/walterbender), [Anindya Kundu](https://github.com/meganindya), [Devin Ulibarri](https://github.com/pikurasa)

**Reporting Period:** 2025-08-03 - 2025-08-09

---

## Goals for This Week

- **Goal:** Connect the MIDI upload widget with the RAG pipeline to enable end-to-end Music Blocks generation from user queries.

---

## This Week's Achievements

This week I made a lot of progress on the Music Blocks generation project. I successfully connected the MIDI upload widget with the RAG pipeline, and now users can enter a query and generate a Music Blocks project as per their request. This creates a complete workflow from natural language input to final Music Blocks output.

[youtube: 5Ha7WlbHOfc]

---

## Challenges & How I Overcame Them

- **Challenge:** The generated MIDI files didn't sound right and had quality issues.
  **Solution:** Improved the prompt engineering and changed the model used for generation, which resulted in better-sounding MIDI output.

---

## Key Learnings

- Gained experience in integrating different components of a music generation pipeline.
- Improved skills in prompt engineering for better MIDI generation quality.
- Learned about the importance of model selection for specific generation tasks.

---

## Next Week's Roadmap

- Adjust the tempo of the generated MIDI files, as they currently seem to always be generated at very fast speeds for some reason.
- Investigate and fix the underlying cause of the tempo issues in the generation process.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,ll=Object.freeze(Object.defineProperty({__proto__:null,default:Zt},Symbol.toStringTag,{value:"Module"})),ea=`---
title: "DMP’25 Week 10 Update by Justin Charles"
excerpt: "Finalized brick connection infrastructure in the workspace and began defining AST parsing constraints for mapping between Masonry and program representation"
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-dmp-25-justin212407-week10"
author: "@/constants/MarkdownFiles/authors/justin-charles.md"
tags: "dmp25,sugarlabs,week10,justin212407"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Justin Charles

**Project:** Music Blocks 4 Masonry  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-08-04 - 2025-08-10   

---

## Goals for This Week

- Complete the **brick connection infrastructure** in the workspace  
- Define **AST parsing constraints** for converting between Masonry representation and program AST  

---

## This Week’s Highlights

### 1. **Brick Connection Infrastructure Completed**

- **Workspace Presentation**  
  - Computed absolute coordinates of all incoming connection points (expression-right, statement-bottom, compound-inner-top) whenever a tower is added.  
  - Reverse map utility converts notch IDs into \`{BrickId, TowerId}\` references.  
  - Optimized for performance by recomputing only towers/bricks that change.  

- **Collision Maps**  
  - Created two separate maps:  
    - **Expression Map** → stores expression-brick notch coordinates  
    - **Statement Map** → stores statement-brick notch coordinates  
  - Each map indexes by unique **Notch ID**, reverse-mapped to brick and tower ownership.  

- **Collision Detection**  
  - On drag-start, remove dragged brick/tower notch coords to prevent self-matching.  
  - On each mouse-move, check outgoing notches against map entries.  
  - Overlapping notch pairs are logged as *potential connections* via reverse mapping.  
  - Example: standalone brick connecting to a tower uses the parent brick model (via reverse map) to identify exact position.  

---

### 2. **AST Parsing Discussions**

- Defined constraints for **AST ↔ Masonry conversions**:  
  - Each **Brick ID** in Masonry must map directly to an **AST Node ID** for consistency.  
  - Constants and rules established for parsing tree hierarchies from visual blocks to program representation.  
  - Ensured that parsing is bidirectional: Masonry → AST for execution, AST → Masonry for reconstruction.  

- Clarified how the tree structure should be preserved while respecting parent-child and tower relationships.  

---

## Challenges & Solutions

**Challenge:** Keeping connection maps efficient while supporting continuous drag.  
**Solution:** Limited recomputation scope to only changed towers/bricks, combined with quadtree partitioning.  

**Challenge:** Ensuring AST parsing rules remain flexible yet consistent with brick model.  
**Solution:** Established a shared ID system and constants for mapping, ensuring robust future conversions.  

---

## Key Learnings

- **Collision Map Architecture**  
  Gained hands-on experience designing performant quadtree-based collision maps.  

- **Reverse Mapping Importance**  
  Saw how a utility mapping notch IDs to \`{BrickId, TowerId}\` streamlines both collisions and merges.  

- **AST Consistency**  
  Understood the importance of keeping **brick IDs == AST IDs** to prevent desync during parsing.  

---

## Next Week’s Roadmap

- Complete brick connections with on merge effects.
- Parse the AST from masonry to program according to the constraints defined in the previous meetings.

---

## Resources & References

- [musicblocks-v4 Branch (with the work)](https://github.com/sugarlabs/musicblocks-v4/tree/gsoc-dmp-2025/week-9/justin)  
- [musicblocks-v4 Repository](https://github.com/sugarlabs/musicblocks-v4)  
- [Quadtree Algorithm Notes](https://en.wikipedia.org/wiki/Quadtree)  

---

## Acknowledgments

Thanks to my mentors for guiding me through both the technical and architectural aspects of connection logic and AST design.
`,dl=Object.freeze(Object.defineProperty({__proto__:null,default:ea},Symbol.toStringTag,{value:"Module"})),na=`---
title: "GSoC ’25 Week 10 Update by Mebin J Thattil"
excerpt: "Deploying SugarAI"
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-gsoc-25-mebinthattil-week10"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week10,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

# Week 10 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-03 - 2025-08-10

---

## Goals for This Week

- **Goal 1:** Setup AWS for LLM deployment - SugarAI 

---

## This Week’s Progress

### **1. Deploy SugarAI**

There is only one final part left in the refactor of the Speak Activity, and those are the LLM powered features. For this we need to have the LLM hosted somewhere.
So it was time to deploy SugarAI on our AWS.

So here is what I did:
- Spin up an EC2 instance that uses g5 large GPUs. This instance is being run under my AWS-Sugarlabs account. So if someone is reading this as documentation and there is an issue with the service and you need to reach out to me, do so by shooting me a mail at : [mail@mebin.in](mailto:mail@mebin.in).
- Ran the following code to setup the instance and pull SugarAI:
\`\`\`bash
# Add Docker's official GPG key:
apt-get update -y
apt-get install -y ca-certificates curl
install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \\
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\
  $(. /etc/os-release && echo "\${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \\
  tee /etc/apt/sources.list.d/docker.list > /dev/null
apt-get update -y
apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

groupadd docker
usermod -aG docker $USER
systemctl enable docker.service
systemctl enable containerd.service

git clone https://github.com/sugarlabs/sugar-ai.git && cd sugar-ai
docker build -t sugar-ai .
docker run --gpus all -it --rm sugar-ai
\`\`\`
- This runs the docker container and can be accessed locally on \`port 8000\`.
- The inbound security rules of the EC2 were set to allow incoming requests only on port \`443(HTTPS)\` and \`22(SSH)\`.
- After this I locally tested if the API was working. It was, but only locally on the EC2 for now. 
- In order to make it publically available I would have to create a nginx proxy from \`port 8000\` to \`port 443\` and also get SSL certificates.
- I then created a static IP using AWS's elastic IP so we could create an \`A record\` for this service, which would be needed to issue the SSL certificate.


---

## Next Week’s Roadmap

- Nginx proxy pass
- SSL Certificates
- A record creation and launch of [ai.sugarlabs.org](https://ai.sugarlabs.org)
- Google OAuth and Github OAuth for login

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support.

---`,cl=Object.freeze(Object.defineProperty({__proto__:null,default:na},Symbol.toStringTag,{value:"Module"})),ta=`---
title: "GSoC '25 Week 10 Update by Nikhil Bhatt"
excerpt: "Wrote 160 backend tests using Jest with controller mocking, and restructured several APIs for improved maintainability."
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-gsoc-25-nikhilbhatt-week10"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week10,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-08-04 – 2025-08-10  

---

## This Week's Achievements

###  Wrote Comprehensive Backend Tests with Jest
This week, I focused heavily on **testing the backend** to ensure long-term stability and reliability.

- Created **160 individual tests** ([view them here](https://github.com/BeNikk/musicblocks-backend/tree/main/tests)) covering core API functionality. 
- Used **Jest** for the testing framework, along with **mocking controllers** to isolate logic from external dependencies.
- Tests cover both **happy paths** and **edge cases**, ensuring robust API behavior.
- This significantly improves our **confidence in future code changes** without fear of breaking existing features.

###  Restructured and Improved APIs
In parallel, I revisited some of our backend APIs for **better structuring and maintainability**.

- Refactored route definitions for better **logical grouping**.
- Improved **error handling** and **consistent response formats**.
- Optimized certain request flows to reduce unnecessary API calls.

---

## Challenges & How I Solved Them

- **Challenge:** Maintaining test isolation without hitting actual APIs or databases.  
  **Solution:** Used Jest mocks and stubs for controllers, ensuring tests run quickly and independently.

- **Challenge:** Some APIs had inconsistent parameter handling.  
  **Solution:** Standardized parameter validation and request body structures.

- **Challenge:** Structuring large test suites while keeping them readable.  
  **Solution:** Organized tests by feature/module and used descriptive naming conventions.

---

## Key Learnings

- Mastered advanced **Jest mocking** techniques for controller and service layer isolation.
- Learned the importance of **test coverage as a safety net** for refactoring.
- Refactoring APIs not only improves code quality but also helps onboarding new contributors.

---

## Next Week's Roadmap

- Continue expanding test coverage to newly added backend features.
- Start preparing **documentation** for the backend APIs.

---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [Jest Documentation](https://jestjs.io/docs/getting-started)

---

## Acknowledgments

Thanks to my mentors and the Sugar Labs community for their support and feedback during the testing phase!  
This week was a major milestone towards making the backend **production-ready**.  
Looking forward to refining it even further next week.

`,ul=Object.freeze(Object.defineProperty({__proto__:null,default:ta},Symbol.toStringTag,{value:"Module"})),aa=`---
title: "GSoC '25 Week 10 Update by Safwan Sayeed"
excerpt: "Design and Implementation of Scheduler for Music Blocks 4"
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-gsoc-25-safwan-sayeed-week10"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week10,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-08-04 - 2025-08-10

---

## A Blog-style Retrospective

This week I Designed and Implemented the Scheduler for Music Blocks 4. The Scheduler is responsible for managing the execution of musical blocks, ensuring that they are played in the correct order and at the right time.

---

## Goals for This Week

- Write a TechSpec for the Scheduler, outlining its architecture and components.
- Implement the Scheduler's core functionality, focusing on the management of musical block execution.
- Develop the Data Flow Diagram (DFD) for the Scheduler to visualize data movement and interactions within the system.
---

## This Week's Highlights

- **TechSpec for Scheduler:**  
  Created a detailed TechSpec document that outlines the architecture and components of the Scheduler, including the timing and sequencing of musical block execution.
- **Implementation of Scheduler:**  
  Successfully implemented the core functionality of the Scheduler, focusing on the management of musical block execution.

- **Data Flow Diagram (DFD):**  
  Developed a Data Flow Diagram (DFD) to visualize the data movement and interactions within the Scheduler system, providing a clear overview of how data flows through the various components.

![Scheduler-DFD](/assets/Developers/Safwan/scheduler-dfd.png)

---

## Challenges & Solutions

- **Complexity of Scheduler Implementation:**  
  The implementation of the Scheduler was complex due to the need to maintain the timing and sequencing of musical block execution. I tackled this by breaking down the implementation process into smaller, manageable components, allowing for easier debugging and testing.

---

## Key Learnings

- Gained a deeper understanding of scheduler design principles, particularly in the context of real-time systems.
- Learned about the intricacies of managing task execution order and timing, including the challenges of maintaining system responsiveness while optimizing for performance.
---

## Next Week's Roadmap

- **Think about the Integration with the Masonry:**  
  Explore how the Engine can be integrated into the Masonry to manage the execution of programs more effectively, including task prioritization and resource allocation.

---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

=======
Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their invaluable support and guidance throughout this project.

---`,hl=Object.freeze(Object.defineProperty({__proto__:null,default:aa},Symbol.toStringTag,{value:"Module"})),oa=`---
title: "GSoC ’25 Week 09 Update by Diwangshu Kakoty"
excerpt: "Reflection Learning Widget in Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-gsoc-25-diwangshu-week09"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week09,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-07-28 - 2025-08-04  

---

## Goals for This Week

- **Goal 1:** Fixed 'reflection' widget UI.
- **Goal 2:** Improved chat interface.
- **Goal 3:** Improved prompts for child-friendly language.
- **Goal 4:** Automated algorithm generation.
- **Goal 5:** Fixed a bug where the first message triggered twice.

---

## This Week’s Achievements

1. **Fixed 'reflection' widget UI**  
  - The user interface design of the widget now aligns with other widgets. There is a sidebar with buttons like export and "generate a summary".

    <a href="https://ibb.co/PZWZQDhN"><img src="https://i.ibb.co/gMWMV4T3/Screenshot-2025-08-10-195926.png" alt="chat interface" border="0"></a>

2. **Improved chat interface**
  - Every message bubble will now show its sender name on top of the text.

3. **Improved prompts for child-friendly language**
  - I was suggested by my mentor that the LLM's responses were not child friendly in terms of its complexity of sentences. So, I have added specific instructions regarding this.

4. **Automated algorithm generation**
  - Earlier, I had a "Start" button to initialize the conversation. When clicked, Music Blocks would send the project code to the backend, which then called the LLM to generate an algorithm for it and attempt to predict the code’s purpose. Now, there’s no button — simply opening the widget window triggers the entire process automatically. Implementing this change took some time, as I had to fix a tricky bug. I’ll explain more about that bug in the next point.

---

## Challenges & How I Overcame Them

- **Challenge 01:** The first message was triggered twice. As I mentioned, the bot automatically sends the first message containing the project code algorithm and asks the user to confirm if the guess is correct. However, the algorithm generation function ended up being triggered twice. I discovered that the widget’s initialization function runs twice. I don’t think this is a bug in itself, as the same behavior occurs with all other widgets.

  **Solution :** The challenge was identifying the problem; the solution itself was straightforward. I initialized a boolean flag that is set to true only during the first call of the initialization function. This allows us to prevent subsequent calls by simply checking the flag’s value.

- **Challenge 02:**  While integrating my \`generateAnalysis()\` function in a JavaScript class, I was passing \`this.chatHistory\` and \`this.summary\` as arguments. This caused a 422 error from the FastAPI backend because the arguments were evaluated before the function executed, leading to stale or incorrect values.

  **Solution :**  I removed the parameters from generateAnalysis() and accessed this.chatHistory and this.summary directly inside the method. This ensured the function always used the latest and correct state from the class instance at the time of execution, eliminating the backend validation error

---

## Key Learnings

- Always ensure method parameters match actual property names, and be mindful that passing arguments captures their value at that moment. Accessing properties directly from this inside the method guarantees using the latest, correct state, especially in asynchronous JavaScript flows.
---

## Next Week’s Roadmap

- The widget is almost complete. Now I need to figure out deploying the FastAPI application in AWS.
- I will also be testing Sugar-ai to see how it can beneficial for the reflection widget.

---

## Resources & References

- **Repository:** [reflection_streamlit](https://github.com/Commanderk3/reflection_streamlit)
- **Streamlit App:** [Reflection App](https://reflectionapp-2yoxtvn6sknvktme2zorvq.streamlit.app/)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,gl=Object.freeze(Object.defineProperty({__proto__:null,default:oa},Symbol.toStringTag,{value:"Module"})),ia=`---
title: "GSoC '25 Week 10 Update by Krish Pandya"
excerpt: "20,000 Lines, Datastore, ObjectChooser, and Sugar Widgets!"
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-gsoc-25-mostlyk-week10"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week10,mostlyk,datastore,objectchooser,widgets"
image: "assets/Images/GSOC.webp"
---

# Week 10: 20,000 Lines, Datastore, ObjectChooser, and Sugar Widgets

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)

**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)

**Reporting Period:** August 3, 2025 – August 10, 2025

---

## 20,000 Lines and Counting

This week marks a milestone: I’ve crossed 20,000 lines of code for the Sugar GTK4 migration!

Here’s the obligatory GitHub Insights screenshot

![20k LOC Milestone](assets/Images/20k-loc-gtk4.png)

It is quite wild to think of how much the codebase has grown since I started writing the python porting. From the initial days of porting just the graphical interfaces to now having pushed the datastore and profile, env , mime required to run the systems on Sugar, the library has come a long way and it has been a good lesson in architecture, I keep mentioning this every 2 weeks that I understand a lot of decision of the old library as I write more and I continue to stand by that. Every new addition is a lesson in architecture, debugging and patiences.

## What’s New This Week?

### 1. Datastore Module

- Stable, Extensible, and Tested: The new \`datastore.py\` and \`datastore/__init__.py\` bring in all the core logic for activity data storage, retrieval, and signals.
- Unit Tests: Comprehensive tests for metadata, object creation, copying, deletion, and signal handling.

### 2. ObjectChooser: Journal Integration for Activities

- ObjectChooser: Activities can now prompt users to select objects from the Journal, with support for mime filters, previews, and DBus integration.
- Example : Try out \`objectchooser_example.py\` to see it in action (with graceful fallback if Journal isn’t running).
( Try this in Sugar Sandbox! )

### 3. Alert System

- Alert, ConfirmationAlert, ErrorAlert, TimeoutAlert, NotifyAlert: All ported and refactored for GTK4, with snapshot-based drawing and flexible button handling.
- Example: \`alert_example.py\` demonstrates all alert types, including timeouts and response signals.

## Technical Deep Dive

This week’s commits were all about foundational infrastructure:

- DBus and Signals: Rewrote the dispatching mechanism for multi-consumer, multi-producer signals (see \`dispatch/dispatcher.py\` and \`dispatch/saferef.py\`).
- Widget Modernization: The new \`widgets.py\` is a beast—over 500 lines of code, refactored for GTK4, with careful preservation of legacy comments and architecture.
- Testing: Every major module now has a corresponding test file in \`tests/\`, following the pattern of previous weeks—mocking DBus where needed, and ensuring coverage for edge cases.
- Tested on VM: I have been testing the examples on the Fedora 42 Sugar ISO and I have had a issue of an extra topbar appreance which is to be tackled next week.

## Closing Thoughts and Next Steps

- Testing on the VMs which is where the tookit will be used is the next important step.
- The library has matured enough that I should start documenting for the last weeks and future plans for the contributors on how to continue from here and where it leads on.
- Activity Porting: With widgets and datastore in place, it’s time to port real Sugar activities—starting with [fractionbounce](https://github.com/sugarlabs/fractionbounce/).
- Documentation: Begin writing developer docs and migration guides for the new toolkit.

---

## Resources & Links

- [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [New C Library (sugar-ext)](https://github.com/sugarlabs/sugar-ext)
- [Game Demo Video](https://youtu.be/B517C_LTCns)
`,ml=Object.freeze(Object.defineProperty({__proto__:null,default:ia},Symbol.toStringTag,{value:"Module"})),sa=`---
title: "GSoC’25 Week 10 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-gsoc-25-omsuneri-week10"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week10,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-08-04 - 2025-08-10

---

## Goal for This Week

**Refine the Debugger UI based on community and mentor feedback to ensure consistency with the traditional Music Blocks widget design and improve usability.**

---

## This Week’s Achievements

### Introduction

After introducing the AI-powered debugger widget, I collected detailed feedback from the Sugar Labs community and mentors. The key point that emerged was **UI consistency** the debugger widget's visuals and interactions needed to feel native to the Music Blocks experience. This week, I focused on implementing those design changes and adding a couple of useful features to enhance the user experience for students and educators.

### What I Did

#### Sidebar Replacement

The previous debugger used a wide sidebar for action buttons like *Reset* and *Clear*. I replaced this with a **compact icon bar** placed at the top-left corner of the debugger window—mirroring other native Music Blocks widgets.

Code snippet that shows this change:
\`\`\`js
this._resetButton = widgetWindow.addButton(
    "reload.svg",
    ICONSIZE,
    _("Reset conversation")
);

this._exportButton = widgetWindow.addButton(
    "export-button.svg",
    ICONSIZE,
    _("Export chat")
);
\`\`\`\`

#### Removed Session Info

Session metadata (like conversation IDs) was previously shown in the UI. However, this cluttered the interface without offering meaningful value to users. It has now been **completely removed** from the visual layout.

#### Export Chat Feature

To encourage debugging collaboration between students and mentors, I added an **export chat button**. This allows users to save the entire conversation (with AI) as a \`.txt\` file. The export includes the music blocks project (in human-readable form) and the complete chat history.

Relevant implementation excerpt:

\`\`\`js
const blob = new Blob([exportContent], { type: "text/plain" });
const url = URL.createObjectURL(blob);
const a = document.createElement("a");
a.href = url;
a.download = "music_blocks_chat_" + timestamp + ".txt";
a.click();
\`\`\`

Use case: A student can now share this file with a mentor or Sugar Labs community to ask, *"Why did the AI suggest this?"* — enabling deeper community engagement and learning.

#### Styling Consistency

* Unified padding, input border styles, and message layout to match the Music Blocks look.
* Implemented hover effects and color schemes that mirror existing widgets.

Example:

\`\`\`js
this.messageInput.style.borderColor = "#ddd";
this.messageInput.onfocus = function() {
    this.style.borderColor = "#2196F3";
};
\`\`\`

--- 

### Preview

<a href=""><img src="https://i.ibb.co/YBKkWK6h/Screenshot-2025-08-09-at-1-17-26-AM.png" alt="Music Blocks Debugger Widget"/></a>

Here’s a quick visual overview of the final UI changes:

* 🎛️ Compact icon toolbar instead of side menu
* 💬 Chat log fully scrollable and styled natively
* 📤 Exportable chat with project summary
* 🧊 Minimalist UI without unnecessary technical data

---

### Why It Matters

These UI updates are not just cosmetic—they directly impact:

* **Accessibility**: Students on smaller screens or low-spec devices can now use the debugger more easily.
* **Clarity**: Reducing technical noise (like session info) makes the tool less intimidating.
* **Collaboration**: The chat export feature opens up avenues for guided mentorship and feedback sharing.
* **Consistency**: Aligning with existing widgets builds confidence for younger learners already familiar with Music Blocks.

---

### Final Thoughts

This week’s work made the debugger more polished, focused, and learner-friendly. It’s rewarding to see the debugger evolve into a tool that integrates seamlessly with the Music Blocks platform, visually and functionally. I’m particularly excited to see how the \`.txt\` chat exports might encourage peer discussions, classroom engagement, and asynchronous mentoring!

---

## Next Week’s Roadmap

**Implement additional user and community feedback and prepare for final evaluations.**

## Resources & References

- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)

## Acknowledgments

Grateful as always to my mentors and the Sugar Labs community for their thoughtful feedback, patience, and encouragement as I shape this into a usable tool for learners.

---
`,pl=Object.freeze(Object.defineProperty({__proto__:null,default:sa},Symbol.toStringTag,{value:"Module"})),ra=`---
title: "SSoC ’25 Week 10 Update by Muhammad Haroon"
excerpt: "Create a FastAPI for connecting frontend with backend for Audio Trimmer."
category: "DEVELOPER NEWS"
date: "2025-08-10"
slug: "2025-08-10-ssoc-25-MuhammadHaroon-week10"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week10,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-4 - 2025-08-10

---

## Goals for This Week

- **Goal 1:** Create a FastAPI for connecting frontend with backend for Audio Trimmer.

---

## This Week's Achievements

1. **Create a FastAPI for connecting frontend with backend for Audio Trimmer.**  
   - I successfully created a FastAPI for connecting the frontend with the backend for Audio Trimmer in Music Blocks.

   - Users can now upload an audio sample. Once uploaded, the file chooser will be replaced by an HTML audio player, where students can listen to the audio and select the segment they want to trim. Below the player, there are two input boxes: the first for the start time and the second for the end time. After entering the times, users can click the Preview button to listen to the trimmed audio and check whether it matches the segment they need or if the times need adjusting. Once they are satisfied with the selection, they can download the segment locally by clicking the Save button.

   - Below is the video demonstrating the AI Sample Generation in Music Blocks.

   [youtube: 2Zq0UOrxe1c]

---

## Key Learnings

- I learned about the Python pydub library, which can be used to trim audio.

---

## Next Week's Roadmap

- Test the changes and document the entire process.

---

## Resources & References
- **Frontend Code** https://github.com/sugarlabs/musicblocks/pull/4740
- **Backend Code** https://github.com/haroon10725/AI-Sample-Generation-Backend

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,bl=Object.freeze(Object.defineProperty({__proto__:null,default:ra},Symbol.toStringTag,{value:"Module"})),la=`---
title: "GSoC ’25 Week 09 Update by Bishoy Wadea"
excerpt: "Odd Scoring game"
category: "DEVELOPER NEWS"
date: "2025-08-14"
slug: "gsoc-25-BishoyWadea-week09"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week09,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

# Week 09 Progress Report by Bishoy Wadea

**Project:** [Odd Scoring game](https://github.com/Bishoywadea/Odd-Scoring)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-08-04 – 2025-08-14  

---

## Goals for This Week

- **Make new Sugar activity**

---

## Achievements

### Added New Sugar acivity (Odd Scoring)

- **Network Multiplayer Setup**  
  Implemented working network multiplayer and integrated game state saving into the Journal  
  [Commit](https://github.com/Bishoywadea/Odd-Scoring/commit/4138378b5a85af2417b7fb9d14c88e95e78ba85e)  

- **Render PNG Instead of Emojis**  
  Replaced emoji graphics with PNG assets for better cross-platform visual consistency  
  [Commit](https://github.com/Bishoywadea/Odd-Scoring/commit/304222ad5aea4feec96c31e14d5fb954f4555c20)  

- **Toggle Theme Feature**  
  Added ability to switch between different themes during gameplay  
  [Commit](https://github.com/Bishoywadea/Odd-Scoring/commit/cefb2bfc465202c8b6e6ee3efd7b1697214dc53e)  


Multiplayer Support Across Devices [youtube: MMVlzYffTiE]

---
## Challenges & Solutions

- **Challenge:** Ensuring smooth integration of network multiplayer while maintaining Sugar’s UI/UX standards. This included aligning window and pop-up styles with Sugar’s palette guidelines and handling state persistence across sessions.

- **Solution:**  
  - Refined UI elements to follow Sugar’s visual language, including pop-up windows and overall palette adherence.  
  - Made the shared game instance persistent to prevent state loss during gameplay transitions.  
  - Simplified multiplayer by removing the lobby flow, reducing friction for players joining sessions.  
  - Replaced emoji-based rendering with PNG assets for better visual consistency across devices.  

---

## Key Learnings

- Learned how to integrate multiplayer functionality with Sugar’s \`collabwrapper\` while ensuring proper state synchronization between devices.  
- Developed a better understanding of Sugar’s palette guidelines and how to adapt window designs to maintain a consistent style.  

---

## Next Week’s Roadmap

- Address any feedback provided by organization members regarding multiplayer flow, UI alignment, and performance.  
- Begin development of a new Sugar activity **Magic Number Grid** 

`,fl=Object.freeze(Object.defineProperty({__proto__:null,default:la},Symbol.toStringTag,{value:"Module"})),da=`---
title: "GSoC '25 Week 10 Update by Shubham Singh"
excerpt: "Successfully implemented action block export functionality."
category: "DEVELOPER NEWS"
date: "2025-08-15"
slug: "2025-08-15-gsoc-25-firepheonix-week10"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week09
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-07-05 – 2025-08-15

---

## Goals for This Week

- Make the color detection and output more accurate.
- Deal with issue related to block length detection errors.

---

## This Week's Achievements

1. **Made color detection and Action Blocks export very accurate**  
   - So, it ignores very small durations (lower that ~350ms) while travelling from left to right, making the color detection very accurate.

      ![After Scan Image](/assets/Developers/Shubham_Singh/gsoc-week10-after-scan.webp)

      ![Image Output](/assets/Developers/Shubham_Singh/gsoc-week10-output-image.webp)

2. **Fixed image overflow issues**  
   - Earlier, when the image either was too small or if it was overflowing on the lego widgets canvas, the lego widget would expand it by either adding more rows or contract it by removing some.
   - But now, it's configured to take blank (green) those rows if the image falls shorter in height, and ignore those rows if it overflows. Now the widget handles each case better

   ![Short Height Image example](/assets/Developers/Shubham_Singh/gsoc-week10-overflow-demo.webp)

---

## Challenges & How I Overcame Them

- **Challenge:** Achieving accurate color detection while avoiding false positives from very small color segments or noise in the image. The system was detecting tiny color variations that didn't represent actual LEGO blocks, leading to incorrect musical note generation.  
  **Solution:** Implemented a duration threshold filter that ignores color segments shorter than ~350ms when scanning from left to right. This eliminated noise while preserving legitimate LEGO block detection, significantly improving the accuracy of both color detection and action block export.

- **Challenge:** Handling varying image sizes and aspect ratios that would either overflow the LEGO widget canvas or leave empty space, causing the widget to behave unpredictably by adding or removing rows automatically.  
  **Solution:** Redesigned the image handling logic to maintain consistent widget dimensions regardless of input image size. For images shorter than the canvas height, empty rows are filled with blank (green) spaces. For images that overflow, excess rows are simply ignored rather than forcing widget expansion.

- **Challenge:** Ensuring the block length detection algorithm worked consistently across different image resolutions and LEGO block arrangements without producing duration calculation errors.  
  **Solution:** Refined the mathematical algorithms for measuring block lengths by implementing relative positioning instead of absolute pixel measurements. This approach maintains accuracy regardless of image scale or resolution.

---

## Key Learnings

- **Threshold-Based Filtering:** Implementing duration thresholds for color detection dramatically improves accuracy in computer vision applications. Small noise elements that pass initial detection can be effectively filtered out using time-based or size-based thresholds, leading to more reliable length-wise pattern recognition.


---

## Next Week's Roadmap

- Add support for other instruments
- Add new SVGs for Image and Webcam
- Auto arrange the pitches according to their order just like in the phrase maker.

---

## Resources & References

- **Music Blocks Documentation:** https://github.com/sugarlabs/musicblocks/tree/master/documentation
- **LEGO Blocks Notation System Video:** https://youtu.be/LOfrCPf3XJU?feature=shared
- **Devin's CMK'24 Blog:** https://medium.com/@sugarlabs/reflections-from-constructing-modern-knowledge-2024-1ce7d60fbb1c
- **Music Blocks Phrase Maker Source Code:** Referenced for action block formatting standards

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Special appreciation for their feedback during the live demonstration and their continued support in refining the project's technical implementation.

---`,wl=Object.freeze(Object.defineProperty({__proto__:null,default:da},Symbol.toStringTag,{value:"Module"})),ca=`---
title: "DMP ’25 Week 11 Update by Aman Naik"
excerpt: "This week focused on restructuring the advice feature for persistent visibility within the sidebar and refining the UX to better support students’ writing flow."
category: "DEVELOPER NEWS"
date: "2025-08-16"
slug: "2025-07-16-dmp-25-AmanNaik-week11"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week11,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-08-10 – 2025-08-16  

---

## Goals for This Week

- Move the advice section into the sidebar for persistent visibility  
- Add a button to toggle the advice section within the sidebar  

---

## This Week’s Achievements

1. **Integrated Advice Section into Sidebar**  
   - Previously, the “Get Advice” button lived in the toolbar and printed feedback in the console, which was not accessible or user-friendly.  
   - I redesigned the interaction so that advice now appears inside the sidebar alongside the framework view.  
   - This allows students to keep advice visible while continuing to build their story, instead of losing it after an action or context switch.  

   ![Advice section toggled on](assets/Images/aman-naik-week11-img1.webp)

2. **Toggle Button for Advice Section**  
   - Added a dedicated toggle button within the sidebar to control the visibility of the advice section.  
   - Students can now choose between focusing only on the story framework or expanding the sidebar to see both the framework and advice in parallel.  
   - The sidebar structure now uses \`Gtk.Stack\` to handle multiple subviews cleanly, preventing layout conflicts and allowing for flexible switching between sections.  

   ![Advice section not toggled on](assets/Images/aman-naik-week11-img2.webp)

---

## Challenges & How I Overcame Them

- **Challenge:** Persistent visibility for advice section  
  **Problem:** In the old design, advice appeared below the toolbar button but disappeared when clicking anywhere else, meaning the student could not revisit it.  
  **Solution:** Created a dedicated advice section inside the sidebar and added a toggle button to control its display. This ensured persistence and improved discoverability without cluttering the workspace.  

- **Challenge:** Iterating UX without upfront testing  
  **Problem:** The initial design underestimated the importance of persistent context. Students often need to revisit advice multiple times while writing.  
  **Solution:** Midway through implementation, I restructured the UI to reflect actual student needs, demonstrating the importance of adaptive design based on iterative testing and mentor feedback.  

---

## Key Learnings

- Learned how to use \`Gtk.Stack\` effectively to manage multiple sidebar views (chat, framework, advice) while maintaining a clean state transition.  
- Understood the importance of persistent UI components in educational tools, where students benefit from continuous access to feedback and guidance.  
- Realized that UX design often requires mid-development revisions and that structured mentor feedback helps identify overlooked usability issues.  

---

## Next Week’s Roadmap

- Implement saving of chat history into the Sugar Journal for persistence across sessions  
- Begin integrating Sugar AI as the inference backend, replacing the temporary Groq API placeholder  

---

## Acknowledgments

Thanks to my mentors for guiding me through iterative design discussions and encouraging me to prioritize the student’s perspective in UI/UX decisions.  

---
`,yl=Object.freeze(Object.defineProperty({__proto__:null,default:ca},Symbol.toStringTag,{value:"Module"})),ua=`---
title: "DMP ’25 Week 10 Update by Harshit Verma"
excerpt: "Focused on refining the Pippy Debugger’s responses to be more age-appropriate by using a larger model, enhancing the prompt workflow, and testing with multiple buggy code examples."
category: "DEVELOPER NEWS"
date: "2025-08-16"
slug: "2025-08-16-dmp-25-therealharshit-week10"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week10,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-04 - 2025-08-10   

---

## Goals for This Week

- **Goal 1:** Refine debugger responses to be more accurate and **age-appropriate**.  
- **Goal 2:** Experiment with a **larger LLM (Gemma-3-27B-it)** for better explanations.  
- **Goal 3:** Test debugger workflow with various **buggy Python code examples**.  

---

## This Week’s Achievements

1. **Integrated Larger Model (Gemma-3-27B-it)**  
   - Switched from the previous smaller model to a larger one to generate more coherent and helpful debugging outputs.  
   - Early results show clearer explanations and smoother response quality.  

2. **Improved Prompt Workflow**  
   - Refined prompt design to balance **technical accuracy** with **child-friendly language**.  
   - Ensures that responses are simple, engaging, and encourage a “debugging journey” rather than just spoon-feeding answers. 
  <img src="assets/Images/Pippy_prompt-workflow.png" alt="Pippy Debugger: Prompt Workflow" width="300">

3. **Extensive Testing with Buggy Code**  
   - Ran multiple test cases on buggy Python programs.  
   - Verified that the responses are not only technically correct but also accessible to younger learners.  
  - Document: [Responses from the LLM-Powered Debugger](https://docs.google.com/document/d/1u5th52avkRwtuu78ojiD2z8llYLuxqbEGOYcBe2-N_8/edit?usp=sharing)  

---

## Challenges & How I Overcame Them

- **Challenge:** Larger models increase inference time.  
  **Solution:** Optimized API calls and reduced unnecessary context in prompts.  

- **Challenge:** Striking the right balance between correctness and simplicity.  
  **Solution:** Iterative prompt tuning and trial runs with varied buggy examples.  

---

## Key Learnings

- Learned how to **fine-tune prompt workflows** for both technical correctness and educational clarity.  
- Understood the trade-offs between **smaller vs larger models** in terms of cost, speed, and output quality.  
- Gained hands-on experience in **debugging pedagogy** making explanations more interactive for kids.  

---

## Next Week’s Roadmap

- Further refine **debug responses** for edge cases based on mentors feedback.  
- Integrate full pipeline with Sugar-AI.

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,kl=Object.freeze(Object.defineProperty({__proto__:null,default:ua},Symbol.toStringTag,{value:"Module"})),ha=`---
title: "GSoC '25 Week 14 Update by Aditya Kumar Singh"
excerpt: "Enhanced shared mode ownership & visibility for Stickman, added Journal import functionality for saved stickmen, and export-to-video integration with Journal storage."
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-gsoc-25-AdityaKrSingh26-week14"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week14,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 14 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-08-14 - 2025-08-20

---

## Goals for This Week

- **Goal 1:** Improve shared mode implementation with clear ownership, visibility, and remote drag/drop support.  
- **Goal 2:** Add Journal import functionality for saved stickmen (similar to Fototoon).  
- **Goal 3:** Begin export-to-video in Journal feature.

---

## This Week’s Achievements

1. **Improved Shared Mode Implementation**  
    - The shared mode experience in Stickman has been improved. Each user now has a clear sense of **ownership** over their characters:  
    - Local stickmen are displayed in black, turning red when actively selected for editing.  
    - Remote stickmen are represented with user-specific colored markers, which makes them visible at all times but clearly distinct from editable ones.
    - Frames are now editable only if the stickman belongs to the current user. For remote stickmen, the timeline remains empty and locked, preventing accidental edits while still allowing observation of their movement.
    - Added the ability to **drag and reposition remote stickmen**. This makes collaborative arrangements easier: one user can adjust where another’s stickman stands in the scene, but without being able to alter its animation frames or joints. This separation of **movement versus editing privileges** ensures smoother teamwork during shared sessions.
    > Shared Mode Implementation  
    ![Shared Mode](https://res.cloudinary.com/djhshvtwo/image/upload/v1755528077/GSoC%2725%20Blog%20Images/57fb70a1-49a8-4fcd-97d8-42a3b818a106.png)

2. **Journal Import Functionality**  
    - Implemented the ability to import saved stickmen from the Journal, allowing users to easily retrieve and work with their previous creations.
    - When choosing to import, the Journal dialog now filters and displays only entries associated with the Stickman activity.
    - Imported stickmen are reconstructed on the canvas using their saved frames and delta movements.
    - Journal entry names are used as identifiers, making it easier for users to recognize their past creations. 
    - This feature allows users to reuse, remix, or continue working on stickmen created in earlier sessions, strengthening the connection between the Journal and creative workflows inside the Stickman activity.
    > Journal Import Functionality  
    ![Shared Mode](https://res.cloudinary.com/djhshvtwo/image/upload/v1755528027/GSoC%2725%20Blog%20Images/2d9491c0-bdfd-44fb-900f-61e967f9d968.png)

3. **Export-to-Video Feature Implemented**  
    - One of the biggest milestones this week was completing the **export-to-video feature**. Stickman animations can now be recorded and saved directly into the Journal as video files.
    - The system sequentially plays through animation frames, rendering them to a canvas.
    - A recording pipeline captures these frames into a **WebM video stream**.
    - Once complete, the video is finalized and saved in the Journal with proper metadata, making it accessible like any other video entry.
    - This implementation turns Stickman into a full animation tool — users can now **create, save, and share animations as videos**.

---

## Challenges & How I Overcame Them

- **Challenge:** Ownership consistency in shared mode  
  **Solution:** I embedded the creator’s network ID into stickman identifiers, ensuring a clear and reliable ownership check.

- **Challenge:** Balancing collaboration with restrictions.  
  **Solution:** I carefully separated drag events from frame editing logic, allowing remote stickmen to be moved but not edited.

---

## Next Week’s Roadmap

- Improve shared mode implementation.
- Improve export to video feature.
- Explore import stickmen from video using AI.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,vl=Object.freeze(Object.defineProperty({__proto__:null,default:ha},Symbol.toStringTag,{value:"Module"})),ga=`---
title: "GSoC ’25 Week 11 Update by Mebin J Thattil"
excerpt: "Deploying SugarAI Continued"
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-gsoc-25-mebinthattil-week11"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week11,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"
---

# Week 11 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-10 - 2025-08-17

---

## Goals for This Week

- **Goal 1:** Finish deployment of SugarAI and start with integration
  - **Subgoal 1:** Nginx proxy pass
  - **Subgoal 2:** SSL Certificates
  - **Subgoal 3:** \`A record\` creation and launch of [ai.sugarlabs.org](https://ai.sugarlabs.org)
  - **Subgoal 4:** Google OAuth and Github OAuth for login

---

## This Week’s Progress

### **1. Finishing up deployment**

- The nginx proxy was created. It maps \`port 8000\` to \`port 443\`, enabling HTTPS access.
The setup looks like:
\`\`\`nginx
server {
    server_name ai.sugarlabs.org;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    listen 443 ssl; # managed by Certbot
    ssl_certificate /etc/letsencrypt/live/ai.sugarlabs.org/fullchain.pem; # managed by Certbot
    ssl_certificate_key /etc/letsencrypt/live/ai.sugarlabs.org/privkey.pem; # managed by Certbot
    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot


}

server {
    listen 443 ssl;
    server_name ai.sugarlabs.org;

    ssl_certificate /etc/letsencrypt/live/ai.sugarlabs.org/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/ai.sugarlabs.org/privkey.pem;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
\`\`\`
- Next, the SSL certificates were created using [Let's Encrypt and Certbot](https://letsencrypt.org/).
- An \`A record\` was created pointing to the static IP of our EC2 instance. The service can now be accessed at : [ai.sugarlabs.org](https://ai.sugarlabs.org/)
- The Google OAuth was set up and registered under the google cloud account of \`mebin@sugarlabs.org\`. The Github OAuth is yet to be done. (_If any changes / support is needed related to Google OAuth in the future, you can reach out to me at [mail@mebin.in](mailto:mail@mebin.in)_)


So finally SugarAI is live!! You can access it via the API. For docs take a look at the [README](https://github.com/sugarlabs/sugar-ai?tab=readme-ov-file#test-api-endpoints).

---

## Next Week’s Roadmap

- Integration of LLM as brains
- Write a \`network_status.py\` script or a function to check if user is connected to internet and decide which brain to use for chatbot (LLM / SLM) based on connectivity.
- Work on personas implementation and UI changes required for that.
- UI accomodation for accepting API key for SugarAI.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for their ongoing support. Special thanks to [Krish](https://www.sugarlabs.org/authors/krish-pandya), who also helped with the deployment and development of SugarAI.

---`,Sl=Object.freeze(Object.defineProperty({__proto__:null,default:ga},Symbol.toStringTag,{value:"Module"})),ma=`---
title: "GSoC '25 Week 11 Update by Nikhil Bhatt"
excerpt: "Focused on writing detailed backend and frontend documentation for MusicBlocks, improving developer onboarding and API clarity."
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-gsoc-25-nikhilbhatt-week11"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,week11,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Reporting Period:** 2025-08-11 – 2025-08-17  

---

## This Week's Achievements

This week was heavily centered on **documentation** for both the backend and frontend of MusicBlocks. The goal was to make the project easier to understand, set up, and contribute to for future developers.

### **Backend Documentation**
- Wrote a comprehensive README detailing the backend's purpose, high-level design, and tech stack (Node.js, Express, TypeScript).
- Documented **all API endpoints** with request/response examples:
  - \`create\`, \`edit\`, \`fork\`, \`forkHistory\`, \`create-pr\`, \`openPR\`, \`commitHistory\`, \`getProjectData\`, etc.
- Added detailed **setup and configuration instructions**, including GitHub App requirements and \`.env\` variables.
- Described **metadata file structure** (\`projectData.json\`, \`metaData.json\`) and their role in authentication and PR workflows.
- Included **security best practices** and notes for production readiness.
- Added developer instructions for **building, linting, and running tests**.

### **Frontend Documentation**
- Created a dedicated guide explaining **how the frontend integrates with the Git-backed backend**.
- Documented **UI flows** (initialize repo, push changes, fork, browse projects, download ZIPs).
- Mapped out **frontend API contracts**, including expected shapes for \`getProjectData\` vs \`getProjectDataAtCommit\`.
- Described **localStorage keys** used by the frontend and their purpose.
- Added **manual test checklist** and troubleshooting tips.
- Clarified **legacy Planet server** replacement strategy and GitHub-based workflows.

### **Developer Experience Improvements**
- Consolidated documentation into a structured format, covering both **high-level workflows** and **low-level API details**.
- Added diagrams and examples to reduce ambiguity for new contributors.
- Made the docs self-contained: anyone can now set up backend + frontend and understand the full flow without tribal knowledge.

---

## Challenges & How I Solved Them

- **Challenge:** Explaining complex Git-backed workflows clearly for both backend and frontend.  
  **Solution:** Used request/response examples, flow diagrams, and separated sections for quick starts vs deep dives.

- **Challenge:** Ensuring documentation reflects **actual code behavior** accurately.  
  **Solution:** Verified each API contract and frontend integration manually, creating a **manual test checklist** to validate workflows.

- **Challenge:** Maintaining consistency between backend and frontend docs.  
  **Solution:** Standardized naming conventions and cross-referenced related sections in both documentation sets.

---

## Key Learnings

- Writing clear, detailed documentation is as impactful as writing code — it **lowers the barrier to entry** for future contributors.
- Learned how to **document APIs effectively**, including authentication flows, request shapes, and edge cases.
- Realized the importance of documenting **project history and future improvements**, making the project more maintainable.

---

## Next Week's Roadmap

- Collect feedback from mentors and community on the documentation usability.
- Add **deployment and CI/CD guides** for backend and frontend.
- Continue refining contributor guides (including coding standards and PR workflows).

---

## Resources & References

- [MusicBlocks Frontend Repo](https://github.com/sugarlabs/musicblocks)
- [musicblocks-backend](https://github.com/benikk/musicblocks-backend)
- [octokit GitHub SDK](https://github.com/octokit/octokit.js)
- [JSDoc](https://jsdoc.app/)

---

## Acknowledgments

Thanks to my mentors and the Sugar Labs community for providing feedback and guidance while drafting the documentation.  
This week’s work makes the MusicBlocks Git backend easier to adopt and extend — a key step towards long-term sustainability and community contributions.

`,Il=Object.freeze(Object.defineProperty({__proto__:null,default:ma},Symbol.toStringTag,{value:"Module"})),pa=`---
title: "GSoC '25 Week 11 Update by Safwan Sayeed"
excerpt: "Integration of Engine with Masonry"
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-gsoc-25-safwan-sayeed-week11"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week11,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-08-11 - 2025-08-17

---

## A Blog-style Retrospective

This Week Me and [Justin](https://github.com/justin212407) collaborated on the Integration of the Engine with the Masonry. We worked on aligning the Engine's execution model with the Masonry's architecture, ensuring seamless communication and data flow between the two components.

---

## Goals for This Week

- Collaborate with Justin on the integration of the Engine with the Masonry.
- Identify potential challenges and solutions for the integration process.
---

## This Week's Highlights

- **Collaboration with Justin:**  
  Worked closely with Justin to align the Engine's execution model with the Masonry's architecture, ensuring seamless integration and communication between the two components.
- **Identifying Challenges:**  
  Identified potential challenges in the integration process, including data flow issues and synchronization concerns, and brainstormed solutions to address them.

---

## Challenges & Solutions

- **Integration Complexity:**  
  The integration of the Engine with the Masonry presented challenges related to data flow and synchronization. To address these, we established clear communication protocols and data handling procedures between the two components.

---

## Key Learnings

- Gained insights into the intricacies of integrating different system components, particularly in terms of data flow and synchronization.
- Developed a better understanding of the Masonry's architecture and how it interacts with the Engine.

---

## Next Week's Roadmap

- **Think about the creation of Bricks as Plugins and then Connecting them with the Engine:**  
  Explore how the Engine can support the creation of Bricks as Plugins, allowing for greater flexibility and modularity in the system architecture.

---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their invaluable support and guidance throughout this project.

---`,Al=Object.freeze(Object.defineProperty({__proto__:null,default:pa},Symbol.toStringTag,{value:"Module"})),ba=`---
title: "GSoC '25 Week 11 Update by Krish Pandya"
excerpt: "Tray Widgets, Activity Examples, and More!"
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-gsoc-25-mostlyk-week11"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week11,mostlyk,tray,activity updates"
image: "assets/Images/GSOC.webp"
---

# Week 11: Tray Widgets, Activity Examples, and More

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)

**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)

**Reporting Period:** August 10, 2025 – August 17, 2025

---

## Trays, Activities

This after updating the datastore and objectchooser modules, I focused on porting the tray widget and updated the Activity.py even more featuring all the old used components of the GTK3 Toolkit.

## What’s New This Week?

### Presence

- Integrated the Presence from previous GTK3 toolkit into the new GTK4 toolkit.
- Communication between activities is now possible using the Presence.

### Activity Expansion

- Updated to handle all the old components of the GTK3 toolkit. Except the 2 Bundling methods.
- Demonstrated using 2 new examples.

#### Simple Activity Example

- Demonstrates basic usage of the new toolkit components.
- Allows saving and loading text files using the new modules.
- Showcases the integration of various widgets and functionalities.

#### Additional Activity Example

- Showcases more complex way of integrating Custom Widgets.
- Users can draw shapes, use tools from toolbar and save as well as preview drawings.

### Documentation

- With the library maturing, we have to fake root some stuff while running on local machines.
- Added how to present metadata and how to fake root in the README.

## VM Testing

- Tested the new library on a VM with Fedora 42 SoaS.

## Closing Thoughts and Next Steps

- The library has matured enough that I should start documenting for the last weeks and future plans for the contributors on how to continue from here and where it leads on.
- Start doing sphinx documentation for the library. (_foreshadowing as it has already been started at the time of writing this_)
- Bundle discussion with mentors for next week’s blog post.

---

## Resources & Links

- [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [New C Library (sugar-ext)](https://github.com/sugarlabs/sugar-ext)
- [Game Demo Video](https://youtu.be/B517C_LTCns)
`,Tl=Object.freeze(Object.defineProperty({__proto__:null,default:ba},Symbol.toStringTag,{value:"Module"})),fa=`---
title: "GSoC’25 Week 11 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-gsoc-25-omsuneri-week11"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week11,Debugger,AI,Music Blocks"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-08-11 - 2025-08-17

---

## Goal for This Week

**Finalize and polish the entire AI debugger stack (frontend + backend) to make it production-ready and suitable for upstream merge.**

---

## This Week’s Achievements

### Introduction

This week, my main focus was on **refining the entire debugger system** to ensure it is **production-ready** and can be safely merged upstream. I worked on polishing both the **frontend widget code** and the **FastAPI backend**, improving code structure, adding helpful logs for developers, handling errors gracefully, and cleaning up the overall implementation. Additionally, I added a proper license to align with community standards. With these changes, the AI-powered debugger is now stable, clean, and ready for long-term maintenance.

### What I Did

### 1. Widget Code Finalization

This week was all about **refining the AI debugger widget** both in terms of **code quality** and **developer ergonomics**.

**Key frontend changes (\`aidebugger.js\`):**

- Improved user interaction with subtle **focus/hover effects** for input fields and buttons.
- Added internal logging with \`console.log()\` for:

  \`\`\`js
  console.log("AI Debugger Backend URL:", BACKEND_CONFIG.BASE_URL);
  \`\`\`

* Handled backend connection failures gracefully with:

  \`\`\`js
  if (!response.ok) {
    throw new Error(\`HTTP \${response.status}: \${response.statusText}\`);
  }
  \`\`\`

* Provided consistent and timestamped system messages for events like:

  \`\`\`js
  this.activity.textMsg(_("Conversation reset."));
  \`\`\`

* Fine-tuned backend call structure and payload tracking via:

  \`\`\`js
  const payload = {
    code: projectData,
    prompt: message,
    history: history,
    prompt_count: this.promptCount
  };
  \`\`\`

---

### 2. Backend API Polishing

**Major changes in [\`api.py\`](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks/blob/main/app/api.py):**

* Added **robust logging** to help developers track error sources:

  \`\`\`python
  print(f"Received request data: {data}")
  print(f"Parsed - code length: {len(raw_json_code)}, prompt: '{user_prompt}'")
  \`\`\`

* Improved **JSON decoding and validation**:

  \`\`\`python
  try:
      json_data = json.loads(raw_json_code)
  except json.JSONDecodeError as e:
      return JSONResponse(status_code=400, content={"error": f"Invalid JSON: {str(e)}"})
  \`\`\`

* Graceful fallback for context/LLM/embedding failure:

  \`\`\`python
  except Exception as e:
      context_chunks = []
  \`\`\`

* Introduced differentiated **system tone logic** based on interaction depth:

  \`\`\`python
  if prompt_count < 2:
      tone = "curious and friendly"
  else:
      tone = "direct and helpful"
  \`\`\`

* All responses are now guaranteed to be returned in a structured format:

  \`\`\`python
  return JSONResponse(content={ "response": gemini_response })
  \`\`\`

--- 

## Preview

The final debugger widget is now **live** — [merged upstream in this PR](https://github.com/sugarlabs/musicblocks/pull/4739)

<a href=""><img src="https://i.ibb.co/392LHzy8/Screenshot-2025-08-17-at-5-35-47-PM.png" alt="Music Blocks Debugger widget merged in upstream/master"/></a>

---

### Why It Matters

These refinements make the AI-powered debugger:

* **More maintainable** – future contributors now have logs and clean API traces.
* **More user-friendly** – better responsiveness and feedback for Music Blocks users.
* **Merge-ready** – all components (frontend/backend) are now clean, stable, and consistent with community standards.
* **Error-resilient** – prevents crashes due to malformed input or unexpected backend failure.

---

### Final Thoughts

Shipping a polished, production-grade AI-powered debugger required focused attention to **DX (Developer Experience)** and **UX (User Experience)**. Thanks to mentor and community feedback in the last few weeks, this week's progress made the system robust, responsive, and user-centric.

---

## Next Week’s Roadmap

For the **final week (Week 12)**, my goal is to deliver **two structured documentation guides**:

**Developer Guide**

* Architecture explanation
* Codebase walkthrough
* How to debug/debugger 😄
* How to contribute and maintain

**User Guide**

* How to use the Debugger widget
* Features of the AI assistant
* Examples of typical usage and benefits

These will be hosted within the project repository and made available via the in-app links.

## Resources & References

- **Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **Debugger Streamlit App:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)

## Acknowledgments

Grateful as always to my mentors and the Sugar Labs community especially for pushing me to meet upstream standards, prioritize accessibility, and always keep the **user's learning journey** front and center.

---
`,Pl=Object.freeze(Object.defineProperty({__proto__:null,default:fa},Symbol.toStringTag,{value:"Module"})),wa=`---
title: "SSoC ’25 Week 11 Update by Muhammad Haroon"
excerpt: "Test the changes and document the entire process."
category: "DEVELOPER NEWS"
date: "2025-08-17"
slug: "2025-08-17-ssoc-25-MuhammadHaroon-week11"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week11,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-11 - 2025-08-17

---

## Goals for This Week

- **Goal 1:** Test the changes and document the entire process.

---

## This Week's Achievements

1. **Test the changes**
    - I tested the changes and discovered a few bugs, which I then fixed.

2. **Create a Dockerfile for backend**
    - I successfully created the Dockerfile of the backend. It was designed so that users or anyone trying to test the backend locally can have a smooth experience without having to manage the dependencies.

3. **Document the code**
    - I completed the documentation of the backend code, wrote the Developer Guide of AI Sample Generation and Audio Trimmer feature in Music Blocks.
    - The User Guide is yet to be written. After discussing with my mentor, we decided to wait until another contributor finishes her work, as she would also be modifying the Sampler Widget UI. Once it is completed, I will write the User Guide.

---

## Key Learnings

- I learned about Docker, including how to write a Dockerfile.

---

## Next Week's Roadmap

- Deploy the backend on AWS.
- Write a detailed blog post summarizing everything I have done during my 12-week internship.

---

## Resources & References
- **Frontend Code** https://github.com/sugarlabs/musicblocks/pull/4740
- **Backend Code** https://github.com/haroon10725/AI-Sample-Generation-Backend
- **Developer Guide** https://github.com/sugarlabs/musicblocks/pull/4754

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Ml=Object.freeze(Object.defineProperty({__proto__:null,default:wa},Symbol.toStringTag,{value:"Module"})),ya=`---
title: "GSoC '25 Week 10 Update by Bishoy Wadea"
excerpt: "Magic Number Grid"
category: "DEVELOPER NEWS"
date: "2025-08-21"
slug: "gsoc-25-BishoyWadea-week10"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week10,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

# Week 10 Progress Report by Bishoy Wadea

**Project:** [Magic Number Grid](https://github.com/Bishoywadea/Magic-Number-Grid)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-08-18 – 2025-08-21  

---

## Goals for This Week

- **Develop new Sugar activity: Magic Number Grid**
- **Implement core Latin Square puzzle mechanics**
- **Add Sugar-compliant UI elements and features**

---

## Achievements

### Core Game Implementation

- **Game Logic Foundation**  
  Implemented Latin Square puzzle mechanics with grid generation and validation  
  [Commit](https://github.com/Bishoywadea/Magic-Number-Grid/commit/87f76cbba392252d3c7002830c1f4889a1e4401b)

- **Visual Identity**  
  Created custom activity icon following Sugar design guidelines  
  [Commit](https://github.com/Bishoywadea/Magic-Number-Grid/commit/605fcb7c92eab120cb9544b0b667c791f65a559f)

- **UI/UX Enhancements**  
  Fixed color scheme to match Sugar's visual standards for better accessibility  
  [Commit](https://github.com/Bishoywadea/Magic-Number-Grid/commit/c820cd105f423081aa6b1f9f4ae842210391a80c)

![Game Interface Screenshot](https://raw.githubusercontent.com/Bishoywadea/Magic-Number-Grid/refs/heads/main/screen_shots/01.png)
*Main game interface showing the grid and number selection buttons*

### Feature Development

- **Duplicate Number Warning**  
  Added visual feedback when players attempt to place duplicate numbers in rows/columns  
  [Commit](https://github.com/Bishoywadea/Magic-Number-Grid/commit/f9b557013677355284ae8138df730441921573be)

- **Difficulty Levels**  
  Implemented multiple difficulty settings to accommodate different skill levels  
  [Commit](https://github.com/Bishoywadea/Magic-Number-Grid/commit/f9a8793fbbaa7aa83d9afbb1d9e15dfa95544ec8)

- **Note-Taking System**  
  Added ability for players to make temporary notes in cells for strategic planning  
  [Commit](https://github.com/Bishoywadea/Magic-Number-Grid/commit/1a7d89e3eec48f19d96a2e33b93846cd9316ad74)

![Successful Completion](https://raw.githubusercontent.com/Bishoywadea/Magic-Number-Grid/refs/heads/main/screen_shots/03.png)
*Victory screen showing completed Latin Square puzzle*

---

## Challenges & Solutions

- **Challenge:** Creating an intuitive note-taking interface that doesn't clutter the main game view while remaining accessible to younger users.

- **Solution:**  
  - Implemented a toggle mode system that switches between number placement and note-taking
  - Added clear visual indicators for note mode activation
  - Fixed note button icon for better clarity
  - Used smaller font sizes for notes to distinguish them from actual answers

- **Challenge:** Balancing difficulty levels to ensure appropriate challenge for Sugar's target age group.

- **Solution:**  
  - Created multiple grid sizes (4x4, 6x6, 8x8) with varying pre-filled cells
  - Ensured all generated puzzles have unique solutions
  - Added progressive difficulty that starts easier for new players

---

## Key Learnings

- Gained experience in implementing constraint-satisfaction puzzles with guaranteed unique solutions
- Learned to design multi-modal interfaces (play mode vs. note mode) that remain intuitive for young users
- Improved understanding of Sugar's dialog system and how to create consistent pop-up experiences

---

## Next Week's Roadmap

- Begin development of new Sugar activity: **Rubik's Cube**
  - Research 3D rendering options compatible with Sugar
  - Design intuitive touch/click controls for cube manipulation
`,Cl=Object.freeze(Object.defineProperty({__proto__:null,default:ya},Symbol.toStringTag,{value:"Module"})),ka=`---
title: "GSoC '25 Week 11 Update by Shubham Singh"
excerpt: "Added SVGs, more instruments, auto arrange method in LegoBricks widget."
category: "DEVELOPER NEWS"
date: "2025-08-21"
slug: "2025-08-21-gsoc-25-firepheonix-week11"
author: "@/constants/MarkdownFiles/authors/shubham-singh.md"
tags:   
  - gsoc25
  - sugarlabs
  - week11
  - firepheonix
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Shubham Singh

**Project:** [Color Sensor for Music Blocks](https://github.com/sugarlabs/musicblocks/issues/4537)  
**Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-08-15 – 2025-08-21

---

## Goals for This Week

- Add support for other instruments
- Add new SVGs for Image and Webcam
- Auto arrange the pitches according to their order just like in the phrase maker.

---

## This Week's Achievements

1. **Added SVGs Corresponding to Camera Image and Live Webcam**   
    - Created custom SVG icons for the camera and webcam functionality using Figma, ensuring they match the existing Music Blocks design standards.
    - Maintained consistent sizing with other widget icons (24x24px) to preserve visual harmony across the interface.
      
        ![Adding it on Figma](/assets/Developers/Shubham_Singh/gsoc-25-week11-svgsOnFigma.webp)

        ![How it looks on Lego Bricks widget](/assets/Developers/Shubham_Singh/gsoc-25-week11-svgsAdded.webp)

2. **Added multiple instrument support and Auto Arrange Pitch according to frequency in Lego Bricks Widget.**  
   - Implemented a dropdown instrument selector that allows users to choose from various instruments including Electronic Synth (default), Piano, Guitar, Violin, and Drums.
   - Integrated the instrument selection with Music Blocks' existing audio engine to ensure proper sound synthesis and playback quality.
   - Each instrument maintains its unique timbral characteristics while preserving the pitch and timing information from the LEGO brick patterns.
   - Added instrument persistence so user selections are maintained throughout their session.

        ![Multiple instruments support](/assets/Developers/Shubham_Singh/gsoc-25-week11-multipleInstruments.webp)

   - Developed an intelligent auto-arrange feature that automatically sorts pitch blocks by frequency, mimicking the phrase maker's behavior.
   - The system detects when pitches are placed in incorrect order and rearranges them from lowest to highest frequency automatically.
   - This feature ensures musical coherence regardless of how users initially arrange their LEGO blocks, making the tool more user-friendly for beginners.
   - Implemented smooth visual transitions during auto-arrangement to help users understand the reordering process.

        ![Putting in wrong order](/assets/Developers/Shubham_Singh/gsoc-25-week11-wrongSVGOrder.webp)

        ![Automatically arranged themselves correctly](/assets/Developers/Shubham_Singh/gsoc-25-week11-autoArrange.webp)

---

## Challenges & How I Overcame Them

- **Challenge:** Ensuring consistent SVG rendering across different browsers and maintaining visual quality at various zoom levels while keeping file sizes minimal.    
  **Solution:** Used vector-based design principles in Figma and optimized SVG code by removing unnecessary elements and using relative units instead of fixed pixels.

- **Challenge:** Ensuring that multiple audio files were being accessed properly.   
  **Solution:** Ensured code modularity, how it's being used in the pie menu that allowed access to multiple instruments without having to have a lot many lines of code.

---

## Key Learnings

- **SVG Optimization:** Proper SVG optimization significantly impacts both file size and rendering performance. Using tools like Figma's export settings and manual code cleanup can reduce file sizes by up to 60% while maintaining visual quality.

- **User Experience Consistency:** Auto-arranging features should provide visual feedback to help users understand what's happening. Implementing smooth transitions and clear visual cues prevents confusion when the system automatically corrects user input.

---

## Next Week's Roadmap

- Optimize performance for larger LEGO brick arrangements.
- Begin work on comprehensive user documentation.
- Make Pull Request and final submissions for GSoC.
- Make Demo video for explaining how it works.

---

## Resources & References

- **Music Blocks Documentation:** https://github.com/sugarlabs/musicblocks/tree/master/documentation
- **LEGO Blocks Notation System Video:** https://youtu.be/LOfrCPf3XJU?feature=shared
- **Figma SVG Optimization Guide:** Used for creating efficient vector graphics
- **Music Blocks Audio Engine:** Referenced for instrument integration

---

## Acknowledgments

Thank you to my mentors [Walter Bender](https://github.com/walterbender) and [Devin Ulibarri](https://github.com/pikurasa) for invaluable guidance throughout this development phase. Special appreciation for their feedback on the instrument integration and auto-arrange functionality.

---`,Ll=Object.freeze(Object.defineProperty({__proto__:null,default:ka},Symbol.toStringTag,{value:"Module"})),va=`---
title: "GSoC ’25 Week 10 Update by Diwangshu Kakoty"
excerpt: "Reflection Widget"
category: "DEVELOPER NEWS"
date: "2025-08-22"
slug: "2025-08-22-gsoc-25-diwangshu-week10"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week10,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 10 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-08-05 - 2025-08-11  

---

## Goals for This Week

- **Goal 1:** Improved 'reflection' widget UI.
- **Goal 2:** Fixed a bug in sender name display.
- **Goal 3:** Simplified first message generation.
- **Goal 4:** Changed 'copy to clipboard' button to 'download text file' button.
- **Goal 5:** Fixed bugs occured by the new changes.

---

## This Week’s Achievements

1. **Improved 'reflection' widget UI**  
  - The three mentor buttons - "Rohan" as a mentor for general purpose, "Steve Job" as the coding mentor and "Ludwig van Beethoven" as the music mentor - have been moved to the sidebar. The buttons are now more visually appealing and easier to access.

  - "Rohan" is set to be the default mentor when the widget is opened. But the other two agents can be selected at any time during the conversation. They will respond in the style of their respective personas and ask relevant questions to their expertise.

  - Connectivity error messages now appear directly in the music block's error message box, ensuring a consistent user experience.

  - Add a minimum message requirement for using the analysis feature. Users now need at least 10 messages in their chat history before accessing it, ensuring the AI has sufficient context to produce a meaningful analysis.

  <a href="https://ibb.co/Cs5y9dxy"><img src="https://i.ibb.co/vvxWd52W/Screenshot-2025-08-22-233052.png" alt="reflection" border="0"></a>



2. **Fixed a bug in sender name display**
  - The sender name was not being displayed after the widget was re-opened. The message history was not storing the names of the agents. Now instead of "assistant", it will store the actual name of the agent.

3. **Simplified first message generation**
  - My mentor suggested that the first message generated by the bot was too complex for children to   understand. It included the project’s algorithm and asked the user to confirm if the guess was correct. The large text could overwhelm users. Therefore, I removed the algorithm from the message. It now simply asks if the guess is correct. This makes it easier for children to understand and respond.

  - The algorithm is still generated but it is kept in the system message. This way, the bot can refer to it later in the conversation if needed.

4. **Changed 'copy to clipboard' button to 'download text file' button**
  - The "copy to clipboard" button was not very useful, as users would have to manually paste the text somewhere. Now, the button allows users to download the chat history as a text file. This makes it easier for them to save and share their reflections.

---

## Next Week’s Roadmap

- Add loading animation while waiting for the bot's response.
- Try implementing streaming responses from the backend.
- I will deploy the backend on Sugar Lab's AWS server.

---

## Resources & References

- **Reflection widget development branch:** [reflection](https://github.com/Commanderk3/musicblocks/tree/reflection)
- **Fast API server:** [musicblocks_reflection_fastapi](https://github.com/Commanderk3/musicblocks_reflection_fastapi)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,xl=Object.freeze(Object.defineProperty({__proto__:null,default:va},Symbol.toStringTag,{value:"Module"})),Sa=`---
title: "DMP ’25 Week 12 Update by Aman Naik"
excerpt: "This week focused on implementing persistent storage for chat history by integrating with Sugar’s Journal, ensuring continuity for students across sessions."
category: "DEVELOPER NEWS"
date: "2025-08-16"
slug: "2025-08-16-dmp-25-AmanNaik-week12"
author: "@/constants/MarkdownFiles/authors/amannaik247.md"
tags: "dmp25,writeactivity,write,sugarlabs,week12,amannaik247"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Aman Naik

**Project:** [Add an AI-assistant to the Write Activity](https://github.com/sugarlabs/write-activity/issues/52)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Reporting Period:** 2025-08-16 – 2025-08-23  

---

## Goals for This Week

- Store chat history in the Sugar Journal for persistent storage  

---

## This Week’s Achievements

1. **Implemented Journal-based Chat History Persistence**  
   - Until now, conversations with Mary Tales were lost when the activity was closed, limiting continuity for students.  
   - Leveraging Sugar’s existing Journal integration, I extended the \`write_file\` method to save chat history alongside document text.  
   - This ensures that when students reopen the activity, whether the next day or after class, their previous chat is restored and they can continue seamlessly.  

   \`\`\`python
    def write_file(self, file_path):
        logging.debug('AbiWordActivity.write_file: %s, mimetype: %s',
                      file_path, self.metadata['mime_type'])
        
        # ... exiting code to save canvas text
        
        # Save conversation messages to metadata
        if hasattr(self, 'chat_sidebar') and hasattr(self.chat_sidebar, 'context') and hasattr(self.chat_sidebar.context, 'messages'):
            try:
                self.metadata['conversation'] = json.dumps(self.chat_sidebar.context.messages)
            except TypeError as e:
                logger.debug(f"Error serializing conversation messages in write_file: {e}")
    \`\`\`

2. **Refined Data Handling with Journal Metadata**  
   - Instead of generating separate JSON files for storing chat messages (which Sugar does not allow), I embedded serialized chat history into Journal metadata.  
   - This approach keeps all user data consolidated in a single entry, aligning with Sugar’s design philosophy of having one canonical record per activity session.  

---

## Challenges & How I Overcame Them

- **Challenge:** Finding a way to persist chat history without creating additional files  
  **Problem:** My first approach involved writing a JSON file every time the activity closed. However, Sugar prohibits programmatically creating arbitrary files within its environment.  
  **Solution:** After a discussion with my mentor Ibiam, I adopted Sugar’s built-in \`read_file\` and \`write_file\` methods to store metadata directly into the Journal entry. This allowed me to serialize and persist the chat state without breaking Sugar’s constraints.  

---

## Key Learnings

- Learned how to extend Sugar’s \`write_file\` and \`read_file\` methods to handle custom metadata, enabling persistent storage beyond just document text.  
- Understood the importance of designing within platform constraints, as Sugar discourages arbitrary file creation and instead enforces centralized data storage through the Journal.  
- Realized that persistent context is essential for educational UX, as students benefit from being able to revisit and build upon previous conversations across multiple sessions.  

---

## Next Week’s Roadmap

- Draft and finalize maintainer and user-facing documentation  
- Submit the final project reports  
- Prepare a presentation deck for the DMP final showcase  

---

## Acknowledgments

Thanks to my mentor Ibiam for pointing me towards Sugar’s Journal \`read_file\`/\`write_file\` workflow, which turned out to be the correct and elegant solution for persisting chat history.  

---
`,Gl=Object.freeze(Object.defineProperty({__proto__:null,default:Sa},Symbol.toStringTag,{value:"Module"})),Ia=`---
title: "GSoC ’25 Week 12 + Final Report by Mebin J Thattil"
excerpt: "Integrating everything, wrapping up the project & Final Report"
category: "DEVELOPER NEWS"
date: "2025-08-24"
slug: "2025-08-24-gsoc-25-mebinthattil-week12"
author: "@/constants/MarkdownFiles/authors/mebin-thattil.md"
tags: "gsoc25,sugarlabs,week12,mebinthattil,speak_activity"
image: "assets/Images/GSOCxSpeak.webp"

---

# Week 12 Progress Report by Mebin J Thattil

**Project:** [Speak Activity](https://github.com/sugarlabs/speak)  
**Mentors:** [Chihurumnaya Ibiam](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-17 - 2025-08-24 

---

## Goals for This Week

- **Goal 1:** Integration of LLM as brains  
- **Goal 2:** Write a script to check if user is connected to internet and choose the appropriate mode for chatbot (LLM or SLM)  
- **Goal 3:** Personas implementation
- **Goal 4:** UI changes to include the new features

---

## This Week’s Progress

### **1. Integration of LLM as brains**

Now that SugarAI was deployed I was finally able to integrate the LLM into speak! It was a fairly simple implementation. I just had to call the API and feed the response to kokoro once it passed the profanity checks. This is ofcourse only if the user is connected to internet and the SugarAI servers are up.

### **2. Script to check internet connectivity**

This is a fairly simple function that checks if the user is able to reach our servers that run SugarAI. Only if this is true will it send request to the servers.

### **3. Personas implementation**

Personas have been implemented! Each persona has a unique name, voice and personality. Personas are stored in \`personas.json\` and new personas can be created very easily by adding more to this file. Here is the current json file that show all the default personas:

\`\`\`json
{
  "Jane": {
    "voice": "af_bella",
    "prompt": "You are a friendly teacher named Jane who is 28 years old. You teach 10 year old children. Always give helpful, educational responses in simple words that children can understand. Keep your answers between 20-40 words. Be encouraging and enthusiastic but never use emojis(ever). If you notice spelling mistakes, gently correct them. Stay focused on the topic and give relevant answers."
  },

  "Dr.Sam": {
    "voice": "am_adam",
    "prompt": "You are Dr. Sam, a friendly and thoughtful doctor who enjoys talking to 10-year-old children about what it's like to be a doctor. You don’t give medical advice—you just explain how doctors help people, what hospitals are like, and how the human body works in fun, simple ways. Use clear, easy-to-understand language and keep your answers between 20–40 words. You're curious, caring, and always calm. You love when kids ask questions and you're happy to share what it's like to care for others. If there are any spelling mistakes, gently correct them. Stay focused on the topic and give helpful, encouraging answers. Sometimes you share neat facts about the body or how doctors train, always making learning feel safe and interesting."
  },

  "Captain Stella": {
    "voice": "am_santa",
    "prompt": "You are Captain Stella, an adventurous space explorer who loves teaching 10-year-old children about planets, stars, and the mysteries of the universe. Use simple words and keep answers between 20–40 words. Be enthusiastic and encourage curiosity about space. If children make spelling mistakes, gently correct them. Stay focused on space topics and give fun, educational answers."
  },

  "Professor Oakley": {
    "voice": "bm_george",
    "prompt": "You are Professor Oakley, a curious scientist who loves explaining experiments, nature, and how things work to 10-year-old children. Use simple, clear words and keep answers between 20–40 words. Be excited about learning and encourage questions. Gently correct spelling mistakes. Stay on topic and share interesting science facts."
  },

  "Liam the Football Player": {
    "voice": "am_liam",
    "prompt": "You are Liam, a fun and energetic football player who teaches 10-year-old children about teamwork, sportsmanship, fitness, and how practice helps improve skills. Use simple words and keep answers between 20–40 words. Be motivating and friendly. Gently correct spelling mistakes. Stay focused on sports topics and give helpful answers."
  },

  "Ollie the Owl": {
    "voice": "ef_dora",
    "prompt": "You are Ollie, a wise and curious owl who teaches 10-year-old children about nature, nighttime animals, and how to observe the world quietly and carefully. Use simple words and keep answers between 20–40 words. Be calm, patient, and encouraging. Gently correct spelling mistakes. Share interesting facts about animals and nature."
  }
}

\`\`\`

### **4. UI changes to include the new features**

The UI was updated to include all the new features like personas switching, voice switching etc. A new icon was made for the button to switch personas. 
![Personas Icon](https://raw.githubusercontent.com/mebinthattil/speak-ai/df1291828088316f4684569a56680e38e7e72491/icons/Personas_Icon.svg)


# Everything finally comes together

This marks the completion of a good MVP. I also made a demo showcasing all the new AI features. Note that this demo was shot before few things like the personas icon was changed, but shows how all the new features work.

*Demo:*
<iframe src="https://drive.google.com/file/d/1CZNywu1THdSUpR0my-UWqnZ4YhZ2BGkW/preview" width="840" height="480" allow="autoplay"></iframe>

---

## Final Report

### **Project Overview**

The objective of this GSoC project was to **modernize and enhance the Speak Activity** using gen-AI and transforming it from a simple text-to-speech tool into an intelligent, conversational learning companion. The project aimed to integrate modern TTS models, deploy both local Small Language Models (SLMs) and cloud-hosted Large Language Models (LLMs), and create an engaging persona-based interaction system for children.

### **Key Deliverables**
1. **Modern TTS Integration** - Replaced traditional espeak with Kokoro TTS for natural-sounding, multi-voice audio generation
2. **Dual Model System For Chatbot Brains** - Implemented both local SLM and cloud LLM as part of the chatbot mode
3. **SugarAI** - Deployed cloud infrastructure at [ai.sugarlabs.org](https://ai.sugarlabs.org) for hosting the LLMs. Used by other activities as well.
4. **Interactive Personas** - Created character based learning experiences with unique voices and personalities
5. **Comprehensive Safety Features** - Built profanity filters and child safe interaction mechanisms

All features are optimized for educational environments and resource constrained devices.

---

### **Project Timeline and Achievements**

#### **Phase 1: Research and Benchmarking (Weeks 1-3)**

**Week 1: Model Selection and Benchmarking**
- **LLM/SLM Evaluation:** Created a [Streamlit benchmarking app](https://llm-benchmarking-sugar.streamlit.app/) to compare different models
- **Dual-Model Architecture Discovery:** Experimented with generation + refinement approach using Gemma3-1B, achieving performance comparable to 30B parameter models
- **Resource Constraint Analysis:** Identified need for models under 100MB for packaging with Speak activity

**Week 2: Fine-tuning Infrastructure and Dataset Development**
- **AWS SageMaker Setup:** Provisioned GPU infrastructure for model training on \`ml.g5.2xlarge\` instances
- **Educational Dataset Creation:** Developed and cleaned [Education-Dialogue-Dataset](https://github.com/mebinthattil/Education-Dialogue-Dataset) with teacher-student conversations
- **Model Training:** Fine-tuned Llama3-1B with educational conversation patterns
- **Deployment Infrastructure:** Created model storage and API endpoint systems on AWS

**Week 3: Dataset Restructuring and Optimization**
- **Conversation Format Refinement:** Restructured dataset to prevent chain response generation issues
- **Model Behavior Analysis:** Identified and resolved conversational flow problems in fine tuned models
- **Training Optimization:** Developed improved training approaches for educational use cases

---

#### **Phase 2: TTS Integration and Voice Development (Weeks 4-6)**

**Week 4: Kokoro TTS Integration**
- **Modern TTS Implementation:** Successfully integrated Kokoro TTS with minimal additional dependencies
- **Voice Catalog Access:** Enabled entire collection of Kokoro voices for different personas
- **Audio Pipeline Development:** Built temporary WAV file approach as initial implementation
- **Dependency Optimization:** Swapped Kokoro's fallback from espeak-ng to espeak to reduce dependencies
- **Community Testing Platform:** Deployed [voice mixing web app](https://newstreamlit-frontend.blackpond-9921706d.eastus.azurecontainerapps.io/) for feedback collection

**Week 5: SLM Development and Quantization**
- **Lightweight Model Training:** Fine-tuned [Llama 135M](https://huggingface.co/amd/AMD-Llama-135m) on educational dataset
- **Size Optimization:** Achieved ~500MB model size with potential for further quantization
- **Performance Evaluation:** Benchmarked model performance against larger alternatives
- **Dataset Quality Improvement:** Enhanced training data with better conversational patterns

**Week 6: Dataset Enhancement and Performance Optimization**
- **Comprehensive Dataset Revision:** Created higher-quality training data using Gemini for teacher-child conversation patterns
- **Model Re-training:** Conducted multiple fine-tuning iterations with improved datasets
- **Performance Analysis:** Formal benchmarking against 50-question evaluation set
- **Size Constraint Solutions:** Achieved critical component sizes:
  - **TTS:** 0.7MB base + 0.5MB per additional voice
  - **SLM:** 82.6MB
  - **Llama.cpp:** 2MB (if using distributed binaries)

---

#### **Phase 3: Infrastructure and Streaming Optimization (Weeks 7-9)**

**Week 7: Community Feedback and Platform Deployment**
- **Comprehensive Model Benchmarking:** Added all 16 fine-tuned SLM variants to [benchmark comparison](https://slm-benchmark.streamlit.app/)
- **AWS Infrastructure Success:** Secured G-series GPU instances after multiple service limit requests
- **Model Repository Organization:** Created [comprehensive model collection](https://huggingface.co/MebinThattil/models) on Hugging Face
- **Community Evaluation Platform:** Deployed benchmarking tools for community model selection

**Week 8: Audio Streaming and Safety Features**
- **GStreamer Optimization:** Implemented direct audio streaming from Kokoro to GStreamer using \`appsrc\` element
- **Platform-Agnostic Inference:** Replaced compiled binaries with \`llama-cpp-python\` for cross-platform compatibility
- **Safety Implementation:** Built comprehensive profanity filtering system with base64-encoded word lists
- **Latency Reduction:** Achieved significant performance improvements through streaming architecture

**Week 9: Critical Bug Fixes and System Integration**
- **Mouth Movement Synchronization:** Resolved timing issues through three iterations of optimization
- **Audio Pipeline Sync:** Achieved synchronization between voice output and mouth movements
- **System Architecture Completion:** Integrated all components into cohesive Speak activity

---

#### **Phase 4: Cloud Infrastructure and Final Integration (Weeks 10-12)**

**Week 10: SugarAI Deployment**
- **Cloud Infrastructure:** Successfully deployed SugarAI on AWS EC2 with G5 GPUs
- **Containers:** Implemented Docker-based deployment with GPU acceleration
- **Network Security:** Configured secure inbound rules limiting access to HTTPS and SSH only
- **Service Architecture:** Established foundation for public API accessibility

**Week 11: Production Deployment and Security**
- **SSL Certificate Integration:** Implemented Let's Encrypt certificates for secure HTTPS access
- **Nginx Proxy Configuration:** Created proxy setup mapping internal services to public endpoints
- **DNS Configuration:** Established A record for [ai.sugarlabs.org](https://ai.sugarlabs.org) domain
- **Authentication Systems:** Integrated Google OAuth under Sugar Labs organization
- **Public API Launch:** Made SugarAI publicly accessible with comprehensive API documentation

**Week 12: Complete System Integration**
- **LLM Integration:** Connected cloud-hosted LLM to Speak activity for enhanced conversations
- **Intelligent Mode Switching:** Implemented automatic fallback between LLM (online) and SLM (offline) based on connectivity
- **Personas System:** Deployed character-based learning with unique voices and personalities
- **UI Enhancement:** Complete interface update accommodating all new AI-powered features
- **Production Demo:** Created comprehensive demonstration showcasing all integrated features

---

### **Repositories and Resources**

#### **Core Repositories**
- [SpeakAI Activity](https://github.com/sugarlabs/speak-ai)
- [PR to SpeakAI](https://github.com/sugarlabs/speak-ai/pull/1)
- [Benchmarking Tools](https://github.com/mebinthattil/LLM-benchmarking)
- [Educational Dataset](https://github.com/mebinthattil/Education-Dialogue-Dataset)
- [Model Archive](https://github.com/mebinthattil/Fine-Tune-Attempts-LlaMA-135)
- [Kokoro Integration](https://github.com/mebinthattil/Kokoro-FastAPI)

#### **Testing Platforms**
- [Model Benchmarking](https://llm-benchmarking-sugar.streamlit.app/)
- [SLM Comparison](https://slm-benchmark.streamlit.app/)
- [Voice Testing](https://newstreamlit-frontend.blackpond-9921706d.eastus.azurecontainerapps.io/)

#### **Model Collection**
[16+ fine-tuned models](https://huggingface.co/MebinThattil/models) on Hugging Face

---

### **Acknowledgments**

Thanks to mentors **Chihurumnaya Ibiam** and **Kshitij Shah**, assisting mentors **Walter Bender** and **Devin Ulibarri**, and the Sugar Labs community.

---

### **Conclusion**

This project transformed the Speak Activity from basic text-to-speech into an intelligent learning companion. The hybrid model architecture ensures accessibility regardless of connectivity, while personas make learning engaging through specialized characters. The SugarAI platform provides scalable infrastructure for future Sugar activities.

The modernized Speak activity demonstrates how AI can enhance education while maintaining offline functionality and resource efficiency for all students globally.

---

`,Wl=Object.freeze(Object.defineProperty({__proto__:null,default:Ia},Symbol.toStringTag,{value:"Module"})),Aa=`---
title: "GSoC '25 Week 12 Update by Safwan Sayeed"
excerpt: "Integration of Engine with Masonry"
category: "DEVELOPER NEWS"
date: "2025-08-24"
slug: "2025-08-24-gsoc-25-safwan-sayeed-week12"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,week12,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Safwan Sayeed

**Project:** Music Blocks 4 Program Engine  
**Mentors:** [Anindya Kundu](https://github.com/meganindya/), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ullibari](https://github.com/pikurasa/), [Walter Bender](https://github.com/walterbender)  
**Reporting Period:** 2025-08-18 - 2025-08-24

---

## A Blog-style Retrospective

This Week Me and [Justin](https://github.com/justin212407) discussed on the Creation of Bricks as Plugins and their Integration with the Engine.

---

## Goals for This Week

- Collaborate with Justin on the creation of Bricks as Plugins and their integration with the Engine.
- Identify potential challenges and solutions for the integration process.
---

## This Week's Highlights

- **Collaboration with Justin:**  
  Worked closely with Justin to explore the creation of Bricks as Plugins and their integration with the Engine.
- **Identifying Challenges:**  
  Identified potential challenges in the integration process, including plugin architecture and communication protocols, and brainstormed solutions to address them.

---

## Challenges & Solutions

- **Plugin Architecture:**  
  The creation of Bricks as Plugins introduced challenges related to plugin architecture and communication protocols. To address these, we established clear guidelines for plugin development and integration with the Engine.

---

## Key Learnings

- Gained insights into the intricacies of creating a plugin architecture, particularly in terms of modularity and communication between components.
- Developed a better understanding of the Engine's capabilities and how they can be leveraged to support plugin-based development.

---

## Resources & References

- **Repository:** [musicblocks-v4](https://github.com/sugarlabs/musicblocks-v4)

---

## Acknowledgments

Special thanks to my mentors Anindya, Sumit, Devin, and Walter for their invaluable support and guidance throughout this project.

---`,Dl=Object.freeze(Object.defineProperty({__proto__:null,default:Aa},Symbol.toStringTag,{value:"Module"})),Ta=`---
title: "GSoC’25 Week 12 Update by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-24"
slug: "2025-08-24-gsoc-25-omsuneri-week12"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,week12,Debugger,AI,Music Blocks,Final Submission"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Om Santosh Suneri

**Project:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender/) [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa/)  
**Reporting Period:** 2025-08-21 - 2025-08-24

---

## Goal for This Week

The **primary objective** for this final week of Google Summer of Code 2025 was to **refactor and modularize the backend FastAPI server**, enabling it to operate **independently from the Streamlit frontend**. Additionally, I aimed to make the project **production-ready by deploying it on an AWS EC2 instance using systemd**, allowing continuous availability of the service.

Alongside the deployment, I also worked on **documenting the complete contributor and user experience**, ensuring that **future contributors and users can easily get started** with the AI Debugger system.

---

## This Week’s Achievements

### Backend Independence from Streamlit

One of the **most important milestones** of this week was separating the **FastAPI backend** from the **Streamlit app**. Previously, the backend was tightly coupled with the Streamlit interface, limiting flexibility. I restructured the repository and added an **independent \`api.py\` file** that runs **Uvicorn as a FastAPI app**, making it easier to scale, test, and deploy.

\`\`\`bash
# Now the backend can be launched directly with:
python -m uvicorn app.api:app --host 0.0.0.0 --port 8000
\`\`\`

This approach aligns with production-grade practices and allows the **Streamlit app and FastAPI backend to scale independently**.


### Production Deployment on AWS EC2 with systemd

To ensure the backend could **serve users 24/7**, I set up a **dedicated EC2 instance** on AWS and deployed the backend using a \`systemd\` service.

Here’s a breakdown of the finalized configuration:

\`\`\`ini
[Unit]
Description=Debugger for Music Blocks - FastAPI backend
After=network.target

[Service]
User=ubuntu
WorkingDirectory=/home/ubuntu/AI-powered-Debugger-for-Music-Blocks
ExecStart=/home/ubuntu/AI-powered-Debugger-for-Music-Blocks/venv/bin/python -m uvicorn app.api:app --host 0.0.0.0 --port 8000
Restart=always
RestartSec=5
Environment=PYTHONUNBUFFERED=1

[Install]
WantedBy=multi-user.target
\`\`\`

**Key Highlights:**

* \`ExecStart\` runs Uvicorn directly from the virtual environment, ensuring environment consistency.
* \`Restart=always\` allows **automatic recovery** in case of backend crashes.
* Using \`systemctl\`, I enabled and started the service:

\`\`\`bash
sudo systemctl daemon-reload
sudo systemctl enable debugger.service
sudo systemctl start debugger.service
\`\`\`

This ensures the backend remains **persistent and robust**, especially under real-world usage.


### Contributor Documentation

To make the project **accessible for new developers**, I authored the **AI-powered Debugger Widget - Contributor Guide**, which outlines the full stack — from the frontend widget integration to backend architecture.

Some key highlights:

* **Architecture Overview**:

<a href=""><img src="https://i.ibb.co/CK8qXhfm/Screenshot-2025-08-22-at-12-34-44-AM.png" alt="Debugger Architecture"></a>

* **API Interaction Sample**:

  \`\`\`js
  fetch("http://13.49.246.243:8000/analyze", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      code: projectData,
      prompt: message,
      history: history,
      prompt_count: this.promptCount
    })
  });
  \`\`\`

📎 [Contributor Guide on GitHub](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/js/widgets/aidebugger-guide.md)


### User Guide & Demo Video

To assist end-users, especially **students, teachers, and parents**, I published a **visually engaging User Guide** along with a demo video:

<a href=""><img src="https://i.ibb.co/93HCW8hC/Screenshot-2025-08-22-at-12-45-48-AM.png" alt="AI-Powered Debugger Widget Demo"/></a>

**🎥 [Click to Watch the Demo Video](https://www.youtube.com/watch?v=G-NfDo_A5PM)**

This guide explains:

* How to drag and use the AI Debugger widget
* Example questions to ask the AI
* How the AI assistant explains errors and suggests fixes

📘 [AI-Powered Debugger Widget Guide](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/AI-Debugger-widget-guide.md)

---

### Why It Matters

This week's work marks a **significant transition from development to deployment**. By **decoupling the backend**, setting up **system-level service management**, and providing **comprehensive documentation**, the project is now **fully production-ready**.

This effort makes the **AI Debugger more scalable**, **developer-friendly**, and **accessible to educators and learners** across the Sugar Labs community. Now, **Music Blocks users can rely on a stable, intelligent assistant** to help them debug their musical creations in real time.

---

### Final Thoughts

As this marks the **final official week of Google Summer of Code 2025**, I want to take a moment to reflect on this incredible journey.

Working on this project has not only sharpened my technical skills in **FastAPI**, **Streamlit**, **systemd**, **deployment pipelines**, and **full-stack architecture**, but also introduced me to the **open-source world** in the most collaborative way possible. I’m **deeply grateful** to my mentors and the Sugar Labs community for their continuous support and guidance.

Building the AI-powered Debugger has been **one of the most fulfilling experiences** of my development journey so far. The ability to contribute to something that helps kids **learn music and programming more easily** makes me feel proud and inspired for future contributions.

---

## Resources & References

* **Backend Repository**: [AI Debugger](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
* **Frontend Widget Code**: [Music Blocks Repository](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/js/widgets/aidebugger.js)
* **Documentation**: [Contributor Guide](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/js/widgets/aidebugger-guide.md) | [User Guide](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/AI-Debugger-widget-guide.md)
* **Demo Video**: [Watch on YouTube](https://www.youtube.com/watch?v=G-NfDo_A5PM)

---

## Acknowledgments

Huge thanks to my mentors **Walter Bender**, **Sumit Srivastava**, and **Devin Ulibarri** for their mentorship, trust, and encouragement throughout the summer.

Thanks also to the **Sugar Labs community** for welcoming me and providing constant feedback and motivation.

I look forward to staying active in this community, contributing more, and supporting new learners through the tools we’ve built together.

---
*Made with ❤️ for Music, Open Source, and Learning.*

`,_l=Object.freeze(Object.defineProperty({__proto__:null,default:Ta},Symbol.toStringTag,{value:"Module"})),Pa=`---
title: "SSoC ’25 Week 12 Update by Muhammad Haroon"
excerpt: "Deploying the backend on AWS and My Journey in the Sugar Summer of Code 2025"
category: "DEVELOPER NEWS"
date: "2025-08-24"
slug: "2025-08-24-ssoc-25-MuhammadHaroon-week12"
author: "@/constants/MarkdownFiles/authors/muhammad-haroon.md"
tags: "ssoc25,sugarlabs,week12,GenAI,MusicBlocks,Music"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Muhammad Haroon

**Project:** [Generative AI Instrument Sample Generation for Music Blocks](https://github.com/sugarlabs/GSoC/blob/master/Ideas-2025.md#Generative-AI-Instrument-Sample-Generation-for-Music-Blocks)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-18 - 2025-08-24

---

## Goals for This Week

- **Goal 1:** Deploy the backend on AWS.
- **Goal 2:** Write a detailed blog post summarizing everything I have done during my 12-week internship.

---

## This Week's Achievements

1. **Deploy the backend on AWS**
    - To deploy the backend on AWS, I reached out to Ibiam and Mebin on the Sugar System channel for guidance. Mebin suggested that I create my own account, as AWS provides free credits to new users, and try deploying there to get familiar with the process since I was new to it and we didn’t want to use Sugar AI credits unnecessarily. I created my own AWS Free Tier account, launched an EC2 instance, after following several blogs and tutorials, I was able to deploy it successfully.

    - However, since I was using the Free Tier, the instance ran out of memory and stopped automatically when accessing the URL. I believe that deploying on SugarLabs AWS, which is a Paid Tier account, would provide more memory and higher resource limits.

    - Although I couldn’t fully deploy the backend in a production-ready way, the process taught me a lot about AWS and deployment practices.

---

## My Journey in the Sugar Summer of Code 2025

- Participating in the Sugar Summer of Code 2025 has been an incredible experience where I learned many new skills and gained hands-on knowledge.

- The first six weeks of the internship were exciting, mostly focused on conducting experiments to find the best model for AI Sample Generation. I learned how to properly carry out experiments. Unfortunately, the current models are not very effective at generating useful instrument samples, they are good at producing sound effects. It was then decided to use these models to generate audio, trim specific segments with an audio trimmer and then import the trimmed audio into Music Blocks.

- The last six weeks were mostly spent creating user interface sketches and then implementing them in Music Blocks. I also developed a FastAPI application to connect the backend with the frontend. To simplify setup and avoid dependency issues, I created a Docker image of the backend. Additionally, I attempted to deploy it on AWS. Comprehensive documentation was prepared for the backend, detailing how it can be easily set up, along with a Developer Guide for the frontend.

- All of my blog posts can be found here: [Muhammad Haroon Blogposts](https://www.sugarlabs.org/authors/muhammad-haroon)

- Finally, I would like to thank Sugar Labs, [Devin Ulibari](https://github.com/pikurasa) and [Walter Bender](https://github.com/walterbender) for providing me with this wonderful opportunity and for the guidance throught the journey.

- The following video demonstrates the AI Sample Generation and Audio Trimmer feature in Music Blocks:

[youtube: ctXpf4dzln4] 

---

## Key Learnings

- Gained hands-on experience with AWS.

---

## Future Goals

- Deploy the backend on Sugar Labs AWS account.
- Create a User Guide for frontend.
- Continue contributing to Sugar Labs and Music Blocks and assisting new contributors. 

---

## Resources & References
- **Frontend Code** https://github.com/sugarlabs/musicblocks/pull/4740
- **Backend Code** https://github.com/haroon10725/AI-Sample-Generation-Backend
- **Developer Guide** https://github.com/sugarlabs/musicblocks/pull/4754

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,El=Object.freeze(Object.defineProperty({__proto__:null,default:Pa},Symbol.toStringTag,{value:"Module"})),Ma=`---
title: "DMP ’25 Week 11 Update by Harshit Verma"
excerpt: "This week I focused on implementing the \`/debug\` endpoint in Sugar-AI, which will serve as the backbone for the Pippy Debugger."
category: "DEVELOPER NEWS"
date: "2025-08-25"
slug: "2025-08-25-dmp-25-therealharshit-week11"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week10,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-11 - 2025-08-17   

---

## Goals for This Week

- **Goal 1:** Implement a new \`/debug\` endpoint in **Sugar-AI**.  
- **Goal 2:** Ensure the endpoint integrates cleanly with the upcoming **Pippy Debugger**.  
- **Goal 3:** Raise a pull request for mentor review and feedback.  

---

## This Week’s Achievements

1. **Implemented \`/debug\` Endpoint in Sugar-AI**  
   - Designed and developed a new API endpoint to handle debugging requests from the Pippy Debugger.  
   - This forms the **core backend logic** enabling the LLM to analyze learners’ code and provide debugging help.  
   - PR: [sugarlabs/sugar-ai/pull/28](https://github.com/sugarlabs/sugar-ai/pull/28)  

2. **Prepared Code for Integration with Pippy**  
   - Structured the API so that it can be directly connected with the Pippy Activity.  
   - This ensures seamless integration of Sugar-Ai with Pippy.  

---

## Challenges & How I Overcame Them

- **Challenge:** Defining a clean and scalable API design for debugging.  
  **Solution:** Discussed with mentors, studied common debugging APIs, and created a minimal but extensible structure.  

---

## Key Learnings

- Learned how to effectively work with LangChain for building modular and flexible AI pipelines.  
- Gained experience in implementing multiple LLM calls within a single chain to generate more context-aware and appropriate debugging responses.

---

## Next Week’s Roadmap

- Further refine **debug responses** for edge cases based on mentors feedback.  
- Work on improving the debugger ui/ux if required.  
- Start the work on saving debug history to sugar journal.  

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,jl=Object.freeze(Object.defineProperty({__proto__:null,default:Ma},Symbol.toStringTag,{value:"Module"})),Ca=`---
title: "GSoC '25 Week 15 Update by Aditya Kumar Singh"
excerpt: "Enhanced shared mode position handling, optimized export-to-video with bounding box stabilization, and introduced AI-based stickman import from video."
category: "DEVELOPER NEWS"
date: "2025-08-25"
slug: "2025-08-25-gsoc-25-AdityaKrSingh26-week15"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week15,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 15 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-08-21 - 2025-08-27

---

## Goals for This Week

- **Goal 1:** Improve shared mode to preserve relative positions and refine deletion logic.
- **Goal 2:** Optimize export-to-video using adaptive bounding box recording.
- **Goal 3:** Add feature to import stickman animation from real videos using AI.

---

## This Week's Achievements

1. **Enhanced Shared Mode Implementation**  
  Previously, when a user dragged a stickman in shared mode, positions were reset whenever remote updates arrived. I introduced relative position preservation:
    - Maintains a local offset for each remote stickman in \`remoteStickmanPositions\`.
    - On incoming updates, the original joints are updated but local offset is reapplied, avoiding position jumps.

   \`\`\`javascript
   function resetRemoteStickmanPosition(stickmanId) {
     const offsetX = remoteStickmanPositions[stickmanId].offsetX || 0;
     const offsetY = remoteStickmanPositions[stickmanId].offsetY || 0;
     // Update original joints then reapply offset
   }
   \`\`\`

    - Added ability to drag and reposition remote stickmen locally without altering their frames or animation sequences.
    - Improved deletion logic, now confirmation modal now appears only when:
      - More than one stickman exists, and
      - Stickman has multiple frames.

2. **Optimized Export-to-Video Feature**  
   - Replaced full-board rendering with a computed bounding box containing all posture changes across all frames and stickmen.
   - This minimizes empty space and centers animation.
   - Algorithm:
     - Iterate through all frames of all stickmen.
     - Collect all joint coordinates.
     - Compute minX, maxX, minY, maxY → define bounding box.
     - Add margin and keep this bounding box fixed for all frames to avoid zoom flicker.
   - Benefit: Consistent view without abrupt zooming in/out during playback.
   \`\`\`javascript
    const boundingBox = { 
        minX, 
        minY, 
        width: maxX - minX, 
        height: maxY - minY 
    };
    ctx.drawImage(frameCanvas, boundingBox.minX, boundingBox.minY, boundingBox.width, boundingBox.height);
   \`\`\`
   - Export pipeline:
     - Plays frames sequentially → renders cropped canvas → records to WebM → saves to Journal.
    > Export-to-Video Feature  
    ![Origanl Canvas](https://res.cloudinary.com/djhshvtwo/image/upload/v1756201507/GSoC%2725%20Blog%20Images/1136ed0e-9987-40d1-963d-48ccfe775a02.png)
    ![Exported Video](https://res.cloudinary.com/djhshvtwo/image/upload/v1756201630/GSoC%2725%20Blog%20Images/7ab7537b-2a4c-48ab-93be-3160da923481.png)

3. **AI-based Import from Video**  
   - Implemented the first step of integrating PoseNet via TensorFlow.js to convert real videos into stickman movements.
   - Workflow:
     - Load video → extract frames.
     - Run PoseNet on each frame to detect body keypoints.
     - Normalize keypoints to match stickman joint hierarchy.
     - Generate baseFrames and deltaFrames arrays for animation.
   - Challenges:
     - Mapping PoseNet keypoints to Stickman joints.
     - Maintaining limb proportions using \`enforceJointDistances()\` (see activity.js).
   - This feature lays the foundation for video-to-animation import, making Stickman a real creative tool for educational content.
   > AI Import from Video 
    ![AI created Frame](https://res.cloudinary.com/djhshvtwo/image/upload/v1756201787/GSoC%2725%20Blog%20Images/ac11bcc6-1bb7-46ae-9f86-24faaab3ac15.png)

---

## Challenges & Solutions

- **Challenge:** Avoid jitter during shared mode movements.  
  **Solution:** Introduced originalJoints + offset logic with local persistence.

- **Challenge:** PoseNet joint mapping didn't align with Stickman's simpler skeleton.  
  **Solution:** Created mapping rules and normalized distances using jointConnections.

---

## Next Week's Roadmap

- Refine AI-based video import with better pose detection accuracy.
- Optimization by removing duplicated frames created by AI (two successive frames with same positions).
- Improve shared mode implementation.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Bl=Object.freeze(Object.defineProperty({__proto__:null,default:Ca},Symbol.toStringTag,{value:"Module"})),La=`---
title: "GSoC '25 Week 12 Update by Krish Pandya"
excerpt: "Sphinx , Bundling Discussion, and Future Plans"
category: "DEVELOPER NEWS"
date: "2025-08-25"
slug: "2025-08-25-gsoc-25-mostlyk-week12"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,week12,mostlyk,sphinx,bundling updates"
image: "assets/Images/GSOC.webp"
---


# Week 12: Sphinx , Bundling Discussion, and Future Plans

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)

**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)

**Reporting Period:** August 17, 2025 – August 25, 2025

---

## Sphinx Documentation

Having the whole library in a working state and getting finished with Activity, which is the essential element to make any sort of activity, I started working on the Sphinx documentation for the library.

Link: [GTK4-Toolkit-Documentation](https://sugar-toolkit-gtk4-py.readthedocs.io/)

## What’s New This Week?

### Documentation

- Contains everything from examples to API references.
- Indexed in the manner of:
  - Activity Framework ( sugar.activity )
  - Graphics and UI (sugar.graphics)
  - Data and Storage (sugar.datastore )
  - Bundle Management (Yet to be implemented)
  - Collaboration (sugar.presence )
  - Event System (sugar.dispatch)
  - Core Utils (sugar package)
  - Examples

### Meet Regarding Bundling

- Had a pleasure to meet Martin , Juan , Walter and Ibiam to discuss the bundling methods.
- We decided on to using the old method of bundling as it is more straightforward and easier to implement , for the most part GTK independent.
- Bundling was implemented and Hello World activity was successfully bundled and tested on a clean Fedora Sugar on a Stick.

## ComboBox, ToggleToolButton and ToolComboBox

- Added 3 new widgets to the library.
- Added the corresponding examples for the same as well it's tests.
- Will keep adding more widgets as I go.

### Future Sugar Plans

- Flatpak Ports
- Sugar Shell Ports
- Complete Wayland Port

## Closing Thoughts and Next Steps

- Documentation was possible as I had written docstrings for most of the methods and classes while writing the library. ( I am so happy about this )
- Documentation covers everything from examples to API references.
- Will write the final blog post and wrap up the project and how to continue from here for future contributors.

---

## Resources & Links

- [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [Documentation](https://sugar-toolkit-gtk4-py.readthedocs.io/en/latest/)
`,Rl=Object.freeze(Object.defineProperty({__proto__:null,default:La},Symbol.toStringTag,{value:"Module"})),xa=`---
title: "GSoC '25 Week 12 Update by Nikhil Bhatt"
excerpt: "Summarizing my Google Summer of Code project — Git backend for MusicBlocks. Highlights include implementing fork/PR workflows, writing detailed backend + frontend docs, and ensuring future contributors can onboard easily."
category: "DEVELOPER NEWS"
date: "2025-08-25"
slug: "2025-08-25-gsoc-25-nikhilbhatt-week12"
author: "@/constants/MarkdownFiles/authors/nikhil-bhatt.md"
tags: "gsoc25,sugarlabs,final,nikhilbhatt"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Google Summer of Code 2025 Final Report by Nikhil Bhatt

**Project:** [Git backend for MusicBlocks](https://github.com/benikk/musicblocks-backend)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Duration:** August 18, 2025 – August 25, 2025  

---

## Project Summary

The goal of my project was to **replace the legacy Planet server** with a modern **Git-backed backend** for [MusicBlocks](https://github.com/sugarlabs/musicblocks). This enables projects to be version-controlled, forked, shared, and collaborated on seamlessly via GitHub workflows.  

I worked on two main areas:  

1. **Backend (Node.js + Express + TypeScript)** — building APIs for \`create\`, \`edit\`, \`fork\`, \`commitHistory\`, \`create-pr\`, etc., with GitHub App integration.  
2. **Frontend (MusicBlocks client)** — integrating the new APIs into the user interface, enabling forking, PR workflows, project history browsing, and ZIP downloads.  

Additionally, I created **comprehensive documentation** for both backend and frontend to ensure long-term maintainability.

---

## Major Contributions

###  **Backend Implementation**
- Designed and built APIs for:
  - **Project creation/editing** with Git-backed persistence.  
  - **Forking & fork history tracking**.  
  - **Commit history retrieval** at both project and commit levels.  
  - **Pull request creation & approval workflows**.  
- Added **metadata structures** (\`projectData.json\`, \`metaData.json\`) for project state and authentication.  
- Implemented **security checks** and configuration options via \`.env\`.  
- Wrote tests for major endpoints and validated responses.  

###  **Frontend Integration**
- Integrated backend APIs into the MusicBlocks client.  
- Added UI flows for:
  - Forking a project and tracking its history.  
  - Browsing and restoring older commits.  
  - Creating pull requests from the frontend.  
  - Downloading projects as ZIP archives.  
- Managed **localStorage keys** for state persistence.  
- Ensured smooth transition from legacy server → GitHub workflows.  

###  **Documentation & Developer Experience**
- Wrote **backend README** with setup steps, API docs, environment variables, and deployment instructions.  
- Documented **frontend integration**: API contracts, UI flows, and troubleshooting.  
- Added **manual testing checklist** to validate project workflows.  
- Created a **contributor’s guide** for future developers.  
- Improved onboarding experience with **diagrams, examples, and standardized conventions**.  

---

## Testing & Results

- Verified all API endpoints with **manual tests and Postman collections**.  
- Conducted **end-to-end tests** by linking backend ↔ frontend flows.  
- Confirmed project history, forks, and PRs behave consistently with GitHub repos.  
- Ran multiple **real-world test scenarios** (student forking a project, teacher reviewing PR, restoring commits) — all successful.  

---

## Challenges & Solutions

- **Complex Git workflows** were hard to explain. → I solved this with request/response examples and flow diagrams.  
- **Maintaining parity between backend and frontend** was tricky. → I standardized API naming conventions and cross-referenced docs.  
- **Time management** balancing documentation + coding. → Broke tasks into milestones and focused on one layer (backend/frontend) at a time.  

---

## Key Learnings

- Learned to design **GitHub-integrated APIs** using Node.js, Express, and Octokit.  
- Understood the importance of **clear documentation** as a first-class contribution.  
- Gained experience in **frontend-backend integration** with real-world workflows.  
- Improved skills in **project management and time prioritization**.  

---

## Code & Documentation

- [MusicBlocks Frontend (Branch)](https://github.com/BeNikk/musicblocks/tree/git-musicblocks-frontend)  
- [MusicBlocks Backend](https://github.com/benikk/musicblocks-backend)  
- [API Documentation (Backend README)](https://github.com/benikk/musicblocks-backend/blob/main/README.md) 
- [Final Report](https://github.com/benikk/GSoC-2025) 

---

## Future Work

- Add **CI/CD pipelines** for backend + frontend.  
- Improve **automated testing** coverage.  
- Extend backend for **more Git features** (branching, rebasing, merging).  
- Expand contributor guides with **video tutorials and walkthroughs**.  

---

## Acknowledgments

A big thank you to my mentors **Walter Bender** and **Sumit Srivastava** for their continuous guidance, and to the **Sugar Labs community** for reviews, feedback, and encouragement.  

This project has been an incredible journey — not only building new features, but also ensuring MusicBlocks is more maintainable, collaborative, and future-ready.  

---
`,Ol=Object.freeze(Object.defineProperty({__proto__:null,default:xa},Symbol.toStringTag,{value:"Module"})),Ga=`---
title: "GSoC '25 Week 11 Update by Bishoy Wadea"
excerpt: "Rubik's Cube - 3D Puzzle Challenge"
category: "DEVELOPER NEWS"
date: "2025-08-28"
slug: "gsoc-25-BishoyWadea-week11"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week11,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

# Week 11 Progress Report by Bishoy Wadea

**Project:** [Rubik's Cube](https://github.com/Bishoywadea/Rubik-s-Cube)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-08-21 – 2025-08-28  

---

## Goals for This Week

- **Complete Magic Number Grid features**
- **Develop new Sugar activity: Rubik's Cube with 3D graphics**
- **Implement intuitive controls for cube manipulation**

---

## About Rubik's Cube

Rubik's Cube is a 3D puzzle game that brings the classic cube-solving challenge to Sugar. This activity helps develop spatial reasoning skills as players rotate faces and manipulate the cube to get each side showing only one color.

---

## Achievements

### Rubik's Cube Development

- **Initial Activity Setup**  
  Created Sugar activity framework with proper manifest and icon  
  [Commit](https://github.com/Bishoywadea/Rubik-s-Cube/commit/20f3f7d84889d4210a9319a627c13bac7d123e22)

- **Core Game Logic**  
  Implemented Rubik's Cube mechanics with accurate rotation algorithms  
  [Commit](https://github.com/Bishoywadea/Rubik-s-Cube/commit/ca45ea368009342317be967fd2f41ab012619ca1)

- **3D Graphics Integration**  
  Added OpenGL setup for 3D rendering within Sugar environment  
  [Commit](https://github.com/Bishoywadea/Rubik-s-Cube/commit/b86e788a9c732163308f9c2e11bb6ac8afd09187)

![Rubik's Cube Interface](https://raw.githubusercontent.com/Bishoywadea/Rubik-s-Cube/refs/heads/main/screen_shots/01.png)
*3D Rubik's Cube with interactive controls*

![Gameplay Example](https://raw.githubusercontent.com/Bishoywadea/Rubik-s-Cube/refs/heads/main/screen_shots/02.png)
*Cube mid-solve showing different colored faces*

---

## Challenges & Solutions

- **Challenge:** Integrating 3D graphics (OpenGL) within Sugar's GTK+ framework while maintaining compatibility across different hardware.

- **Solution:**  
  - Used PyOpenGL with careful context management
  - Implemented fallback rendering for systems with limited GPU support
  - Created custom event handling to bridge GTK and OpenGL interactions

- **Challenge:** Making 3D cube manipulation intuitive for young users unfamiliar with Rubik's Cube notation.

- **Solution:**  
  - Designed visual toolbar with clear icons for each move
  - Implemented mouse drag rotation for natural cube exploration
  - Added keyboard shortcuts matching standard cube notation

---

## Key Learnings

- Gained deep understanding of 3D graphics programming within constrained environments
- Learned to implement complex rotation algorithms and quaternion mathematics
- Developed skills in creating hybrid 2D/3D interfaces that remain user-friendly

---

## Next Week's Roadmap

- Begin development of new Sugar activity: **Sequence Wizard**
  - Design pattern recognition and sequence completion challenges
  - Implement various sequence types (arithmetic, geometric, visual patterns)
  - Create progressive difficulty system for different age groups`,zl=Object.freeze(Object.defineProperty({__proto__:null,default:Ga},Symbol.toStringTag,{value:"Module"})),Wa=`---
title: "GSoC ’25 Week 11 Update by Diwangshu Kakoty"
excerpt: "Reflection Widget"
category: "DEVELOPER NEWS"
date: "2025-08-29"
slug: "2025-08-29-gsoc-25-diwangshu-week11"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week11,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 11 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-08-12 - 2025-08-18  

---

## Goals for This Week

- **Goal :** Deploy the backend on AWS.

---

## This Week’s Achievements

1. **Deployed the backend on AWS**  
  - I was able to successfully deploy the FastAPI backend on Sugar Labs' AWS. This involved setting up the server environment, configuring necessary dependencies, and ensuring that the API endpoints were accessible.

  - I chose EC2 instance and set up a linux server. I installed Python, FastAPI, and other required libraries. I also configured security groups to allow incoming traffic on the necessary ports.

  - Because the backend is runing a sentence-transformer model, I chose t3.micro instance which has 2 vCPUs and 1 GiB of memory. This is sufficient for handling requests without incurring high costs.

  - It is using systemd to manage the FastAPI service. This ensures that the service starts automatically on server reboot and can be easily monitored.

---

## Challenges & How I Overcame Them

- **Challenge 01:**  This was my first time deploying a backend on AWS, so I faced several challenges related to server configuration, security settings, and dependency management. The first cahllenge was setting up thr disk space. The default disk space was not sufficient for installing all the required libraries and models. I increase the volume size from 8 GB to 25 GB but it was not enough.

  **Solution:** I came to know that the volume size was not the issue but the root partition size was the issue. So, I resized the root partition using \`growpart\` and \`resize2fs\` commands. After resizing, I was able to install all the required libraries and models without any issues.

- **Challenge 02:** Next challenge was running the uvicorn server. The t3.micro instance has low memory and therefore, the sentence transformer model was causing the server to crash frequently.

  **Solution:** I used the leftover swap space to increase the memory. I created a swap file of 1 GB and enabled it. This helped in stabilizing the server and preventing crashes.
 

---

## Next Week’s Roadmap

- Work on things suggested by my mentors. This may include:
  - Adding more features to the reflection widget.
  - Improving the performance of the backend.

- Write documentation for the project.

---

## Resources & References

- **Reflection widget development branch:** [reflection](https://github.com/Commanderk3/musicblocks/tree/reflection)
- **Fast API server:** [musicblocks_reflection_fastapi](https://github.com/Commanderk3/musicblocks_reflection_fastapi)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Fl=Object.freeze(Object.defineProperty({__proto__:null,default:Wa},Symbol.toStringTag,{value:"Module"})),Da=`---
title: "DMP ’25 Week 12 Update by Harshit Verma"
excerpt: "Progress on implementing debug history saving in the Journal and polishing code for final review."
category: "DEVELOPER NEWS"
date: "2025-08-30"
slug: "2025-08-30-dmp-25-therealharshit-week12"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,week12,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Harshit Verma

**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-08-18 - 2025-08-24   

---

## Goals for This Week

- **Goal 1:** Work on implementing saving debug history into the Sugar Journal.  
- **Goal 2:** Polish existing codebase in preparation for final review.  
- **Goal 3:** Improve the Markdown parser for more readable debug responses in the terminal.  
- **Goal 4:** Conduct end-to-end testing of the \`/debug\` endpoint.  

---

## This Week’s Achievements

1. **Worked on saving the debugger response in the sugar journal**  
   - Explored how activities interact with the Journal using the \`write_file()\` and \`read_file()\` methods.  
   - Extended the default workflow (which only saves source tab data) to also capture **debugging terminal outputs**.  
   - Designed a JSON-based structure to record **code, errors, and LLM responses** for each session.  

2. **Refactoring of codebase**  
   - Began cleaning up previously committed code based on mentor feedback.  
   - Improved function naming, modularized some logic, and reduced redundancy.  
   - Focused on ensuring **seamless integration between Sugar-AI and Pippy**, reducing chances of UI freeze or broken API calls.  

3. **Markdown Parser Improvements**  
   - Iterated on the custom Markdown parser to better format LLM responses.  
   - Ensured that **bold keywords, bullet lists, and code snippets** appear cleanly in the GTK terminal.  
   - Began testing rendering consistency with multiple LLM outputs.  

4. **End-to-End Workflow Testing**  
   - Tested the complete flow: Pippy code → API call to Sugar-AI → Debugging response → Display in terminal.  
   - Verified data integrity across each step, ensuring nothing is lost or malformed in transmission.  

---

## Challenges & How I Overcame Them

- **Challenge:** Understanding how the Sugar Journal stores and restores activity state.  
  **Solution:** Based on discussion with my mentors I went through the Sugar toolkit documentation, experimented with other activities and learn about the \`write_file()\` and \`read_file()\` methods .  

- **Challenge:** Formatting inconsistencies in Markdown parsing.  
  **Solution:** Added step-by-step rendering checks and created a fallback for unrecognized Markdown syntax.  

---

## Key Learnings

- Learned about the importance of journaling. 
-  Improved skills in **code refactoring**, focusing on maintainability and integration.   

---

## Next Week’s Roadmap

- Raise the final PR for Pippy.  
- Complete the **project final report** and submit for evaluation.  
- Write User docs and technical docs.

---

## Resources & References

**Repository**
- [Pippy](https://github.com/therealharshit/Pippy/tree/DMP2025/Pippy-Debugger)
- [sugar-ai](https://github.com/sugarlabs/sugar-ai)
- [pippy-debugger-server](https://github.com/therealharshit/pippy-debugger-server)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for your continued guidance and support!

---
`,Ul=Object.freeze(Object.defineProperty({__proto__:null,default:Da},Symbol.toStringTag,{value:"Module"})),_a=`---
title: "GSoC '25 Week 16 Update by Aditya Kumar Singh"
excerpt: "Advanced shared mode with global vs local moves, extended PoseNet-based video import with MobileNet/ResNet, template palette with event-driven design, and multiple UX refinements."
category: "DEVELOPER NEWS"
date: "2025-08-30"
slug: "2025-08-30-gsoc-25-AdityaKrSingh26-week16"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week16,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 16 Progress Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-08-25 - 2025-09-01

---

## Goals for This Week

- **Goal 1:** Improve shared mode implementation with fine-grained move handling.  
- **Goal 2:** Extend AI-based video import feature with multiple PoseNet backbones and UX polish.  
- **Goal 3:** Build a reusable template palette for stickman animations.  
- **Goal 4:** Address UI inconsistencies and quality-of-life fixes.  

---


## This Week’s Achievements

1. **Shared Mode Enhancements**
    - In earlier weeks, shared mode already supported ownership markers and drag/drop of remote stickmen. This week’s focus was on movement semantics and ensuring consistency across animations:
    - **Relative Position Preservation During Animation**
        - Each stickman maintains both its original joints (from remote updates) and a local offset (applied when dragged). During animations, incoming updates refresh the joints but do not overwrite local offsets, so remote stickmen appear stable in the scene.
        \`\`\`js
        function applyOffset(stickman, frame) {
            const base = stickman.originalFrames[frame];
            const offset = stickman.localOffsets[frame] || { x: 0, y: 0 };
            return base.map(joint => ({
                x: joint.x + offset.x,
                y: joint.y + offset.y
            }));
        }
        \`\`\`
    - **Global vs Local Moves**
        - Moves performed on frame 0 (the initial frame) are tagged as global and applied across all frames.
        - Moves on later frames are local and affect only that frame’s playback.
        - This required maintaining a globalOffset in the stickman object and a localOffsets dictionary keyed by frame index.

    - **Tutorial Updates**: The help/tutorial system was updated to explain new behavior and color-coding:
        - Black Head → local stickman.
        - Red dots → active/selected stickman.
        - Yellow dot at waist → For dragging stickman across screen.
        - Colored Head → remote stickman (color corresponds to the user).

2. **Video Import Improvements (PoseNet → Stickman)**
    - This task built on last week’s AI integration, moving from a working prototype into a more robust import pipeline:
    - **Debugging with Hardcoded PoseNet Samples**: Extracted sample keypoints directly from PoseNet output to manually verify joint mappings. This surfaced alignment issues between PoseNet’s 17-keypoint skeleton and Stickman’s simpler joint hierarchy.
    - **Support for Multiple Backbones**: Added flexibility to run PoseNet with two different architectures:
        - MobileNetV1 (~4.2M params) → optimized for performance on low-power devices.
        - ResNet50 (~25M params) → slower but higher accuracy, especially useful for complex movements.
    - **Joint Distance Enforcement**: A recurring issue was unnatural limb proportions when mapping PoseNet joints. To solve this, I used the \`enforceJointDistances()\` method from \`activity.js\`:
        \`\`\`js
        jointConnections.forEach(([a, b, expectedDist]) => {
            const actual = distance(joints[a], joints[b]);
            if (Math.abs(actual - expectedDist) > tolerance) {
                adjustJoint(joints, a, b, expectedDist);
            }
        });
        \`\`\`
    - This keeps the stickman body consistent regardless of PoseNet noise.
    - **Frame Deduplication**: Implemented logic to skip saving consecutive identical frames, which reduced output clutter and produced smoother animations.
    - **UI/UX Enhancements in Import Dialog**: 
        - Loading spinner during TensorFlow.js model initialization.
        - Autoplay of input video with a green pose overlay (restored for clarity).
        - Simplified controls (only Cancel + Insert).
        - Neat display of current frame index.
    - Fixed delete-frame bug → selection now stays on previous frame, not reset to first.
    - Randomized imported stickman positions to avoid overlap when multiple stickmen are added.


3. **Template Palette Feature**
    - I introduced a Template Palette, enabling quick insertion of prebuilt animations into the workspace.
    - **Implementation (templatepalette.js)**: Using Sugar’s palette system, I created a palette with buttons (run, boxing, dance1, dance2). Each button dispatches a template-selected event:
        \`\`\`js
        runButton.addEventListener("click", () => {
            document.dispatchEvent(new CustomEvent('template-selected', {
                detail: { template: 'run' }
            }));
            setActiveButton(runButton);
            self.popDown();
        });
        \`\`\`
    - **Preloaded Templates**: Templates were generated from exported animations and stored as JSON. These JSONs are loaded at startup, making templates instantly available.
    - **UI Design**: Each template button shows a name and animated preview, helping users recognize the animation before inserting it. This also makes the feature accessible for younger students with limited reading skills.
    > Template Preview
    ![](https://res.cloudinary.com/djhshvtwo/image/upload/v1756666561/GSoC%2725%20Blog%20Images/2802bab9-7001-4fc1-beab-4c156d5b3ff1.png)


4. **Minor Improvements & Bug Fixes**
    - Fixed palette color persistence and closing behavior.
    - Ensured imported palette stickmen are also shared in collaborative mode.
    - Applied Sugar UI look-and-feel to buttons (rounded corners, consistent style).
    - Restored the green pose overlay in PoseNet video preview.
    - Added spinner + disabled UI during first TensorFlow.js library load.
    - Multiple incremental bug fixes merged into PR, improving stability for both single-user and shared sessions.
    > UI Changes
    ![Green pose overlay](https://res.cloudinary.com/djhshvtwo/image/upload/v1756666689/GSoC%2725%20Blog%20Images/a3235b2f-47a8-4cbb-a2ee-0fa224d80c4a.png)

## Challenges & Solutions

- **Challenge:** Explaining and implementing global vs local moves.     
  **Solution:** Designed clear frame-based rules (frame 0 = global, others = local) and updated tutorials with color-coded indicators.     

- **Challenge:** Building an extensible template system.     
  **Solution:** Used CustomEvent('template-selected') so templates are decoupled from activity logic. This makes it easy to add more templates later without touching core code.    


---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---
`,Nl=Object.freeze(Object.defineProperty({__proto__:null,default:_a},Symbol.toStringTag,{value:"Module"})),Ea=`---
title: "GSoC ’25 Week 12 Update by Diwangshu Kakoty"
excerpt: "Reflection Widget"
category: "DEVELOPER NEWS"
date: "2025-08-30"
slug: "2025-08-30-gsoc-25-diwangshu-week12"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,week12,AI"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 12 Progress Report by Diwangshu Kakoty

**Project:** [AI Tools for Reflection](https://github.com/Commanderk3/reflection_ai)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Sumit Srivastava](https://github.com/sum2it)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa), [Ajeet Pratap Singh](https://github.com/apsinghdev)  
**Reporting Period:** 2025-08-19 - 2025-08-25  

---

## Goals for This Week

- **Goal 1:** Changed mentor name from "Steve Jobs" to "Alen Kay".
- **Goal 2:** Added a refresh button to the widget.
- **Goal 3:** Added a 'thinking' animation while waiting for the bot's response.

---

## This Week’s Achievements

1. **Changed mentor name from "Steve Jobs" to "Alen Kay"**  
  - My mentor suggested me to change the coding mentor's name from "Steve Jobs" to "Alen Kay". Steve Jobs, while a significant figure in technology, is not primarily known for coding. Alen Kay, on the other hand, is a pioneer in object-oriented programming and has made substantial contributions to the field. He was also a musician which makes him a more fitting choice for the reflection widget. I have made the necessary changes in the codebase to reflect this update.

2. **Added a refresh button to the widget**
  - A refresh button has been addded to the widget. This button updates the algorithmic summary of the user's Music Blocks project. Now the AI mentors can see the latest changes made by the user. This allows a more dynamic and interactive experience.

3. **Added a 'thinking' animation while waiting for the bot's response**
  - I got inspired by the 'AI debugger' widget and added a 'thinking' animation that appears while the bot is processing and generating a response. This provides visual feedback to users, letting them know that their input is being processed and enhancing the overall user experience.

---

## Next Week’s Roadmap

- **Goal:** Final testing and bug fixes. The widget is complete and functional. But it needs to be tested with real users to identify any potential issues or areas for improvement.

---

## Resources & References

- **Reflection widget development branch:** [reflection](https://github.com/Commanderk3/musicblocks/tree/reflection)
- **Fast API server:** [musicblocks_reflection_fastapi](https://github.com/Commanderk3/musicblocks_reflection_fastapi)

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---`,Hl=Object.freeze(Object.defineProperty({__proto__:null,default:Ea},Symbol.toStringTag,{value:"Module"})),ja=`---
title: "Google Summer of Code 2025 – Final Report by Aditya Kumar Singh"
excerpt: "Final report summarizing the achievements and outcomes of the GSoC 2025 project."
category: "DEVELOPER NEWS"
date: "2025-08-31"
slug: "2025-08-31-gsoc-25-AdityaKrSingh26-final-report"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,final-report,AdityaKrSingh26"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Google Summer of Code 2025 – Final Report
**Organization:** [Sugar Labs](https://sugarlabs.org)  
**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  

---

## Project Overview

The objective of this GSoC project was to **enhance the existing 3D Human Body Activity** and **create a completely new Stickman Animation Activity** for Sugarizer, Sugar Labs' open-source learning platform. These activities aim to make learning anatomy and animation interactive, accessible, and collaborative, especially for students in low-resource environments.

### Key Deliverables
1. **Enhanced 3D Human Body Activity** - An interactive 3D anatomy explorer with multi-layer visualization, collaborative learning modes, and educational features
2. **New Stickman Animation Activity** - A frame-based animation editor with AI-assisted pose generation, collaborative editing, and export capabilities

Both activities are optimized for Sugarizer's offline-first philosophy and designed to run smoothly on low-power devices while maintaining educational effectiveness.

---

## Project Timeline and Achievements

### Phase 1: Foundation and Enhancement (Weeks 1-6)

### **3D Human Body Activity Development**
The first phase focused on establishing a solid foundation for the 3D Human Body Activity through model optimization, internationalization, and core feature implementation.

**Week 1-3: Model Optimization and Asset Management**
- **Asset Identification and Optimization:** Reviewed existing Z-Anatomy models and identified missing anatomical components (stomach, intestines, kidneys, liver, brain, eyes)
- **Model Simplification:** Reduced mesh complexity in Blender while preserving anatomical accuracy, improving performance on low-end devices
- **Anatomical Accuracy:** Enhanced spacing between organs and simplified intestine models by merging multiple segments into unified meshes
- **Code Refactoring:** Removed redundant functions, consolidated model loading logic, and unified zoom controls into a single parameterized function

**Week 4-5: Internationalization and UI Enhancement**
- **Multi-Model Support:** Implemented a model selection palette allowing users to toggle between Human body, Skeleton, and Organ systems
- **Localization Integration:** Added comprehensive \`i18next.js\` support with full English and French translations
- **Skeletal Model Enhancement:** Improved bone naming conventions with accurate anatomical terminology (e.g., splitting "Lower Leg" into "Tibia" and "Fibula")
- **UI Improvements:** Fixed model selection palette to reflect current selection and implemented vertical mode selector inspired by Dollar Street UI design

**Week 6: Educational Features and User Experience**
- **Tutorial System:** Integrated \`Intro.js\` library for interactive onboarding with Sugarizer-themed styling and full localization support
- **Metadata Management:** Created comprehensive JSON structure for body parts containing names, mesh references, and 3D positions
- **Performance Optimization:** Reduced organ model size from 19MB to 5.92MB through Blender optimization techniques
- **Paint Mode Integration:** Merged Paint and Learn modes with bottom-right modal notifications and fade transitions

--- 

### Phase 2: Collaboration and Advanced Features (Weeks 7-9)

### **Shared Mode Implementation**
**Week 7: Real-time Collaboration Foundation**
- **Tour Mode Synchronization:** Implemented broadcast messaging for synchronized camera movements and mesh highlighting across multiple users
- **Doctor Mode Collaboration:** Built real-time quiz system with first-correct-gets-points logic and peer-to-peer visual feedback
- **Camera Persistence:** Added Journal integration for saving camera position, target, and FOV across sessions
- **Multi-View Support:** Extended Tour mode with side and back view positioning using adaptive camera orientation

**Week 8-9: Collaboration Refinement and New Activity Bootstrap**
- **Bug Fixes and UX Improvements:** Resolved zoom-out limitations, implemented late joiner synchronization for painted parts, and created XO icon leaderboard with user-specific colors
- **Stickman Activity Foundation:** Created initial activity scaffold with complete toolbar infrastructure and basic stickman drawing capabilities
- **Frame Management System:** Built Add/Remove frame functionality with onion skinning and real-time canvas rendering loop


--- 

### Phase 3: Stickman Animation Development (Weeks 10-12)

### **Core Animation Features**
**Week 10: Multi-Character Support and Visual Design**
- **Multi-Stickman Canvas:** Implemented support for multiple independent stickman characters with isolated frame histories and selectable states
- **Visual Design Overhaul:** Redesigned stickman proportions with shorter necks, thicker limbs, and filled circular heads inspired by Pivot Animator
- **Frame Preview Enhancement:** Added automatic thumbnail updates on canvas changes without requiring manual frame addition
- **Journal Integration:** Implemented comprehensive save/load functionality with JSON serialization of all stickman data

**Week 11: Advanced Joint Mechanics and User Experience**
- **Hierarchical Joint System:** Developed sophisticated parent-child joint relationships mimicking Pivot Animator functionality
- **Per-Character Rendering:** Implemented selective frame previews and joint visibility for currently selected stickman only
- **Size Enhancement:** Increased stickman visual scale for better visibility on high-resolution displays
- **Safe Deletion:** Added confirmation popups for removing stickmen with multiple frames to prevent data loss

**Week 12: Polish and Accessibility**
- **Image Export:** Implemented PNG export functionality for Human Body activity with high-quality 3D canvas capture
- **Visual Improvements:** Further enhanced stickman size and visibility with improved joint circles (8px to 12px) and thicker limb lines (2px to 4px)
- **Comprehensive Localization:** Added full i18n support for Stickman activity with multilingual toolbar and UI elements
- **Interactive Tutorial:** Integrated IntroJS-based tutorial system with step-by-step guided tours of all features

--- 

### Phase 4: Advanced Features and Integration (Weeks 13-16)

### **System Architecture and Collaboration**
**Week 13: Architecture Improvements**
- **Critical Bug Resolution:** Fixed model switching synchronization issues in Human Body shared mode
- **Individual Frame Management:** Transitioned from shared timeline to independent frame sequences per stickman
- **Relative Positioning System:** Implemented anchor-point based coordinate system enabling O(1) character movement operations
- **Shared Mode Foundation:** Built real-time collaborative framework using Sugar's presence system with conflict resolution

**Week 14: Advanced Collaboration and Export**
- **Enhanced Shared Mode:** Implemented clear ownership visualization with color-coded markers and local vs. remote editing permissions
- **Journal Import:** Added functionality to import saved stickmen from previous sessions with activity filtering
- **Export-to-Video:** Completed WebM video export pipeline with MediaRecorder API integration and Journal storage

**Week 15-16: AI Integration and Final Polish**
- **AI-Powered Import:** Integrated \`TensorFlow.js\` and \`PoseNet\` for converting real videos into stickman animations
- **Template Palette:** Built reusable template system with preloaded animations (run, dance, boxing) and event-driven architecture
- **Advanced Shared Mode:** Implemented global vs. local movement handling with offset preservation during animations
- **Export Optimization:** Added adaptive bounding box recording for consistent video framing without zoom flicker

---

## UI Screenshots and Visual Demonstration

> 3D Human Body Activity Interface
![Main Activity Interface](https://res.cloudinary.com/djhshvtwo/image/upload/v1756671606/GSoC%2725%20Blog%20Images/a6a3ddfe-9713-4494-a67d-ddf5b5a66c34.png)
![Paint Mode](https://i.ibb.co/7tW0PdzH/image.webp)
![Tour Mode](https://i.ibb.co/JW5JNMVD/image.webp)
![Doctor Mode (Collaborative Quiz)](https://i.ibb.co/jkLPqWDP/image.webp)
![Localization examples - French](https://res.cloudinary.com/djhshvtwo/image/upload/v1756671641/GSoC%2725%20Blog%20Images/f18c2be1-2734-4067-99bd-84d8baf3ed3a.png)

> Stickman Animation Activity Interface
![Animation Editor](https://i.ibb.co/YFRRH2Ys/image.png)
![AI Pose Import](https://res.cloudinary.com/djhshvtwo/image/upload/v1756666689/GSoC%2725%20Blog%20Images/a3235b2f-47a8-4cbb-a2ee-0fa224d80c4a.png)
![Template Palette](https://res.cloudinary.com/djhshvtwo/image/upload/v1756666561/GSoC%2725%20Blog%20Images/2802bab9-7001-4fc1-beab-4c156d5b3ff1.png)
![Shared Mode](https://res.cloudinary.com/djhshvtwo/image/upload/v1755528077/GSoC%2725%20Blog%20Images/57fb70a1-49a8-4fcd-97d8-42a3b818a106.png)
![Import From Journals](https://res.cloudinary.com/djhshvtwo/image/upload/v1755528027/GSoC%2725%20Blog%20Images/2d9491c0-bdfd-44fb-900f-61e967f9d968.png)

---

## Technical Architecture

### **3D Human Body Activity**
- **Rendering Engine:** \`Three.js\` with \`GLTFLoader\` for 3D model handling
- **Interaction Modes:** Paint (coloring), Tour (guided navigation), Doctor (collaborative quiz)
- **Networking:** Real-time synchronization via Sugar Presence API with throttled updates
- **Data Persistence:** State management using Sugar Journal with camera position and painted parts storage
- **Performance:** Optimized 3D models and efficient rendering pipeline for low-end devices

### **Stickman Animation Activity**
- **Animation System:** Frame-based animation with delta compression and onion skinning
- **Joint Mechanics:** Hierarchical parent-child relationships with distance constraints for anatomical accuracy
- **Collaboration:** Real-time multi-user editing with ownership-based permissions and conflict resolution
- **AI Integration:** \`TensorFlow.js\` and \`PoseNet\` for pose detection and automatic stickman generation from videos
- **Export Capabilities:** WebM video generation with MediaRecorder API and PNG image export

### **Shared Technologies**
- **Internationalization:** \`l10n.js\` for multi-language support
- **Tutorial System:** \`IntroJS\` for interactive user onboarding
- **Canvas Optimization:** Efficient 2D/3D rendering with performance monitoring
- **Journal Integration:** Comprehensive save/load functionality with metadata preservation

---

## Key Technical Innovations

### **1. Hierarchical Joint Animation System**
Developed a sophisticated joint hierarchy system for natural stickman movement:
- **Parent-Child Relationships:** Moving a parent joint automatically affects all children (e.g., rotating elbow moves hand)
- **Distance Constraints:** Maintains anatomical proportions during manipulation
- **Recursive Transformations:** Efficient propagation of movements through the joint tree
- **Pivot Point Calculations:** Context-aware rotation centers based on anatomical structure

### **2. Real-time Collaborative Architecture**
Built robust multi-user systems for both activities:
- **Presence-based Networking:** Sugar's presence API for user discovery and communication
- **Ownership Management:** Clear visual indicators and permission systems for shared editing
- **State Synchronization:** Efficient delta updates with conflict resolution mechanisms
- **Late Joiner Support:** Automatic state synchronization for users joining ongoing sessions

### **3. AI-Powered Pose Generation**
Integrated machine learning for automatic animation creation:
- **PoseNet Integration:** Real-time pose detection from video input
- **Joint Mapping:** Conversion between 17-keypoint skeleton and simplified stickman structure
- **Constraint Enforcement:** Maintaining natural proportions despite ML prediction noise
- **Multi-Model Support:** MobileNetV1 for performance, ResNet50 for accuracy

### **4. Performance Optimization Strategies**
Implemented comprehensive optimization for low-resource environments:
- **3D Model Optimization:** Blender-based mesh reduction and texture compression
- **Memory Management:** Efficient frame storage with delta compression
- **Rendering Optimization:** Selective updates and viewport-based culling
- **Network Efficiency:** Throttled updates and payload minimization

---

## Educational Impact and Features

### **Pedagogical Design**
Both activities are designed with educational effectiveness as the primary goal:

**3D Human Body Activity:**
- **Multi-Modal Learning:** Visual, interactive, and collaborative learning approaches
- **Progressive Complexity:** Tour mode for guided exploration, Paint mode for hands-on learning, Doctor mode for assessment
- **Accessibility:** Multi-language support and intuitive touch interfaces
- **Collaborative Learning:** Shared sessions enable peer teaching and group exploration

**Stickman Animation Activity:**
- **Creative Expression:** Students can create original animations and stories
- **STEM Integration:** Physics concepts through joint mechanics and movement principles
- **Digital Literacy:** Introduction to animation concepts and video production
- **Collaborative Creativity:** Shared editing enables group projects and peer feedback

### **Inclusive Design**
- **Low-Resource Optimization:** Efficient performance on older devices and slow networks
- **Offline Functionality:** Full feature availability without internet connectivity
- **Multi-Language Support:** Comprehensive localization framework
- **Intuitive Interfaces:** Age-appropriate UI design with visual feedback


## Challenges Overcome

### **Technical Challenges**

**3D Asset Management:**
- **Problem:** Original anatomical models were too resource-intensive for target devices
- **Solution:** Implemented comprehensive Blender optimization pipeline with polygon reduction and texture compression while maintaining educational accuracy

**Real-time Synchronization:**
- **Problem:** Network lag and state conflicts in collaborative sessions
- **Solution:** Developed throttled update system with authoritative host architecture and conflict resolution based on timestamps

**Cross-Platform Performance:**
- **Problem:** Inconsistent performance across different devices and browsers
- **Solution:** Implemented adaptive quality settings and efficient rendering pipelines with performance monitoring

### **AI Integration Challenges**

**Pose Detection Accuracy:**
- **Problem:** PoseNet output didn't align perfectly with stickman joint structure
- **Solution:** Developed sophisticated mapping algorithms with constraint enforcement and anatomical validation

**Performance vs. Accuracy Trade-offs:**
- **Problem:** Balancing ML model performance with detection quality
- **Solution:** Implemented multi-model support allowing users to choose between speed (MobileNet) and accuracy (ResNet)

---

## Quantitative Impact

### **Performance Improvements**
- **Model Size Reduction:** 3D organ models reduced from 19MB to 5.92MB (69% reduction)
- **Loading Time:** Initial activity load time improved by approximately 60%
- **Memory Usage:** Efficient frame management reducing memory footprint by ~40% for complex animations
- **Network Efficiency:** Collaborative updates optimized with ~75% reduction in message payload

### **Feature Completeness**
- **Human Body Activity:** 3 interaction modes, 3 anatomical systems, 2+ languages, shared collaboration
- **Stickman Activity:** Full animation pipeline, AI integration, video export, template system, collaboration support
- **Code Quality:** 15+ pull requests, comprehensive testing, documentation, and code reviews

---

## Repository Information

### **Development Branches and Pull Requests**
- **Main Repository:** [Sugarizer](https://github.com/llaske/sugarizer)
- **Development Branch (Human Body):** [dev-3d](https://github.com/AdityaKrSingh26/sugarizer/tree/dev-3d)
- **Development Branch (Stickman):** [feature/aditya-stickman](https://github.com/AdityaKrSingh26/sugarizer/tree/feature/aditya-stickman)

### **Merged Pull Requests**
**Human Body Activity:**
- [#1794](https://github.com/llaske/sugarizer/pull/1794) - Code refactoring and optimization
- [#1796](https://github.com/llaske/sugarizer/pull/1796) - Model palette and localization
- [#1798](https://github.com/llaske/sugarizer/pull/1798) - Tutorial system integration
- [#1800](https://github.com/llaske/sugarizer/pull/1800) - Shared mode enhancements
- [#1801](https://github.com/llaske/sugarizer/pull/1801) - Final optimizations
- [#1802](https://github.com/llaske/sugarizer/pull/1802) - Image export feature

**Stickman Animation Activity:**
- [#1799](https://github.com/llaske/sugarizer/pull/1799) - Complete activity implementation

---

## Learning Outcomes and Personal Growth

### **Technical Skills Developed**
- **3D Graphics Programming:** Advanced Three.js and WebGL optimization techniques
- **Machine Learning Integration:** Practical experience with TensorFlow.js and computer vision
- **Real-time Systems:** WebSocket-based collaboration and state synchronization
- **Performance Optimization:** Memory management and rendering efficiency for resource-constrained environments
- **Cross-platform Development:** Browser compatibility and responsive design principles


### **Educational Technology Insights**
- **Pedagogical Design:** Understanding of educational effectiveness in digital tools
- **Accessibility Considerations:** Inclusive design for diverse learning environments
- **Collaborative Learning:** Design patterns for effective group learning experiences
- **Assessment Integration:** Balancing learning objectives with engaging interactions

---

## Acknowledgments

This GSoC project would not have been possible without the exceptional support and guidance from multiple individuals and the broader Sugar Labs community:

### **Mentorship Team**
Special recognition goes to **Lionel Laské** and **Samarth Bagga**, whose patient guidance, technical expertise, and educational insights were instrumental in shaping both activities. Their feedback helped balance technical complexity with educational effectiveness, ensuring the final products truly serve the Sugar Labs mission.

### **Sugar Labs Community**
Gratitude to the entire Sugar Labs community for their welcoming atmosphere, constructive feedback, and commitment to educational technology. The collaborative spirit of open-source development was evident throughout the project.

### **Technical Contributors**
Appreciation for the developers of the foundational technologies that made this project possible: Three.js, TensorFlow.js, IntroJS, and the broader web standards community.

### **Educational Inspiration**
Recognition of the educators and students who will ultimately benefit from these activities, whose needs and learning objectives guided every design decision throughout the development process.

---

## Conclusion

The GSoC 2025 Sugarizer Human Activity Pack project successfully delivered two comprehensive educational activities that advance Sugar Labs' mission of providing accessible, engaging learning tools for students worldwide. Through 16 weeks of dedicated development, the project achieved significant technical innovations while maintaining focus on educational effectiveness and accessibility.

The enhanced **3D Human Body Activity** transforms anatomical learning through interactive 3D visualization, collaborative exploration, and multilingual support. Students can now paint anatomical structures, take guided tours of body systems, and participate in collaborative quizzes with peers, all while developing deeper understanding of human anatomy.

The new **Stickman Animation Activity** introduces creative animation tools that make complex concepts accessible to young learners. Through intuitive joint manipulation, AI-assisted pose generation, and collaborative editing capabilities, students can express creativity while learning fundamental animation and physics principles.

Both activities embody Sugar Labs' core values: they work offline on low-resource devices, support collaborative learning, provide comprehensive accessibility features, and maintain the child-friendly design philosophy that makes learning engaging rather than intimidating.

The technical achievements from real-time collaboration systems to AI integration and performance optimization demonstrate that educational technology can be both sophisticated and accessible. The project's open-source nature ensures that these innovations can be adapted, extended, and improved by the global community of educators and developers.

Most importantly, this project represents a contribution to educational equity. By creating high-quality learning tools that work effectively in resource-constrained environments, the Human Activity Pack helps ensure that all students, regardless of their economic circumstances, have access to engaging and effective educational technology.

The journey through GSoC 2025 has been transformative, providing invaluable experience in educational technology development, open-source collaboration, and the intersection of technical innovation with pedagogical effectiveness. The project's completion marks not an end, but a beginning these activities will continue to evolve through community contributions, serving students and educators worldwide for years to come.

---

## Technical Specifications Summary

### **Supported Platforms**
- Modern web browsers (Chrome, Firefox, Safari, Edge)
- Desktop and tablet interfaces
- Offline functionality with local storage
- Multi-language support (English, French, extensible)

### **Performance Requirements**
- Minimum 2GB RAM for optimal performance
- WebGL-capable graphics
- Canvas 2D support for Stickman activity
- Network connectivity for collaborative features (optional)

### **Educational Specifications**
- Age range: 8-16 years (adaptable)
- Subject areas: Biology, anatomy, animation
- Learning modalities: Visual, kinesthetic, collaborative
- Assessment integration: Built-in quiz and progress features

---

*This report represents 16 weeks of dedicated development contributing to Sugar Labs' mission of providing accessible, high-quality educational technology for all students worldwide.*`,ql=Object.freeze(Object.defineProperty({__proto__:null,default:ja},Symbol.toStringTag,{value:"Module"})),Ba=`---
title: "GSoC’25 Final Report by Om Santosh Suneri"
excerpt: "AI-powered Debugger for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-31"
slug: "2025-08-31-gsoc-25-omsuneri-final-report"
author: "@/constants/MarkdownFiles/authors/om-santosh-suneri.md"
tags: "gsoc25,sugarlabs,final-report,Debugger,AI,Music Blocks,Final Submission"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

## Abstract

This project presents the development and implementation of an AI-powered debugging assistant integrated directly into the Music Blocks visual programming environment. Music Blocks, as a visual programming language designed for creating music, faces significant accessibility challenges for young learners who struggle with debugging complex block-based compositions. The traditional debugging process requires users to manually trace through their code logic, which can be overwhelming for children and beginners.

This implementation addresses these challenges by leveraging Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and vector embeddings to provide contextual debugging support specifically designed for educational environments. The system transforms raw Music Blocks JSON project files into human-readable text representations and provides intelligent, conversational assistance that helps users understand their code structure, identify potential issues, and learn programming concepts through natural language interaction.

The debugger addresses the critical need for accessible programming assistance in educational technology, particularly for young learners engaged with visual programming languages, while maintaining the educational scaffolding necessary for effective learning.

## Problem Statement and Motivation

Music Blocks serves as an entry point for many children into the world of programming through music creation. However, the current debugging process presents several significant challenges:

**Complexity Barriers for Young Learners:**
- Traditional debugging requires understanding complex program flow and logic structures
- Visual block relationships can become difficult to trace in larger compositions
- Error identification often requires advanced programming knowledge beyond typical user capabilities

**Educational Accessibility Issues:**
- Limited scaffolding for learners who encounter errors or unexpected behavior
- Lack of contextual help that connects programming concepts to musical outcomes
- Absence of natural language explanation for technical programming constructs

**Technical Limitations:**
- No integrated assistance for understanding block relationships and dependencies
- Limited feedback mechanisms for helping users improve their programming practices
- Insufficient support for educators teaching programming concepts through Music Blocks

**Project Objectives:**
This project aims to bridge these gaps by creating an intelligent debugging companion that provides educational support through conversational AI, making programming concepts more accessible while maintaining the creative and educational value of the Music Blocks environment.

## Project Demonstration

<div>

[![AI-Powered Debugger Widget Demo](http://img.youtube.com/vi/G-NfDo_A5PM/0.jpg)](http://www.youtube.com/watch?v=G-NfDo_A5PM "AI-Powered Debugger Widget Demo")

**🎥 [Click to Watch the Demo Video](https://www.youtube.com/watch?v=G-NfDo_A5PM)**

</div>

---

## Technical Implementation

### Core Innovation: AI-Powered Educational Debugging

The implementation follows a comprehensive approach that transforms traditional debugging into an educational conversation. Rather than simply identifying errors, the system provides contextual learning opportunities that help users understand both their immediate problems and broader programming concepts.

### Phase 1: Foundation Components (Weeks 1-2)

**JSON-to-Text Converter Development**
- Designed and implemented a comprehensive parser for Music Blocks JSON project files that addresses the fundamental challenge of making visual programming code readable
- Migrated JavaScript-based conversion logic to Python for seamless backend integration, ensuring consistency across development environments
- Developed hierarchical text representation with proper indentation and block relationship mapping, creating a bridge between visual and textual programming concepts
- Implemented support for complex block structures including nested loops, conditional statements, and parameter passing
- Deployed public-facing tool via GitHub Pages for community accessibility, enabling educators and students to understand project structure

<a href=""><img src="https://i.ibb.co/ycNPrKVs/Screenshot-2025-06-28-at-10-42-38-AM.png" alt="JSON-to-Text Converter"></a>

- **Repository:** [JSON to Text Converter](https://github.com/omsuneri/JSON-to-Text-representation/)
- **Live Demo:** [Converter Interface](https://omsuneri.github.io/JSON-to-Text-representation/)

### Phase 2: AI Backend Infrastructure (Weeks 2-7)

**Retrieval-Augmented Generation System**
- Implemented FastAPI backend with Google Gemini LLM integration, chosen for its strong performance in educational contexts and ability to generate age-appropriate responses
- Established Qdrant vector database for semantic search capabilities, enabling the system to retrieve relevant examples and explanations based on user queries
- Created vector embeddings from 25+ curated Music Blocks example projects, providing the AI with practical knowledge of common programming patterns and solutions
- Developed automated scraping pipeline for Music Blocks lesson plans from MAP FLC, ensuring curriculum alignment and pedagogical appropriateness
- Implemented context-aware prompt engineering with adaptive response mechanisms that adjust complexity based on user interaction patterns and apparent skill level

**Educational Context Integration:**
- Embedded lesson plans and educational materials to ensure responses align with established pedagogical approaches
- Developed progressive difficulty system that starts with simple explanations and gradually introduces more complex concepts
- Created specialized prompts for different learning scenarios, from basic block placement to advanced composition techniques

**Technical Specifications:**
- **LLM Provider:** Google Gemini API
- **Vector Database:** Qdrant Cloud Cluster
- **Embedding Model:** Sentence Transformers
- **Backend Framework:** FastAPI with CORS support

### Phase 3: Web Application Development (Weeks 3-6)

**Streamlit-based Debugging Interface**
- Developed comprehensive web application deployed on Streamlit Cloud
- Integrated JSON conversion pipeline directly into debugging workflow
- Implemented session management with conversation history tracking
- Added chat export functionality for educational documentation and review

<a href=""><img src="https://i.ibb.co/FbHymBYN/Screenshot-2025-07-11-at-2-16-30-PM.png" alt="Standalone streamlit app for Music Blocks Debugger"></a>

- **Live Application:** [Music Blocks Debugger](https://debuggmb.streamlit.app/)

### Phase 4: Native Widget Integration (Weeks 8-12)

**Music Blocks Widget Implementation**
- Developed JavaScript-based widget integrated seamlessly into the Music Blocks environment, eliminating the need for external tools or context switching
- Implemented real-time project analysis that automatically processes the current state of user projects and provides immediate contextual feedback
- Created conversational interface with session-aware interaction tracking, allowing for continuous dialogue that builds upon previous exchanges
- Established production deployment on AWS EC2 with systemd service management, ensuring reliable 24/7 availability
- Achieved UI/UX consistency with existing Music Blocks design patterns, maintaining familiar interaction paradigms for users
- Integrated export functionality allowing students and educators to save debugging conversations for review and assessment purposes

<a href=""><img src="https://i.ibb.co/GQhsc2fk/Screenshot-2025-08-23-at-12-35-13-PM.png" alt="Music Blocks Debugger Widget"></a>

**Key Innovation - Seamless Educational Integration:**
The widget represents a breakthrough in educational software design by providing AI assistance without disrupting the creative flow. Students can ask questions, receive explanations, and continue working within the same environment, maintaining focus on their musical and programming objectives while receiving intelligent support when needed.

---

## System Architecture

### High-Level Architecture Diagram

<a href=""><img src="https://i.ibb.co/dYWCkh4/t1agqf3q.png" alt="High-Level Architecture"></a>

### Data Flow Architecture

<a href=""><img src="https://i.ibb.co/fGkGn3q4/Screenshot-2025-08-22-at-12-34-44-AM.png" alt="Data Flow Architecture"></a>

### Core System Components

**Frontend Layer**
- **Music Blocks Widget:** JavaScript-based UI component with chat interface
- **Web Application:** Streamlit-based standalone debugging platform
- **Converter Interface:** Public JSON-to-text conversion tool

**Backend Services**
- **FastAPI Server:** RESTful API with LLM integration and context retrieval
- **Authentication Layer:** Session management and conversation tracking
- **JSON Processor:** Music Blocks project parsing and text conversion

**Data Layer**
- **Qdrant Vector Database:** Semantic search and embedding storage
- **Project Repository:** Curated Music Blocks examples and lesson plans
- **Session Storage:** Conversation history and user context

**External Integrations**
- **Google Gemini API:** Large Language Model for conversational responses
- **AWS EC2:** Production deployment infrastructure

---

## Educational Impact and Innovation

### Pedagogical Innovation in Programming Education

**Addressing Critical Educational Challenges:**
This implementation directly addresses the documented challenges in visual programming education, particularly the "debugging barrier" that prevents many young learners from progressing beyond basic programming concepts. By providing intelligent, contextual assistance that maintains educational scaffolding principles, the system enables learners to overcome obstacles without compromising the learning process.

**For Student Learning:**
- **Contextual Learning Support:** AI assistance draws from embedded educational content to provide explanations that connect programming concepts to musical outcomes
- **Progressive Skill Development:** Adaptive response system that adjusts complexity based on user interaction patterns, supporting learners as they advance from novice to intermediate programming skills
- **Maintained Creative Flow:** Seamless integration eliminates context switching, allowing students to maintain focus on creative expression while receiving technical support

**For Educational Practice:**
- **Assessment and Documentation:** Exportable conversation logs provide educators with detailed insights into student thinking processes and problem-solving approaches
- **Curriculum Integration:** AI responses align with established Music Blocks lesson plans and educational frameworks, supporting classroom implementation
- **Scalable Support:** Enables individualized assistance in classroom
- **Professional Development:** Comprehensive documentation and guides support educator training and implementation in diverse educational contexts

### Technical Innovations and Implementation

**AI-Education Integration:**
- **Implementation of RAG in Visual Programming Education:** This project represents documented application of Retrieval-Augmented Generation specifically designed for visual programming education, establishing new patterns for AI-assisted learning in creative programming environments
- **Adaptive Educational Prompt Engineering:** Developed sophisticated prompt engineering techniques that adjust response complexity, tone, and content based on user interaction patterns and apparent skill level, creating a truly adaptive learning companion
- **Context-Aware Educational Response Generation:** Implemented advanced context retrieval that combines current project state, educational content embeddings, and user history to generate responses that are both technically accurate and pedagogically appropriate
- **Session-Aware Learning Continuity:** Created conversation management systems that maintain learning context across sessions, enabling progressive skill development and personalized learning pathways

**Architectural Innovations:**
- **Modular Educational AI Architecture:** Designed component-based system enabling independent scaling of AI services, educational content management, and user interface components while maintaining educational effectiveness
- **Production-Ready Educational Deployment:** Established robust deployment patterns for educational AI systems including error handling, monitoring, and reliability measures essential for classroom environments
- **Cross-Platform Educational Integration:** Developed integration patterns that support both web-based and native application deployment, ensuring accessibility across diverse educational technology infrastructures
- **Real-Time Educational Content Retrieval:** Implemented efficient vector search systems optimized for educational content retrieval, enabling sub-second response times critical for maintaining learner engagement

---

## Development Timeline and Milestones

| **Development Phase** | **Duration** | **Technical Focus** | **Key Deliverables** |
|----------------------|--------------|--------------------|--------------------|
| **Foundation** | Weeks 1-2 | JSON Parser & RAG Implementation | JSON-to-Text converter, Initial Streamlit prototype |
| **Infrastructure** | Weeks 3-4 | Cloud deployment & LLM optimization | Public applications, Enhanced response quality |
| **Integration** | Weeks 5-6 | System consolidation & UX refinement | Unified debugger application, Export functionality |
| **Backend Development** | Week 7 | API architecture & Educational content | FastAPI server, Lesson plan embedding pipeline |
| **Native Integration** | Weeks 8-9 | Music Blocks widget development | JavaScript widget, Real-time chat interface |
| **Production Polish** | Weeks 10-11 | UI/UX consistency & Testing | Production-ready widget, Design system compliance |
| **Deployment** | Week 12 | Infrastructure & Documentation | AWS deployment, Comprehensive documentation |

## Technical Specifications

### Performance Metrics
- **Response Time:** Average 5-7 seconds for context-aware debugging responses
- **Scalability:** Supports concurrent users through modular backend architecture
- **Availability:** 99.9% uptime through AWS EC2 with systemd service management
- **Accuracy:** Context retrieval from 20+ embedded projects and lesson plans

### Technology Stack
- **Frontend:** JavaScript (Music Blocks widget), Streamlit (web application)
- **Backend:** Python FastAPI, uvicorn ASGI server
- **AI/ML:** Google Gemini API, sentence-transformers for embeddings
- **Database:** Qdrant vector database cluster
- **Infrastructure:** AWS EC2, systemd service management, GitHub Pages
- **Development:** Git version control, modular Python architecture

---

## Project Resources and Documentation

### Source Code Repositories
- **Primary Repository:** [AI-powered Debugger for Music Blocks](https://github.com/omsuneri/AI-powered-Debugger-for-Music-Blocks)
- **JSON Converter:** [JSON to Text Representation](https://github.com/omsuneri/JSON-to-Text-representation)

### Live Deployments and Demonstrations
- **Production Debugger:** [Streamlit Application](https://debuggmb.streamlit.app/)
- **JSON Converter Tool:** [Public Interface](https://omsuneri.github.io/JSON-to-Text-representation/)
- **System Demonstration:** [YouTube Video](https://www.youtube.com/watch?v=G-NfDo_A5PM)

### Technical Documentation
- **Developer Guide:** [Contributor Documentation](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/js/widgets/aidebugger-guide.md)
- **User Manual:** [Implementation Guide](https://github.com/omsuneri/musicblocks/blob/Debugger-docs/AI-Debugger-widget-guide.md)
- **API Documentation:** Available in repository README and inline code documentation

---

## Pull Requests and Weekly Blogs 

### **Pull Requests** 
 - [AI Debugger Widget](https://github.com/sugarlabs/musicblocks/pull/4739)
 - [Minor UI fixes](https://github.com/sugarlabs/musicblocks/pull/4741)
 - [Technical Documentation](https://github.com/sugarlabs/musicblocks/pull/4746)

### **Weekly Blogs**
 - [Week 1](https://www.sugarlabs.org/news/developer-news/2025-06-07-gsoc-25-omsuneri-week01)
 - [Week 2](https://www.sugarlabs.org/news/developer-news/2025-06-14-gsoc-25-omsuneri-week02)
 - [Week 3](https://www.sugarlabs.org/news/developer-news/2025-06-22-gsoc-25-omsuneri-week03)
 - [Week 4](https://www.sugarlabs.org/news/developer-news/2025-06-29-gsoc-25-omsuneri-week04)
 - [Week 5](https://www.sugarlabs.org/news/developer-news/2025-07-06-gsoc-25-omsuneri-week05)
 - [Week 6](https://www.sugarlabs.org/news/developer-news/2025-07-13-gsoc-25-omsuneri-week06)
 - [Week 7](https://www.sugarlabs.org/news/developer-news/2025-07-20-gsoc-25-omsuneri-week07)
 - [Week 8](https://www.sugarlabs.org/news/developer-news/2025-07-27-gsoc-25-omsuneri-week08)
 - [Week 9](https://www.sugarlabs.org/news/developer-news/2025-08-04-gsoc-25-omsuneri-week09)
 - [Week 10](https://www.sugarlabs.org/news/developer-news/2025-08-10-gsoc-25-omsuneri-week10)
 - [Week 11](https://www.sugarlabs.org/news/developer-news/2025-08-17-gsoc-25-omsuneri-week11)
 - [Week 12](https://www.sugarlabs.org/news/all/2025-08-24-gsoc-25-omsuneri-week12)

---

## Project Impact and Future Directions

### Transformative Impact on Educational Technology

This implementation represents a paradigm shift in how AI can be integrated into educational programming environments. Rather than replacing traditional teaching methods, the system amplifies educator effectiveness and provides personalized support that scales across diverse learning contexts. The project demonstrates that AI can serve as an effective pedagogical tool when designed with educational principles as foundational requirements rather than secondary considerations.

**Measurable Educational Outcomes:**
- **Reduced Barrier to Entry:** The natural language interface significantly lowers the technical threshold for engaging with programming concepts, making Music Blocks accessible to broader demographic groups
- **Enhanced Learning Retention:** By providing contextual explanations rather than simple error correction, the system supports deeper understanding of programming principles
- **Increased Creative Expression:** Students can focus on musical creativity while receiving technical support, leading to more ambitious and complex compositions
- **Improved Educator Efficiency:** Teachers can support larger classes more effectively with AI providing individualized assistance for common debugging scenarios

### Future Development Opportunities

**Technical Enhancements:**
- Multi-language support for international educational deployment
- Offline capability using local language models for resource-constrained environments
- Advanced analytics for educator insights into student learning patterns
- Integration with learning management systems for assignment tracking

**Educational Expansions:**
- Collaborative debugging features for classroom group projects
- Adaptive assessment integration for personalized learning paths
- Teacher dashboard for monitoring student progress and common debugging patterns
- Extended curriculum support beyond music programming concepts

---

## Acknowledgments

This project was completed under the mentorship of Walter Bender, Sumit Srivastava, and Devin Ulibarri as part of Google Summer of Code 2025 with Sugar Labs. The successful implementation reflects the collaborative nature of open-source educational technology development and the commitment of the Sugar Labs community to accessible learning tools.

Special recognition to the broader Music Blocks community for providing feedback during development and testing phases, and to Google Summer of Code for enabling this contribution to educational technology infrastructure.

---
`,Kl=Object.freeze(Object.defineProperty({__proto__:null,default:Ba},Symbol.toStringTag,{value:"Module"})),Ra=`---
title: "GSoC’25 Final Report by Diwangshu Kakoty"
excerpt: "Reflection Widget for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-09-01"
slug: "2025-09-01-gsoc-25-diwangshu-final-report"
author: "@/constants/MarkdownFiles/authors/diwangshu-kakoty.md"
tags: "gsoc25,sugarlabs,final-report,AI,Music Blocks,Final Submission"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

## Abstract

Music Blocks is an educational tool that combines coding and music to enhance learning outcomes. To further support this goal, the 'Reflection Widget' was developed.

But first, what is reflective learning? It is a technique in which learners ask themselves questions that encourage them to think critically about their past actions. This requires careful analysis of what actually happened in order to understand the depth of the experience. The AI-powered Reflection Widget provides an accessible way to engage in this process.

At its core, the widget is a chat interface where AI mentors pose reflective questions, and users respond. By answering these questions, learners are encouraged to think more deeply about their experiences.

Users can interact with any mentor at any time. Another key feature of the widget is analysis: the AI mentor generates a detailed report on the user’s learning progress by comparing past reflections with the most recent conversation.

---

## Technical Implementation

### Phase 1: Project Setup

- The first step was deciding which LLM to use, since it forms the core of the chatbot. I initially experimented with Llama-3 running locally, but later switched to Gemini API.  
- I explored various sentence transformers available on HuggingFace. These play a crucial role in building a reliable RAG system. I ultimately chose the \`sentence-transformers/all-MiniLM-L6-v2\` model because it is both lightweight and accurate.  
- I learned and implemented a basic RAG pipeline. At first, I used ChromaDB as the vector database, but eventually migrated to a Qdrant cluster, a cloud-based vector database.
- The chatbot was hosted on Streamlit to allow mentors to test it.  
- A FastAPI backend was developed with \`/chat\`, \`/summary\`, and \`/analysis\` endpoints.

### Phase 2: Adding Features

**Multi-Agent Chatbot**  
- To make reflection more engaging, three persona-based AI agents were introduced:  
  - **Rohan** – for general reflection practice.  
  - **Alan Kay** – for logical and coding-related reflections.  
  - **Ludwig van Beethoven** – for reflections on musical aspects.  

**Enhanced Context Passing**  
- To better understand the user’s project, the chatbot now leverages the JSON conversion function originally developed for the \`AI Debugger\`. The resulting flowchart is transformed into an algorithmic summary, which helps the LLM interpret the project’s structure.  
- In addition, the descriptions of the blocks used in the project are also passed to the LLM.  

**Automated Periodic Summaries**  
- Previously, users had to click a separate button to generate summaries. However, based on feedback from Streamlit app testing, the system was updated to generate summaries periodically on its own, improving the overall user experience.  

**Reasoning Model Integration**  
- I experimented with \`reasoning models\`, which employ a chain-of-thought approach to simulate logical reasoning. This significantly improved the LLM’s ability to understand user projects.  
- As a result, the algorithmic summary is now generated using a reasoning model, while the rest of the conversation is handled by a base model.  

### Phase 3: Fast API Backend

- Initially, FastAPI was not part of the setup. Later, it was upgraded to include new API endpoints such as \`/chat\` and \`/analysis\`. Over time, additional endpoints like \`/projectcode\` and \`/updatecode\` were also introduced.  

You can learn more about this [here](https://github.com/sugarlabs/musicblocks_reflection_fastapi).  

### Phase 4: Native Widget Integration

- Developed a JavaScript widget and integrated it into the Music Blocks application.  
- Added real-time project analysis that continuously evaluates the user’s project state, produces an algorithmic summary, and initiates reflection with the user.  
- Built a conversational interface with session-aware tracking, allowing seamless dialogue that carries over context from previous exchanges.  
- Implemented \`localStorage\` support to store analysis reports, which can be reused for generating updated insights.  
- Introduced a **Download as Text** button for easy report export.  
- Added a **Refresh** button to ensure the AI receives the latest code whenever the user makes changes.  

<a href="https://ibb.co/kgVBJkJ9"><img src="https://i.ibb.co/Z6RXStSY/Screenshot-2025-09-04-213236.png" alt="reflection" border="0"></a>

### Phase 5: Deploy to EC2

- The FastAPI server was deployed on an AWS EC2 t3.micro instance running Ubuntu 22.04 LTS. 
- Security groups were configured to allow HTTP, HTTPS, SSH, and FastAPI’s custom port. 
- Since the default storage and memory were limited, the disk was resized and a swap file was created to prevent crashes.
- The project repository was cloned, dependencies installed in a virtual environment, and environment variables configured. - - - Finally, the FastAPI app was set up as a systemd service, allowing it to run in the background, restart on failure, and start automatically on boot.

---

## Data Flow Diagram

<a href="https://ibb.co/LdrV1mp5"><img src="https://i.ibb.co/608jFzsB/final-report.png" alt="client-server" border="0"></a>

---

## Tech Stack and Tools

**Frontend**
- Technologies: HTML, CSS, JavaScript
- Component: Music Blocks widget (chat-based interface)

**Backend**
- Framework: Python FastAPI with Uvicorn server, LangChain
- LLM Services: Google Gemini API
- Sentence-transformers (embedding generation)

**Vector Database**
- Qdrant cluster for semantic search and storage

**Infrastructure**
- AWS EC2 (deployment)
- systemd (service management)

---

## Project Code

- **Backend Code:** [Fast API server](https://github.com/sugarlabs/musicblocks_reflection_fastapi)
- **Frontend Code:** [Reflection Widget](https://github.com/sugarlabs/musicblocks/blob/master/js/widgets/reflection.js)

## Pull Requests 

 - [Music Blocks Reflection Widget (Frontend)](https://github.com/sugarlabs/musicblocks/pull/4747)
 - [Documentation for Developers](https://github.com/sugarlabs/musicblocks/pull/4749)
 - [Documentation for Users](https://github.com/sugarlabs/musicblocks/pull/4753)

## Weekly Blogs

 - [Week 1](https://www.sugarlabs.org/news/developer-news/2025-06-04-gsoc-25-Diwangshu-week01)
 - [Week 2](https://www.sugarlabs.org/news/developer-news/diwangshu-kakoty)
 - [Week 3](https://www.sugarlabs.org/news/developer-news/2025-06-22-gsoc-25-diwangshu-week03)
 - [Week 4](https://www.sugarlabs.org/news/developer-news/2025-06-29-gsoc-25-diwangshu-week04)
 - [Week 5](https://www.sugarlabs.org/news/developer-news/2025-07-06-gsoc-25-diwangshu-week05)
 - [Week 6](https://www.sugarlabs.org/news/developer-news/2025-07-13-gsoc-25-diwangshu-week06)
 - [Week 7](https://www.sugarlabs.org/news/developer-news/2025-07-20-gsoc-25-diwangshu-week07)
 - [Week 8](https://www.sugarlabs.org/news/developer-news/2025-07-30-gsoc-25-diwangshu-week08)
 - [Week 9](https://www.sugarlabs.org/news/developer-news/2025-08-10-gsoc-25-diwangshu-week09)
 - [Week 10](https://www.sugarlabs.org/news/developer-news/2025-08-22-gsoc-25-diwangshu-week10)
 - [Week 11](https://www.sugarlabs.org/news/developer-news/2025-08-29-gsoc-25-diwangshu-week11)
 - [Week 12](https://www.sugarlabs.org/news/developer-news/2025-08-30-gsoc-25-diwangshu-week12)

---

## Key Learnings

### Frameworks and Tools
- Gained hands-on experience with **FastAPI** and **Streamlit**, including building prototypes and integrating frontend widgets with backend services.  
- Learned to work with **LangChain** as the primary development framework.  
- Explored and deepened understanding of **Gemini** and **LangChain** documentation, covering advanced LLM concepts like structured output, function calling, reasoning, and prompting techniques.  

### APIs and Backend Development
- Learned how API endpoints function and how to manage API keys securely during deployment.  
- Improved understanding of structuring API requests and responses for a smoother user experience.   

### Prompt Engineering
- Discovered the importance of refining prompts and using **few-shot prompting** to achieve more accurate and context-aware LLM outputs.  

### Deployment and Infrastructure
- Learned how to deploy an **EC2 instance on AWS**.  

### Learning Approach
- Realized the importance of relying on **official documentation** over tutorials or blog posts, since it provides the most reliable and up-to-date information.  

## Future Development Goals
- Integrate **Sugar-AI** to enhance capabilities in the near future.  
- Add **multi-language support** to enable international educational use.  
- Implement **offline functionality** using small language models for resource-constrained environments.  
- Extend the reflection learning interface to additional Sugar apps like Sugar Journal.

---

## Acknowledgments

This project was carried out under the mentorship of **Walter Bender**, **Sumit Srivastava**, and **Devin Ulibarri** as part of **Google Summer of Code 2025** with **Sugar Labs**. Its successful implementation highlights the collaborative spirit of open-source educational technology and the dedication of the Sugar Labs community to creating accessible learning tools.  

Special thanks to the wider **Music Blocks community** for their valuable feedback during development and testing, and to **Google Summer of Code** for making this contribution to educational technology possible.  

---`,Vl=Object.freeze(Object.defineProperty({__proto__:null,default:Ra},Symbol.toStringTag,{value:"Module"})),Oa=`---
title: "GSoC '25 Week 12 Update by Bishoy Wadea"
excerpt: "Sequence Wizard - AI-Powered Pattern Learning"
category: "DEVELOPER NEWS"
date: "2025-09-04"
slug: "gsoc-25-BishoyWadea-week12"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week12,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

# Week 12 Progress Report by Bishoy Wadea

**Project:** [Sequence Wizard](https://github.com/Bishoywadea/Sequence-Wizard)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-08-29 – 2025-09-04  

---

## Goals for This Week

- **Develop new Sugar activity: Sequence Wizard**
- **Implement AI-powered sequence prediction system**
- **Create adaptive learning mechanism for pattern recognition**

---

## About Sequence Wizard

Sequence Wizard is an innovative AI-powered educational tool that learns to predict the next number in mathematical sequences. Unlike traditional pattern games, this activity features a sophisticated AI that improves its predictions through user feedback, creating a unique collaborative learning experience between student and machine.

---

## Achievements

### Core Framework

- **Activity Structure**  
  Established basic Sugar activity framework with modular architecture  
  [Commit](https://github.com/Bishoywadea/Sequence-Wizard/commit/eb35d55d322b75940b032b3e9b487d6105dd4c84)

- **Modular Design**  
  Split prediction logic into separate files for better maintainability  
  [Commit](https://github.com/Bishoywadea/Sequence-Wizard/commit/fbe7731cc4857d1e77193532ce14e125952a8b55)

![Sequence Wizard Interface](https://raw.githubusercontent.com/Bishoywadea/Sequence-Wizard/refs/heads/main/screen_shots/01.png)
*Main interface showing sequence input and AI prediction*

### AI Learning System

- **Feedback Mechanism**  
  Created user feedback system for training the AI  
  [Commit](https://github.com/Bishoywadea/Sequence-Wizard/commit/1bc971e55d8876cb2ad356b0ead069150cbc43c8)

- **Data Persistence**  
  Implemented saving of learned patterns for continuous improvement  
  [Commit](https://github.com/Bishoywadea/Sequence-Wizard/commit/4a24130a28f56bcb23c0385dfe0d9ee7b493019c)


![Learning in Action](https://raw.githubusercontent.com/Bishoywadea/Sequence-Wizard/refs/heads/main/screen_shots/02.png)
*AI learning from user feedback on incorrect predictions*

---

## How It Works

1. **Enter Sequence**: Type numbers separated by spaces or commas
2. **Get Prediction**: Click "Predict Next Number" to see AI's guess
3. **Give Feedback**: Mark the prediction as Correct or Wrong
4. **Teach AI**: If wrong, provide the correct answer to train the AI

---

## Challenges & Solutions

- **Challenge:** Creating an AI system that could learn from limited examples while being computationally efficient for XO laptops.

- **Solution:**  
  - Implemented a hierarchical rule system that tries simple patterns first
  - Used lightweight pattern matching algorithms instead of heavy ML frameworks
  - Created a confidence scoring system to prioritize learned patterns
  - Optimized memory usage by storing only successful pattern templates

- **Challenge:** Making the AI's learning process transparent and educational for students.

- **Solution:**  
  - Added visual feedback showing which rule the AI used for prediction
  - Implemented explanation system that shows the AI's "thinking process"
  - Designed the interaction to feel like teaching a friend rather than using a tool

---

## Key Learnings

- Developed understanding of pattern recognition algorithms and their educational applications
- Learned to implement lightweight machine learning suitable for resource-constrained environments
- Gained experience in creating interactive AI systems that learn from user feedback
- Improved skills in designing educational tools that make abstract concepts tangible

---

## Technical Highlights

- **4-Level Hierarchy**: Rule-based system with increasing complexity levels
- **Adaptive Learning**: AI improves accuracy through user corrections
- **Pattern Memory**: Stores successful patterns for future recognition
- **Lightweight Design**: Optimized for low-resource Sugar environments

---

## Next Week's Roadmap

- Begin development of new Sugar activity: **AI Organizer**`,Jl=Object.freeze(Object.defineProperty({__proto__:null,default:Oa},Symbol.toStringTag,{value:"Module"})),za=`---
title: "DMP ’25 Final Report by Harshit Verma"
excerpt: "Final Report for the project LLM Powered Debugger for Pippy"
category: "DEVELOPER NEWS"
date: "2025-09-08"
slug: "2025-09-08-dmp-25-therealharshit-final-report"
author: "@/constants/MarkdownFiles/authors/harshit-verma.md"
tags: "dmp25,sugarlabs,final report,therealharshit"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# DMP '25 Final Report by Harshit Verma

## Contributor Details

**Name:** Harshit Verma  
**Email:** [therealharshit014@gmail.com](therealharshit014@gmail.com)  
**GitHub:** [therealharshit](https://github.com/therealharshit)   
**Organization:** [Sugar Labs](https://www.sugarlabs.org/)  
**Project:** [LLM-powered Debugger for Pippy](https://github.com/sugarlabs/Pippy/issues/95)  
**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya](https://github.com/chimosky), [Kshitij Shah](https://github.com/kshitijdshah99)  


## Introduction  

Debugging is one of the most challenging parts of programming for beginners, especially children who are just starting their coding journey. While many Large Language Models (LLMs) are marketed as tools that “write code for you,” they also have great potential to guide learners through the process of understanding and fixing errors in their code.  

The Pippy Debugger project was developed to harness this potential by integrating an LLM-powered debugger into the Pippy Activity which is a Python learning environment in Sugar. The goal was not just to provide solutions, but to teach children how to debug, giving them context, explanations, and guidance in an age-appropriate manner.  


## Objectives  

- To integrate an LLM-powered debugger within the Pippy Activity.  
- To make debugging accessible, engaging, and educational for children.  
- To provide contextual feedback that helps learners understand the purpose of their code before debugging.  
- To ensure seamless integration with Sugar AI, allowing Pippy to use centralized inference endpoints.  
- To design a system where debugging history is saved to the Journal, enabling reflection and learning over time.  


## Background  

Many debugging tools are built for professional developers and are often too complex for beginners. Existing LLM applications primarily focus on code generation, while their educational potential for debugging remains underexplored.  

The proposed Pippy Debugger builds on the idea of guiding learners through a debugging journey rather than spoon-feeding solutions. By integrating with Pippy and Sugar AI:  
- Learners see the context of their code before debugging starts.  .  
- The output is filtered and age-appropriate for children.  

## Methodology  

### Tools & Technologies Used  

- **Python** – Core programming language.  
- **FastAPI** – Backend framework for the \`/debug\` endpoint.  
- **LangChain** – To chain multiple LLM calls for better workflows.  
- **Hugging Face Transformers** – For integrating **Mistral 7B**.   
- **Google Gen AI** – For running **Gemma-3-27B-IT**.  
- **GTK 3** – For UI integration in Pippy.  
- **Sugar AI** – Central inference system connecting Pippy with LLMs.  
- **Custom Markdown Parser** – To render responses in the Debug Terminal.  

### Workflow  
1. Learner writes Python code in Pippy.  
2. On clicking Debug, the code is sent to the \`/debug\` endpoint in Sugar AI.  
3. The backend processes the request, retrieves model inference, and formats the response.  
4. The response is contextualized, simplified, and displayed in a debugging terminal inside Pippy.  
5. Debug history (code, errors, suggestions) is saved into the Journal for future reflection.  

## Technical Implimentation

### **Phase 1 (Week 1 – Week 3): Exploration & Setup**
- Studied the Pippy codebase and its integration with Sugar.  
- Explored Sugar AI and tested existing endpoints.  
- Evaluated multiple LLM options (CodeLlama, Mistral via Ollama).  
- Mentor suggested moving inference to Hugging Face models.  
- Improved base prompt design for debugging tips.  
- Experimented with different ways of displaying debugging responses.  

---

### **Phase 2 (Week 4 – Week 6): Backend Development & UI Integration**
- Set up a FastAPI server with a \`/debug\` endpoint.  
- Integrated Mistral 7B model through Hugging Face for debugging.  
- Added Run and Debug buttons in the Pippy UI.  
- Built a debugging terminal in GTK.  
- Implemented contextualization – showing learners the code context before debugging starts.  
- Raised a PR in Sugar AI for \`/debug\` endpoint.
- Learned LangChain for chaining LLM calls into a structured workflow.  

---

### **Phase 3 (Week 7 – Week 9): Refinement & Sugar AI Integration**
- Prepared and presented midterm PPT for DMP evaluation.  
- Continued developing and refining the \`/debug\` endpoint in Sugar AI.  
- Completed integration of \`/debug\` endpoint.  
- Tested debugging responses on various buggy Python codes.  
- Found that some responses were too technical → began refining prompt workflow.  

---

### **Phase 4 (Week 10 – Week 12): Optimization**    
- Shifted to a larger model (Gemma-3-27B-IT) for more age-appropriate responses.  
- Improved prompt workflows to simplify explanations for children.  
- Enhanced Markdown parser for better formatting in the debugging terminal.  
- Began work on saving debug history to the Sugar Journal.  
- Designed a JSON-based structure for storing session details (code, error, AI suggestions).  
- Partially implemented prototype for saving and retrieving debug logs.  

## Demonstrations

### UI Implimentation 

- Updated Pippy UI:  
  ![Pippy UI](assets/Images/Pippy-UI01.png)  

- Debugging terminal with LLM response:  
  1. ![Debug Terminal](assets/Images/Pippy-UI02.png)  

  2. ![Debug Terminal](assets/Images/Pippy-UI03.png)  


### Project Demo  
**[Watch Video](https://drive.google.com/file/d/1APnZja9uzX197zNhyT4xZ2wRJTvH0wIN/view?usp=sharing)**    

## Resources

### Code Repositories  

- **[Pippy Debugger Backend](https://github.com/sugarlabs/pippy-debugger-backend)**  
- **[Sugar AI](https://github.com/sugarlabs/sugar-ai)**  
- **[Pippy](https://github.com/sugarlabs/Pippy)**  

### Pull Requests  
- **[Sugar AI: Add /debug endpoint for Pippy Debugger #28](https://github.com/sugarlabs/sugar-ai/pull/28)**  
- **[Pippy: Pippy Debugger Integration #113](https://github.com/sugarlabs/Pippy/pull/113)**
- **[Help Activity: Add Debugger docs to Pippy #121](https://github.com/godiard/help-activity/pull/121)**  

### Docs
- **[Responses from the Debugger](https://docs.google.com/document/d/1zy0udbisHH9ZMHo3ln6tbKVYhPTRfw4cs9N0g3W_CKg/edit?usp=sharing)**  

### Blogs

- **[Weekly Blogs](https://www.sugarlabs.org/authors/harshit-verma)**   


## Key Learnings  

### Frameworks and Tools  
- Gained hands-on experience with FastAPI by building and refining the \`/debug\` endpoint.  
- Learned to integrate LangChain for chaining multiple LLM calls and improving prompt workflows.  
- Worked with Hugging Face Transformers and Google Gen AI APIs to run and test LLMs like Mistral 7B and Gemma-3-27B-IT.  
- Built a custom Markdown parser and explored GTK 3 widgets for UI integration in Pippy.  

### APIs and Backend Development  
- Improved understanding of designing API request/response schemas to enable clean communication between Sugar-AI and Pippy.  
- Implemented error handling, response validation, and threading for a more reliable and responsive system.  

### Prompt Engineering  
- Learned the importance of refining prompts to make debugging responses child-friendly and age-appropriate.  
- Experimented with contextualization and code-first workflows to guide learners before debugging.  

### Deployment and Infrastructure  
- Learned how to dockerize applications and deploy them on AWS EC2 for scalable and efficient model inference.

## Conclusion  

The Pippy Debugger successfully laid the foundation for the LLM-powered debugger tailored for children. With the ability to display contextual explanations, simplify errors, and guide learners through debugging, the project moves one step closer to making programming education more accessible and engaging.  

## Acknowledgment  

This project was completed under the mentorship of Walter Bender, Ibiam Chihurumnaya & Kshitij Shah as part the Dedicated Mentorship Program 2025.

I sincerely thank my mentors, the Sugar Labs, and C4GT community for their continuous guidance and support throughout this project.

It has been an incredibly rewarding summer working on this project, where I not only had the opportunity to contribute to open-source development but also to learn, grow, and collaborate with an inspiring community. This experience has motivated me to carry forward the spirit of open source, to continue contributing, and to build tools and software that make technology more accessible and impactful for everyone.

---`,Xl=Object.freeze(Object.defineProperty({__proto__:null,default:za},Symbol.toStringTag,{value:"Module"})),Fa=`---
title: "GSoC '25 Week 17 and Bug Fixes Update by Aditya Kumar Singh"
excerpt: "Final polish: template palette, fullscreen mode implemented, export/import refinements, shared-mode fixes, localization and final report PRs."
category: "DEVELOPER NEWS"
date: "2025-09-09"
slug: "2025-09-09-gsoc-25-AdityaKrSingh26-week17"
author: "@/constants/MarkdownFiles/authors/aditya-singh.md"
tags: "gsoc25,sugarlabs,week17,AdityaKrSingh26,final"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week 17 Progress and Bug Fix Report by Aditya Kumar Singh

**Project:** [Sugarizer](https://github.com/llaske/sugarizer)  
**Mentors:** [Lionel Laské](https://github.com/llaske)  
**Assisting Mentors:** [Samarth Bagga](https://github.com/SamarthBagga)  
**Reporting Period:** 2025-09-03 - 2025-09-10

---

## Goals for this week

- Land final UX polish and localization for the Template Palette.  
- Implement fullscreen viewing mode and evaluate behavior after canvas resize.  
- Make export-to-video produce standard-resolution outputs and verify parity with preview.  
- Harden PoseNet-based import from video and prevent multi-person crashes.  
- Finish documentation / PRs: weekly progress + final report.  

---

## This week’s achievements

1. **Published progress and final report PRs**
    - Created and submitted the weekly progress PR documenting the code changes, decisions, and open issues.  
    - Submitted the final GSoC report as a PR summarizing the whole project and linking the main feature merges. The final report contains the overall timeline, metrics, and merged PR list.
    - Final Submissions : 
        - [GSoC '25 Final Report by Aditya Kumar Singh](https://www.sugarlabs.org/news/all/2025-08-31-gsoc-25-AdityaKrSingh26-final-report)
        - [GSoC '25 Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/etFtxnpi)



3. **Fullscreen viewing mode**
    - **Fullscreen implemented.** A fullscreen toggle hides toolbars and the timeline, enlarges the canvas to the viewport, and reveals an "unfullscreen" control. The code adds/removes a \`fullscreen\` class on the canvas and calls \`resizeCanvas()\` to recompute dimensions. 
    - **Optimized fullscreen behavior for video preview.** Frame list / thumbnails are hidden in fullscreen to provide an uncluttered video-showing mode. This makes the activity better for presentations or playback-only viewing.

4. **Export-to-Video — fixed resolution and preview parity**
    - **Standard resolutions.** Export pipeline changed from recording the raw bounding box dimensions to rendering at fixed standard resolutions (720p and 1080p). This makes outputs predictable and easier to share. The export code now renders the animation frames into a fixed-size canvas before feeding them to MediaRecorder.
    - **Verified preview parity.** Exported video frames are rendered using the same frame reconstruction (baseFrames + deltaFrames) and same \`enforceJointDistances()\` constraints that power the activity preview, ensuring exported video matches what users see in the editor.

5. **Import from video (PoseNet) — safer, more robust**
    - **Limit to one stickman per video import.** Import flow now only produces a single stickman from a video to avoid crashes and ambiguity when PoseNet detects multiple people. This was a pragmatic choice to keep the feature reliable on low-end devices and in shared sessions. The import flow and library-loading guard live in \`activity.js\`.
    - **Model selection & loading UX.** PoseNet can be loaded as either MobileNet (fast, light) or ResNet (heavier, more accurate). A loading spinner and disabled UI guard prevent user interactions while TensorFlow.js/Posenet models initialize. There is also a timeout to avoid indefinite blocking.
    - **Frame de-duplication & joint constraints.** Duplicate consecutive frames are skipped and \`enforceJointDistances()\` is applied after mapping PoseNet keypoints to the stickman skeleton to avoid odd limb lengths. This reduces noise and yields smoother imported animations.

6. **Shared mode improvements and remote-offset handling**
    - **Remote offsets stored separately.** When a remote user drags a stickman locally, the offset is stored in \`remoteStickmanPositions[stickmanId]\` and only applied during rendering. This prevents network updates from wiping out local adjustments.
    - **Global vs local moves clarified.** Frame 0 changes are considered global (applied across all frames); moves on later frames are local. Tutorials were updated to explain this, and color-coded indicators were added to the UI. The tutorial and network handlers are updated in the activity code.
    - **Preserve local positioning across drags.** Multiple drag ops no longer accumulate errors; offsets are re-applied consistently so remote stickmen remain stable during playback.

7. **Joint color coding & small UI/UX refinements**
    - **Joint color coding restored:** red = end joints (movable), orange = parent joints (move children), green = hip joint (dragging center). These colors improve discoverability for new users. (Color code implemented in the rendering path.)
    - **Template palette UI finalized.** Buttons follow Sugar UI look-and-feel, previews autoplay muted, and palette close/active state behavior is stabilized.

---

## Challenges & How I Overcame Them

- **Challenge:** Users dragging remote stickmen observed position jumps when network updates arrived.  
  **Solution:** Keep original network joints and a separate local offset; apply offset only during rendering. This preserves local adjustments without interfering with incoming updates.

- **Challenge:** PoseNet sometimes detects multiple people and mapping to a single stickman led to crashes or malformed animations.  
  **Solution:** Limit video import to a single detected person, randomize imported stickman placement to avoid overlap, and apply \`enforceJointDistances()\` after mapping. Also added frame deduplication to reduce noise.

---

## Acknowledgments

Thanks to Lionel Laské and Samarth Bagga for patient guidance and code review, and to the Sugar Labs community for testing and helpful UX feedback. The work this week packaged final UX polish, export/import stability, and the template system into a form ready for the wider community to try and extend.

---
`,$l=Object.freeze(Object.defineProperty({__proto__:null,default:Fa},Symbol.toStringTag,{value:"Module"})),Ua=`---
title: "GSoC '25 Week 13 Update by Bishoy Wadea"
excerpt: "AI Organizer - Image Classification with Machine Learning"
category: "DEVELOPER NEWS"
date: "2025-09-11"
slug: "gsoc-25-BishoyWadea-week13"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,week13,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

# Week 13 Progress Report by Bishoy Wadea

**Project:** [AI Organizer](https://github.com/Bishoywadea/AI-Organizer)  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-09-05 – 2025-09-11 

---

## Goals for This Week

- **Develop new Sugar activity: AI Organizer**
- **Implement machine learning-based image classification**
- **Create educational interface for exploring AI capabilities**

---

## About AI Organizer

AI Organizer (Image Classifier) is an educational activity that introduces students to machine learning concepts through hands-on image classification. The activity uses AI to automatically categorize images into animals, shapes, numbers, or objects, helping students understand how computers "see" and interpret visual information.

---

## Achievements

### Core Implementation

- **Activity Framework**  
  Established Sugar activity structure with AI/ML integration  
  [Commit]()

- **Machine Learning Pipeline**  
  Integrated image classification model with pre-trained weights  
  [Commit](https://github.com/Bishoywadea/AI-Organizer/commit/ee311244568cbf8aa88d56515efc37889939698f)


![AI Organizer Interface](https://raw.githubusercontent.com/Bishoywadea/AI-Organizer/refs/heads/main/screen_shots/01.png)
*Clean interface for image selection and classification*

### User Experience Features

- **Image Selection System**  
  Created intuitive file browser integration for image selection  
  [Commit](https://github.com/Bishoywadea/AI-Organizer/commit/ed66375ebdd4d0641762e6f08b3b54ce248865d5)

- **Confidence Display**  
  Added visual representation of AI confidence levels in predictions  
  [Commit](https://github.com/Bishoywadea/AI-Organizer/commit/388df0ba44d9816ad496e53e6d02427bd4a24f2c)


![Classification Results](https://raw.githubusercontent.com/Bishoywadea/AI-Organizer/refs/heads/main/screen_shots/02.png)
*AI successfully classifying an image with confidence scores*

## How to Use

1. **Choose Image:** Click the folder button or "Choose Image" to select a photo
2. **Classify:** Click "Classify Image" to let the AI analyze it
3. **View Results:** See the category, details, and confidence level
4. **Try Again:** Use Clear button to reset and try different images

---

## Challenges & Solutions

- **Challenge:** Running complex ML models on resource-constrained XO laptops while maintaining responsive performance.

- **Solution:**  
  - Used lightweight, quantized models optimized for edge devices
  - Implemented lazy loading to reduce initial memory footprint
  - Created efficient image preprocessing pipeline
  - Added progress indicators during classification to improve perceived performance

- **Challenge:** Making abstract AI concepts understandable for young students.

- **Solution:**  
  - Designed visual confidence meters instead of numerical percentages
  - Used familiar category names and simple explanations
  - Created interactive tutorials showing step-by-step AI decision process
  - Added "Why did AI think this?" explanations for each classification

---

## Key Learnings

- Gained experience in deploying ML models in educational environments
- Learned to balance model accuracy with computational constraints
- Developed skills in making AI technology accessible to young learners
- Improved understanding of edge computing optimization techniques

---
## Next Week's Roadmap

- **Final GSoC Documentation**
  - Prepare comprehensive final report documenting all 10 activities
  - Compile user feedback and testing results
  - Prepare presentation materials for final evaluation
  - Submit pull requests for official Sugar Labs activity repository`,Yl=Object.freeze(Object.defineProperty({__proto__:null,default:Ua},Symbol.toStringTag,{value:"Module"})),Na=`---
title: "GSoC’25 Final Report by Bishoy Wadea"
excerpt: "Developing 10 Math Sugar Activities"
category: "DEVELOPER NEWS"
date: "2025-09-12"
slug: "2025-09-12-gsoc-25-bishoy-wadea-final-report"
author: "@/constants/MarkdownFiles/authors/bishoy-wadea.md"
tags: "gsoc25,sugarlabs,Final-Report,BishoyWadea"
image: "assets/Images/GSOC.webp"
---

# Google Summer of Code 2025: Educational Activities for Sugar

**Project:** Developing 10 Math Sugar Activities  
**Mentors:** [Ibiam Chihurumnaya](https://github.com/chimosky)  
**Assisting Mentor:** [Walter Bender](https://github.com/walterbender/)  
**Reporting Period:** 2025-05-08 – 2025-09-12  

---

During Google Summer of Code 2025, I embarked on an ambitious journey to develop ten innovative educational activities for the Sugar learning platform. My mission was to create engaging, educational experiences that would enhance various cognitive skills in young learners through interactive gameplay and cutting-edge technologies. Throughout this project, I focused on implementing diverse educational concepts ranging from classic puzzles to AI-powered learning tools, ensuring each activity not only served its educational purpose but also captivated users with intuitive interfaces and engaging mechanics.

This project allowed me to explore various domains including game development, 3D graphics, network programming, and machine learning, while contributing meaningfully to the Sugar community. Through challenges and triumphs, I successfully delivered a comprehensive suite of activities that span mathematical reasoning, spatial intelligence, pattern recognition, and artificial intelligence education.

## Table of Activities

| **Activities** |
|----------------|
| [![Four Color Map Puzzle](https://raw.githubusercontent.com/sugarlabs/Four-Color-Map/e82f9972550ff44e6d400394e4fb53d3eb24d11a/activity/activity-fourcolormap.svg)](https://github.com/sugarlabs/Four-Color-Map) |
| [![Broken Calculator](https://raw.githubusercontent.com/sugarlabs/Broken-Calculator/main/activity/activity-brokencalculator.svg)](https://github.com/sugarlabs/Broken-Calculator) |
| [![Soma Cube](https://raw.githubusercontent.com/sugarlabs/Soma-Cube/main/activity/activity-somacube.svg)](https://github.com/sugarlabs/Soma-Cube) |
| [![Fifteen Puzzle](https://raw.githubusercontent.com/sugarlabs/FifteenPuzzle/86fcd04db881c39b1734a5416cf87042a9f9bb08/activity/puzzle.svg)](https://github.com/Bishoywadea/FifteenPuzzle) |
| [![Euclid's Game](https://raw.githubusercontent.com/sugarlabs/Euclid-s-Game/main/activity/activity-euclids.svg)](https://github.com/sugarlabs/Euclid-s-Game) |
| [![Odd Scoring](https://raw.githubusercontent.com/sugarlabs/Odd-Scoring/main/activity/activity-oddscoring.svg)](https://github.com/sugarlabs/Odd-Scoring) |
| [![Magic Number Grid](https://raw.githubusercontent.com/sugarlabs/Magic-Number-Grid/b6cc4e11b2c0db7326c6111b6cac046c928d13af/activity/activity-magicnumbergrid.svg)](https://github.com/sugarlabs/Magic-Number-Grid) |
| [![Rubik's Cube](https://raw.githubusercontent.com/sugarlabs/Rubik-s-Cube/refs/heads/main/activity/activity-rubiccube.svg)](https://github.com/sugarlabs/Rubik-s-Cube) |
| [![Sequence Wizard](https://raw.githubusercontent.com/sugarlabs/Sequence-Wizard/refs/heads/main/activity/activity-sequencewizard.svg)](https://github.com/sugarlabs/Sequence-Wizard) |
| [![AI Organizer](https://raw.githubusercontent.com/sugarlabs/AI-Organizer/14177a295a5c4143313dc1ef67dabd97d227435f/activity/activity-aiorganizer.svg)](https://github.com/sugarlabs/AI-Organizer) |



## Detailed Activities Description

### Four Color Map Puzzle | [GitHub Repo](https://github.com/Bishoywadea/Four-Color-Map)
The **Four Color Map Puzzle** brings the famous four-color theorem to life as an interactive educational game. Players must color different regions of real-world maps (Egypt, USA, Nigeria, India) using only four colors, ensuring no adjacent regions share the same color. This activity teaches logical reasoning, constraint satisfaction, and introduces children to basic graph theory concepts through an engaging visual interface.

**Key Features:**
- Real geographical maps converted from GeoJSON data
- Interactive coloring with constraint validation
- Undo/redo functionality and help system
- Child-friendly UI with zoom capabilities

![Four Color Map Puzzle](https://raw.githubusercontent.com/Bishoywadea/Four-Color-Map/refs/heads/main/screen_shots/02.png)

---

### Broken Calculator | [GitHub Repo](https://github.com/Bishoywadea/Broken-Calculator)
The **Broken Calculator** challenges players to reach target numbers using a calculator with limited functionality. Only certain digits and operations are available, forcing players to think creatively about mathematical operations and number relationships. This activity enhances mental math skills and problem-solving abilities.

**Key Features:**
- Dynamic puzzle generation with varying difficulty
- Restricted digit/operator sets for each puzzle
- Scoring system and completion animations

![Broken Calculator](https://raw.githubusercontent.com/Bishoywadea/Broken-Calculator/refs/heads/main/screen_shots/02.png)

---

### Soma Cube | [GitHub Repo](https://github.com/Bishoywadea/Soma-Cube)
The **Soma Cube** is a 3D spatial reasoning puzzle where players must assemble seven unique polycube pieces into a 3×3×3 cube. This activity develops three-dimensional visualization skills and spatial intelligence through hands-on manipulation of 3D objects.

**Key Features:**
- Interactive 3D piece manipulation
- Rotation and positioning controls
- Video tutorial integration
- Visual feedback for correct placement

<div style="max-width:800px; margin:0 auto;">
  <iframe
    width="100%"
    height="450"
    src="https://www.youtube.com/embed/Q4BKp3Yo3Uw"
    title="Soma Cube Tutorial"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
  </iframe>
</div>

---

### Fifteen Puzzle | [GitHub Repo](https://github.com/Bishoywadea/FifteenPuzzle)
The classic **Fifteen Puzzle** reimagined for Sugar, where players slide numbered tiles to arrange them in order. This timeless puzzle develops logical thinking and planning skills while providing a satisfying challenge for all ages.

**Key Features:**
- Smooth tile animations
- Move counter and completion detection
- Responsive grid layout
- Help overlay with instructions

![Fifteen Puzzle](https://raw.githubusercontent.com/sugarlabs/FifteenPuzzle/refs/heads/main/screenshots/en/03.png)

---

### Euclid's Game | [GitHub Repo](https://github.com/Bishoywadea/Euclid-s-Game)
**Euclid's Game** is a mathematical strategy game based on the Euclidean algorithm. Two players take turns creating new numbers by finding differences between existing numbers, with the goal of forcing their opponent into a position with no valid moves. This activity teaches number theory concepts and strategic thinking.

**Key Features:**
- Single-player (vs AI) and multiplayer modes
- Network multiplayer support across devices
- Journal integration for game saves
- AI opponent with multiple difficulty levels

<div style="max-width:800px; margin:0 auto;">
  <iframe
    width="100%"
    height="450"
    src="https://www.youtube.com/embed/42-uk2LwToo"
    title="Euclid’s Game Sugar activity"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
  </iframe>
</div>

---

### Odd Scoring | [GitHub Repo](https://github.com/Bishoywadea/Odd-Scoring)
**Odd Scoring** is a strategic puzzle game with unique scoring mechanics that challenge conventional thinking. Players must carefully plan their moves to maximize points while considering the odd scoring rules that reward unconventional strategies.

**Key Features:**
- Network multiplayer functionality
- Theme switching capabilities
- PNG-based graphics for consistency
- Journal integration for state persistence
- Sugar-compliant UI design

<div style="max-width:800px; margin:0 auto;">
  <iframe
    width="100%"
    height="450"
    src="https://www.youtube.com/embed/MMVlzYffTiE"
    title="YouTube video"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
  </iframe>
</div>

---

### Magic Number Grid | [GitHub Repo](https://github.com/Bishoywadea/Magic-Number-Grid)
The **Magic Number Grid** is a Latin Square puzzle where players fill a grid ensuring each number appears exactly once in every row and column. This mathematical puzzle enhances logical reasoning and pattern recognition skills through increasingly complex challenges.

**Key Features:**
- Multiple difficulty levels (4×4, 6×6, 8×8 grids)
- Note-taking system for strategic planning
- Visual feedback for duplicate numbers
- Help system with game instructions
- Sugar-style dialog windows

![Magic Number Grid](https://raw.githubusercontent.com/Bishoywadea/Magic-Number-Grid/refs/heads/main/screen_shots/02.png)

---

### Rubik's Cube | [GitHub Repo](https://github.com/Bishoywadea/Rubiks-Cube)
A fully interactive 3D **Rubik's Cube** implementation that brings the classic puzzle to Sugar. This activity develops spatial reasoning and problem-solving skills through manipulation of the iconic 3×3×3 cube puzzle.

**Key Features:**
- Full 3D graphics with OpenGL integration
- Mouse-based view rotation
- Complete set of cube moves (18 standard rotations)
- Keyboard shortcuts for experienced users
- Scramble and reset functions

![Rubik's Cube](https://raw.githubusercontent.com/Bishoywadea/Rubik-s-Cube/refs/heads/main/screen_shots/02.png)

---

### Sequence Wizard | [GitHub Repo](https://github.com/Bishoywadea/Sequence-Wizard)
**Sequence Wizard** is an innovative AI-powered educational tool where students teach an artificial intelligence to recognize and predict mathematical sequences. Through interactive feedback, the AI learns from its mistakes and improves its pattern recognition abilities.

**Key Features:**
- Multiple sequence types (arithmetic, geometric, factorial, quadratic)
- Adaptive AI that learns from user corrections
- Hierarchical rule system for pattern detection
- Persistent learning across sessions
- Educational explanations of AI reasoning

![Sequence Wizard](https://raw.githubusercontent.com/Bishoywadea/Sequence-Wizard/refs/heads/main/screen_shots/02.png)

---

### AI Organizer | [GitHub Repo](https://github.com/Bishoywadea/AI-Organizer)
The **AI Organizer** introduces young learners to machine learning through an image classification system. Students can explore how computers "see" and categorize images, making abstract AI concepts tangible and understandable.

**Key Features:**
- Image classification into animals, shapes, numbers, and objects
- Visual confidence indicators
- Educational explanations of AI decisions
- Optimized for low-resource devices
- Child-friendly interface

![AI Organizer](https://raw.githubusercontent.com/Bishoywadea/AI-Organizer/refs/heads/main/screen_shots/02.png)

---

---

## Weekly Blogs

Throughout the summer, I documented my progress in weekly blog posts.  
These updates include detailed explanations of challenges, solutions, and milestones for each week of the program.

| **Week** | **Blog Link** |
|----------|----------------|
| Week 1   | [GSoC ’25 Week 1 Update](https://www.sugarlabs.org/news/all/2025-06-07-gsoc-25-BishoyWadea-week01) |
| Week 2   | [GSoC ’25 Week 2 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week01) |
| Week 3   | [GSoC ’25 Week 3 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week03) |
| Week 4   | [GSoC ’25 Week 4 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week04) |
| Week 5   | [GSoC ’25 Week 5 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week05) |
| Week 6   | [GSoC ’25 Week 6 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week06) |
| Week 7   | [GSoC ’25 Week 7 Update]() |
| Week 8   | [GSoC ’25 Week 8 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week08) |
| Week 9   | [GSoC ’25 Week 9 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week09) |
| Week 10  | [GSoC ’25 Week 10 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week10) |
| Week 11  | [GSoC ’25 Week 11 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week11) |
| Week 12  | [GSoC ’25 Week 12 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week12) |
| Week 13  | [GSoC ’25 Week 13 Update](https://www.sugarlabs.org/news/all/gsoc-25-BishoyWadea-week13) |

---


---

## Challenges Overcome

### Technical Challenges

**Sugar OS Compatibility**
- Initially faced numerous compatibility issues with Sugar's unique environment
- Solution: Deep dive into Sugar's API documentation and extensive testing on actual Sugar environments
- Result: All activities now run seamlessly on Sugar OS

**Resource Constraints**
- XO laptops have limited processing power and memory
- Solution: Implemented efficient algorithms, lazy loading, and optimized graphics
- Result: Smooth performance across all target devices

**Network Multiplayer Implementation**
- Sugar's collaboration framework required specific implementation patterns
- Solution: Studied existing Sugar activities and adapted best practices
- Result: Robust multiplayer functionality in multiple activities

## Key Learnings

### Technical Skills
- **Game Development**: Mastered Pygame for 2D games and PyOpenGL for 3D graphics
- **Network Programming**: Learned real-time synchronization and state management
- **ML Integration**: Gained experience deploying ML models in resource-constrained environments
- **UI/UX Design**: Developed skills in creating child-friendly educational interfaces

### Soft Skills
- **Project Management**: Successfully managed 10 different activities simultaneously
- **Open Source Contribution**: Learned best practices for code organization, documentation, and community interaction
- **Communication**: Improved ability to explain complex concepts simply

---

## Acknowledgments

This incredible journey would not have been possible without the support and guidance of many individuals:

**Mentors**
- **[Ibiam Chihurumnaya](https://github.com/chimosky)**: For patient guidance, constructive feedback, and constant encouragement throughout the project

**Sugar Labs Community**
- The entire Sugar Labs community for creating an environment that prioritizes children's education

**Google Summer of Code**
- Thank you to Google for organizing this program that connects students with open source organizations

---

## Conclusion

This GSoC journey has been transformative. The ten activities created represent not just code, but opportunities for children worldwide to learn through play. From logical puzzles to AI-powered learning tools, each activity targets specific educational goals while remaining engaging and accessible.

I'm grateful for the opportunity to contribute to Sugar Labs and excited about the potential impact of these tools on education. The open source nature ensures they will continue to evolve, reaching more children and adapting to new educational needs.

Thank you to everyone who made this journey possible. Here's to the future of open source education!`,Ql=Object.freeze(Object.defineProperty({__proto__:null,default:Na},Symbol.toStringTag,{value:"Module"})),Ha=`---
title: "GSoC '25 Final Week Update by Krish Pandya"
excerpt: "Everything Everywhere all at Once"
category: "DEVELOPER NEWS"
date: "2025-09-01"
slug: "2025-09-01-gsoc-25-mostlyk-final"
author: "@/constants/MarkdownFiles/authors/krish-pandya.md"
tags: "gsoc25,sugarlabs,final week,mostlyk,bundling updates,future"
image: "assets/Images/GSOC.webp"
---


# Final Week: Everything Everywhere all at Once

**Project:** [GTK4 Exploration](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)

**Mentors:** [Walter Bender](https://github.com/walterbender), [Ibiam Chihurumnaya Ibiam](https://github.com/chimosky), [Juan Pablo Ugarte](https://github.com/xjuan)

**Reporting Period:** August 17, 2025 – August 25, 2025

---

## Confession Time

This marks the end of my GSoC blogs, (_more blogs yet to come_) but this, better be the magnus opus of all my blogs. I have been postponing this blog for a while because I wanted it to start perfect , end perfect and be perfect throughout. So it starts with confession time, this blog is not perfect, this idea is not perfect. I started off for port with the idea of it being perfect, but GSoC taught me a lot of things, one of them is "perfection is the enemy of done". So here I am, writing this blog, not perfect but done.

## Humble Beginnings

The first few changes were too simple almost, read GTK3 line by line, translate it to GTK4 and voila, done. Starting with update \`gi.require_version\`, fixing build includes, this was all tutorial. Then the first boss fight, \`GdkEvent\`!. In GTK3 you can just reach the code and grab whatever you want, but in GTK4, that pointer ->x was shut down. This was the first "welcome to the game". Demanded new philosophy, stop translating , start thinking!

The project was re-structured from the second week itself and we decided to write a new library from scratch, keeping the old GTK3 toolkit as reference.
( The pivotal call in Week 2 with my mentors Juan Pablo and Ibiam wasn't just a check in , it was complete teardown of the old plan and a fresh start.)
It was ambitious, but I was determined to make it work. First few weeks were like a breeze, I write, I poke at it, write an example and done. Write the blog for that week and done. But as the weeks progressed, the project got more and more complex.
The first time I felt truly stuck was Palettes, when I had to deal with X11 , wayland discourse and all that jazz. Sticking with it, finally got it working.
As the weeks progressed, workflows changed, now it's not about writing code, it's about finding origins of the bugs, reading GTK4 docs, reading protocols and old code deeply. Refactor more , write less.

## Absurdity and the Obstacle

We are around few weeks in, to give you the sense of idea that I had. I would explain it in a way where, I knew where everything was, where everything would go, but wasn't sure if it was correct or not. It was a limbo. The shift from direct signals to abstract Gesture objects and the death of \`draw()\` in favor of \`snapshot()\` were major shifts. Quietly things ran, it was the mid-point and I was able to build "Super Ball Dodge", a simple game that was my proof of work, a sign that the new library was functional and could do something dynamic. But the real test was yet to come.

Everything was going well, then came _Palettes_ the Obstacle. On X11 , you could ask, "Where is my widget on the screen?" and get a straight answer. On Wayland? for security reasons it was forbidden knowledge. This was a tough one, many gnome discourses later, my popovers started to pop. By week 10, the biggest challenges were behind me.

## Path Forward

With the graphics layer stable, it was time to bring back datastore, presence, and all the other things that made Sugar, Sugar.
Most were GTK independent, so it was just a matter of plugging them in and testing. We had some plans for modernizing the bundling system, but that will be for future ( check week-12 future plans ) . The goal was to get the new library stable and usable, and that was achieved.
The library was pushed to [pypi](https://pypi.org/project/sugar-toolkit-gtk4/#description) and can be installed via pip:

\`\`\`
pip install sugar-toolkit-gtk4 
\`\`\`

Finally for the last week, I focused on documentation, the map for future explorers. Documentation built with sphinx, is clean, comprehensive and live at [sugar-toolkit-gtk4-py.readthedocs.io](https://sugar-toolkit-gtk4-py.readthedocs.io/en/latest/).

I will attach all the videos and links at the end of the blog, but for now, I want to thank my mentors Walter Bender, Ibiam Chihurumnaya Ibiam and Juan Pablo Ugarte for their constant support and guidance. This journey has been incredible, and I am grateful for the opportunity to contribute to Sugar Labs and the open-source community. Also a thanks to Martin Abente for his help with bundling discussions.

And now, for the first time in 13 blogs, there will be no "Future Plans." Instead, I'll leave you with a quote from one of my favorite films, Perfect Days:
[clip](https://youtu.be/F24IoeMlM3Y?si=xeY2M1n1B-fzz0kS)the quote says. "Next Time is Next Time, Now is Now".

So here I am, signing off, not with future plans, but with a promise to keep my presence and contributions, keep learning and keep growing.
Thank you once again, it has been a great summer!

## Resources & Links

- [Project Page](https://summerofcode.withgoogle.com/programs/2025/projects/rsHsYZKy)
- [New Python Library (sugar-toolkit-gtk4-py)](https://github.com/MostlyKIGuess/sugar-toolkit-gtk4-py)
- [Documentation](https://sugar-toolkit-gtk4-py.readthedocs.io/en/latest/)
- PyPI: [sugar-toolkit-gtk4](https://pypi.org/project/sugar-toolkit-gtk4/#description)

## Video Demonstrations

_Update with the final Sugar Presentation video once available_

- [Event Controller Video](https://youtu.be/m0gwwo_0ZDE)
- [Sugar Python Initialization Video](https://youtu.be/OD1PBOK3g94)
- [Menu and Style Video](https://youtu.be/-WTojjHpQLs)
- [Animations, ToolBox and Super Ball Dodge](https://youtu.be/B517C_LTCns)
- [Palettes, Popovers and Bundling](https://youtu.be/gbaG9CaJJ-U)
`,Zl=Object.freeze(Object.defineProperty({__proto__:null,default:Ha},Symbol.toStringTag,{value:"Module"})),qa=`---
title: "Comprehensive Markdown Syntax Guide"
excerpt: "A complete reference template showcasing all common markdown features and formatting options"
category: "TEMPLATE"
date: "2025-06-13"
slug: "markdown-guide"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "markdown,reference,guide,syntax,documentation,template"
image: "https://images.unsplash.com/photo-1506744038136-46273834b3fb?w=2070"
---
<!-- markdownlint-disable -->

# Comprehensive Markdown Syntax Guide

This document serves as a complete reference for markdown syntax, demonstrating various formatting elements and features supported by our enhanced markdown parser with GitHub-style rendering.

## Headings

# Heading Level 1
## Heading Level 2
### Heading Level 3
#### Heading Level 4
##### Heading Level 5
###### Heading Level 6

## Text Formatting

**Bold text** or __also bold text__

*Italic text* or _also italic text_

***Bold and italic text*** or ___also bold and italic___

~~Strikethrough text~~

==Highlighted text with custom styling==

Super^script^ text and Sub~script~ text

Here's some \`inline code\` within a paragraph for demonstration.

## Code Examples

### Inline Code vs Code Blocks

Single backticks for \`inline code highlighting\` like \`const variable = "value"\` or \`npm install\`.

### Code Blocks with Language Support

\`\`\`javascript
// JavaScript example with syntax highlighting
function calculateSum(a, b) {
    return a + b;
}

const result = calculateSum(5, 10);
console.log(\`The sum is: \${result}\`);
\`\`\`

\`\`\`python
# Python example
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# Generate first 10 Fibonacci numbers
for i in range(10):
    print(f"F({i}) = {fibonacci(i)}")
\`\`\`

\`\`\`typescript
// TypeScript example
interface User {
    id: number;
    name: string;
    email: string;
}

const createUser = (userData: Partial<User>): User => {
    return {
        id: Date.now(),
        name: userData.name || "Anonymous",
        email: userData.email || "user@example.com"
    };
};
\`\`\`

\`\`\`css
/* CSS example */
.markdown-content {
    font-family: 'Inter', sans-serif;
    line-height: 1.6;
    color: #333;
}

.code-block {
    background: #f6f8fa;
    border-radius: 6px;
    padding: 16px;
    overflow-x: auto;
}
\`\`\`

\`\`\`bash
# Bash commands
git clone https://github.com/username/repo.git
cd repo
npm install
npm run dev
\`\`\`

\`\`\`sql
-- SQL example
SELECT users.name, posts.title, posts.created_at
FROM users
JOIN posts ON users.id = posts.user_id
WHERE posts.published = true
ORDER BY posts.created_at DESC
LIMIT 10;
\`\`\`

## Links and References

### Basic Links
[Basic link to example.com](https://example.com)

[Link with title](https://example.com "Example Website")

### Auto-links
<https://example.com>

<email@example.com>

## Lists

### Unordered Lists
- Item 1
- Item 2
  - Nested Item 2.1
  - Nested Item 2.2
    - Deeply nested item
- Item 3

Alternative syntax:
* Item 1
* Item 2
  * Nested item
* Item 3

### Ordered Lists
1. First item
2. Second item
   1. Nested item 2.1
   2. Nested item 2.2
      1. Deeply nested numbered item
3. Third item

### Task Lists
- [x] Completed task
- [ ] Incomplete task
- [x] Another completed task
- [ ] Task with **bold text**
- [ ] Task with \`inline code\`

### Definition Lists
First Term
: Definition of the first term

Second Term
: Definition of the second term
: Another definition of the second term

Complex Term
: This is a more complex definition that can include **bold text**, *italic text*, and \`inline code\`.

## Images and Media

### Basic Image
![Alt text for image](https://images.unsplash.com/photo-1531297484001-80022131f5a1?w=600 "Optional title")

### Linked Image
[![Alt text for linked image](https://images.unsplash.com/photo-1488590528505-98d2b5aba04b?w=300 "Click me!")](https://example.com)

### YouTube Video Embeds

[youtube: MM-H69cHYMk]

## Tables

### Basic Table
| Header 1 | Header 2 | Header 3 |
|----------|:--------:|---------:|
| Default  | Centered | Right    |
| aligned  | aligned  | aligned  |
| text     | text     | text     |

### Advanced Table with Formatting
| Command | Description | Example |
| --- | --- | --- |
| \`git status\` | List all new or modified files | Shows modified files in red |
| \`git diff\` | Show file differences not yet staged | \`git diff HEAD~1\` |
| \`git add .\` | Stage all changes | Adds all files to staging |
| \`git commit -m "message"\` | **Commit** with message | Creates new commit |

### Feature Comparison Table
| Feature | Basic Plan | Pro Plan | Enterprise |
|---------|:----------:|:--------:|:----------:|
| Users | 5 | 25 | Unlimited |
| Storage | 10GB | 100GB | 1TB |
| Support | Email | Priority | 24/7 Phone |
| Price | $10/mo | $25/mo | Custom |

## Blockquotes

### Simple Blockquote
> This is a simple blockquote

### Multi-paragraph Blockquote
> This is a blockquote with multiple paragraphs
>
> Second paragraph in the blockquote

### Nested Blockquotes
> This is the first level of quoting.
>
> > This is nested blockquote.
>
> Back to the first level.

### Complex Blockquote
> #### Blockquote with other elements
>
> - Lists inside blockquote
> - Another item with \`inline code\`
>
> **Bold text** inside blockquote with *italic* and \`code\`.
>
> \`\`\`javascript
> // Code block inside blockquote
> console.log("Hello from blockquote!");
> \`\`\`

## Horizontal Rules

Three or more hyphens:

---

Asterisks:

***

Underscores:

___

## GitHub-Style Alerts

:::note
This is a note alert. Use it to provide additional information that's helpful but not critical.
:::

:::tip Pro Tip
This is a tip alert. Great for sharing best practices and helpful suggestions!
:::

:::important Important Notice
This is an important alert. Use it for information that users should definitely pay attention to.
:::

:::warning Be Careful
This is a warning alert. Use it to highlight potential issues or things to watch out for.
:::

:::caution Critical Warning
This is a caution alert. Use it for serious warnings about potential problems or security issues.
:::

## Collapsible Sections

### Basic Collapsible
:::details Click to expand basic details
This content is hidden by default and can be expanded by clicking the summary.

You can include:
- **Formatted text**
- \`Code examples\`
- And other markdown elements

\`\`\`javascript
console.log("Code works too!");
\`\`\`
:::

### Advanced Collapsible
:::details Advanced Configuration Options
Here are some advanced configuration options:

#### Database Settings
- **Host**: localhost
- **Port**: 5432
- **Database**: myapp_production

#### Security Configuration
\`\`\`yaml
security:
  encryption: AES-256
  hashing: bcrypt
  session_timeout: 3600
\`\`\`

#### Performance Tuning
| Setting | Development | Production |
|---------|-------------|------------|
| Cache TTL | 60s | 3600s |
| Max Connections | 10 | 100 |
| Timeout | 30s | 10s |
:::

<details>
<summary>HTML-style Collapsible Section</summary>

This is using HTML details/summary tags.

- You can include **formatted text**
- And other elements
- \`Code snippets\`

\`\`\`python
def hello_world():
    print("Hello from collapsible section!")
\`\`\`

</details>

## Extended Features

### Footnotes

Here's a sentence with a footnote[^1].

Here's another footnote reference[^2].

Multiple footnotes in one sentence[^3][^4].

[^1]: This is the footnote content with **formatting**.
[^2]: This footnote contains \`code\` and *emphasis*.
[^3]: Short footnote.
[^4]: This is a longer footnote that can contain multiple sentences. It can even contain code blocks and other formatting elements.

### Emoji Support

#### Emotions and Reactions
:smile: I'm happy to see this working!  
:heart: Love this feature!  
:thumbsup: Looks good to me!  
:thumbsdown: This needs work.  
:eyes: I'm watching this.  
:tada: Celebration time!  

#### Technical and Development
:rocket: Let's launch this feature!  
:fire: This is awesome!  
:star: Five-star quality!  
:bug: There's a bug here.  
:wrench: Fix needed.  
:gear: Configuration required.  
:sparkles: New feature!  
:package: New release.  
:zap: Performance improvement.  
:boom: Breaking change.  

#### Communication and Status
:warning: Be careful with this syntax.  
:info: Here's some information.  
:check: This is correct!  
:x: This is wrong.  
:bulb: Great idea!  
:memo: Take notes.  
:link: Related link.  
:lock: Secure content.  
:unlock: Public content.  

#### Objects and Places
:computer: Development environment.  
:phone: Mobile responsive.  
:email: Contact information.  
:calendar: Scheduled event.  
:clock: Timing important.  
:house: Home page.  
:car: Fast delivery.  
:plane: Deploy quickly.  
:coffee: Developer fuel.  
:pizza: Team lunch.  

### Deletions and Insertions

~~This text has been deleted~~ and replaced with new content.

<del>This is also deleted text</del>

<ins>This text has been inserted</ins>

## Advanced Formatting Combinations

### Mixed Formatting Examples

Here's text with **bold**, *italic*, \`code\`, ==highlighted==, ~~strikethrough~~, and [[Ctrl+A]] keyboard shortcut.

> **Important Quote**: Use \`console.log()\` for debugging, but remember to ==remove it== before production. ~~Don't use alert().~~ :warning:

| Feature | Status | Shortcut | Notes |
|---------|--------|----------|--------|
| **Bold** | :check: | [[Ctrl+B]] | Works everywhere |
| *Italic* | :check: | [[Ctrl+I]] | \`_text_\` also works |
| \`Code\` | :check: | [[Ctrl+\`]] | Inline highlighting |
| ==Highlight== | :check: | N/A | Custom feature |

### Complex List with Everything

1. **First Item** with \`code\` and [link](https://example.com)
   - Nested item with ==highlighting==
   - Another nested item with :rocket: emoji
   - [ ] Unchecked task with ~~strikethrough~~
   - [x] Completed task with **bold text**

2. **Second Item** with math: $E = mc^2$
   \`\`\`python
   # Code block in list
   def example():
       return "Hello World"
   \`\`\`

3. **Third Item** with blockquote:
   > This is a quote inside a list item
   > with **bold** and *italic* text

## Accessibility Features

### Screen Reader Friendly Content

All images have descriptive alt text:
![A developer working on code with multiple monitors showing colorful syntax highlighting](https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=600 "Developer workspace")

All links have descriptive text:
[Read the complete accessibility guidelines](https://example.com "Complete guide to web accessibility")

### Semantic HTML Elements

<details>
<summary>Semantic Structure Information</summary>

Our markdown parser generates semantic HTML with:
- Proper heading hierarchy
- Accessible form controls
- ARIA labels where appropriate
- Focus management for interactive elements

</details>

---

### Final Thoughts

This comprehensive markdown guide demonstrates the full capabilities of our enhanced parser. From basic formatting to advanced features like mathematical expressions and interactive elements, this parser provides a rich, GitHub-style experience.

Thank you for reading this detailed markdown reference! :heart: :rocket:

Remember to use the copy button on code blocks to quickly copy examples! :sparkles:

---

*Last updated: 2025-06-13 | Version 2.0 | Contributors: Safwan Sayeed*`,ed=Object.freeze(Object.defineProperty({__proto__:null,default:qa},Symbol.toStringTag,{value:"Module"})),Ka=`---
title: "GSoC ’25 Week XX Update by Safwan Sayeed"
excerpt: "This is a Template to write Blog Posts for weekly updates"
category: "TEMPLATE"
date: "2025-05-10"
slug: "YYYY-MM-DD-gsoc-25-sa-fw-an-weekXX"
author: "@/constants/MarkdownFiles/authors/safwan-sayeed.md"
tags: "gsoc25,sugarlabs,weekXX,sa-fw-an"
image: "assets/Images/GSOC.webp"
---

<!-- markdownlint-disable -->

# Week XX Progress Report by Safwan Sayeed

**Project:** [Project Name](https://github.com/sugarlabs/www-v2)  
**Mentors:** [Mentor1](https://github.com/Username), [Mentor2](https://github.com/Username)  
**Assisting Mentors:** [Mentor3](https://github.com/Username), [Mentor4](https://github.com/Username)  
**Reporting Period:** yyyy-mm-dd - yyyy-mm-dd  

---

## Goals for This Week

- **Goal 1:** Describe the first planned deliverable.
- **Goal 2:** Describe the second planned deliverable.
- **Goal 3:** Describe an additional target.

---

## This Week’s Achievements

1. **[Task or Feature]**  
   - What you did and why it matters.  
   - Links (if any): PR [#123](https://github.com/owner/repo/pull/123), Issue [#456](https://github.com/owner/repo/issues/456).

2. **[Task or Feature]**  
   - Brief summary or a video.
   [youtube: MM-H69cHYMk]

3. **[Task or Feature]**  
   - Add screenshots or diagrams here if useful:
   ![screenshot-description](https://images.unsplash.com/photo-1506744038136-46273834b3fb?w=2070)

---

## Challenges & How I Overcame Them

- **Challenge:** Describe a blocker or difficulty.  
  **Solution:** Outline your approach or resources used.

- **Challenge:** Another issue faced.  
  **Solution:** Steps taken to resolve or next action plan.

---

## Key Learnings

- Gained familiarity with **XYZ library or tool**.
- Deepened understanding of **SOLID principles**, **architecture modeling**, **DFDs**, etc.
- Improved skills in **testing**, **documentation**, and **collaboration workflows**.

---

## Next Week’s Roadmap

- Implement **Feature XYZ** and write corresponding tests.
- Refine **technical design** based on mentor feedback.
- Prepare a mini-demo for the community check-in.

---

## Resources & References

- **PRD:** [Link to Product Requirements Document]({{prd_link}})
- **Tech Spec & Diagrams:** [Architecture & Specs]({{tech_spec_link}})
- **Repository:** [github.com/owner/repo](https://github.com/owner/repo)
- Any additional links, diagrams, or attachments.

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow GSoC contributors for ongoing support.

---

`,nd=Object.freeze(Object.defineProperty({__proto__:null,default:Ka},Symbol.toStringTag,{value:"Module"})),Va=`---\r
title: "DMP ’25 Week 01 Update by Aman Chadha"\r
excerpt: "Working on a RAG model for Music Blocks core files to enhance context-aware retrieval"\r
category: "DEVELOPER NEWS"\r
date: "2025-06-09"\r
slug: "2025-06-09-dmp-25-aman-week01"\r
author: "Aman Chadha"\r
description: "DMP '25 Contributor working on retrieval-augmented generation for Music Blocks"\r
tags: "dmp25,musicblocks,rag,week01"\r
image: "assets/Images/c4gt_DMP.webp"\r
---\r
\r
<!--markdownlint-disable-->\r
\r
# Week 01 Progress Report by Aman Chadha\r
\r
**Project:** [JS Internationalization with AI Translation Support](https://github.com/sugarlabs/musicblocks/pull/4459)  \r
\r
**Mentors:** [Walter Bender](https://github.com/walterbender)\r
\r
**Reporting Period:** 2025-06-02 - 2025-06-08\r
\r
---\r
\r
## Goals for This Week\r
\r
- Develop a Retrieval-Augmented Generation (RAG) model using the core files of Music Blocks to provide context-aware responses.\r
- Collect and parse .po files, extracting msgid and msgstr pairs along with comments showing usage in source files.\r
- Use AST parsing (with Babel) to gather metadata chunks from source files to improve retrieval relevance.\r
\r
---\r
\r
## This Week’s Achievements\r
\r
1. **RAG Model Development**  \r
   - Started working on building a RAG model focused on the core Music Blocks files. This aims to give the model context about what Music Blocks is and how it functions, improving answer relevance.\r
   \r
2. **Metadata Extraction from .po Files**  \r
   - Successfully collected msgid and msgstr pairs from translation files.\r
   - Parsed comments above the translations to identify which files use each msgstr.\r
   \r
3. **AST Parsing and Chunking**  \r
   - Used Babel to parse Music Blocks source files and extract relevant code chunks.\r
   - Stored these chunks with their associated metadata to enable better context retrieval during RAG.\r
\r
---\r
\r
## Challenges & How I Overcame Them\r
\r
- **Challenge:** Parsing complex .po files with varied comment styles and ensuring correct association of usage metadata.  \r
  **Solution:** Created robust parsing scripts to handle different comment formats and verified chunk associations manually on sample files.\r
\r
- **Challenge:** Extracting meaningful code chunks via AST parsing while maintaining useful granularity.  \r
  **Solution:** Experimented with different AST traversal strategies and filters to optimize chunk size for retrieval.\r
\r
---\r
\r
## Key Learnings\r
\r
- Gained deeper understanding of the internals of Music Blocks core files and their translation system.\r
- Improved skills with Babel AST parsing and metadata extraction techniques.\r
- Learned the importance of detailed metadata in enhancing RAG model retrieval accuracy.\r
\r
---\r
\r
## Next Week’s Roadmap\r
\r
- Build a demo to showcase the RAG model's ability to answer Music Blocks-related queries with context from core files.\r
- Begin integrating metadata-enriched .po file chunks into the RAG database for improved translation string retrieval.\r
- Optimize chunking and metadata tagging strategy based on initial demo feedback.\r
\r
---\r
\r
## Resources & References\r
\r
- **Music Blocks Repository:** [github.com/your-org/musicblocks](https://github.com/your-org/musicblocks)  \r
- **Babel AST Docs:** https://babeljs.io/docs/en/babel-parser  \r
- **RAG Model Concepts:** https://arxiv.org/abs/2005.11401  \r
\r
---\r
\r
## Acknowledgments\r
\r
Thanks to my mentors and the DMP community for their guidance and support throughout this work.\r
\r
---\r
\r
## Connect with Me\r
\r
- GitHub: [@aman-chadha](https://github.com/ac-mmi)  \r
- Gmail: [aman.chadha.mmi@gmail.com](mailto:aman.chadha.mmi@gmail.com)  \r
\r
---\r
`,td=Object.freeze(Object.defineProperty({__proto__:null,default:Va},Symbol.toStringTag,{value:"Module"})),Ja=`---\r
title: "DMP '25 Week 02 Update by Aman Chadha"\r
excerpt: "Enhanced RAG output format with POS tagging and optimized code chunking for Music Blocks"\r
category: "DEVELOPER NEWS"\r
date: "2025-06-16"\r
slug: "2025-06-16-dmp-25-aman-chadha-week02"\r
author: "@/constants/MarkdownFiles/authors/aman-chadha.md"\r
tags: "dmp25,sugarlabs,week02,aman-chadha"\r
image: "assets/Images/c4gt_DMP.webp"\r
---\r
\r
<!-- markdownlint-disable -->\r
\r
# Week 02 Progress Report by Aman Chadha\r
\r
**Project:** [JS Internationalization with AI Translation Support](https://github.com/sugarlabs/musicblocks/pull/4459)  \r
**Mentors:** [Walter Bender](https://github.com/walterbender)  \r
**Assisting Mentors:** *None this week*  \r
**Reporting Period:** 2025-06-09 - 2025-06-16  \r
\r
---\r
\r
## Goals for This Week\r
\r
- **Refactor RAG model output** to a structured dictionary format that includes part-of-speech (POS) tagging.\r
- **Optimize AST-based chunking** by limiting code context to 5 lines above and below translation usage, per mentor feedback.\r
- **Begin functional testing** of the updated RAG pipeline on real-world translation queries.\r
\r
---\r
\r
## This Week's Achievements\r
\r
1. **RAG Output Enhancement**  \r
   - Refactored the Retrieval-Augmented Generation model to return results as structured dictionaries.\r
   - Each entry now includes \`msgid\`, \`msgstr\`, source metadata, and the dominant part of speech, improving retrieval relevance.\r
\r
2. **Code Chunking Optimization**  \r
   - Reduced each extracted code chunk to include only 5 lines above and below the relevant \`msgid\` usage.\r
   - This improves retrieval precision and avoids irrelevant surrounding code.  \r
   - Implemented using Babel’s AST traversal logic.\r
\r
3. **Initial Model Testing**  \r
   - Started testing the RAG model using sample translation queries.\r
   - Observed noticeable improvements in answer context relevance due to cleaner chunks and richer metadata.\r
\r
---\r
\r
## Challenges & How I Overcame Them\r
\r
- **Challenge:** Integrating POS tagging meaningfully into the RAG data pipeline.  \r
  **Solution:** Designed a dictionary schema that includes the part-of-speech alongside translation metadata, and verified correctness using test entries.\r
\r
- **Challenge:** Tuning chunk granularity without losing contextual utility.  \r
  **Solution:** Followed mentor Walter’s advice to use fixed ±5 line windows, and manually verified semantic coherence of resulting chunks.\r
\r
---\r
\r
## Key Learnings\r
\r
- Part-of-speech tagging can significantly improve the contextual strength of retrieved translations.\r
- Smaller, focused code chunks often result in better retrieval precision for RAG applications.\r
- Mentor feedback and collaborative iteration are key to refining both code structure and user outcomes.\r
\r
---\r
\r
## Next Week's Roadmap\r
\r
- Integrate POS-tagged RAG responses into the full i18n fallback translation pipeline.\r
- Expand test coverage to include edge-case translations and re-used \`msgid\`s.\r
- Prepare an internal demo to show RAG-powered retrieval resolving contextually ambiguous translation strings.\r
\r
---\r
\r
## Resources & References\r
\r
- **Repository:** [github.com/sugarlabs/musicblocks](https://github.com/sugarlabs/musicblocks)\r
- **RAG Concepts:** [arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)\r
- **Babel Parser Docs:** [babeljs.io/docs/en/babel-parser](https://babeljs.io/docs/en/babel-parser)\r
- **spaCy POS Tagging:** [spacy.io/usage/linguistic-features#pos-tagging](https://spacy.io/usage/linguistic-features#pos-tagging)\r
\r
---\r
\r
## Acknowledgments\r
\r
Thanks to my mentor Walter Bender for his guidance on optimizing chunking strategy and enriching the retrieval logic with linguistic features.\r
\r
---\r
\r
## Connect with Me\r
\r
- GitHub: [@aman-chadha](https://github.com/ac-mmi)  \r
- Gmail: [aman.chadha.mmi@gmail.com](mailto:aman.chadha.mmi@gmail.com)  \r
\r
---\r
`,ad=Object.freeze(Object.defineProperty({__proto__:null,default:Ja},Symbol.toStringTag,{value:"Module"})),Xa=`---\r
title: "DMP '25 Week 03 Update by Aman Chadha"\r
excerpt: "Translated RAG-generated context strings, initiated batch processing, and planned for automated context regeneration"\r
category: "DEVELOPER NEWS"\r
date: "2025-06-23"\r
slug: "2025-06-23-dmp-25-aman-chadha-week03"\r
author: "@/constants/MarkdownFiles/authors/aman-chadha.md"\r
tags: "dmp25,sugarlabs,week03,aman-chadha"\r
image: "assets/Images/c4gt_DMP.webp"\r
---\r
\r
<!-- markdownlint-disable -->\r
\r
# Week 03 Progress Report by Aman Chadha\r
\r
**Project:** [JS Internationalization with AI Translation Support](https://github.com/sugarlabs/musicblocks/pull/4459)  \r
**Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/devinulibarri)  \r
**Assisting Mentors:** *None this week*  \r
**Reporting Period:** 2025-06-17 – 2025-06-23  \r
\r
---\r
\r
## Goals for This Week\r
\r
- Translate a sample set of RAG-generated context strings using AI-powered tools.\r
- Share Japanese translation variants (Kana and Kanji) with mentors for review.\r
- Begin building a batch-processing workflow to generate context for all 1535 msgid entries in the .po files.\r
- Plan an update pipeline to regenerate context for newly added or reused translation strings automatically.\r
\r
---\r
\r
## This Week’s Achievements\r
\r
1. **Translation of RAG-Generated Contexts**  \r
   - Translated ~70 RAG-generated context descriptions using DeepL.\r
   - Shared English and Japanese translations with mentors Walter and Devin for review.\r
   - For Japanese, provided both **Kana** and **Kanji** variants to ensure localization accuracy.\r
\r
2. **Batch Processing Pipeline Development**  \r
   - Initiated work on a batch-processing system to automate RAG context generation for all 1535 msgid entries in the translation .po file.\r
   - This will drastically reduce manual overhead and improve coverage.\r
\r
3. **Planning for Context Maintenance Workflow**  \r
   - Designed a future-proofing plan to automatically detect newly added or reused msgids in pull requests.\r
   - Began outlining a GitHub Actions-based workflow to regenerate context chunks when changes are merged into the repo.\r
\r
---\r
\r
## Challenges & How I Overcame Them\r
\r
- **Challenge:** Japanese localization required thoughtful distinction between script types (Kana vs Kanji).  \r
  **Solution:** Generated both forms using translation tools and consulted native guidance to ensure cultural appropriateness.\r
\r
- **Challenge:** Scaling RAG context generation to 1500+ entries without losing efficiency.  \r
  **Solution:** Started designing a batch system to streamline the entire generation process and set up hooks for automation in future updates.\r
\r
---\r
\r
## Key Learnings\r
\r
- Multi-language support requires nuanced translation strategies, especially for languages like Japanese.\r
- Batch automation is essential when working with large-scale i18n datasets and AI-generated content.\r
- Proactive planning for long-term maintenance helps keep i18n tooling relevant as the codebase evolves.\r
\r
---\r
\r
## Next Week’s Roadmap\r
\r
- Complete batch-processing implementation for generating RAG context for all msgids.\r
- Add persistence/storage layer to cache generated results and avoid recomputation.\r
- Set up a GitHub workflow for regenerating context on new PRs that modify or add translation strings.\r
\r
---\r
\r
## Resources & References\r
\r
- **Music Blocks Repository:** [github.com/sugarlabs/musicblocks](https://github.com/sugarlabs/musicblocks)\r
- **DeepL Translator API:** [deepl.com/docs-api](https://www.deepl.com/docs-api)\r
- **GitHub Actions Docs:** [docs.github.com/actions](https://docs.github.com/actions)\r
- **RAG Concepts:** [arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)\r
\r
---\r
\r
## Acknowledgments\r
\r
Thanks to mentors Walter Bender and Devin Ulibarri for their ongoing guidance, especially on translation validation and workflow design.\r
\r
---\r
`,od=Object.freeze(Object.defineProperty({__proto__:null,default:Xa},Symbol.toStringTag,{value:"Module"})),$a=`---\r
title: "DMP '25 Week 04 Update by Aman Chadha"\r
excerpt: "Completed context generation for all UI strings and submitted Turkish translations using DeepL with RAG-generated context"\r
category: "DEVELOPER NEWS"\r
date: "2025-06-30"\r
slug: "2025-06-30-dmp-25-aman-chadha-week04"\r
author: "@/constants/MarkdownFiles/authors/aman-chadha.md"\r
tags: "dmp25,sugarlabs,week04,aman-chadha"\r
image: "assets/Images/c4gt_DMP.webp"\r
---\r
\r
<!-- markdownlint-disable -->\r
\r
# Week 04 Progress Report by Aman Chadha\r
\r
**Project:** [JS Internationalization with AI Translation Support](https://github.com/sugarlabs/musicblocks/pull/4459)  \r
**Mentors:** [Walter Bender](https://github.com/walterbender), [Devin Ulibarri](https://github.com/devinulibarri)  \r
**Reporting Period:** 2025-06-24 – 2025-06-30  \r
\r
---\r
\r
## Goals for This Week\r
\r
- Complete RAG-based context generation for **all UI strings** in the \`.po\` file.\r
- Translate the Turkish \`.po\` file using DeepL with generated context.\r
- Share Turkish translation with mentors for review and validation of context effectiveness.\r
\r
---\r
\r
## This Week’s Achievements\r
\r
1. **Full Context Generation Completed**  \r
   - Successfully generated context for all 1,536 active \`msgid\` entries using the RAG (Retrieval-Augmented Generation) model.\r
   - Ensured each UI string now has an associated contextual description to guide translators.\r
\r
2. **Turkish Translation via DeepL with Context**  \r
   - Used the DeepL API to translate the Turkish \`.po\` file, injecting the RAG-generated context for each \`msgid\`.\r
   - This serves as a real-world test to evaluate how well contextual guidance improves translation accuracy and usability.\r
   - Currently awaiting feedback on the quality of Turkish translations to assess the effectiveness of the context-driven approach.\r
\r
---\r
\r
## Challenges & How I Addressed Them\r
\r
- **Challenge:** Integrating RAG-generated context into \`.po\` translation pipeline.  \r
  **Solution:** Adapted the \`.po\` processing script to pair each \`msgid\` with its context before sending it to DeepL, ensuring translators benefit from semantic clarity.\r
\r
- **Challenge:** Validating quality of translations in a language I do not speak.  \r
  **Solution:** Coordinated with mentors to review Turkish output and identify whether contextual enrichment improved translation fidelity.\r
\r
---\r
\r
## Key Learnings\r
\r
- Contextual guidance significantly strengthens AI-driven translation quality, especially for UI-specific phrases.\r
- Systematic pairing of context with each string allows scalable improvements across languages.\r
- Human review remains crucial to validate AI-generated translations and refine context generation methods.\r
\r
---\r
\r
## Next Week’s Roadmap\r
\r
- Collect and analyze mentor feedback on the Turkish \`.po\` file.\r
- Fine-tune the RAG context generation logic based on observed shortcomings, if any.\r
- Generalize the context-injection workflow for use with other languages (e.g., Spanish, French).\r
- Begin documenting the context generation + translation pipeline for future contributors.\r
\r
---\r
\r
## Resources & References\r
\r
- **Music Blocks Repository:** [github.com/sugarlabs/musicblocks](https://github.com/sugarlabs/musicblocks)\r
- **DeepL Translator API:** [deepl.com/docs-api](https://www.deepl.com/docs-api)\r
- **GitHub Actions Docs:** [docs.github.com/actions](https://docs.github.com/actions)\r
- **RAG Concepts:** [arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)\r
\r
---\r
\r
## Acknowledgments\r
\r
Thanks to mentors Walter Bender and Devin Ulibarri for their feedback, review assistance, and continued support in improving translation workflows.\r
\r
---\r
`,id=Object.freeze(Object.defineProperty({__proto__:null,default:$a},Symbol.toStringTag,{value:"Module"})),Ya=`---
title: "DMP '25 Week 01 Update by Anvita Prasad"
excerpt: "Initial research and implementation of Music Blocks tuner feature"
category: "DEVELOPER NEWS"
date: "2025-06-08"
slug: "2025-06-08-DMP-25-AnvitaPrasad-week01"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week01,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 01 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-02 - 2025-06-08  

---

## Goals for This Week

- **Goal 1:** Update Tone.js to the latest version  
- **Goal 2:** Begin tuner implementation with pitch detection  
- **Goal 3:** Create basic tuner visualization  

---

## This Week's Achievements

1. **Updated Tone.js Library**  
   - Successfully upgraded from version 15.0.4 to 15.1.22  
   - Verified compatibility with existing codebase  

2. **Implemented Pitch Detection**  
   - Integrated YIN algorithm for pitch detection  
   - Established foundation for note identification  

3. **Created Basic Tuner Interface**  
   - Implemented 11-segment tuner display  
   - Added initial cents adjustment UI  

---

## Challenges & How I Overcame Them

- **Challenge:** Understanding complex audio processing concepts  
  **Solution:** Studied Web Audio API documentation and experimented with example code  

---

## Key Learnings

- Gained familiarity with Tone.js API and audio processing  
- Learned about pitch detection algorithms and their implementation  

---

## Next Week's Roadmap

- Complete tuner implementation with accurate visualization  
- Implement cents adjustment calculations  
- Add fine-tuning to pitch detection system  
- Test with various audio sources  
- Write Week 02 blog post summarizing progress and learnings  

---

## Resources & References

- **Web Audio Resources:** [MDN Web Audio API Guide](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)  
- **Pitch Detection:** [PitchDetect Example](https://github.com/cwilso/pitchdetect)  
- **Online Tuner Reference:** [Musicca's Online Tuner Guide](https://www.musicca.com/tuner)  

---

## Acknowledgments

Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

---`,sd=Object.freeze(Object.defineProperty({__proto__:null,default:Ya},Symbol.toStringTag,{value:"Module"})),Qa=`---
title: "DMP '25 Week 02 Update by Anvita Prasad"
excerpt: "Research and design of tuner visualization system and cents adjustment UI"
category: "DEVELOPER NEWS"
date: "2025-06-15"
slug: "2025-06-15-DMP-25-AnvitaPrasad-week02"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week02,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 02 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-09 - 2025-06-15  

---

## Goals for This Week
- **Goal 1:** Design dual-mode tuner interface
- **Goal 2:** Research and prototype cents adjustment UI
- **Goal 3:** Investigate temperament systems and EDO implementations
- **Goal 4:** Implement visual feedback system for pitch detection

---

## This Week's Achievements

1. **Researched Dual-Mode Tuner Design**
   - Analyzed requirements for two proposed tuning modes:
     - Specific Target Pitch mode with fixed reference
     - Arbitrary mode with dynamic ±50 cents range detection
   - Started working on UI mockups for both modes
   - Researching effective visual feedback systems for pitch deviation

2. **Implemented Initial Cents Adjustment Feature**
   - Created basic manual cents adjustment UI
   - Exploring alternative UI approaches for better user experience
   - Studying various tuner implementations for inspiration

3. **Developed Tuner Visualization System**
   - Implemented center-outward segment lighting system
   - Left/right segments indicate flat/sharp notes respectively
   - Number of lit segments shows pitch deviation magnitude

4. **Pitch Detection System Research**
   - Studied advanced pitch detection methodologies
   - Researched FFT spectrum analysis and phase information evaluation

---

## Challenges & How I Overcame Them

- **Challenge:** Difficulty in accurately detecting pitch in real-time
  **Solution:** Researched and implemented better audio processing algorithms with help from mentor feedback

- **Challenge:** Making the tuner interface user-friendly and responsive
  **Solution:** Studied existing tuner applications and simplified the visual feedback system

---

## Key Learnings
- Gained deep understanding of Equal Divisions of the Octave (EDO) systems and their implementation challenges
- Learned about various temperament systems (Equal, Just, Werckmeister, Kirnberger)
- Studied advanced audio processing techniques including FFT window optimization and spectrum phase analysis
- Researched UX patterns for precise musical instrument tuning interfaces
- Explored different approaches to visual feedback systems for micro-pitch detection

---

## Next Week's Roadmap
- Complete tuner implementation with accurate visualization
- Finalize and implement the selected cents adjustment UI design
- Write Week 03 blog post summarizing progress and learnings

---

## Resources & References
- **EDO & Tuning Systems:** [Ableton's Guide to EDO Tunings](https://tuning.ableton.com/edo/intro-to-edo/)
- **Online Tuner Reference:** [Musicca's Online Tuner Guide](https://www.musicca.com/tuner)
- **Pitch Detection Implementation:** [PitchDetect JavaScript Implementation](https://github.com/cwilso/PitchDetect/blob/main/js/pitchdetect.js)
- **Research Reference:** [F-Droid Tuner Implementation](https://f-droid.org/en/packages/de.moekadu.tuner/)

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

---
`,rd=Object.freeze(Object.defineProperty({__proto__:null,default:Qa},Symbol.toStringTag,{value:"Module"})),Za=`---
title: "DMP '25 Week 05 Update by Anvita Prasad"
excerpt: "Implementation of manual cent adjustment interface and mode-specific icons for the tuner system"
category: "DEVELOPER NEWS"
date: "2025-07-06"
slug: "2025-07-06-DMP-25-AnvitaPrasad-week05"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week05,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 05 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-06-30 - 2025-07-06  

---

## Goals for This Week
- **Goal 1:** Design and implement a slider for manual cent adjustment
- **Goal 2:** Develop functionality for cent adjustment system
- **Goal 3:** Design and implement mode-specific icons for the tuner interface


---

## This Week's Achievements

1. **Mode-Specific Icon Design and Implementation**
   - Created distinctive icons for both tuning modes
   - Successfully integrated icons into the tuner interface
   - Ensured visual consistency with existing Music Blocks design language

2. **Manual Cent Adjustment Interface Redesign**
   - Transitioned from pie menu to slider-based interface
   - Implemented basic slider UI for cent adjustment
   - Designed interface to accommodate ±50 cents range
   - Optimized for both recorded and uploaded samples through the sampler

3. **Cent Adjustment System Development**
   - Implementing core functionality for precise pitch adjustment
   - Developed system to handle cent adjustments within ±50 range
   - Created framework for real-time pitch modification

4. **Integration and Testing**
   - Successfully integrated new components with existing tuner system
   - Conducted initial testing of slider functionality
   - Verified icon visibility and clarity in different modes

---

## Challenges & How I Overcame Them

- **Challenge:** Maintaining precise control over cent adjustments while ensuring smooth slider operation
- **Solution:** Implemented a custom scaling algorithm and added intermediate value snapping for better control


---

## Key Learnings
- Gained deeper understanding of real-time audio processing in web applications
- Discovered best practices for handling micro-pitch adjustments in digital audio systems
- Enhanced knowledge of Web Audio API's capabilities and limitations

---

## Next Week's Roadmap
- Conduct extensive testing with various audio sources and instruments
- Process free/open samples from identified sources
- Design basic categorization system for samples
- Write Week 06 blog post summarizing progress and learnings

---

## Resources & References
- **Audio Processing:** [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- **Cent Calculation:** [Cents to Frequency Ratio Calculator](https://www.sengpielaudio.com/calculator-centsratio.htm)
- **Musical Tuning:** [Musical Acoustics - Cents and Frequency Ratios](https://newt.phys.unsw.edu.au/jw/notes.html)
- **UI Components:** Referenced existing Music Blocks slider implementations for consistency

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

--- `,ld=Object.freeze(Object.defineProperty({__proto__:null,default:Za},Symbol.toStringTag,{value:"Module"})),eo=`---
title: "DMP '25 Week 06 Update by Anvita Prasad"
excerpt: "Improve Synth and Sample Feature for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-13"
slug: "2025-07-13-DMP-25-AnvitaPrasad-week06"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week06,AnvitaPrasad,midterm"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 06 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-07 - 2025-07-13  

---

## Goals for This Week
- **Goal 1:** Implement manual cent adjustment functionality in the sampler widget
- **Goal 2:** Ensure cent adjustments persist when saving samples
- **Goal 3:** Research methods for manual cent adjustment implementation
- **Goal 4:** Collect SVG icons for the set instrument widget
- **Goal 5:** Design basic categorization system for samples

---

## This Week's Achievements

1. **Cent Adjustment Persistence Implementation**
   - Extended the CUSTOMSAMPLES array to include cent adjustment values
   - Modified _addSample function to maintain backward compatibility
   - Updated __save function to include cent adjustment in block properties
   - Enhanced _updateBlocks to display cent adjustments in block text (e.g., "C4 +10¢")

2. **Playback Rate Calculation System**
   - Implemented the mathematical formula for converting cents to playback rate
   - Applied consistent calculation throughout the codebase (playbackRate = Math.pow(2, cents/1200))
   - Ensured accurate pitch modification across all sample playback scenarios

3. **Synth Integration**
   - Modified _createSampleSynth function to store cent adjustments with samples
   - Updated trigger function to apply adjustments to playback rate during sample playback
   - Created framework for real-time pitch modification during performance

4. **Instrument Organization and Visualization**
   - Collected SVG icons for each instrument and instrument family
   - Designed a hierarchical structure to better organize the set instruments widget
   - Created a more intuitive categorization system for instrument selection
   - Improved visual navigation through instrument families

---

## Challenges & How I Overcame Them

- **Challenge:** Persisting Cent Adjustment Information  
  **Solution:** In the previous week, I had implemented cent adjustments by modifying the playback rate in real-time, but this information wasn't being stored with the sample. This meant that when a user saved a sample after making cent adjustments, the adjustments were lost, creating inconsistency in musical compositions. I researched two main approaches: storing notes as floating-point MIDI values (e.g., 60.1 for C4+10¢) or storing integer MIDI notes and cent adjustments separately. I chose the second approach for better compatibility with Music Blocks' existing codebase, clearer data representation, and easier UI integration. I'm still testing this implementation to ensure it works correctly across all use cases.

- **Challenge:** Modifying the Sample Data Structure  
  **Solution:** I carefully extended the CUSTOMSAMPLES array to include the cent adjustment value while ensuring backward compatibility. This required precise modifications to several core functions that interact with the sample data structure.

---

## Key Learnings
- Audio Processing Fundamentals: Deepened understanding of how cent adjustments affect pitch perception and the mathematical relationship between cents and playback rate.
- Data Persistence Strategies: Learned different approaches to storing and retrieving fine-grained musical parameters, and the trade-offs between integrated vs. separate storage models
- DOM Manipulation for Audio UI: Gained experience creating responsive audio controls that provide visual feedback while manipulating sound parameters in real-time
- Code Refactoring Best Practices: Developed skills in modifying existing functionality while maintaining backward compatibility, especially in a complex music programming environment
- Tone.js Audio API: Enhanced understanding of Tone.js's Sampler implementation and how to manipulate playback parameters like playback rate for pitch adjustments

---

## Midterm Evaluation Summary (Weeks 01–06)

Over the past six weeks, I've made significant progress on improving Music Blocks' synth and sample features, focusing on enhancing the tuning system and implementing micro-pitch adjustments. I've successfully completed the development of a comprehensive dual-mode tuner system that provides precise pitch feedback and visualization. Additionally, I've implemented a manual cent adjustment feature that allows for microtonality exploration and fine-tuning of samples. These enhancements significantly expand Music Blocks' capabilities for musical education, enabling students to explore pitch relationships beyond standard Western tuning systems and providing educators with powerful tools for teaching advanced musical concepts.

### Technical Achievements

1. **Audio Foundation Improvements**
   - Updated Tone.js library from version 15.0.4 to 15.1.22
   - Integrated YIN algorithm for accurate pitch detection
   - Implemented low-pass filtering to handle high-frequency noise
   - Enhanced pitch detection accuracy using parabolic interpolation

2. **Tuner System Development**
   - Created comprehensive dual-mode tuner interface:
     - Chromatic mode that automatically finds closest pitch
     - Target pitch mode with fixed reference point
   - Implemented 11-segment visualization system with center-outward lighting
   - Added clear visual feedback for cent deviation
   - Designed mode-specific icons and toggle interface

3. **Cent Adjustment System**
   - Evolved from initial pie menu design to more efficient slider interface
   - Implemented ±50 cents range adjustment capability
   - Created framework for real-time pitch modification
   - Developed system to store and apply cent adjustments to samples
   - Extended data structures to maintain cent adjustment information

4. **Integration and Testing**
   - Conducted extensive testing with various audio sources
   - Created test suite for tuner accuracy verification
   - Optimized signal processing for better performance
   - Ensured backward compatibility throughout implementation

### Educational and Creative Impact

These improvements significantly enhance Music Blocks' capabilities for musical education and exploration:

- **Microtonality Access**: Students can now explore pitches between standard Western notes, opening doors to world music traditions and experimental composition
- **Improved Accuracy**: The enhanced tuner provides precise feedback for instrument tuning and vocal training
- **Educational Value**: Visual feedback systems help students understand pitch relationships and develop better ear training
- **Creative Possibilities**: Cent adjustments enable more expressive performances and composition with subtle pitch variations

### Final Thoughts

The first half of this project has established a solid foundation for Music Blocks' enhanced audio capabilities. The dual-mode tuner and cent adjustment systems provide both technical accuracy and user-friendly interfaces for students and educators. These features have significantly expanded Music Blocks' capacity for musical exploration beyond standard Western tuning. Moving forward, I'll focus on sample organization and multiple sample functionality to further enhance the expressiveness and educational value of the platform.

---

## Next Week's Roadmap
- Implement the basic categorization system for samples
- Process free/open samples from identified sources
- Work on handling multiple samples
- Test the manual cent adjustment feature and finalise the approach
- Write Week 07 blog post summarizing progress and learnings

---

## Resources & References
- **Audio Processing:** [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- **Cent Calculation:** [Cents to Frequency Ratio Calculator](https://www.sengpielaudio.com/calculator-centsratio.htm)
- **Musical Tuning:** [Musical Acoustics - Cents and Frequency Ratios](https://newt.phys.unsw.edu.au/jw/notes.html)
- **Tone.js Documentation:** [Tone.js Sampler](https://tonejs.github.io/docs/14.7.77/Sampler)
- **Audio Sample Processing:** [Microtonality in Digital Audio Workstations](https://www.researchgate.net/publication/327567188_Microtonality_and_the_DAW_A_Design_Study)

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

--- `,dd=Object.freeze(Object.defineProperty({__proto__:null,default:eo},Symbol.toStringTag,{value:"Module"})),no=`---
title: "DMP '25 Week 07 Update by Anvita Prasad"
excerpt: "Improve Synth and Sample Feature for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-20"
slug: "2025-07-20-DMP-25-AnvitaPrasad-week07"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week07,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 07 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-14 - 2025-07-20  

---

## Goals for This Week
- **Goal 1:** Research and document comprehensive sampling strategy for instruments
- **Goal 2:** Begin sample collection and quality assessment process
- **Goal 3:** Begin implementing multiple sample functionality starting with piano
- **Goal 4:** Create draft PR for tuner implementation

---

## This Week's Achievements

1. **Comprehensive Sampling Strategy Research**
   - Conducted in-depth analysis of acoustic properties and sampling requirements:
     
     **Piano - Multiple Register Sampling**
     - Analyzed acoustic reality across registers:
       - Low notes (C2-C3): Thick steel strings with copper winding, large felt hammers
       - Middle notes (C4-C5): Plain steel strings, medium hammers
       - High notes (C6-C7): Thin steel strings, small light hammers
     - Documented why transposition fails:
       - Upward transposition (e.g., C2 → C4) creates thin, metallic sound
       - Downward transposition (e.g., C6 → C4) results in muddy, artificial sound
     - Recommended sampling structure:
       \`\`\`javascript
       "piano": {
           "C2": { "staccato": "...", "legato": "..." },  // Bass register
           "C3": { "staccato": "...", "legato": "..." },  // Lower middle
           "C4": { "staccato": "...", "legato": "..." },  // Middle C
           "C5": { "staccato": "...", "legato": "..." },  // Upper middle
           "C6": { "staccato": "...", "legato": "..." }   // Treble register
       }
       // 10 samples total
       \`\`\`

     **Flute - Register-Based Approach**
     - Mapped register characteristics:
       - Low (C4-F4): Breathy, weak tone
       - Middle (G4-C6): Clear, characteristic sound
       - High (D6-C7): Bright, piercing quality
     - Different embouchure techniques affect overtone series
     - Recommended sampling structure:
       \`\`\`javascript
       "flute": {
           "low": { "D4": { "staccato": "...", "legato": "..." } },    // Breathy
           "middle": { "G4": { "staccato": "...", "legato": "..." } }, // Clear
           "high": { "C6": { "staccato": "...", "legato": "..." } }    // Bright
       }
       // 6 samples total
       \`\`\`

     **Violin - String-Specific Sampling**
     - Analyzed individual string characteristics:
       - G string (G3): Warm, rich, slightly nasal
       - D string (D4): Balanced, clear tone
       - A string (A4): Bright, focused sound
       - E string (E5): Brilliant, potentially harsh
     - Documented playing techniques (arco/pizzicato)
     - Note: Articulations (staccato/legato) can be simulated within each technique
     - Recommended sampling structure:
       \`\`\`javascript
       "violin": {
           "G_string": { "G3": { "arco": "...", "pizzicato": "..." } },
           "D_string": { "D4": { "arco": "...", "pizzicato": "..." } },
           "A_string": { "A4": { "arco": "...", "pizzicato": "..." } },
           "E_string": { "E5": { "arco": "...", "pizzicato": "..." } }
       }
       // 8 samples total
       \`\`\`

     **Trumpet - Harmonic Series Based**
     - Leverages natural harmonic series principles
     - Consistent timbre across range due to uniform bore
     - Natural acoustics support pitch shifting
     - Recommended sampling structure:
       \`\`\`javascript
       "trumpet": {
           "Bb3": { "open": "...", "muted": "..." },
           "Bb4": { "open": "...", "muted": "..." }
       }
       // 4 samples total
       \`\`\`

     **Drums - Individual Sampling**
     - Each drum requires individual sampling
     - No transposition possible due to fixed acoustic properties
     - Separate samples needed for different playing techniques
     - Recommended sampling structure:
       \`\`\`javascript
       "drums": {
           "kick": { "hit": "kick.wav" },
           "snare": { "hit": "snare.wav", "rim": "rim.wav" },
           "hihat": { "closed": "hihat_closed.wav", "open": "hihat_open.wav" }
       }
       // Each drum needs individual samples
       \`\`\`

   Detailed specifications and complete analysis available in the [Comprehensive Sampling Strategy Document](https://docs.google.com/document/d/1VoRCEq9SgVe22Q5nvP-9_-R-R3cKR7hfvBHKa3VBFM8/edit?usp=sharing).

2. **Sample Collection Progress**
   - Started collecting samples for all instrument categories
   - Established quality criteria for sample selection
   - Set up framework for sample organization and naming conventions
   - Created systematic approach for sample categorization

3. **Implementation Initiation**
   - Began implementation with piano as proof of concept
   - Designed data structure for multiple sample storage
   - Started developing sample loading and management system
   - Created framework for handling different articulations

4. **Tuner Implementation Progress**
   - Created draft PR for tuner and manual cent adjustment features
   - Resolved UI alignment issues in maximized window state
   - PR: [#4725](https://github.com/sugarlabs/musicblocks/pull/4725)

---

## Challenges & How I Overcame Them

- **Challenge:** Post-Rebase Integration Issues  
  **Solution:** After rebasing with upstream/master, the toolbar search completely stopped working. I traced the root cause to disrupted jQuery script loading order during conflict resolution. Fixed the issue by restoring the correct script dependency order in index.html:
  \`\`\`html
  <script src="lib/jquery-2.1.4.min.js"><\/script>
  <script src="lib/jquery-ui.js" defer><\/script>
  \`\`\`
  This experience highlighted the importance of carefully reviewing dependency relationships during rebase operations.

- **Challenge:** Sample Collection and Quality Management  
  **Solution:** Faced significant challenges in finding high-quality samples with consistent recording techniques, especially for specialized articulations like staccato piano notes. I developed a systematic approach by:
  1. Creating clear criteria for sample selection
  2. Documenting required articulations per instrument
  3. Establishing minimum recording quality standards
  4. Setting up a consistent naming and organization system

---

## Key Learnings
- Sample Management Strategy: Learned to analyze instrument-specific sampling requirements based on acoustic properties
- Progressive Loading: Learned about strategies to optimize memory usage by loading samples only for instruments currently in use, which will be crucial for performance optimization

---

## Next Week's Roadmap
- Continue implementing multiple sample functionality
- Search, collect, and clean up samples for different instruments
- Test and refine implementation
- Write Week 08 blog post summarizing progress and learnings

---

## Resources & References
- **Documentation:** [Comprehensive Sampling Strategy Document](https://docs.google.com/document/d/1VoRCEq9SgVe22Q5nvP-9_-R-R3cKR7hfvBHKa3VBFM8/edit?usp=sharing)
- **Pull Request:** [Implemented tuner and manual cent adjustment in sampler widget](https://github.com/sugarlabs/musicblocks/pull/4725)
- **Sample Sources:**
  - [MTG Freesound Collection](https://freesound.org/people/MTG/)
  - [Freesound Harmonium Samples](https://freesound.org/search/?q=harmonium)
  - [Freesound Percussion Collection](https://freesound.org/search/?q=cowbell)
  - [Sonic Pi Sample Repository](https://github.com/sonic-pi-net/sonic-pi/tree/dev/etc/samples/perc)
  - [Philharmonia Orchestra Sound Samples](https://philharmonia.co.uk/resources/sound-samples/)
- **Audio Processing:** [Web Audio API Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- **Performance:** [Progressive Loading Techniques for Audio Applications](https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps/Loading)

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

--- `,cd=Object.freeze(Object.defineProperty({__proto__:null,default:no},Symbol.toStringTag,{value:"Module"})),to=`---
title: "DMP '25 Week 08 Update by Anvita Prasad"
excerpt: "Improve Synth and Sample Feature for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-07-27"
slug: "2025-07-27-DMP-25-AnvitaPrasad-week08"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week08,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 08 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-21 - 2025-07-27  

---

## Goals for This Week
- **Goal 1:** Design and implement multi-sample piano system with register-based sampling
- **Goal 2:** Develop intelligent sample selection logic based on MIDI note ranges
- **Goal 3:** Create comprehensive testing framework to validate multi-sample functionality

---

## This Week's Achievements

1. **Multi-Sample Piano System Implementation**
   - Created comprehensive piano_multi.js file with C1-C8 sample placeholders
   - Successfully integrated multi-sample system into Music Blocks' audio synthesis
   - Implemented intelligent sample selection covering full piano range

2. **Core System Architecture Development**
   - Enhanced synthutils.js with MULTIPITCH configuration for piano registers
   - Modified createSampleSynth method to handle multi-sample instruments
   - Updated samplesManifest and SOUNDSAMPLESDEFINES for seamless integration

3. **Intelligent Sample Selection Logic**
   - Implemented MIDI note range boundaries for optimal sample selection
   - C1 sample covers notes up to B1 (MIDI 0-35)
   - C2 sample covers notes up to B2 (MIDI 36-47)
   - C3 sample covers notes up to B3 (MIDI 48-59)
   - And so on up to C8 for highest octave

4. **Testing and Validation Framework**
   - Developed verifyPianoMultiSamples() function for sample integrity validation
   - Created piano-multi-direct-test.js for comprehensive console testing
   - Built multiple HTML test files for different testing scenarios

---

## Challenges & How I Overcame Them

- **Challenge:** Ensuring proper sample loading and preventing crashes during multi-sample initialization  
  **Solution:** Implemented robust error checking and added comprehensive logging to track sample loading process

- **Challenge:** Implementing precise MIDI note range calculations for optimal sample selection  
  **Solution:** Developed systematic boundary logic with extensive testing to verify correct sample mapping

- **Challenge:** Finding high-quality audio samples for different articulations 
  **Solution:** Still actively searching for better solutions to ensure consistent sound quality across all samples

---

## Key Learnings
- Gained deep understanding of Tone.js Sampler implementation for multi-sample instruments
- Discovered importance of proper sample format consistency across different instrument types
- Enhanced knowledge of MIDI note range calculations and their impact on audio quality

---

## Next Week's Roadmap
- Extend multi-sample system to additional instruments (violin, cello, etc.)
- Implement advanced sample selection algorithms for better timbre matching
- Develop user interface for sample management and customization
- Write Week 09 blog post summarizing progress and learnings

---

## Resources & References
- **Pull Request:** [Initial multi-sample implementation](https://github.com/sugarlabs/musicblocks/pull/4738)
- **Audio Synthesis:** [Tone.js Sampler Documentation](https://tonejs.github.io/docs/14.7.77/Sampler)
- **MIDI Standards:** [MIDI Note Numbers and Frequencies](https://www.midi.org/specifications-old/item/table-1-summary-of-midi-message)
- **Sample Management:** Referenced existing Music Blocks sample handling patterns for consistency

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

---
`,ud=Object.freeze(Object.defineProperty({__proto__:null,default:to},Symbol.toStringTag,{value:"Module"})),ao=`---
title: "DMP '25 Week 09 Update by Anvita Prasad"
excerpt: "Improve Synth and Sample Feature for Music Blocks"
category: "DEVELOPER NEWS"
date: "2025-08-03"
slug: "2025-08-03-DMP-25-AnvitaPrasad-week09"
author: "@/constants/MarkdownFiles/authors/anvita-prasad.md"
tags: "dmp25,sugarlabs,week09,AnvitaPrasad"
image: "assets/Images/c4gt_DMP.webp"
---

<!-- markdownlint-disable -->

# Week 09 Progress Report by Anvita Prasad

**Project:** [Music Blocks - Improve Synth and Sample Features](https://github.com/sugarlabs/musicblocks/issues/4539)  
**Mentors:** [Walter Bender](https://github.com/walterbender)  
**Assisting Mentors:** [Devin Ulibarri](https://github.com/pikurasa)  
**Reporting Period:** 2025-07-28 - 2025-08-03  

---

## Goals for This Week
- **Goal 1:** Extend multi-sample system to violin with string-based sampling strategy
- **Goal 2:** Implement codebase restructuring and proper Git workflow management
- **Goal 3:** Create comprehensive testing framework for violin multi-sample system

---

## This Week's Achievements

1. **Violin Multi-Sample System Implementation**
   - Created violin_multi.js with 6 key violin samples (G3, D4, A4, E5, A5, E6)
   - Implemented string-based sampling strategy optimized for violin timbre characteristics
   - Successfully integrated violin multi-sample into existing system architecture

2. **Codebase Organization and Git Workflow**
   - Created dedicated multi-sample-feature branch to separate work from tuner widget development
   - Successfully resolved merge conflicts when integrating with latest master branch

3. **Enhanced Testing Framework Development**
   - Built violin-multi-direct-test.js for comprehensive violin sample validation
   - Enhanced sample verification system to handle different sample types
   - Implemented thorough boundary testing for smooth transitions between samples

4. **Technical Architecture Improvements**
   - Ensured consistent sample file syntax across piano and violin implementations
   - Fine-tuned MIDI note range boundaries for violin-specific timbre characteristics
   - Implemented robust error handling and comprehensive logging capabilities

---

## Challenges & How I Overcame Them

- **Challenge:** Implementing violin-specific sample selection logic while maintaining system consistency  
  **Solution:** Adapted piano's octave-based approach to violin's string-based strategy with optimized MIDI boundaries

- **Challenge:** Finding high-quality violin samples for different articulations 
 - **Challenge:** Finding high-quality violin samples for different articulations  
  **Solution:** Still continuing to search for better solutions to ensure consistent sound quality across all violin samples

- **Challenge:** Resolving complex merge conflicts when integrating multi-sample code with master branch  
  **Solution:** Manually resolved conflicts by carefully selecting appropriate changes and maintaining code integrity

---

## Key Learnings
- Enhanced understanding of string instrument timbre characteristics and optimal sampling strategies

---

## Next Week's Roadmap
- Implement multi-sample system for additional string instruments (double bass, cello)
- Develop advanced articulation detection and sample selection algorithms
- Optimize performance and memory usage for large multi-sample libraries
- Write Week 10 blog post summarizing progress and learnings

---

## Resources & References
- **Pull Request:** [Initial multi-sample implementation](https://github.com/sugarlabs/musicblocks/pull/4738)
- **String Instrument Acoustics:** [Violin String Characteristics and Timbre](https://www.violinist.com/blog/laurie/20145/28087/)

---

## Acknowledgments
Thank you to my mentors, the Sugar Labs community, and fellow contributors for ongoing support.

---
`,hd=Object.freeze(Object.defineProperty({__proto__:null,default:ao},Symbol.toStringTag,{value:"Module"})),oo=`---
title: Culture and Pedagogy
slug: culture
author: Sugar Labs Team
lastUpdated: 2025-03-07
category: Education
---
<!-- markdownlint-disable -->

## What makes Sugar different?  
It would be nice to define what we are talking about when we say "Sugar," since we have multiple platforms. For example, is this page dedicated to Sugar as a desktop environment, or do we want to make this broader to include web apps, Sugarizer, etc.?  

- **Sugar facilitates sharing and collaboration**: children can write articles, share books, or make music together with a single mouse click.  
- **Activities, not applications**: Sugar activities are applicable beyond the scope of the classroom and even Sugar itself.  
- **Automatic backup of Activity work**: No worrying about files or folders. Sugar’s Journal makes it almost impossible to lose any data.  
- **The Journal records everything you do**: It is a place to reflect upon and evaluate your work.  
- **Sugar runs on most computer hardware**, including slower machines.  
- **Sugar is Free (Libre) Software**: It is written in Python and easily customized.  
- **Sugar is documented by its users**: It is easy to use, and teachers worldwide have created a wealth of pedagogical materials for it.  
- **Sugar is written by its users**: 50% of the updates to our latest release came directly from our users.  
  - It would be nice to have a link here, for reference.  

## What are the benefits of using Sugar?  
- **Hundreds of tools for discovery**: Exploring, expressing, and sharing through online research, writing, coding, and more.  
- **Built-in collaboration system**: Peer-to-peer learning; always-on support; and single-click sharing.  
  - What is "always-on support"?  
- **A built-in portfolio assessment tool** called Journal that serves as a forum for discussion between children, parents, and teachers.  
- **A discoverable learning platform**: It uses simple means to reach complex ends.  
  - What do we mean by "discoverable"? That we can use the platform to discover ideas?  
- **Designed for local appropriation**: Sugar has built-in tools for making changes and improvements and a growing global community of support.  
  - Twenty-five languages are currently available.  
- **An emphasis on learning through doing and debugging**: Engages learners better to tackle authentic problems.  
- **Available in a wide variety of forms**: As part of GNU/Linux distributions, as well as LiveCD, LiveUSB, and in a virtual machine for Windows and Mac machines.  

## What are the Sugar advantages?  
- **Pedagogical framework** centered around Constructionism learning and founded on student empowerment.  
- **Collaboration and journaling features**, uniquely designed by educators for educators and learners.  
- **Hundreds of activities**.  
- **Large and committed community** of developers, teachers, and learners from all around the globe.  
  - Perhaps it would be nice to have numbers here, if possible.  
- **24/7 community support**.  
  - What do we mean by this? That we are available by Matrix/IRC?  
- **Online and in-person training and workshops available**.  
- **Handouts available to use in the classroom**.  
- **Teacher-driven development**, rapidly expanding every day.  
- **Easily localizable and customizable**.  
- **Free/Libre software**: No licensing fees.  
- **A global project**: No single point of dependency or failure.  

## A *learning-centric* approach  
At Sugar Labs, we strive for a *learning-centric* approach, where teachers mentor students as they engage with powerful ideas, or *instructing less and learning more*.  

At Sugar Labs, we give children access to *knowledge*—through media such as electronic books, the world-wide web, and multimedia—but, more importantly, we give them the tools they need to *create*, to learn about learning, to put knowledge to use, and engage in reflection and critical dialogue.  

With Sugar, we help learners *acquire knowledge* so that they grow as active consumers, critics, and *creators of knowledge*; Sugar welcomes them as members of a vibrant learning community.  

Plus, cross-community collaboration between technologists and teachers ensures that the ideals of student empowerment, freedom, sharing, open critique, and transparency will remain an integral part of Sugar—one that touches the lives of children and their communities all across the world’s classrooms.  

## The Free (Libre) Software culture  
The Sugar pedagogy is embodied in the culture of Free/Libre Software; teachers and students are empowered with both the freedom to actively participate and the freedom to be critical.  

Criticism of ideas is a powerful force in learning, as well as in fostering economic development; unleashing this potential is an important part of our mission.
`,gd=Object.freeze(Object.defineProperty({__proto__:null,default:oo},Symbol.toStringTag,{value:"Module"})),io=`---
title: 'Markdown Test Page'
slug: 'markdown-test'
category: 'MarkdownData'
---
<!-- markdownlint-disable -->
# The Ultimate Markdown Test Document (NOTE: THIS IS AI GENERATED)

## Basic Formatting

This text is **bold** and this is *italic*. You can also have ~~strikethrough text~~ and ==highlighted text== for emphasis.

You can add super^script^ and sub~script~ text when needed.

## Links and Code

Visit [our website](https://example.com) for more information.

Here's some \`inline code\` within a paragraph for demonstration.

### Code Block Example

Below is an example of a JavaScript function:

\`\`\`javascript
// Returns a greeting for the provided name

function greet(name) {

    return \`Hello, \${name}!\`;

}

console.log(greet("Markdown"));
\`\`\`

## Lists

### Unordered Lists

- First item
- Second item
- Third item

### Ordered Lists

1. First ordered item
2. Second ordered item
3. Third ordered item

### Task Lists

- [ ] Uncompleted task
- [x] Completed task
- [ ] Another pending task

## Tables

| Feature        | Supported | Notes                               |
|----------------|-----------|-------------------------------------|
| Headers        | ✅        | With anchor links                   |
| Bold/Italic    | ✅        | Basic formatting                    |
| Code Blocks    | ✅        | With language support               |
| Tables         | ✅        | Responsive design                   |
| Lists          | ✅        | Unordered, ordered, task lists      |

## Blockquotes with Proper Nesting

> This is a simple blockquote.

> This is a multi-line blockquote that continues on the next line.
> This is a multi-line blockquote that continues on the next line.

## Images with Captions

![A beautiful landscape](https://images.unsplash.com/photo-1506744038136-46273834b3fb?w=600 "Beautiful mountain landscape")

## Horizontal Rules

Above this text is regular content.

----

Below is separated by a horizontal rule.

## Special Features

### Collapsible Sections

:::details Click to see hidden content
This content is hidden by default until the user clicks the summary.

Here you can write additional **markdown content**, include lists, or even code.
Enjoy the hidden content!
:::

### YouTube Embed

[youtube: MM-H69cHYMk]

### Emoji Support

:smile: I'm happy to see this working!  
:rocket: Let's launch this feature!  
:warning: Be careful with this syntax.  
:thumbsup: Looks good to me!  
:heart: Love this feature!  
:fire: This is awesome!  
:star: Five-star quality!  
:info: Here's some information.  
:check: This is correct!  
:x: This is wrong.

## Combined Examples

> This blockquote contains **bold text** and a [link](https://example.com) to example.com.

- List item with **bold** and *italic* text.
- Item with a [link](https://example.com) and \`inline code\`.
- Item with ==highlighted text== that stands out.

## Advanced Typography Test

Water is H~2~O and an ordinal number like 5^th^ is very common.

This paragraph includes ~~strikethrough text~~ and ==highlighted text== to denote important information.

## Paragraphs with Line Breaks

This is a paragraph with  
line breaks that are preserved as spaces within the paragraph.

This is another paragraph  
after a blank line.

### Final Thoughts

This Markdown file has been designed to demonstrate multiple aspects of our custom Markdown parser. Every section shows different capabilities from formatting to embedded media.

Thank you for reading this detailed Markdown test document! :heart:`,md=Object.freeze(Object.defineProperty({__proto__:null,default:io},Symbol.toStringTag,{value:"Module"})),so=`---
title: Sugar Labs For Parents
slug: parents
author: Sugar Labs Team
lastUpdated: 2025-03-07
category: Education
---
<!-- markdownlint-disable -->

## Background  
The Sugar Learning Platform (Sugar) was first developed as the software platform for the One Laptop per Child (OLPC) program, a spin-off project from the MIT Media Lab in 2006.  

The founders of OLPC, Nicholas Negroponte, Seymour Papert, and Walter Bender, promoted the idea that learning is not a luxury and that a lack of an educated society is not just an inconvenience. Learning is fundamental to a free society that aspires to be both prosperous and sustainable. All societies value the role that education plays in economic development, and education is essential to the survival of democratic societies.  

Seymour Papert and Cynthia Solomon, co-inventors of the Logo programming language (along with Wally Feurzeig), described their pioneering efforts to use the Logo language as a vehicle for introducing children to computational thinking. They defined it in terms of heuristics: things to think with and reflect upon.  

In 1971, Papert and Solomon published *“20 Things to do with a Computer”*, a catalog of project ideas ranging from robotics to music to visual arts. This work foreshadowed what today is often referred to as the *Maker Movement*. Almost 50 years ago, children were using Logo as a tool for the autonomous construction of meaningful artifacts and pursuing mastery in solving personally meaningful problems.  

---

## Sugar Pedagogy  
> **“Learning is hard fun.”** – Marvin Minsky  
> **“A six-year-old child can become an expert.”** – Marvin Minsky  

In a 2008 essay questioning “general” education, Marvin Minsky proposed that we *“re-aim our schools towards encouraging children to pursue more focused hobbies and specialties—to provide them with more time for (and earlier experience with) developing more powerful sets of mental skills, which they later can extend to more academic activities.”*  

Minsky encourages children to construct multi-level *cognitive towers*, built upon:  
- Instinctive reactions  
- Learned reactions  
- Deliberate thinking  
- Reflective thinking  
- Self-reflective thinking  
- Self-conscious reflection  

These levels span agencies specializing in areas such as gaining knowledge from experience, planning and causal attribution, the construction of models, and identifying values and ideals.  

A focus on achieving meaningful goals—not just the accumulation of simple knowledge objects—exercises all levels in a cognitive tower, helping children *develop proficiencies that can be used in other domains*. As a model for learning, the levels within Minsky’s cognitive towers represent broadly applicable skills.  

Minsky’s towers are inherently complex and require a learner to be motivated and persistent in their construction—a process he once described as *"hard fun."*  

This aligns with research by Daniel Pink, who reviewed four decades of studies showing that motivation for learning comes from:  
1. **Autonomy** – the freedom to explore and express ideas  
2. **Mastery** – confidence and space to develop expertise  
3. **Purpose** – authentic problem-solving opportunities  

A key insight of Minsky, Papert, and Solomon is to give children tools they can explore, master, and apply to problems they care about. Children using Sugar are **motivated learners**, pursuing meaningful goals that help them build their own “cognitive towers.”`,pd=Object.freeze(Object.defineProperty({__proto__:null,default:so},Symbol.toStringTag,{value:"Module"})),ro=`---
title: Sugar Labs For School Administrators
slug: school-admin
author: Sugar Labs Team
lastUpdated: 2025-03-07
category: Education
---
<!-- markdownlint-disable -->

## Student and teacher agency

Sugar provides the user with affordances (things we designed for the possibility of taking action by the user) and pathways to engage in developing skills. Sugar is not instructional curricula in part because curricula tend to reflect very local norms and needs, and as a consequence, are resistant to global solutions. 

Also, Sugar reflects an explicit rejection of instruction as a pedagogical framework. With Sugar, we try to give agency to the learner, knowing that in all likelihood, the institution of school would likely be trying to take away agency. At each design decision point, we asked ourselves:  
- *How will this impact the learning?*  
- *How will this impact the autonomy and agency of the learner and the teacher?*

Agency is made possible in part because of the choice of a software license, the **General Public License (GPL)**, which ensures that the learner has permission to both use Sugar and to modify it. 

We go a step further by giving the learner affordances to engage in software development and debugging, i.e., to exploit the license. We provide a context for encouraging the learner to take initiative, both by deliberately leaving the platform “incomplete” and by providing a social norm in which it is expected to take initiative. Even if it were possible to make Sugar “complete”, we would have chosen not to. We wanted there always to be “itches” needing to be scratched.  

In a related design decision, Sugar was never intended to be an endpoint in and of itself. Rather, we envisioned it as a waypoint along a lifelong journey of learning. We encourage our users to outgrow Sugar and even provide them with a means of advancing from the Sugar desktop, with its tools for exploration, to the **GNOME desktop**, with its more powerful tools for production.

---

## What using Sugar can do for your students and school?

The **Sugar Learning Platform** was designed to promote collaborative learning through tools and activities that encourage critical thinking. Sugar puts an emphasis on divergent thinking. A related goal is to make that thinking visible to the learner. 

Sugar equally promotes cultures of **expression and reflection**. With Sugar, we provide teachers and learners with a collection of open-ended tools and activities, applicable to problems of their own choosing.

### Sugar offers an alternative to traditional “office-desktop” software based on three affordances:

1. **Sharing:**  
   Collaboration is a first-order experience. The interface always shows the presence of other learners who are available for collaboration. Sugar allows users to dialog, support, critique, and share ideas with each other.

2. **Reflecting:**  
   A "journal" records each learner’s activity. It is a built-in space for reflection and assessment of progress.

3. **Discovering:**  
   Sugar tries to accommodate a wide variety of users with different levels of skill in terms of reading and language and different levels of experience with computing by providing activities with a "low floor" and, where possible, "no ceiling."

> **“The only time collaboration is called cheating is when you are in school.” – Walter Bender**

Sugar drew inspiration for its activities and the fluid interface between activities from observing how the **free software community** collaborates. Software developers chat, socialize, play games, share media, and collaborate on media creation and programming in both formal and informal settings.

Sugar users are given access to a variety of commonly used tools for collaboration, e.g., **Chat and IRC**. By default, the IRC application opens into the \`#sugar\` channel on \`irc.freenode.net\`, where Sugar developers discuss their work.

---

## Reflection and assessment in the context of Sugar and interoperability with school administrative systems

In the early days of the development of the Sugar user interface, one of the biggest points of contention with the OLPC advisory board was when we told them that we were not going to use **file browsing** as the primary mode of navigation. We were asked,  
*"How will the children learn to use Windows?"*  
Our response was, *"Why do they need to learn to use Windows?"*  

Instead of browsing a filesystem, Sugar gives the user a **journal or notebook** into which one’s work is “kept” rather than “saved.” The interface tries to keep things that offer value automatically in the Sugar journal.

The primary function of the journal is as a **time-based view** of the activities of a learner. As with physical media, such as pen on paper, no explicit "saving" step is needed. The individual journal entries are treated much like pages in a **laboratory notebook**.

### Assessment in Sugar:
- **Digital Portfolio:**  
  Sugar journal entries are directly incorporated into **digital portfolios** to support reflection that can help students (as well as teachers and parents) be aware of their own learning.
- **Impact Measurement:**  
  Sugar acknowledges the need for **measurement and evaluation**. Sugar does not take a position on high-stake testing but advocates for an evaluation that looks more broadly than standardized tests.
- **Custom Metadata for Journal Entries:**  
  Teachers can know what tools a student may have used and how many iterations they made in creating an artifact.

---

## Where to get resources?

For more information, visit the **official Sugar Labs website** and explore its resources on **collaborative learning, development tools, and community support**.`,bd=Object.freeze(Object.defineProperty({__proto__:null,default:ro},Symbol.toStringTag,{value:"Module"})),lo=`---
title: Student Learning Goals and Sugar
slug: students
author: Sugar Labs Team
lastUpdated: 2025-03-07
category: Education
---
<!-- markdownlint-disable -->

## Student Learning Goals and Sugar

> *"Learning with Sugar is something a child does, not something that is done to or for a child." – Walter Bender*

Sugar is a collection of hundreds of tools designed to introduce children to programming, computational thinking, and problem-solving. Sugar has no set curriculum; its best practice is to immerse children in problem-solving and debugging. Children are given agency to work on problems they are passionate about in a context where there is an expectation that there were no predetermined solutions or prescribed paths to a solution. 

As Solomon observed, *“debugging is the greatest learning opportunity of the 21st century.”* While engaged in problem-solving, children are developing and refining the algorithms employed by the agents in the various levels of their cognitive towers.

While computation and coding are at the heart of Sugar, Sugar is not a programming curriculum: computational thinking goes well beyond the realm of learning to code. While the specific algorithms they discuss—searching, sorting, optimal stopping, predicting, etc.—are useful in and of themselves, the real power of computational thinking lies in its systematic approach to debugging and problem-solving. 

Learning that problems can be addressed systematically is the underlying **“powerful idea”** of programming. The process of writing and then repairing or **debugging** a program provides a basis for active learning through trial and error, regardless of what the problem that is actually being solved.

---

## Learning with Pages in the Wiki

These books are recommended as a rich source of ideas on how to use Sugar in and out of the classroom:

- **Sdenka book**
- **Bender, W., Kane, C., Cornish, J., Donahue, N.** (2012). *Learning to Change the World: The Social Impact of One Laptop per Child.* Palgrave Macmillan.
- **Christian, B. and Griffiths, T.** (2016). *Algorithms to Live By: The Computer Science of Human Decisions.* Henry Holt and Co.
- **Hetland, L., Winner, E., Veenema S., and Sheridan, K.M.** (2007). *Studio Thinking: The Real Benefits of Visual Arts Education.* Teachers College Press.
- **Papert, S. & Solomon, C.** (1971). *Twenty Things to Do with a Computer.* *Artificial Intelligence Memo No. 248* and *Logo Memo No. 3.*
- **Pink, D.** (2009). *Drive: The Surprising Truth About What Motivates Us.* Riverhead Press.
- **Stefanakis, E.** (2002). *Multiple Intelligences and Portfolios: A Window into the Learner's Mind.* Greenwood Press.
- **Trinidad, G.** (2013). *Física con XO.*`,fd=Object.freeze(Object.defineProperty({__proto__:null,default:lo},Symbol.toStringTag,{value:"Module"}));export{di as $,Bo as A,Ro as B,Oo as C,zo as D,Fo as E,Uo as F,No as G,Ho as H,qo as I,Ko as J,Vo as K,Jo as L,Xo as M,$o as N,Yo as O,Qo as P,Zo as Q,ei as R,ni as S,ti as T,ai as U,oi as V,ii as W,si as X,ri as Y,li as Z,Mo as _,co as a,ys as a$,ci as a0,ui as a1,hi as a2,gi as a3,mi as a4,pi as a5,bi as a6,fi as a7,wi as a8,yi as a9,Ki as aA,Vi as aB,Ji as aC,Xi as aD,$i as aE,Yi as aF,Qi as aG,Zi as aH,es as aI,ns as aJ,ts as aK,as as aL,os as aM,is as aN,ss as aO,rs as aP,ls as aQ,ds as aR,cs as aS,us as aT,hs as aU,gs as aV,ms as aW,ps as aX,bs as aY,fs as aZ,ws as a_,ki as aa,vi as ab,Si as ac,Ii as ad,Ai as ae,Ti as af,Pi as ag,Mi as ah,Ci as ai,Li as aj,xi as ak,Gi as al,Wi as am,Di as an,_i as ao,Ei as ap,ji as aq,Bi as ar,Ri as as,Oi as at,zi as au,Fi as av,Ui as aw,Ni as ax,Hi as ay,qi as az,uo as b,Lr as b$,ks as b0,vs as b1,Ss as b2,Is as b3,As as b4,Ts as b5,Ps as b6,Ms as b7,Cs as b8,Ls as b9,tr as bA,ar as bB,or as bC,ir as bD,sr as bE,rr as bF,lr as bG,dr as bH,cr as bI,ur as bJ,hr as bK,gr as bL,mr as bM,pr as bN,br as bO,fr as bP,wr as bQ,yr as bR,kr as bS,vr as bT,Sr as bU,Ir as bV,Ar as bW,Tr as bX,Pr as bY,Mr as bZ,Cr as b_,xs as ba,Gs as bb,Ws as bc,Ds as bd,_s as be,Es as bf,js as bg,Bs as bh,Rs as bi,Os as bj,zs as bk,Fs as bl,Us as bm,Ns as bn,Hs as bo,qs as bp,Ks as bq,Vs as br,Js as bs,Xs as bt,$s as bu,Ys as bv,Qs as bw,Zs as bx,er as by,nr as bz,ho as c,Ol as c$,xr as c0,Gr as c1,Wr as c2,Dr as c3,_r as c4,Er as c5,jr as c6,Br as c7,Rr as c8,Or as c9,hl as cA,gl as cB,ml as cC,pl as cD,bl as cE,fl as cF,wl as cG,yl as cH,kl as cI,vl as cJ,Sl as cK,Il as cL,Al as cM,Tl as cN,Pl as cO,Ml as cP,Cl as cQ,Ll as cR,xl as cS,Gl as cT,Wl as cU,Dl as cV,_l as cW,El as cX,jl as cY,Bl as cZ,Rl as c_,zr as ca,Fr as cb,Ur as cc,Nr as cd,Hr as ce,qr as cf,Kr as cg,Vr as ch,Jr as ci,Xr as cj,$r as ck,Yr as cl,Qr as cm,Zr as cn,el as co,nl as cp,tl as cq,al as cr,ol as cs,il as ct,sl as cu,rl as cv,ll as cw,dl as cx,cl as cy,ul as cz,go as d,zl as d0,Fl as d1,Ul as d2,Nl as d3,Hl as d4,ql as d5,Kl as d6,Vl as d7,Jl as d8,Xl as d9,$l as da,Yl as db,Ql as dc,Zl as dd,ed as de,nd as df,td as dg,ad as dh,od as di,id as dj,sd as dk,rd as dl,ld as dm,dd as dn,cd as dp,ud as dq,hd as dr,gd as ds,md as dt,pd as du,bd as dv,fd as dw,mo as e,po as f,bo as g,fo as h,vo as i,wo as j,yo as k,To as l,ko as m,So as n,Io as o,Po as p,Co as q,Lo as r,Ao as s,xo as t,Go as u,Wo as v,Do as w,_o as x,Eo as y,jo as z};
